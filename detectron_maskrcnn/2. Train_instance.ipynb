{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "819d7eed-2014-49cd-a0a7-7c51bd95c70b",
   "metadata": {},
   "source": [
    "Setup directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "451b64c0-1ff2-4837-a94a-5cd0da66ea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlflow\n",
    "# mlflow.autolog(log_models=True)\n",
    "# mlflow.set_tracking_uri('https://mlflow.krschap.tech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17d48cf5-fe65-4827-930b-ec19888d977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define a single working directory\n",
    "WORK_DIR = r\"training_dataset_generated\\training_sets\"\n",
    "\n",
    "# Now use it in all paths\n",
    "IMAGE_DIR_TRAIN = os.path.join(WORK_DIR, \"train_images\")\n",
    "IMAGE_DIR_VAL = os.path.join(WORK_DIR, \"val_images\")\n",
    "ANNOTATIONS_DIR = os.path.join(WORK_DIR, \"annotations\")\n",
    "\n",
    "TRAIN_JSON = os.path.join(ANNOTATIONS_DIR, \"instances_train.json\")\n",
    "VAL_JSON = os.path.join(ANNOTATIONS_DIR, \"instances_val.json\")\n",
    "OUTPUT_DIR = os.path.join(WORK_DIR, \"model\")\n",
    "\n",
    "# Create output dir if not exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b721b4ba-eda2-4ea9-aafe-caa2126c4124",
   "metadata": {},
   "source": [
    "Step 1: Dataset Registration (Detectron2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef7e5729-7ce6-45ad-a6a2-426411a3576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "register_coco_instances(\"solar_train\", {}, TRAIN_JSON, IMAGE_DIR_TRAIN)\n",
    "register_coco_instances(\"solar_val\", {}, VAL_JSON, IMAGE_DIR_VAL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6957ec-2e05-4562-bfd6-cea6929fe3ce",
   "metadata": {},
   "source": [
    " test if the datasets are correctly registered: The image will appear where you can check visually image and masks are properly overlaid or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f57a095d-583b-4fb6-8e5a-677acb83b3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.structures import BoxMode, PolygonMasks\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# ---- CONFIG ----\n",
    "RESIZE_DIM = (256, 256)\n",
    "\n",
    "# ---- Load dataset ----\n",
    "dataset_dicts = DatasetCatalog.get(\"solar_train\")\n",
    "metadata = MetadataCatalog.get(\"solar_train\")\n",
    "\n",
    "# Pick a random sample\n",
    "sample = copy.deepcopy(random.choice(dataset_dicts))\n",
    "img_path = sample[\"file_name\"]\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# Resize image\n",
    "orig_height, orig_width = img.shape[:2]\n",
    "resized_img = cv2.resize(img, RESIZE_DIM)\n",
    "scale_x = RESIZE_DIM[0] / orig_width\n",
    "scale_y = RESIZE_DIM[1] / orig_height\n",
    "\n",
    "# Create blank overlay for masks\n",
    "mask_overlay = np.zeros_like(resized_img)\n",
    "\n",
    "# Draw only masks (skip bbox)\n",
    "for ann in sample[\"annotations\"]:\n",
    "    if \"segmentation\" in ann and isinstance(ann[\"segmentation\"], list):\n",
    "        for seg in ann[\"segmentation\"]:\n",
    "            pts = np.array(seg).reshape(-1, 2)\n",
    "            pts[:, 0] *= scale_x\n",
    "            pts[:, 1] *= scale_y\n",
    "            pts = np.round(pts).astype(np.int32)\n",
    "            cv2.fillPoly(mask_overlay, [pts], color=(0, 0, 255))  # red fill\n",
    "\n",
    "# Blend the mask onto the image\n",
    "alpha = 0.4\n",
    "blended = cv2.addWeighted(resized_img, 1, mask_overlay, alpha, 0)\n",
    "\n",
    "# Show result\n",
    "cv2.imshow(\"Segmentation Only\", blended)\n",
    "cv2.waitKey(10000)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7531e919-fb1b-4423-8bea-1165815fbc88",
   "metadata": {},
   "source": [
    "Step 2: Set Config and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4677078d-ee21-49b2-801f-7d62fdb04aa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2733f066-c51f-48b1-a605-57f2b58fe2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this 1 or 2 for training.\n",
    "#1. applied things to fix small instances of solar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a99e1461-8b7b-4009-965d-2282cb6c9cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/29 18:07:07 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/29 18:07:07 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[07/29 18:07:07 d2.data.datasets.coco]: \u001b[0mLoaded 111 images in COCO format from training_dataset_generated\\training_sets\\annotations\\instances_train.json\n",
      "\u001b[32m[07/29 18:07:07 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 111 images left.\n",
      "\u001b[32m[07/29 18:07:07 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "| PV_bigger  | 174          |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[07/29 18:07:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(512, 768, 1024), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/29 18:07:07 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/29 18:07:07 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/29 18:07:07 d2.data.common]: \u001b[0mSerializing 111 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/29 18:07:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[07/29 18:07:07 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "\u001b[32m[07/29 18:07:07 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/29 18:07:08 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ROG\\.conda\\envs\\detectron_env\\lib\\site-packages\\torch\\functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:4316.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/29 18:07:19 d2.utils.events]: \u001b[0m eta: 0:14:40  iter: 19  total_loss: 1.983  loss_cls: 0.5983  loss_box_reg: 0.4473  loss_mask: 0.6929  loss_rpn_cls: 0.1324  loss_rpn_loc: 0.04682    time: 0.2608  last_time: 0.1768  data_time: 0.2435  last_data_time: 0.0023   lr: 4.9953e-06  max_mem: 2288M\n",
      "\u001b[32m[07/29 18:07:25 d2.utils.events]: \u001b[0m eta: 0:14:24  iter: 39  total_loss: 2.005  loss_cls: 0.525  loss_box_reg: 0.5183  loss_mask: 0.6834  loss_rpn_cls: 0.1607  loss_rpn_loc: 0.05031    time: 0.2544  last_time: 0.2198  data_time: 0.0019  last_data_time: 0.0017   lr: 9.9902e-06  max_mem: 2288M\n",
      "\u001b[32m[07/29 18:07:31 d2.utils.events]: \u001b[0m eta: 0:14:20  iter: 59  total_loss: 1.816  loss_cls: 0.462  loss_box_reg: 0.4345  loss_mask: 0.667  loss_rpn_cls: 0.1085  loss_rpn_loc: 0.039    time: 0.2613  last_time: 0.3121  data_time: 0.0019  last_data_time: 0.0019   lr: 1.4985e-05  max_mem: 2288M\n",
      "\u001b[32m[07/29 18:07:36 d2.utils.events]: \u001b[0m eta: 0:14:18  iter: 79  total_loss: 1.706  loss_cls: 0.3892  loss_box_reg: 0.4651  loss_mask: 0.6439  loss_rpn_cls: 0.04227  loss_rpn_loc: 0.05118    time: 0.2658  last_time: 0.3365  data_time: 0.0020  last_data_time: 0.0018   lr: 1.998e-05  max_mem: 2288M\n",
      "\u001b[32m[07/29 18:07:42 d2.utils.events]: \u001b[0m eta: 0:14:19  iter: 99  total_loss: 1.608  loss_cls: 0.3496  loss_box_reg: 0.503  loss_mask: 0.5998  loss_rpn_cls: 0.02576  loss_rpn_loc: 0.0656    time: 0.2723  last_time: 0.3177  data_time: 0.0018  last_data_time: 0.0016   lr: 2.4975e-05  max_mem: 2288M\n",
      "\u001b[32m[07/29 18:07:47 d2.utils.events]: \u001b[0m eta: 0:14:07  iter: 119  total_loss: 1.73  loss_cls: 0.3335  loss_box_reg: 0.6398  loss_mask: 0.565  loss_rpn_cls: 0.02493  loss_rpn_loc: 0.02652    time: 0.2688  last_time: 0.2351  data_time: 0.0018  last_data_time: 0.0019   lr: 2.997e-05  max_mem: 2288M\n",
      "\u001b[32m[07/29 18:07:53 d2.utils.events]: \u001b[0m eta: 0:14:07  iter: 139  total_loss: 1.685  loss_cls: 0.3088  loss_box_reg: 0.6131  loss_mask: 0.5039  loss_rpn_cls: 0.01736  loss_rpn_loc: 0.06852    time: 0.2739  last_time: 0.3332  data_time: 0.0020  last_data_time: 0.0021   lr: 3.4965e-05  max_mem: 2288M\n",
      "\u001b[32m[07/29 18:07:59 d2.utils.events]: \u001b[0m eta: 0:14:05  iter: 159  total_loss: 1.408  loss_cls: 0.2588  loss_box_reg: 0.5457  loss_mask: 0.449  loss_rpn_cls: 0.01854  loss_rpn_loc: 0.05035    time: 0.2733  last_time: 0.1562  data_time: 0.0019  last_data_time: 0.0021   lr: 3.996e-05  max_mem: 2288M\n",
      "\u001b[32m[07/29 18:08:05 d2.utils.events]: \u001b[0m eta: 0:14:28  iter: 179  total_loss: 1.473  loss_cls: 0.2767  loss_box_reg: 0.6276  loss_mask: 0.366  loss_rpn_cls: 0.02301  loss_rpn_loc: 0.1567    time: 0.2789  last_time: 0.3608  data_time: 0.0019  last_data_time: 0.0018   lr: 4.4955e-05  max_mem: 2288M\n",
      "\u001b[32m[07/29 18:08:11 d2.utils.events]: \u001b[0m eta: 0:14:17  iter: 199  total_loss: 1.252  loss_cls: 0.2385  loss_box_reg: 0.5947  loss_mask: 0.276  loss_rpn_cls: 0.01071  loss_rpn_loc: 0.04088    time: 0.2793  last_time: 0.3475  data_time: 0.0020  last_data_time: 0.0017   lr: 4.995e-05  max_mem: 2289M\n",
      "\u001b[32m[07/29 18:08:17 d2.utils.events]: \u001b[0m eta: 0:14:18  iter: 219  total_loss: 1.504  loss_cls: 0.2595  loss_box_reg: 0.567  loss_mask: 0.262  loss_rpn_cls: 0.02073  loss_rpn_loc: 0.08898    time: 0.2822  last_time: 0.3566  data_time: 0.0019  last_data_time: 0.0014   lr: 5.4945e-05  max_mem: 2289M\n",
      "\u001b[32m[07/29 18:08:23 d2.utils.events]: \u001b[0m eta: 0:14:19  iter: 239  total_loss: 1.18  loss_cls: 0.2273  loss_box_reg: 0.6118  loss_mask: 0.1905  loss_rpn_cls: 0.02  loss_rpn_loc: 0.06818    time: 0.2843  last_time: 0.3553  data_time: 0.0021  last_data_time: 0.0016   lr: 5.994e-05  max_mem: 2289M\n",
      "\u001b[32m[07/29 18:08:29 d2.utils.events]: \u001b[0m eta: 0:14:05  iter: 259  total_loss: 1.207  loss_cls: 0.1941  loss_box_reg: 0.5764  loss_mask: 0.2252  loss_rpn_cls: 0.01096  loss_rpn_loc: 0.03312    time: 0.2833  last_time: 0.3689  data_time: 0.0019  last_data_time: 0.0017   lr: 6.4935e-05  max_mem: 2289M\n",
      "\u001b[32m[07/29 18:08:35 d2.utils.events]: \u001b[0m eta: 0:13:59  iter: 279  total_loss: 1.103  loss_cls: 0.2019  loss_box_reg: 0.6585  loss_mask: 0.172  loss_rpn_cls: 0.01148  loss_rpn_loc: 0.04574    time: 0.2843  last_time: 0.3442  data_time: 0.0018  last_data_time: 0.0016   lr: 6.993e-05  max_mem: 2289M\n",
      "\u001b[32m[07/29 18:08:41 d2.utils.events]: \u001b[0m eta: 0:13:59  iter: 299  total_loss: 1.062  loss_cls: 0.1931  loss_box_reg: 0.5906  loss_mask: 0.2152  loss_rpn_cls: 0.01649  loss_rpn_loc: 0.05593    time: 0.2869  last_time: 0.5320  data_time: 0.0020  last_data_time: 0.0018   lr: 7.4925e-05  max_mem: 2289M\n",
      "\u001b[32m[07/29 18:08:46 d2.engine.hooks]: \u001b[0mOverall training speed: 313 iterations in 0:01:30 (0.2881 s / it)\n",
      "\u001b[32m[07/29 18:08:46 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:31 (0:00:00 on hooks)\n",
      "\u001b[32m[07/29 18:08:46 d2.utils.events]: \u001b[0m eta: 0:13:54  iter: 315  total_loss: 1.014  loss_cls: 0.184  loss_box_reg: 0.574  loss_mask: 0.183  loss_rpn_cls: 0.01455  loss_rpn_loc: 0.07343    time: 0.2875  last_time: 0.3786  data_time: 0.0020  last_data_time: 0.0019   lr: 7.8672e-05  max_mem: 2289M\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m trainer \u001b[38;5;241m=\u001b[39m DefaultTrainer(cfg)\n\u001b[0;32m     55\u001b[0m trainer\u001b[38;5;241m.\u001b[39mresume_or_load(resume\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 56\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\rog\\documents\\termatics\\segmentation\\solar_panel_segmentation\\detectron_maskrcnn\\libraries\\detectron2\\detectron2\\engine\\defaults.py:520\u001b[0m, in \u001b[0;36mDefaultTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    514\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;124;03m    Run training.\u001b[39;00m\n\u001b[0;32m    516\u001b[0m \n\u001b[0;32m    517\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;124;03m        OrderedDict of results, if evaluation is enabled. Otherwise None.\u001b[39;00m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 520\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mTEST\u001b[38;5;241m.\u001b[39mEXPECTED_RESULTS) \u001b[38;5;129;01mand\u001b[39;00m comm\u001b[38;5;241m.\u001b[39mis_main_process():\n\u001b[0;32m    522\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[0;32m    523\u001b[0m             \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_last_eval_results\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    524\u001b[0m         ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo evaluation results obtained during training!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\users\\rog\\documents\\termatics\\segmentation\\solar_panel_segmentation\\detectron_maskrcnn\\libraries\\detectron2\\detectron2\\engine\\train_loop.py:155\u001b[0m, in \u001b[0;36mTrainerBase.train\u001b[1;34m(self, start_iter, max_iter)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_iter, max_iter):\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbefore_step()\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter_step()\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# self.iter == max_iter can be used by `after_train` to\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# tell whether the training successfully finished or failed\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# due to exceptions.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\rog\\documents\\termatics\\segmentation\\solar_panel_segmentation\\detectron_maskrcnn\\libraries\\detectron2\\detectron2\\engine\\defaults.py:530\u001b[0m, in \u001b[0;36mDefaultTrainer.run_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_step\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39miter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter\n\u001b[1;32m--> 530\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\rog\\documents\\termatics\\segmentation\\solar_panel_segmentation\\detectron_maskrcnn\\libraries\\detectron2\\detectron2\\engine\\train_loop.py:310\u001b[0m, in \u001b[0;36mSimpleTrainer.run_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    307\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;124;03mIf you want to do something with the losses, you can wrap the model.\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loss_dict, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    312\u001b[0m     losses \u001b[38;5;241m=\u001b[39m loss_dict\n",
      "File \u001b[1;32m~\\.conda\\envs\\detectron_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\detectron_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\users\\rog\\documents\\termatics\\segmentation\\solar_panel_segmentation\\detectron_maskrcnn\\libraries\\detectron2\\detectron2\\modeling\\meta_arch\\rcnn.py:167\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[1;34m(self, batched_inputs)\u001b[0m\n\u001b[0;32m    164\u001b[0m     proposals \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproposals\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m batched_inputs]\n\u001b[0;32m    165\u001b[0m     proposal_losses \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 167\u001b[0m _, detector_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroi_heads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproposals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_instances\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvis_period \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    169\u001b[0m     storage \u001b[38;5;241m=\u001b[39m get_event_storage()\n",
      "File \u001b[1;32m~\\.conda\\envs\\detectron_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\detectron_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\users\\rog\\documents\\termatics\\segmentation\\solar_panel_segmentation\\detectron_maskrcnn\\libraries\\detectron2\\detectron2\\modeling\\roi_heads\\roi_heads.py:743\u001b[0m, in \u001b[0;36mStandardROIHeads.forward\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    739\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_box(features, proposals)\n\u001b[0;32m    740\u001b[0m \u001b[38;5;66;03m# Usually the original proposals used by the box head are used by the mask, keypoint\u001b[39;00m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;66;03m# heads. But when `self.train_on_pred_boxes is True`, proposals will contain boxes\u001b[39;00m\n\u001b[0;32m    742\u001b[0m \u001b[38;5;66;03m# predicted by the box head.\u001b[39;00m\n\u001b[1;32m--> 743\u001b[0m losses\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproposals\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    744\u001b[0m losses\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_keypoint(features, proposals))\n\u001b[0;32m    745\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m proposals, losses\n",
      "File \u001b[1;32mc:\\users\\rog\\documents\\termatics\\segmentation\\solar_panel_segmentation\\detectron_maskrcnn\\libraries\\detectron2\\detectron2\\modeling\\roi_heads\\roi_heads.py:846\u001b[0m, in \u001b[0;36mStandardROIHeads._forward_mask\u001b[1;34m(self, features, instances)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    845\u001b[0m     features \u001b[38;5;241m=\u001b[39m {f: features[f] \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_in_features}\n\u001b[1;32m--> 846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstances\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\detectron_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\detectron_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\users\\rog\\documents\\termatics\\segmentation\\solar_panel_segmentation\\detectron_maskrcnn\\libraries\\detectron2\\detectron2\\modeling\\roi_heads\\mask_head.py:199\u001b[0m, in \u001b[0;36mBaseMaskRCNNHead.forward\u001b[1;34m(self, x, instances)\u001b[0m\n\u001b[0;32m    197\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers(x)\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m--> 199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mmask_rcnn_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvis_period\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_weight}\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m     mask_rcnn_inference(x, instances)\n",
      "File \u001b[1;32mc:\\users\\rog\\documents\\termatics\\segmentation\\solar_panel_segmentation\\detectron_maskrcnn\\libraries\\detectron2\\detectron2\\modeling\\roi_heads\\mask_head.py:92\u001b[0m, in \u001b[0;36mmask_rcnn_loss\u001b[1;34m(pred_mask_logits, instances, vis_period)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Log the training accuracy (using gt classes and sigmoid(0.0) == 0.5 threshold)\u001b[39;00m\n\u001b[0;32m     91\u001b[0m mask_incorrect \u001b[38;5;241m=\u001b[39m (pred_mask_logits \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m) \u001b[38;5;241m!=\u001b[39m gt_masks_bool\n\u001b[1;32m---> 92\u001b[0m mask_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m (\u001b[43mmask_incorrect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mmax\u001b[39m(mask_incorrect\u001b[38;5;241m.\u001b[39mnumel(), \u001b[38;5;241m1.0\u001b[39m))\n\u001b[0;32m     93\u001b[0m num_positive \u001b[38;5;241m=\u001b[39m gt_masks_bool\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     94\u001b[0m false_positive \u001b[38;5;241m=\u001b[39m (mask_incorrect \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m~\u001b[39mgt_masks_bool)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mmax\u001b[39m(\n\u001b[0;32m     95\u001b[0m     gt_masks_bool\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m-\u001b[39m num_positive, \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m     96\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "import torch\n",
    "\n",
    "# Define working directory\n",
    "WORK_DIR = r\"C:\\Users\\ROG\\Documents\\Termatics\\segmentation\\detectron_maskrcnn\\training_dataset_generated\\training_sets\"\n",
    "OUTPUT_DIR = os.path.join(WORK_DIR, \"output\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Create config\n",
    "cfg = get_cfg()\n",
    "\n",
    "# Load base config\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "# Register datasets\n",
    "cfg.DATASETS.TRAIN = (\"solar_train\",)\n",
    "cfg.DATASETS.TEST = (\"solar_val\",)\n",
    "\n",
    "# Data loader\n",
    "cfg.DATALOADER.NUM_WORKERS = 4  # More workers can help with larger data\n",
    "\n",
    "# Pretrained weights\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "\n",
    "# Solver settings\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.MAX_ITER = 3000  # Increased iterations for better convergence\n",
    "cfg.SOLVER.STEPS = []\n",
    "\n",
    "# ROI Head\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # Only solar panel class\n",
    "\n",
    "# Enable image size resizing for training\n",
    "cfg.INPUT.MIN_SIZE_TRAIN = (512, 768, 1024)  # Multi-scale training\n",
    "cfg.INPUT.MAX_SIZE_TRAIN = 1333\n",
    "cfg.INPUT.MIN_SIZE_TEST = 1024\n",
    "cfg.INPUT.MAX_SIZE_TEST = 1333\n",
    "\n",
    "# Data augmentation\n",
    "cfg.INPUT.RANDOM_FLIP = \"horizontal\"\n",
    "\n",
    "# Set device\n",
    "cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Output\n",
    "cfg.OUTPUT_DIR = OUTPUT_DIR\n",
    "\n",
    "# Trainer\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b84a6a-d002-4370-b598-b8e66878fa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. save best model and apply more augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "932e4ead-bec1-4234-8b90-ba205c8e2101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/29 18:21:07 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      " Augmentations applied: ResizeShortestEdge(512,768,1024), RandomFlip, RandomBrightness(0.91.1), RandomContrast(0.91.1)\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/29 18:21:07 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[07/29 18:21:07 d2.data.datasets.coco]: \u001b[0mLoaded 111 images in COCO format from training_dataset_generated\\training_sets\\annotations\\instances_train.json\n",
      "\u001b[32m[07/29 18:21:07 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 111 images left.\n",
      "\u001b[32m[07/29 18:21:07 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "| PV_bigger  | 174          |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[07/29 18:21:07 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/29 18:21:07 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/29 18:21:07 d2.data.common]: \u001b[0mSerializing 111 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/29 18:21:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[07/29 18:21:07 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "\u001b[32m[07/29 18:21:07 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/29 18:21:07 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ROG\\.conda\\envs\\detectron_env\\lib\\site-packages\\torch\\functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:4316.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0000 | loss_cls: 0.6695 | loss_box_reg: 0.5953 | loss_mask: 0.6902 | loss_rpn_cls: 0.0647 | loss_rpn_loc: 0.0166 | Total Loss: 2.0363\n",
      " Best model saved at Epoch 0 | Total Loss: 2.0363\n",
      "Epoch 0001 | loss_cls: 0.7447 | loss_box_reg: 0.3940 | loss_mask: 0.6896 | loss_rpn_cls: 0.1870 | loss_rpn_loc: 0.2667 | Total Loss: 2.2821\n",
      "Epoch 0002 | loss_cls: 0.6893 | loss_box_reg: 0.7471 | loss_mask: 0.6895 | loss_rpn_cls: 1.1007 | loss_rpn_loc: 0.1617 | Total Loss: 3.3883\n",
      "Epoch 0003 | loss_cls: 0.7095 | loss_box_reg: 0.3764 | loss_mask: 0.6892 | loss_rpn_cls: 0.0781 | loss_rpn_loc: 0.0216 | Total Loss: 1.8748\n",
      " Best model saved at Epoch 3 | Total Loss: 1.8748\n",
      "Epoch 0004 | loss_cls: 0.6494 | loss_box_reg: 0.6982 | loss_mask: 0.6889 | loss_rpn_cls: 0.0520 | loss_rpn_loc: 0.0072 | Total Loss: 2.0957\n",
      "Epoch 0005 | loss_cls: 0.7258 | loss_box_reg: 0.2822 | loss_mask: 0.6895 | loss_rpn_cls: 0.0165 | loss_rpn_loc: 0.0188 | Total Loss: 1.7328\n",
      " Best model saved at Epoch 5 | Total Loss: 1.7328\n",
      "Epoch 0006 | loss_cls: 0.6895 | loss_box_reg: 0.6395 | loss_mask: 0.6884 | loss_rpn_cls: 0.3762 | loss_rpn_loc: 0.2346 | Total Loss: 2.6282\n",
      "Epoch 0007 | loss_cls: 0.6787 | loss_box_reg: 0.4692 | loss_mask: 0.6891 | loss_rpn_cls: 0.0514 | loss_rpn_loc: 0.0250 | Total Loss: 1.9134\n",
      "Epoch 0008 | loss_cls: 0.7040 | loss_box_reg: 0.4138 | loss_mask: 0.6876 | loss_rpn_cls: 0.0241 | loss_rpn_loc: 0.0573 | Total Loss: 1.8869\n",
      "Epoch 0009 | loss_cls: 0.6902 | loss_box_reg: 0.2516 | loss_mask: 0.6889 | loss_rpn_cls: 0.0524 | loss_rpn_loc: 0.0399 | Total Loss: 1.7231\n",
      " Best model saved at Epoch 9 | Total Loss: 1.7231\n",
      "Epoch 0010 | loss_cls: 0.7460 | loss_box_reg: 0.2855 | loss_mask: 0.6897 | loss_rpn_cls: 0.1227 | loss_rpn_loc: 0.2646 | Total Loss: 2.1085\n",
      "Epoch 0011 | loss_cls: 0.7085 | loss_box_reg: 0.2859 | loss_mask: 0.6889 | loss_rpn_cls: 0.1607 | loss_rpn_loc: 0.2129 | Total Loss: 2.0569\n",
      "Epoch 0012 | loss_cls: 0.7224 | loss_box_reg: 0.4449 | loss_mask: 0.6892 | loss_rpn_cls: 0.1829 | loss_rpn_loc: 0.0538 | Total Loss: 2.0932\n",
      "Epoch 0013 | loss_cls: 0.6897 | loss_box_reg: 0.3468 | loss_mask: 0.6879 | loss_rpn_cls: 0.0268 | loss_rpn_loc: 0.0062 | Total Loss: 1.7574\n",
      "Epoch 0014 | loss_cls: 0.6787 | loss_box_reg: 0.8046 | loss_mask: 0.6849 | loss_rpn_cls: 0.5006 | loss_rpn_loc: 0.1113 | Total Loss: 2.7801\n",
      "Epoch 0015 | loss_cls: 0.6826 | loss_box_reg: 0.4955 | loss_mask: 0.6877 | loss_rpn_cls: 0.7990 | loss_rpn_loc: 0.1028 | Total Loss: 2.7677\n",
      "Epoch 0016 | loss_cls: 0.7075 | loss_box_reg: 0.3326 | loss_mask: 0.6853 | loss_rpn_cls: 0.4072 | loss_rpn_loc: 0.4612 | Total Loss: 2.5938\n",
      "Epoch 0017 | loss_cls: 0.6704 | loss_box_reg: 0.4252 | loss_mask: 0.6875 | loss_rpn_cls: 0.1314 | loss_rpn_loc: 0.0406 | Total Loss: 1.9551\n",
      "Epoch 0018 | loss_cls: 0.6608 | loss_box_reg: 0.7134 | loss_mask: 0.6897 | loss_rpn_cls: 0.0547 | loss_rpn_loc: 0.0167 | Total Loss: 2.1354\n",
      "Epoch 0019 | loss_cls: 0.6614 | loss_box_reg: 0.6979 | loss_mask: 0.6852 | loss_rpn_cls: 0.0417 | loss_rpn_loc: 0.0299 | Total Loss: 2.1161\n",
      "\u001b[32m[07/29 18:21:19 d2.utils.events]: \u001b[0m eta: 0:15:54  iter: 19      time: 0.3180  last_time: 0.3300   lr: 4.9953e-06  max_mem: 2288M\n",
      "Epoch 0020 | loss_cls: 0.6987 | loss_box_reg: 0.2491 | loss_mask: 0.6843 | loss_rpn_cls: 0.2206 | loss_rpn_loc: 0.2013 | Total Loss: 2.0541\n",
      "Epoch 0021 | loss_cls: 0.6825 | loss_box_reg: 0.4981 | loss_mask: 0.6856 | loss_rpn_cls: 0.0860 | loss_rpn_loc: 0.0547 | Total Loss: 2.0069\n",
      "Epoch 0022 | loss_cls: 0.6543 | loss_box_reg: 0.5281 | loss_mask: 0.6842 | loss_rpn_cls: 0.6470 | loss_rpn_loc: 0.2754 | Total Loss: 2.7889\n",
      "Epoch 0023 | loss_cls: 0.6474 | loss_box_reg: 0.7192 | loss_mask: 0.6855 | loss_rpn_cls: 0.3344 | loss_rpn_loc: 0.0543 | Total Loss: 2.4408\n",
      "Epoch 0024 | loss_cls: 0.6220 | loss_box_reg: 0.6477 | loss_mask: 0.6826 | loss_rpn_cls: 0.9510 | loss_rpn_loc: 0.1171 | Total Loss: 3.0204\n",
      "Epoch 0025 | loss_cls: 0.6663 | loss_box_reg: 0.3811 | loss_mask: 0.6815 | loss_rpn_cls: 0.0237 | loss_rpn_loc: 0.0101 | Total Loss: 1.7627\n",
      "Epoch 0026 | loss_cls: 0.6408 | loss_box_reg: 0.3729 | loss_mask: 0.6844 | loss_rpn_cls: 0.5178 | loss_rpn_loc: 0.1314 | Total Loss: 2.3473\n",
      "Epoch 0027 | loss_cls: 0.6774 | loss_box_reg: 0.6171 | loss_mask: 0.6796 | loss_rpn_cls: 0.5955 | loss_rpn_loc: 0.1020 | Total Loss: 2.6715\n",
      "Epoch 0028 | loss_cls: 0.6384 | loss_box_reg: 0.2478 | loss_mask: 0.6783 | loss_rpn_cls: 0.0357 | loss_rpn_loc: 0.0072 | Total Loss: 1.6074\n",
      " Best model saved at Epoch 28 | Total Loss: 1.6074\n",
      "Epoch 0029 | loss_cls: 0.6619 | loss_box_reg: 0.3197 | loss_mask: 0.6814 | loss_rpn_cls: 0.1433 | loss_rpn_loc: 0.2281 | Total Loss: 2.0343\n",
      "Epoch 0030 | loss_cls: 0.6020 | loss_box_reg: 0.5662 | loss_mask: 0.6774 | loss_rpn_cls: 0.0555 | loss_rpn_loc: 0.0269 | Total Loss: 1.9281\n",
      "Epoch 0031 | loss_cls: 0.6335 | loss_box_reg: 0.3149 | loss_mask: 0.6775 | loss_rpn_cls: 0.1504 | loss_rpn_loc: 0.2219 | Total Loss: 1.9982\n",
      "Epoch 0032 | loss_cls: 0.6146 | loss_box_reg: 0.5580 | loss_mask: 0.6760 | loss_rpn_cls: 0.1772 | loss_rpn_loc: 0.0968 | Total Loss: 2.1226\n",
      "Epoch 0033 | loss_cls: 0.6143 | loss_box_reg: 0.5632 | loss_mask: 0.6714 | loss_rpn_cls: 1.5543 | loss_rpn_loc: 0.7183 | Total Loss: 4.1214\n",
      "Epoch 0034 | loss_cls: 0.5714 | loss_box_reg: 0.4533 | loss_mask: 0.6718 | loss_rpn_cls: 0.0163 | loss_rpn_loc: 0.0084 | Total Loss: 1.7211\n",
      "Epoch 0035 | loss_cls: 0.5957 | loss_box_reg: 0.4453 | loss_mask: 0.6709 | loss_rpn_cls: 1.7207 | loss_rpn_loc: 0.3406 | Total Loss: 3.7733\n",
      "Epoch 0036 | loss_cls: 0.5917 | loss_box_reg: 0.5733 | loss_mask: 0.6714 | loss_rpn_cls: 0.0371 | loss_rpn_loc: 0.0249 | Total Loss: 1.8983\n",
      "Epoch 0037 | loss_cls: 0.6152 | loss_box_reg: 0.6593 | loss_mask: 0.6770 | loss_rpn_cls: 0.0405 | loss_rpn_loc: 0.0473 | Total Loss: 2.0393\n",
      "Epoch 0038 | loss_cls: 0.5993 | loss_box_reg: 0.3705 | loss_mask: 0.6710 | loss_rpn_cls: 0.1907 | loss_rpn_loc: 0.2381 | Total Loss: 2.0696\n",
      "Epoch 0039 | loss_cls: 0.5506 | loss_box_reg: 0.2312 | loss_mask: 0.6701 | loss_rpn_cls: 0.1658 | loss_rpn_loc: 0.0192 | Total Loss: 1.6369\n",
      "\u001b[32m[07/29 18:21:25 d2.utils.events]: \u001b[0m eta: 0:16:00  iter: 39      time: 0.3147  last_time: 0.3893   lr: 9.9902e-06  max_mem: 2289M\n",
      "Epoch 0040 | loss_cls: 0.5357 | loss_box_reg: 0.4902 | loss_mask: 0.6787 | loss_rpn_cls: 0.0303 | loss_rpn_loc: 0.0253 | Total Loss: 1.7601\n",
      "Epoch 0041 | loss_cls: 0.5849 | loss_box_reg: 1.0616 | loss_mask: 0.6684 | loss_rpn_cls: 0.0415 | loss_rpn_loc: 0.0332 | Total Loss: 2.3896\n",
      "Epoch 0042 | loss_cls: 0.5518 | loss_box_reg: 0.5084 | loss_mask: 0.6668 | loss_rpn_cls: 0.0269 | loss_rpn_loc: 0.0078 | Total Loss: 1.7616\n",
      "Epoch 0043 | loss_cls: 0.5049 | loss_box_reg: 0.2817 | loss_mask: 0.6628 | loss_rpn_cls: 0.1386 | loss_rpn_loc: 0.2045 | Total Loss: 1.7924\n",
      "Epoch 0044 | loss_cls: 0.5008 | loss_box_reg: 0.6321 | loss_mask: 0.6585 | loss_rpn_cls: 0.0523 | loss_rpn_loc: 0.0161 | Total Loss: 1.8597\n",
      "Epoch 0045 | loss_cls: 0.5268 | loss_box_reg: 0.4435 | loss_mask: 0.6753 | loss_rpn_cls: 0.0452 | loss_rpn_loc: 0.0107 | Total Loss: 1.7016\n",
      "Epoch 0046 | loss_cls: 0.5687 | loss_box_reg: 0.9911 | loss_mask: 0.6675 | loss_rpn_cls: 0.6866 | loss_rpn_loc: 0.2330 | Total Loss: 3.1468\n",
      "Epoch 0047 | loss_cls: 0.5661 | loss_box_reg: 0.3159 | loss_mask: 0.6778 | loss_rpn_cls: 0.8513 | loss_rpn_loc: 0.3012 | Total Loss: 2.7122\n",
      "Epoch 0048 | loss_cls: 0.5031 | loss_box_reg: 0.1946 | loss_mask: 0.6703 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.0131 | Total Loss: 1.3862\n",
      " Best model saved at Epoch 48 | Total Loss: 1.3862\n",
      "Epoch 0049 | loss_cls: 0.5206 | loss_box_reg: 0.3396 | loss_mask: 0.6509 | loss_rpn_cls: 0.0921 | loss_rpn_loc: 0.0169 | Total Loss: 1.6201\n",
      "Epoch 0050 | loss_cls: 0.5028 | loss_box_reg: 0.3899 | loss_mask: 0.6707 | loss_rpn_cls: 0.0497 | loss_rpn_loc: 0.2180 | Total Loss: 1.8310\n",
      "Epoch 0051 | loss_cls: 0.5099 | loss_box_reg: 0.7159 | loss_mask: 0.6730 | loss_rpn_cls: 0.0756 | loss_rpn_loc: 0.0163 | Total Loss: 1.9907\n",
      "Epoch 0052 | loss_cls: 0.5290 | loss_box_reg: 0.8622 | loss_mask: 0.6515 | loss_rpn_cls: 0.0169 | loss_rpn_loc: 0.0156 | Total Loss: 2.0753\n",
      "Epoch 0053 | loss_cls: 0.5232 | loss_box_reg: 0.3324 | loss_mask: 0.6546 | loss_rpn_cls: 0.0936 | loss_rpn_loc: 0.2103 | Total Loss: 1.8140\n",
      "Epoch 0054 | loss_cls: 0.4654 | loss_box_reg: 0.4925 | loss_mask: 0.6441 | loss_rpn_cls: 0.0144 | loss_rpn_loc: 0.0048 | Total Loss: 1.6211\n",
      "Epoch 0055 | loss_cls: 0.5369 | loss_box_reg: 0.1639 | loss_mask: 0.6618 | loss_rpn_cls: 0.6184 | loss_rpn_loc: 0.1078 | Total Loss: 2.0888\n",
      "Epoch 0056 | loss_cls: 0.4535 | loss_box_reg: 0.2889 | loss_mask: 0.6434 | loss_rpn_cls: 0.0141 | loss_rpn_loc: 0.0092 | Total Loss: 1.4091\n",
      "Epoch 0057 | loss_cls: 0.4902 | loss_box_reg: 0.6268 | loss_mask: 0.6504 | loss_rpn_cls: 0.5142 | loss_rpn_loc: 0.1068 | Total Loss: 2.3885\n",
      "Epoch 0058 | loss_cls: 0.4573 | loss_box_reg: 0.4135 | loss_mask: 0.6487 | loss_rpn_cls: 0.0236 | loss_rpn_loc: 0.0087 | Total Loss: 1.5518\n",
      "Epoch 0059 | loss_cls: 0.4207 | loss_box_reg: 0.2449 | loss_mask: 0.6481 | loss_rpn_cls: 0.0770 | loss_rpn_loc: 0.0608 | Total Loss: 1.4515\n",
      "\u001b[32m[07/29 18:21:31 d2.utils.events]: \u001b[0m eta: 0:16:03  iter: 59      time: 0.3096  last_time: 0.3374   lr: 1.4985e-05  max_mem: 2289M\n",
      "Epoch 0060 | loss_cls: 0.4366 | loss_box_reg: 0.6817 | loss_mask: 0.6540 | loss_rpn_cls: 0.0607 | loss_rpn_loc: 0.0293 | Total Loss: 1.8623\n",
      "Epoch 0061 | loss_cls: 0.4464 | loss_box_reg: 0.4921 | loss_mask: 0.6355 | loss_rpn_cls: 0.0520 | loss_rpn_loc: 0.1554 | Total Loss: 1.7813\n",
      "Epoch 0062 | loss_cls: 0.4089 | loss_box_reg: 0.4254 | loss_mask: 0.6240 | loss_rpn_cls: 1.9646 | loss_rpn_loc: 0.5112 | Total Loss: 3.9341\n",
      "Epoch 0063 | loss_cls: 0.4989 | loss_box_reg: 0.8719 | loss_mask: 0.6337 | loss_rpn_cls: 0.0184 | loss_rpn_loc: 0.0195 | Total Loss: 2.0424\n",
      "Epoch 0064 | loss_cls: 0.4302 | loss_box_reg: 0.3407 | loss_mask: 0.6605 | loss_rpn_cls: 0.0461 | loss_rpn_loc: 0.2091 | Total Loss: 1.6867\n",
      "Epoch 0065 | loss_cls: 0.4670 | loss_box_reg: 0.7461 | loss_mask: 0.6349 | loss_rpn_cls: 0.0436 | loss_rpn_loc: 0.1460 | Total Loss: 2.0376\n",
      "Epoch 0066 | loss_cls: 0.4222 | loss_box_reg: 0.6630 | loss_mask: 0.6387 | loss_rpn_cls: 0.0096 | loss_rpn_loc: 0.0087 | Total Loss: 1.7422\n",
      "Epoch 0067 | loss_cls: 0.3847 | loss_box_reg: 0.2952 | loss_mask: 0.6403 | loss_rpn_cls: 0.0195 | loss_rpn_loc: 0.0390 | Total Loss: 1.3787\n",
      " Best model saved at Epoch 67 | Total Loss: 1.3787\n",
      "Epoch 0068 | loss_cls: 0.4166 | loss_box_reg: 0.3521 | loss_mask: 0.6368 | loss_rpn_cls: 0.1396 | loss_rpn_loc: 0.2253 | Total Loss: 1.7704\n",
      "Epoch 0069 | loss_cls: 0.4090 | loss_box_reg: 0.5472 | loss_mask: 0.6309 | loss_rpn_cls: 0.0666 | loss_rpn_loc: 0.0210 | Total Loss: 1.6746\n",
      "Epoch 0070 | loss_cls: 0.4967 | loss_box_reg: 0.8475 | loss_mask: 0.6247 | loss_rpn_cls: 1.2842 | loss_rpn_loc: 0.2976 | Total Loss: 3.5508\n",
      "Epoch 0071 | loss_cls: 0.4106 | loss_box_reg: 0.5721 | loss_mask: 0.6271 | loss_rpn_cls: 0.0567 | loss_rpn_loc: 0.2216 | Total Loss: 1.8881\n",
      "Epoch 0072 | loss_cls: 0.3572 | loss_box_reg: 0.2871 | loss_mask: 0.6274 | loss_rpn_cls: 0.0154 | loss_rpn_loc: 0.0231 | Total Loss: 1.3102\n",
      " Best model saved at Epoch 72 | Total Loss: 1.3102\n",
      "Epoch 0073 | loss_cls: 0.3424 | loss_box_reg: 0.3462 | loss_mask: 0.6261 | loss_rpn_cls: 0.0777 | loss_rpn_loc: 0.1950 | Total Loss: 1.5874\n",
      "Epoch 0074 | loss_cls: 0.3505 | loss_box_reg: 0.3846 | loss_mask: 0.6383 | loss_rpn_cls: 0.0086 | loss_rpn_loc: 0.0206 | Total Loss: 1.4026\n",
      "Epoch 0075 | loss_cls: 0.3853 | loss_box_reg: 0.3492 | loss_mask: 0.6537 | loss_rpn_cls: 0.0782 | loss_rpn_loc: 0.3895 | Total Loss: 1.8559\n",
      "Epoch 0076 | loss_cls: 0.3871 | loss_box_reg: 0.3406 | loss_mask: 0.6442 | loss_rpn_cls: 0.1568 | loss_rpn_loc: 0.0193 | Total Loss: 1.5481\n",
      "Epoch 0077 | loss_cls: 0.4108 | loss_box_reg: 0.6347 | loss_mask: 0.6337 | loss_rpn_cls: 0.8098 | loss_rpn_loc: 0.2148 | Total Loss: 2.7037\n",
      "Epoch 0078 | loss_cls: 0.3351 | loss_box_reg: 0.3991 | loss_mask: 0.6178 | loss_rpn_cls: 0.3980 | loss_rpn_loc: 0.0735 | Total Loss: 1.8235\n",
      "Epoch 0079 | loss_cls: 0.4073 | loss_box_reg: 0.6688 | loss_mask: 0.6214 | loss_rpn_cls: 0.0098 | loss_rpn_loc: 0.0092 | Total Loss: 1.7165\n",
      "\u001b[32m[07/29 18:21:38 d2.utils.events]: \u001b[0m eta: 0:16:16  iter: 79      time: 0.3183  last_time: 0.1678   lr: 1.998e-05  max_mem: 2290M\n",
      "Epoch 0080 | loss_cls: 0.3658 | loss_box_reg: 0.3985 | loss_mask: 0.6227 | loss_rpn_cls: 0.0303 | loss_rpn_loc: 0.0646 | Total Loss: 1.4819\n",
      "Epoch 0081 | loss_cls: 0.2951 | loss_box_reg: 0.2526 | loss_mask: 0.6039 | loss_rpn_cls: 0.0195 | loss_rpn_loc: 0.0116 | Total Loss: 1.1827\n",
      " Best model saved at Epoch 81 | Total Loss: 1.1827\n",
      "Epoch 0082 | loss_cls: 0.3607 | loss_box_reg: 0.5131 | loss_mask: 0.5957 | loss_rpn_cls: 3.4891 | loss_rpn_loc: 1.4056 | Total Loss: 6.3641\n",
      "Epoch 0083 | loss_cls: 0.3387 | loss_box_reg: 0.3431 | loss_mask: 0.6166 | loss_rpn_cls: 0.0481 | loss_rpn_loc: 0.4036 | Total Loss: 1.7501\n",
      "Epoch 0084 | loss_cls: 0.4245 | loss_box_reg: 0.7652 | loss_mask: 0.6249 | loss_rpn_cls: 0.3001 | loss_rpn_loc: 0.2416 | Total Loss: 2.3563\n",
      "Epoch 0085 | loss_cls: 0.3304 | loss_box_reg: 0.4526 | loss_mask: 0.5943 | loss_rpn_cls: 0.0159 | loss_rpn_loc: 0.0241 | Total Loss: 1.4173\n",
      "Epoch 0086 | loss_cls: 0.4133 | loss_box_reg: 0.7421 | loss_mask: 0.5928 | loss_rpn_cls: 0.0248 | loss_rpn_loc: 0.0098 | Total Loss: 1.7827\n",
      "Epoch 0087 | loss_cls: 0.3207 | loss_box_reg: 0.2963 | loss_mask: 0.6522 | loss_rpn_cls: 0.0357 | loss_rpn_loc: 0.2037 | Total Loss: 1.5086\n",
      "Epoch 0088 | loss_cls: 0.4127 | loss_box_reg: 0.7559 | loss_mask: 0.5941 | loss_rpn_cls: 0.0239 | loss_rpn_loc: 0.0218 | Total Loss: 1.8084\n",
      "Epoch 0089 | loss_cls: 0.3241 | loss_box_reg: 0.4540 | loss_mask: 0.5837 | loss_rpn_cls: 0.0086 | loss_rpn_loc: 0.0046 | Total Loss: 1.3750\n",
      "Epoch 0090 | loss_cls: 0.3735 | loss_box_reg: 0.6817 | loss_mask: 0.5873 | loss_rpn_cls: 0.6432 | loss_rpn_loc: 0.1049 | Total Loss: 2.3906\n",
      "Epoch 0091 | loss_cls: 0.3226 | loss_box_reg: 0.2775 | loss_mask: 0.6391 | loss_rpn_cls: 0.0108 | loss_rpn_loc: 0.0215 | Total Loss: 1.2714\n",
      "Epoch 0092 | loss_cls: 0.2885 | loss_box_reg: 0.3796 | loss_mask: 0.5954 | loss_rpn_cls: 0.0095 | loss_rpn_loc: 0.0222 | Total Loss: 1.2952\n",
      "Epoch 0093 | loss_cls: 0.3410 | loss_box_reg: 0.5216 | loss_mask: 0.5846 | loss_rpn_cls: 0.0145 | loss_rpn_loc: 0.0220 | Total Loss: 1.4836\n",
      "Epoch 0094 | loss_cls: 0.4161 | loss_box_reg: 0.8292 | loss_mask: 0.5891 | loss_rpn_cls: 0.6596 | loss_rpn_loc: 0.1963 | Total Loss: 2.6903\n",
      "Epoch 0095 | loss_cls: 0.4432 | loss_box_reg: 0.9428 | loss_mask: 0.6055 | loss_rpn_cls: 0.0126 | loss_rpn_loc: 0.0282 | Total Loss: 2.0322\n",
      "Epoch 0096 | loss_cls: 0.2769 | loss_box_reg: 0.3572 | loss_mask: 0.5982 | loss_rpn_cls: 0.0151 | loss_rpn_loc: 0.1322 | Total Loss: 1.3796\n",
      "Epoch 0097 | loss_cls: 0.3396 | loss_box_reg: 0.6822 | loss_mask: 0.5288 | loss_rpn_cls: 0.0218 | loss_rpn_loc: 0.1054 | Total Loss: 1.6778\n",
      "Epoch 0098 | loss_cls: 0.4422 | loss_box_reg: 1.0070 | loss_mask: 0.5810 | loss_rpn_cls: 0.1233 | loss_rpn_loc: 0.0245 | Total Loss: 2.1781\n",
      "Epoch 0099 | loss_cls: 0.3372 | loss_box_reg: 0.6101 | loss_mask: 0.5516 | loss_rpn_cls: 0.1392 | loss_rpn_loc: 0.0219 | Total Loss: 1.6600\n",
      "\u001b[32m[07/29 18:21:44 d2.utils.events]: \u001b[0m eta: 0:16:10  iter: 99      time: 0.3163  last_time: 0.2383   lr: 2.4975e-05  max_mem: 2290M\n",
      "Epoch 0100 | loss_cls: 0.3814 | loss_box_reg: 0.6726 | loss_mask: 0.6044 | loss_rpn_cls: 0.0378 | loss_rpn_loc: 0.2113 | Total Loss: 1.9074\n",
      "Epoch 0101 | loss_cls: 0.2780 | loss_box_reg: 0.4642 | loss_mask: 0.5550 | loss_rpn_cls: 0.0088 | loss_rpn_loc: 0.0087 | Total Loss: 1.3146\n",
      "Epoch 0102 | loss_cls: 0.3129 | loss_box_reg: 0.4623 | loss_mask: 0.6101 | loss_rpn_cls: 0.0282 | loss_rpn_loc: 0.0296 | Total Loss: 1.4432\n",
      "Epoch 0103 | loss_cls: 0.3540 | loss_box_reg: 0.6957 | loss_mask: 0.5868 | loss_rpn_cls: 0.0349 | loss_rpn_loc: 0.0310 | Total Loss: 1.7023\n",
      "Epoch 0104 | loss_cls: 0.4161 | loss_box_reg: 0.7876 | loss_mask: 0.6140 | loss_rpn_cls: 0.3672 | loss_rpn_loc: 0.1887 | Total Loss: 2.3735\n",
      "Epoch 0105 | loss_cls: 0.4193 | loss_box_reg: 0.9895 | loss_mask: 0.5628 | loss_rpn_cls: 0.3418 | loss_rpn_loc: 0.1426 | Total Loss: 2.4560\n",
      "Epoch 0106 | loss_cls: 0.3606 | loss_box_reg: 0.6330 | loss_mask: 0.5999 | loss_rpn_cls: 0.0412 | loss_rpn_loc: 0.0608 | Total Loss: 1.6955\n",
      "Epoch 0107 | loss_cls: 0.2832 | loss_box_reg: 0.4500 | loss_mask: 0.5603 | loss_rpn_cls: 0.0055 | loss_rpn_loc: 0.0101 | Total Loss: 1.3089\n",
      "Epoch 0108 | loss_cls: 0.2796 | loss_box_reg: 0.2771 | loss_mask: 0.5907 | loss_rpn_cls: 0.0102 | loss_rpn_loc: 0.1936 | Total Loss: 1.3511\n",
      "Epoch 0109 | loss_cls: 0.3034 | loss_box_reg: 0.4523 | loss_mask: 0.6058 | loss_rpn_cls: 0.0088 | loss_rpn_loc: 0.1737 | Total Loss: 1.5440\n",
      "Epoch 0110 | loss_cls: 0.2952 | loss_box_reg: 0.5004 | loss_mask: 0.5279 | loss_rpn_cls: 0.6181 | loss_rpn_loc: 0.1408 | Total Loss: 2.0825\n",
      "Epoch 0111 | loss_cls: 0.3288 | loss_box_reg: 0.5493 | loss_mask: 0.5525 | loss_rpn_cls: 0.0231 | loss_rpn_loc: 0.1904 | Total Loss: 1.6440\n",
      "Epoch 0112 | loss_cls: 0.3228 | loss_box_reg: 0.5955 | loss_mask: 0.5365 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.0577 | Total Loss: 1.5159\n",
      "Epoch 0113 | loss_cls: 0.2593 | loss_box_reg: 0.3076 | loss_mask: 0.6435 | loss_rpn_cls: 0.0088 | loss_rpn_loc: 0.2257 | Total Loss: 1.4449\n",
      "Epoch 0114 | loss_cls: 0.3932 | loss_box_reg: 0.8952 | loss_mask: 0.5617 | loss_rpn_cls: 0.0255 | loss_rpn_loc: 0.0755 | Total Loss: 1.9511\n",
      "Epoch 0115 | loss_cls: 0.3385 | loss_box_reg: 0.5722 | loss_mask: 0.5656 | loss_rpn_cls: 0.0100 | loss_rpn_loc: 0.0559 | Total Loss: 1.5421\n",
      "Epoch 0116 | loss_cls: 0.3105 | loss_box_reg: 0.4447 | loss_mask: 0.6027 | loss_rpn_cls: 0.0068 | loss_rpn_loc: 0.0447 | Total Loss: 1.4094\n",
      "Epoch 0117 | loss_cls: 0.4114 | loss_box_reg: 0.9754 | loss_mask: 0.5611 | loss_rpn_cls: 0.2696 | loss_rpn_loc: 0.0764 | Total Loss: 2.2939\n",
      "Epoch 0118 | loss_cls: 0.3274 | loss_box_reg: 0.7238 | loss_mask: 0.5137 | loss_rpn_cls: 0.0136 | loss_rpn_loc: 0.0206 | Total Loss: 1.5990\n",
      "Epoch 0119 | loss_cls: 0.4313 | loss_box_reg: 0.9447 | loss_mask: 0.5223 | loss_rpn_cls: 1.0544 | loss_rpn_loc: 0.2951 | Total Loss: 3.2480\n",
      "\u001b[32m[07/29 18:21:51 d2.utils.events]: \u001b[0m eta: 0:16:09  iter: 119      time: 0.3173  last_time: 0.2787   lr: 2.997e-05  max_mem: 2290M\n",
      "Epoch 0120 | loss_cls: 0.4223 | loss_box_reg: 0.9958 | loss_mask: 0.5022 | loss_rpn_cls: 0.0361 | loss_rpn_loc: 0.0227 | Total Loss: 1.9790\n",
      "Epoch 0121 | loss_cls: 0.2666 | loss_box_reg: 0.4541 | loss_mask: 0.5345 | loss_rpn_cls: 0.6147 | loss_rpn_loc: 0.1365 | Total Loss: 2.0065\n",
      "Epoch 0122 | loss_cls: 0.2878 | loss_box_reg: 0.5533 | loss_mask: 0.4775 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.0077 | Total Loss: 1.3285\n",
      "Epoch 0123 | loss_cls: 0.3506 | loss_box_reg: 0.7253 | loss_mask: 0.5056 | loss_rpn_cls: 0.3213 | loss_rpn_loc: 0.1312 | Total Loss: 2.0340\n",
      "Epoch 0124 | loss_cls: 0.2882 | loss_box_reg: 0.4077 | loss_mask: 0.5373 | loss_rpn_cls: 0.2205 | loss_rpn_loc: 0.2367 | Total Loss: 1.6904\n",
      "Epoch 0125 | loss_cls: 0.2362 | loss_box_reg: 0.3416 | loss_mask: 0.5087 | loss_rpn_cls: 0.0041 | loss_rpn_loc: 0.0219 | Total Loss: 1.1124\n",
      " Best model saved at Epoch 125 | Total Loss: 1.1124\n",
      "Epoch 0126 | loss_cls: 0.3182 | loss_box_reg: 0.5589 | loss_mask: 0.5292 | loss_rpn_cls: 0.2555 | loss_rpn_loc: 0.1322 | Total Loss: 1.7941\n",
      "Epoch 0127 | loss_cls: 0.3700 | loss_box_reg: 0.7285 | loss_mask: 0.5147 | loss_rpn_cls: 0.0164 | loss_rpn_loc: 0.0318 | Total Loss: 1.6614\n",
      "Epoch 0128 | loss_cls: 0.2831 | loss_box_reg: 0.6531 | loss_mask: 0.4589 | loss_rpn_cls: 0.0059 | loss_rpn_loc: 0.0082 | Total Loss: 1.4091\n",
      "Epoch 0129 | loss_cls: 0.2848 | loss_box_reg: 0.5352 | loss_mask: 0.4900 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.0224 | Total Loss: 1.3334\n",
      "Epoch 0130 | loss_cls: 0.3895 | loss_box_reg: 0.8936 | loss_mask: 0.5264 | loss_rpn_cls: 0.0378 | loss_rpn_loc: 0.0265 | Total Loss: 1.8739\n",
      "Epoch 0131 | loss_cls: 0.4005 | loss_box_reg: 0.8991 | loss_mask: 0.4921 | loss_rpn_cls: 0.1784 | loss_rpn_loc: 0.1603 | Total Loss: 2.1304\n",
      "Epoch 0132 | loss_cls: 0.2414 | loss_box_reg: 0.3288 | loss_mask: 0.5372 | loss_rpn_cls: 0.0104 | loss_rpn_loc: 0.1803 | Total Loss: 1.2981\n",
      "Epoch 0133 | loss_cls: 0.3769 | loss_box_reg: 0.7478 | loss_mask: 0.5066 | loss_rpn_cls: 0.0160 | loss_rpn_loc: 0.0105 | Total Loss: 1.6578\n",
      "Epoch 0134 | loss_cls: 0.3120 | loss_box_reg: 0.6072 | loss_mask: 0.5064 | loss_rpn_cls: 0.0086 | loss_rpn_loc: 0.0149 | Total Loss: 1.4491\n",
      "Epoch 0135 | loss_cls: 0.2763 | loss_box_reg: 0.5105 | loss_mask: 0.4516 | loss_rpn_cls: 0.0073 | loss_rpn_loc: 0.1564 | Total Loss: 1.4021\n",
      "Epoch 0136 | loss_cls: 0.3357 | loss_box_reg: 0.6966 | loss_mask: 0.4352 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.0237 | Total Loss: 1.4926\n",
      "Epoch 0137 | loss_cls: 0.3122 | loss_box_reg: 0.6906 | loss_mask: 0.4684 | loss_rpn_cls: 0.0244 | loss_rpn_loc: 0.0454 | Total Loss: 1.5410\n",
      "Epoch 0138 | loss_cls: 0.3022 | loss_box_reg: 0.6482 | loss_mask: 0.4414 | loss_rpn_cls: 0.1568 | loss_rpn_loc: 0.0493 | Total Loss: 1.5979\n",
      "Epoch 0139 | loss_cls: 0.2197 | loss_box_reg: 0.2878 | loss_mask: 0.5258 | loss_rpn_cls: 0.0154 | loss_rpn_loc: 0.1245 | Total Loss: 1.1732\n",
      "\u001b[32m[07/29 18:21:57 d2.utils.events]: \u001b[0m eta: 0:15:56  iter: 139      time: 0.3158  last_time: 0.3460   lr: 3.4965e-05  max_mem: 2290M\n",
      "Epoch 0140 | loss_cls: 0.3273 | loss_box_reg: 0.7365 | loss_mask: 0.4180 | loss_rpn_cls: 0.0095 | loss_rpn_loc: 0.0281 | Total Loss: 1.5194\n",
      "Epoch 0141 | loss_cls: 0.2621 | loss_box_reg: 0.4994 | loss_mask: 0.5273 | loss_rpn_cls: 0.0275 | loss_rpn_loc: 0.0162 | Total Loss: 1.3324\n",
      "Epoch 0142 | loss_cls: 0.2232 | loss_box_reg: 0.3627 | loss_mask: 0.4239 | loss_rpn_cls: 0.0024 | loss_rpn_loc: 0.0192 | Total Loss: 1.0313\n",
      " Best model saved at Epoch 142 | Total Loss: 1.0313\n",
      "Epoch 0143 | loss_cls: 0.2494 | loss_box_reg: 0.3672 | loss_mask: 0.4356 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0075 | Total Loss: 1.0608\n",
      "Epoch 0144 | loss_cls: 0.2576 | loss_box_reg: 0.5484 | loss_mask: 0.4428 | loss_rpn_cls: 0.0163 | loss_rpn_loc: 0.0205 | Total Loss: 1.2855\n",
      "Epoch 0145 | loss_cls: 0.3169 | loss_box_reg: 0.6508 | loss_mask: 0.4460 | loss_rpn_cls: 1.2230 | loss_rpn_loc: 0.9207 | Total Loss: 3.5574\n",
      "Epoch 0146 | loss_cls: 0.3471 | loss_box_reg: 0.7310 | loss_mask: 0.4473 | loss_rpn_cls: 0.0089 | loss_rpn_loc: 0.1815 | Total Loss: 1.7157\n",
      "Epoch 0147 | loss_cls: 0.2763 | loss_box_reg: 0.5538 | loss_mask: 0.3961 | loss_rpn_cls: 0.0677 | loss_rpn_loc: 0.0574 | Total Loss: 1.3513\n",
      "Epoch 0148 | loss_cls: 0.3278 | loss_box_reg: 0.7250 | loss_mask: 0.5110 | loss_rpn_cls: 0.0113 | loss_rpn_loc: 0.0235 | Total Loss: 1.5985\n",
      "Epoch 0149 | loss_cls: 0.2972 | loss_box_reg: 0.4629 | loss_mask: 0.4675 | loss_rpn_cls: 0.0307 | loss_rpn_loc: 0.1896 | Total Loss: 1.4480\n",
      "Epoch 0150 | loss_cls: 0.2477 | loss_box_reg: 0.3810 | loss_mask: 0.4576 | loss_rpn_cls: 0.0026 | loss_rpn_loc: 0.0203 | Total Loss: 1.1092\n",
      "Epoch 0151 | loss_cls: 0.2155 | loss_box_reg: 0.2503 | loss_mask: 0.5456 | loss_rpn_cls: 0.0239 | loss_rpn_loc: 0.3168 | Total Loss: 1.3521\n",
      "Epoch 0152 | loss_cls: 0.2656 | loss_box_reg: 0.6743 | loss_mask: 0.4847 | loss_rpn_cls: 0.0100 | loss_rpn_loc: 0.0117 | Total Loss: 1.4461\n",
      "Epoch 0153 | loss_cls: 0.2925 | loss_box_reg: 0.7007 | loss_mask: 0.4251 | loss_rpn_cls: 0.0444 | loss_rpn_loc: 0.1189 | Total Loss: 1.5817\n",
      "Epoch 0154 | loss_cls: 0.3227 | loss_box_reg: 0.7100 | loss_mask: 0.4655 | loss_rpn_cls: 0.0289 | loss_rpn_loc: 0.0158 | Total Loss: 1.5429\n",
      "Epoch 0155 | loss_cls: 0.2740 | loss_box_reg: 0.4862 | loss_mask: 0.4024 | loss_rpn_cls: 0.0052 | loss_rpn_loc: 0.0628 | Total Loss: 1.2306\n",
      "Epoch 0156 | loss_cls: 0.3521 | loss_box_reg: 0.6699 | loss_mask: 0.4049 | loss_rpn_cls: 0.0693 | loss_rpn_loc: 0.1824 | Total Loss: 1.6786\n",
      "Epoch 0157 | loss_cls: 0.2362 | loss_box_reg: 0.4254 | loss_mask: 0.4067 | loss_rpn_cls: 0.0154 | loss_rpn_loc: 0.1390 | Total Loss: 1.2229\n",
      "Epoch 0158 | loss_cls: 0.2821 | loss_box_reg: 0.4046 | loss_mask: 0.4454 | loss_rpn_cls: 0.6855 | loss_rpn_loc: 0.2210 | Total Loss: 2.0386\n",
      "Epoch 0159 | loss_cls: 0.3059 | loss_box_reg: 0.5479 | loss_mask: 0.3457 | loss_rpn_cls: 0.1854 | loss_rpn_loc: 0.0518 | Total Loss: 1.4368\n",
      "\u001b[32m[07/29 18:22:04 d2.utils.events]: \u001b[0m eta: 0:16:00  iter: 159      time: 0.3192  last_time: 0.2554   lr: 3.996e-05  max_mem: 2290M\n",
      "Epoch 0160 | loss_cls: 0.2090 | loss_box_reg: 0.3461 | loss_mask: 0.4931 | loss_rpn_cls: 0.0218 | loss_rpn_loc: 0.1422 | Total Loss: 1.2121\n",
      "Epoch 0161 | loss_cls: 0.2266 | loss_box_reg: 0.5330 | loss_mask: 0.3108 | loss_rpn_cls: 0.0169 | loss_rpn_loc: 0.1092 | Total Loss: 1.1965\n",
      "Epoch 0162 | loss_cls: 0.2730 | loss_box_reg: 0.5824 | loss_mask: 0.3907 | loss_rpn_cls: 0.0153 | loss_rpn_loc: 0.0089 | Total Loss: 1.2703\n",
      "Epoch 0163 | loss_cls: 0.3819 | loss_box_reg: 1.0324 | loss_mask: 0.3579 | loss_rpn_cls: 0.2161 | loss_rpn_loc: 0.1332 | Total Loss: 2.1214\n",
      "Epoch 0164 | loss_cls: 0.3089 | loss_box_reg: 0.6249 | loss_mask: 0.3666 | loss_rpn_cls: 0.0053 | loss_rpn_loc: 0.0286 | Total Loss: 1.3343\n",
      "Epoch 0165 | loss_cls: 0.3405 | loss_box_reg: 0.8852 | loss_mask: 0.4030 | loss_rpn_cls: 0.3840 | loss_rpn_loc: 0.1459 | Total Loss: 2.1585\n",
      "Epoch 0166 | loss_cls: 0.4100 | loss_box_reg: 0.8707 | loss_mask: 0.4400 | loss_rpn_cls: 0.3245 | loss_rpn_loc: 0.2396 | Total Loss: 2.2847\n",
      "Epoch 0167 | loss_cls: 0.3294 | loss_box_reg: 0.6989 | loss_mask: 0.3800 | loss_rpn_cls: 0.0198 | loss_rpn_loc: 0.0790 | Total Loss: 1.5071\n",
      "Epoch 0168 | loss_cls: 0.1985 | loss_box_reg: 0.2648 | loss_mask: 0.3801 | loss_rpn_cls: 0.0131 | loss_rpn_loc: 0.2013 | Total Loss: 1.0577\n",
      "Epoch 0169 | loss_cls: 0.3097 | loss_box_reg: 0.6864 | loss_mask: 0.3493 | loss_rpn_cls: 0.0068 | loss_rpn_loc: 0.0202 | Total Loss: 1.3724\n",
      "Epoch 0170 | loss_cls: 0.3024 | loss_box_reg: 0.7177 | loss_mask: 0.3970 | loss_rpn_cls: 0.2105 | loss_rpn_loc: 0.2940 | Total Loss: 1.9216\n",
      "Epoch 0171 | loss_cls: 0.3043 | loss_box_reg: 0.6903 | loss_mask: 0.4180 | loss_rpn_cls: 0.0322 | loss_rpn_loc: 0.0105 | Total Loss: 1.4554\n",
      "Epoch 0172 | loss_cls: 0.2100 | loss_box_reg: 0.4254 | loss_mask: 0.3697 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.0227 | Total Loss: 1.0329\n",
      "Epoch 0173 | loss_cls: 0.2244 | loss_box_reg: 0.5403 | loss_mask: 0.2729 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0100 | Total Loss: 1.0483\n",
      "Epoch 0174 | loss_cls: 0.3707 | loss_box_reg: 0.6862 | loss_mask: 0.3524 | loss_rpn_cls: 0.0428 | loss_rpn_loc: 0.1267 | Total Loss: 1.5788\n",
      "Epoch 0175 | loss_cls: 0.2107 | loss_box_reg: 0.4758 | loss_mask: 0.2638 | loss_rpn_cls: 0.0104 | loss_rpn_loc: 0.0675 | Total Loss: 1.0282\n",
      " Best model saved at Epoch 175 | Total Loss: 1.0282\n",
      "Epoch 0176 | loss_cls: 0.3206 | loss_box_reg: 0.6774 | loss_mask: 0.4405 | loss_rpn_cls: 0.0069 | loss_rpn_loc: 0.1286 | Total Loss: 1.5739\n",
      "Epoch 0177 | loss_cls: 0.2809 | loss_box_reg: 0.5177 | loss_mask: 0.4247 | loss_rpn_cls: 0.0146 | loss_rpn_loc: 0.1708 | Total Loss: 1.4086\n",
      "Epoch 0178 | loss_cls: 0.3161 | loss_box_reg: 0.6607 | loss_mask: 0.3369 | loss_rpn_cls: 0.0437 | loss_rpn_loc: 0.0814 | Total Loss: 1.4388\n",
      "Epoch 0179 | loss_cls: 0.2713 | loss_box_reg: 0.6388 | loss_mask: 0.2821 | loss_rpn_cls: 0.1550 | loss_rpn_loc: 0.0470 | Total Loss: 1.3942\n",
      "\u001b[32m[07/29 18:22:11 d2.utils.events]: \u001b[0m eta: 0:16:07  iter: 179      time: 0.3227  last_time: 0.2470   lr: 4.4955e-05  max_mem: 2290M\n",
      "Epoch 0180 | loss_cls: 0.1924 | loss_box_reg: 0.2938 | loss_mask: 0.2974 | loss_rpn_cls: 0.0226 | loss_rpn_loc: 0.2705 | Total Loss: 1.0766\n",
      "Epoch 0181 | loss_cls: 0.3410 | loss_box_reg: 0.9242 | loss_mask: 0.2888 | loss_rpn_cls: 0.0165 | loss_rpn_loc: 0.0611 | Total Loss: 1.6317\n",
      "Epoch 0182 | loss_cls: 0.2478 | loss_box_reg: 0.6311 | loss_mask: 0.4494 | loss_rpn_cls: 0.0031 | loss_rpn_loc: 0.0073 | Total Loss: 1.3386\n",
      "Epoch 0183 | loss_cls: 0.2905 | loss_box_reg: 0.7819 | loss_mask: 0.2889 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.0269 | Total Loss: 1.3931\n",
      "Epoch 0184 | loss_cls: 0.2446 | loss_box_reg: 0.6632 | loss_mask: 0.4766 | loss_rpn_cls: 0.0058 | loss_rpn_loc: 0.0904 | Total Loss: 1.4806\n",
      "Epoch 0185 | loss_cls: 0.2572 | loss_box_reg: 0.4201 | loss_mask: 0.2307 | loss_rpn_cls: 0.2507 | loss_rpn_loc: 0.0594 | Total Loss: 1.2182\n",
      "Epoch 0186 | loss_cls: 0.2585 | loss_box_reg: 0.4488 | loss_mask: 0.3669 | loss_rpn_cls: 0.0587 | loss_rpn_loc: 0.0710 | Total Loss: 1.2039\n",
      "Epoch 0187 | loss_cls: 0.3182 | loss_box_reg: 0.9451 | loss_mask: 0.2565 | loss_rpn_cls: 0.1827 | loss_rpn_loc: 0.0663 | Total Loss: 1.7689\n",
      "Epoch 0188 | loss_cls: 0.2606 | loss_box_reg: 0.7541 | loss_mask: 0.2465 | loss_rpn_cls: 0.0195 | loss_rpn_loc: 0.0152 | Total Loss: 1.2959\n",
      "Epoch 0189 | loss_cls: 0.3444 | loss_box_reg: 0.8012 | loss_mask: 0.3374 | loss_rpn_cls: 0.0134 | loss_rpn_loc: 0.0651 | Total Loss: 1.5616\n",
      "Epoch 0190 | loss_cls: 0.2824 | loss_box_reg: 0.8736 | loss_mask: 0.2121 | loss_rpn_cls: 1.1409 | loss_rpn_loc: 0.6023 | Total Loss: 3.1113\n",
      "Epoch 0191 | loss_cls: 0.2563 | loss_box_reg: 0.6011 | loss_mask: 0.3121 | loss_rpn_cls: 0.0222 | loss_rpn_loc: 0.0442 | Total Loss: 1.2360\n",
      "Epoch 0192 | loss_cls: 0.2208 | loss_box_reg: 0.4144 | loss_mask: 0.3977 | loss_rpn_cls: 0.0102 | loss_rpn_loc: 0.0485 | Total Loss: 1.0915\n",
      "Epoch 0193 | loss_cls: 0.1935 | loss_box_reg: 0.3588 | loss_mask: 0.4604 | loss_rpn_cls: 0.0077 | loss_rpn_loc: 0.0262 | Total Loss: 1.0466\n",
      "Epoch 0194 | loss_cls: 0.2123 | loss_box_reg: 0.5514 | loss_mask: 0.2323 | loss_rpn_cls: 0.0173 | loss_rpn_loc: 0.1463 | Total Loss: 1.1595\n",
      "Epoch 0195 | loss_cls: 0.2022 | loss_box_reg: 0.3452 | loss_mask: 0.2142 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0178 | Total Loss: 0.7801\n",
      " Best model saved at Epoch 195 | Total Loss: 0.7801\n",
      "Epoch 0196 | loss_cls: 0.2123 | loss_box_reg: 0.4547 | loss_mask: 0.2985 | loss_rpn_cls: 0.0175 | loss_rpn_loc: 0.1395 | Total Loss: 1.1226\n",
      "Epoch 0197 | loss_cls: 0.2731 | loss_box_reg: 0.8248 | loss_mask: 0.2866 | loss_rpn_cls: 0.0017 | loss_rpn_loc: 0.0352 | Total Loss: 1.4214\n",
      "Epoch 0198 | loss_cls: 0.3326 | loss_box_reg: 1.0696 | loss_mask: 0.2905 | loss_rpn_cls: 0.0053 | loss_rpn_loc: 0.0154 | Total Loss: 1.7134\n",
      "Epoch 0199 | loss_cls: 0.2268 | loss_box_reg: 0.4053 | loss_mask: 0.2475 | loss_rpn_cls: 0.0150 | loss_rpn_loc: 0.0315 | Total Loss: 0.9261\n",
      "\u001b[32m[07/29 18:22:18 d2.utils.events]: \u001b[0m eta: 0:16:09  iter: 199      time: 0.3246  last_time: 0.3873   lr: 4.995e-05  max_mem: 2290M\n",
      "Epoch 0200 | loss_cls: 0.2571 | loss_box_reg: 0.7252 | loss_mask: 0.2257 | loss_rpn_cls: 0.9030 | loss_rpn_loc: 0.2713 | Total Loss: 2.3823\n",
      "Epoch 0201 | loss_cls: 0.1798 | loss_box_reg: 0.3908 | loss_mask: 0.2384 | loss_rpn_cls: 0.0238 | loss_rpn_loc: 0.1600 | Total Loss: 0.9928\n",
      "Epoch 0202 | loss_cls: 0.3084 | loss_box_reg: 0.5102 | loss_mask: 0.3598 | loss_rpn_cls: 0.3596 | loss_rpn_loc: 0.3042 | Total Loss: 1.8422\n",
      "Epoch 0203 | loss_cls: 0.2521 | loss_box_reg: 0.4761 | loss_mask: 0.3051 | loss_rpn_cls: 0.0126 | loss_rpn_loc: 0.0102 | Total Loss: 1.0560\n",
      "Epoch 0204 | loss_cls: 0.1994 | loss_box_reg: 0.4581 | loss_mask: 0.3797 | loss_rpn_cls: 0.0083 | loss_rpn_loc: 0.0102 | Total Loss: 1.0557\n",
      "Epoch 0205 | loss_cls: 0.2140 | loss_box_reg: 0.4805 | loss_mask: 0.2023 | loss_rpn_cls: 0.0134 | loss_rpn_loc: 0.0203 | Total Loss: 0.9305\n",
      "Epoch 0206 | loss_cls: 0.3277 | loss_box_reg: 0.6853 | loss_mask: 0.3133 | loss_rpn_cls: 1.0459 | loss_rpn_loc: 0.3494 | Total Loss: 2.7217\n",
      "Epoch 0207 | loss_cls: 0.2787 | loss_box_reg: 0.5864 | loss_mask: 0.2626 | loss_rpn_cls: 0.0505 | loss_rpn_loc: 0.0999 | Total Loss: 1.2781\n",
      "Epoch 0208 | loss_cls: 0.2809 | loss_box_reg: 0.8505 | loss_mask: 0.2914 | loss_rpn_cls: 0.1214 | loss_rpn_loc: 0.2095 | Total Loss: 1.7537\n",
      "Epoch 0209 | loss_cls: 0.1993 | loss_box_reg: 0.5460 | loss_mask: 0.2353 | loss_rpn_cls: 0.0164 | loss_rpn_loc: 0.0076 | Total Loss: 1.0047\n",
      "Epoch 0210 | loss_cls: 0.2775 | loss_box_reg: 0.7639 | loss_mask: 0.2893 | loss_rpn_cls: 0.2525 | loss_rpn_loc: 0.1006 | Total Loss: 1.6837\n",
      "Epoch 0211 | loss_cls: 0.3036 | loss_box_reg: 0.7919 | loss_mask: 0.3501 | loss_rpn_cls: 0.1848 | loss_rpn_loc: 0.1621 | Total Loss: 1.7925\n",
      "Epoch 0212 | loss_cls: 0.3080 | loss_box_reg: 0.7209 | loss_mask: 0.2104 | loss_rpn_cls: 0.0373 | loss_rpn_loc: 0.2245 | Total Loss: 1.5011\n",
      "Epoch 0213 | loss_cls: 0.1852 | loss_box_reg: 0.2524 | loss_mask: 0.2704 | loss_rpn_cls: 0.0126 | loss_rpn_loc: 0.1950 | Total Loss: 0.9156\n",
      "Epoch 0214 | loss_cls: 0.3305 | loss_box_reg: 1.0761 | loss_mask: 0.2561 | loss_rpn_cls: 0.0337 | loss_rpn_loc: 0.0487 | Total Loss: 1.7452\n",
      "Epoch 0215 | loss_cls: 0.3015 | loss_box_reg: 0.5977 | loss_mask: 0.2488 | loss_rpn_cls: 0.4894 | loss_rpn_loc: 0.1830 | Total Loss: 1.8204\n",
      "Epoch 0216 | loss_cls: 0.2974 | loss_box_reg: 0.8100 | loss_mask: 0.2870 | loss_rpn_cls: 0.0132 | loss_rpn_loc: 0.0438 | Total Loss: 1.4513\n",
      "Epoch 0217 | loss_cls: 0.1718 | loss_box_reg: 0.4130 | loss_mask: 0.1907 | loss_rpn_cls: 0.0107 | loss_rpn_loc: 0.0301 | Total Loss: 0.8163\n",
      "Epoch 0218 | loss_cls: 0.3319 | loss_box_reg: 0.9771 | loss_mask: 0.3115 | loss_rpn_cls: 0.0042 | loss_rpn_loc: 0.0516 | Total Loss: 1.6762\n",
      "Epoch 0219 | loss_cls: 0.1579 | loss_box_reg: 0.2216 | loss_mask: 0.2658 | loss_rpn_cls: 0.0062 | loss_rpn_loc: 0.0207 | Total Loss: 0.6722\n",
      " Best model saved at Epoch 219 | Total Loss: 0.6722\n",
      "\u001b[32m[07/29 18:22:24 d2.utils.events]: \u001b[0m eta: 0:16:04  iter: 219      time: 0.3252  last_time: 0.5053   lr: 5.4945e-05  max_mem: 2290M\n",
      "Epoch 0220 | loss_cls: 0.2317 | loss_box_reg: 0.6749 | loss_mask: 0.1963 | loss_rpn_cls: 0.0100 | loss_rpn_loc: 0.0057 | Total Loss: 1.1185\n",
      "Epoch 0221 | loss_cls: 0.1749 | loss_box_reg: 0.4484 | loss_mask: 0.1559 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.0145 | Total Loss: 0.7988\n",
      "Epoch 0222 | loss_cls: 0.1879 | loss_box_reg: 0.3764 | loss_mask: 0.1964 | loss_rpn_cls: 0.0298 | loss_rpn_loc: 0.0661 | Total Loss: 0.8566\n",
      "Epoch 0223 | loss_cls: 0.2481 | loss_box_reg: 0.6022 | loss_mask: 0.2747 | loss_rpn_cls: 0.8529 | loss_rpn_loc: 0.6095 | Total Loss: 2.5874\n",
      "Epoch 0224 | loss_cls: 0.1706 | loss_box_reg: 0.1957 | loss_mask: 0.1837 | loss_rpn_cls: 0.0065 | loss_rpn_loc: 0.0417 | Total Loss: 0.5982\n",
      " Best model saved at Epoch 224 | Total Loss: 0.5982\n",
      "Epoch 0225 | loss_cls: 0.2861 | loss_box_reg: 0.7658 | loss_mask: 0.3097 | loss_rpn_cls: 0.1699 | loss_rpn_loc: 0.2176 | Total Loss: 1.7490\n",
      "Epoch 0226 | loss_cls: 0.3212 | loss_box_reg: 0.8136 | loss_mask: 0.1715 | loss_rpn_cls: 0.1835 | loss_rpn_loc: 0.2698 | Total Loss: 1.7596\n",
      "Epoch 0227 | loss_cls: 0.2219 | loss_box_reg: 0.5741 | loss_mask: 0.2192 | loss_rpn_cls: 0.0105 | loss_rpn_loc: 0.0292 | Total Loss: 1.0548\n",
      "Epoch 0228 | loss_cls: 0.2646 | loss_box_reg: 0.6619 | loss_mask: 0.3340 | loss_rpn_cls: 0.0072 | loss_rpn_loc: 0.1711 | Total Loss: 1.4387\n",
      "Epoch 0229 | loss_cls: 0.1682 | loss_box_reg: 0.3007 | loss_mask: 0.1825 | loss_rpn_cls: 0.0296 | loss_rpn_loc: 0.0879 | Total Loss: 0.7689\n",
      "Epoch 0230 | loss_cls: 0.2195 | loss_box_reg: 0.3238 | loss_mask: 0.2736 | loss_rpn_cls: 0.0277 | loss_rpn_loc: 0.2285 | Total Loss: 1.0731\n",
      "Epoch 0231 | loss_cls: 0.2505 | loss_box_reg: 0.6781 | loss_mask: 0.1694 | loss_rpn_cls: 0.0305 | loss_rpn_loc: 0.0129 | Total Loss: 1.1414\n",
      "Epoch 0232 | loss_cls: 0.2757 | loss_box_reg: 0.4861 | loss_mask: 0.2524 | loss_rpn_cls: 0.1644 | loss_rpn_loc: 0.1599 | Total Loss: 1.3385\n",
      "Epoch 0233 | loss_cls: 0.2327 | loss_box_reg: 0.5252 | loss_mask: 0.1799 | loss_rpn_cls: 0.0117 | loss_rpn_loc: 0.0505 | Total Loss: 1.0001\n",
      "Epoch 0234 | loss_cls: 0.2127 | loss_box_reg: 0.4116 | loss_mask: 0.2033 | loss_rpn_cls: 0.0157 | loss_rpn_loc: 0.1769 | Total Loss: 1.0202\n",
      "Epoch 0235 | loss_cls: 0.2980 | loss_box_reg: 0.9360 | loss_mask: 0.1931 | loss_rpn_cls: 0.0411 | loss_rpn_loc: 0.0459 | Total Loss: 1.5140\n",
      "Epoch 0236 | loss_cls: 0.2091 | loss_box_reg: 0.7516 | loss_mask: 0.1534 | loss_rpn_cls: 0.0193 | loss_rpn_loc: 0.0056 | Total Loss: 1.1390\n",
      "Epoch 0237 | loss_cls: 0.3155 | loss_box_reg: 0.8870 | loss_mask: 0.2072 | loss_rpn_cls: 0.2732 | loss_rpn_loc: 0.1533 | Total Loss: 1.8362\n",
      "Epoch 0238 | loss_cls: 0.2550 | loss_box_reg: 0.6387 | loss_mask: 0.2671 | loss_rpn_cls: 0.0680 | loss_rpn_loc: 0.1621 | Total Loss: 1.3908\n",
      "Epoch 0239 | loss_cls: 0.3088 | loss_box_reg: 0.6939 | loss_mask: 0.2644 | loss_rpn_cls: 0.4372 | loss_rpn_loc: 0.3635 | Total Loss: 2.0678\n",
      "\u001b[32m[07/29 18:22:31 d2.utils.events]: \u001b[0m eta: 0:15:59  iter: 239      time: 0.3281  last_time: 0.2533   lr: 5.994e-05  max_mem: 2290M\n",
      "Epoch 0240 | loss_cls: 0.2720 | loss_box_reg: 0.5799 | loss_mask: 0.2598 | loss_rpn_cls: 0.0173 | loss_rpn_loc: 0.0286 | Total Loss: 1.1576\n",
      "Epoch 0241 | loss_cls: 0.1808 | loss_box_reg: 0.2611 | loss_mask: 0.2270 | loss_rpn_cls: 0.0227 | loss_rpn_loc: 0.2615 | Total Loss: 0.9532\n",
      "Epoch 0242 | loss_cls: 0.2297 | loss_box_reg: 0.5561 | loss_mask: 0.2380 | loss_rpn_cls: 0.0309 | loss_rpn_loc: 0.0647 | Total Loss: 1.1193\n",
      "Epoch 0243 | loss_cls: 0.2312 | loss_box_reg: 0.6933 | loss_mask: 0.2022 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.0078 | Total Loss: 1.1372\n",
      "Epoch 0244 | loss_cls: 0.1540 | loss_box_reg: 0.1890 | loss_mask: 0.7113 | loss_rpn_cls: 0.0036 | loss_rpn_loc: 0.1537 | Total Loss: 1.2116\n",
      "Epoch 0245 | loss_cls: 0.2098 | loss_box_reg: 0.3297 | loss_mask: 0.3268 | loss_rpn_cls: 0.2502 | loss_rpn_loc: 0.1808 | Total Loss: 1.2973\n",
      "Epoch 0246 | loss_cls: 0.1452 | loss_box_reg: 0.2180 | loss_mask: 0.1609 | loss_rpn_cls: 0.0063 | loss_rpn_loc: 0.1430 | Total Loss: 0.6734\n",
      "Epoch 0247 | loss_cls: 0.2086 | loss_box_reg: 0.5390 | loss_mask: 0.2433 | loss_rpn_cls: 0.0106 | loss_rpn_loc: 0.0108 | Total Loss: 1.0123\n",
      "Epoch 0248 | loss_cls: 0.2275 | loss_box_reg: 0.5216 | loss_mask: 0.2229 | loss_rpn_cls: 0.0075 | loss_rpn_loc: 0.0864 | Total Loss: 1.0659\n",
      "Epoch 0249 | loss_cls: 0.2260 | loss_box_reg: 0.5203 | loss_mask: 0.2161 | loss_rpn_cls: 0.0391 | loss_rpn_loc: 0.0186 | Total Loss: 1.0201\n",
      "Epoch 0250 | loss_cls: 0.2547 | loss_box_reg: 0.8278 | loss_mask: 0.2047 | loss_rpn_cls: 0.0519 | loss_rpn_loc: 0.2145 | Total Loss: 1.5534\n",
      "Epoch 0251 | loss_cls: 0.2387 | loss_box_reg: 0.6844 | loss_mask: 0.1653 | loss_rpn_cls: 0.0224 | loss_rpn_loc: 0.0223 | Total Loss: 1.1331\n",
      "Epoch 0252 | loss_cls: 0.3370 | loss_box_reg: 0.9844 | loss_mask: 0.2823 | loss_rpn_cls: 0.0055 | loss_rpn_loc: 0.0113 | Total Loss: 1.6204\n",
      "Epoch 0253 | loss_cls: 0.1386 | loss_box_reg: 0.2092 | loss_mask: 0.1276 | loss_rpn_cls: 0.0252 | loss_rpn_loc: 0.2777 | Total Loss: 0.7783\n",
      "Epoch 0254 | loss_cls: 0.2987 | loss_box_reg: 0.9636 | loss_mask: 0.1627 | loss_rpn_cls: 0.1057 | loss_rpn_loc: 0.0680 | Total Loss: 1.5987\n",
      "Epoch 0255 | loss_cls: 0.2408 | loss_box_reg: 0.7728 | loss_mask: 0.3081 | loss_rpn_cls: 0.0414 | loss_rpn_loc: 0.0424 | Total Loss: 1.4055\n",
      "Epoch 0256 | loss_cls: 0.1706 | loss_box_reg: 0.4042 | loss_mask: 0.2276 | loss_rpn_cls: 0.0114 | loss_rpn_loc: 0.0247 | Total Loss: 0.8385\n",
      "Epoch 0257 | loss_cls: 0.1594 | loss_box_reg: 0.3798 | loss_mask: 0.3384 | loss_rpn_cls: 0.0198 | loss_rpn_loc: 0.2382 | Total Loss: 1.1356\n",
      "Epoch 0258 | loss_cls: 0.1288 | loss_box_reg: 0.2222 | loss_mask: 0.2022 | loss_rpn_cls: 0.0064 | loss_rpn_loc: 0.1736 | Total Loss: 0.7332\n",
      "Epoch 0259 | loss_cls: 0.2054 | loss_box_reg: 0.5807 | loss_mask: 0.2392 | loss_rpn_cls: 0.0134 | loss_rpn_loc: 0.0770 | Total Loss: 1.1157\n",
      "\u001b[32m[07/29 18:22:38 d2.utils.events]: \u001b[0m eta: 0:15:54  iter: 259      time: 0.3277  last_time: 0.3873   lr: 6.4935e-05  max_mem: 2291M\n",
      "Epoch 0260 | loss_cls: 0.1446 | loss_box_reg: 0.3636 | loss_mask: 0.1733 | loss_rpn_cls: 0.0105 | loss_rpn_loc: 0.1377 | Total Loss: 0.8296\n",
      "Epoch 0261 | loss_cls: 0.1850 | loss_box_reg: 0.6167 | loss_mask: 0.2311 | loss_rpn_cls: 0.0046 | loss_rpn_loc: 0.0138 | Total Loss: 1.0512\n",
      "Epoch 0262 | loss_cls: 0.1405 | loss_box_reg: 0.2953 | loss_mask: 0.1022 | loss_rpn_cls: 0.0304 | loss_rpn_loc: 0.1505 | Total Loss: 0.7189\n",
      "Epoch 0263 | loss_cls: 0.2575 | loss_box_reg: 0.7786 | loss_mask: 0.2221 | loss_rpn_cls: 0.1124 | loss_rpn_loc: 0.1180 | Total Loss: 1.4886\n",
      "Epoch 0264 | loss_cls: 0.3023 | loss_box_reg: 0.9838 | loss_mask: 0.2313 | loss_rpn_cls: 0.0020 | loss_rpn_loc: 0.0395 | Total Loss: 1.5588\n",
      "Epoch 0265 | loss_cls: 0.2244 | loss_box_reg: 0.9186 | loss_mask: 0.1324 | loss_rpn_cls: 0.0073 | loss_rpn_loc: 0.0129 | Total Loss: 1.2957\n",
      "Epoch 0266 | loss_cls: 0.2461 | loss_box_reg: 0.6887 | loss_mask: 0.1835 | loss_rpn_cls: 0.0140 | loss_rpn_loc: 0.0153 | Total Loss: 1.1476\n",
      "Epoch 0267 | loss_cls: 0.1614 | loss_box_reg: 0.4012 | loss_mask: 0.1409 | loss_rpn_cls: 0.0037 | loss_rpn_loc: 0.0261 | Total Loss: 0.7334\n",
      "Epoch 0268 | loss_cls: 0.1485 | loss_box_reg: 0.5262 | loss_mask: 0.1365 | loss_rpn_cls: 0.0022 | loss_rpn_loc: 0.0165 | Total Loss: 0.8298\n",
      "Epoch 0269 | loss_cls: 0.2834 | loss_box_reg: 0.7000 | loss_mask: 0.5212 | loss_rpn_cls: 0.0202 | loss_rpn_loc: 0.0257 | Total Loss: 1.5505\n",
      "Epoch 0270 | loss_cls: 0.2210 | loss_box_reg: 0.7468 | loss_mask: 0.1369 | loss_rpn_cls: 0.0003 | loss_rpn_loc: 0.0406 | Total Loss: 1.1456\n",
      "Epoch 0271 | loss_cls: 0.1808 | loss_box_reg: 0.5626 | loss_mask: 0.1622 | loss_rpn_cls: 0.0031 | loss_rpn_loc: 0.0287 | Total Loss: 0.9375\n",
      "Epoch 0272 | loss_cls: 0.1927 | loss_box_reg: 0.6019 | loss_mask: 0.1631 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.0526 | Total Loss: 1.0114\n",
      "Epoch 0273 | loss_cls: 0.2648 | loss_box_reg: 0.5689 | loss_mask: 0.2789 | loss_rpn_cls: 0.0170 | loss_rpn_loc: 0.1045 | Total Loss: 1.2341\n",
      "Epoch 0274 | loss_cls: 0.3251 | loss_box_reg: 0.9731 | loss_mask: 0.1469 | loss_rpn_cls: 0.0348 | loss_rpn_loc: 0.0494 | Total Loss: 1.5292\n",
      "Epoch 0275 | loss_cls: 0.2592 | loss_box_reg: 0.8778 | loss_mask: 0.1501 | loss_rpn_cls: 0.5304 | loss_rpn_loc: 0.2861 | Total Loss: 2.1036\n",
      "Epoch 0276 | loss_cls: 0.1969 | loss_box_reg: 0.7976 | loss_mask: 0.1486 | loss_rpn_cls: 0.0103 | loss_rpn_loc: 0.0108 | Total Loss: 1.1642\n",
      "Epoch 0277 | loss_cls: 0.2083 | loss_box_reg: 0.6996 | loss_mask: 0.1747 | loss_rpn_cls: 0.0127 | loss_rpn_loc: 0.0716 | Total Loss: 1.1668\n",
      "Epoch 0278 | loss_cls: 0.2145 | loss_box_reg: 0.7228 | loss_mask: 0.1892 | loss_rpn_cls: 0.1777 | loss_rpn_loc: 0.0792 | Total Loss: 1.3835\n",
      "Epoch 0279 | loss_cls: 0.1753 | loss_box_reg: 0.2938 | loss_mask: 0.1684 | loss_rpn_cls: 0.0039 | loss_rpn_loc: 0.1713 | Total Loss: 0.8127\n",
      "\u001b[32m[07/29 18:22:44 d2.utils.events]: \u001b[0m eta: 0:15:50  iter: 279      time: 0.3272  last_time: 0.3766   lr: 6.993e-05  max_mem: 2291M\n",
      "Epoch 0280 | loss_cls: 0.2266 | loss_box_reg: 0.5906 | loss_mask: 0.2879 | loss_rpn_cls: 0.0125 | loss_rpn_loc: 0.0450 | Total Loss: 1.1625\n",
      "Epoch 0281 | loss_cls: 0.1446 | loss_box_reg: 0.3161 | loss_mask: 0.2124 | loss_rpn_cls: 0.0161 | loss_rpn_loc: 0.0153 | Total Loss: 0.7045\n",
      "Epoch 0282 | loss_cls: 0.1890 | loss_box_reg: 0.5139 | loss_mask: 0.2931 | loss_rpn_cls: 0.0129 | loss_rpn_loc: 0.0072 | Total Loss: 1.0161\n",
      "Epoch 0283 | loss_cls: 0.2106 | loss_box_reg: 0.9080 | loss_mask: 0.1701 | loss_rpn_cls: 0.0267 | loss_rpn_loc: 0.0386 | Total Loss: 1.3540\n",
      "Epoch 0284 | loss_cls: 0.1366 | loss_box_reg: 0.2571 | loss_mask: 0.2753 | loss_rpn_cls: 0.0117 | loss_rpn_loc: 0.3297 | Total Loss: 1.0105\n",
      "Epoch 0285 | loss_cls: 0.1423 | loss_box_reg: 0.3432 | loss_mask: 0.1575 | loss_rpn_cls: 0.0110 | loss_rpn_loc: 0.1686 | Total Loss: 0.8226\n",
      "Epoch 0286 | loss_cls: 0.1294 | loss_box_reg: 0.5353 | loss_mask: 0.4437 | loss_rpn_cls: 0.0098 | loss_rpn_loc: 0.0052 | Total Loss: 1.1234\n",
      "Epoch 0287 | loss_cls: 0.1724 | loss_box_reg: 0.6344 | loss_mask: 0.1345 | loss_rpn_cls: 0.0030 | loss_rpn_loc: 0.0194 | Total Loss: 0.9637\n",
      "Epoch 0288 | loss_cls: 0.1937 | loss_box_reg: 0.6588 | loss_mask: 0.1594 | loss_rpn_cls: 0.0179 | loss_rpn_loc: 0.0856 | Total Loss: 1.1153\n",
      "Epoch 0289 | loss_cls: 0.2492 | loss_box_reg: 0.8834 | loss_mask: 0.1682 | loss_rpn_cls: 0.2293 | loss_rpn_loc: 0.1601 | Total Loss: 1.6902\n",
      "Epoch 0290 | loss_cls: 0.2609 | loss_box_reg: 0.9490 | loss_mask: 0.2677 | loss_rpn_cls: 0.0217 | loss_rpn_loc: 0.0197 | Total Loss: 1.5189\n",
      "Epoch 0291 | loss_cls: 0.1503 | loss_box_reg: 0.3734 | loss_mask: 0.2917 | loss_rpn_cls: 0.0031 | loss_rpn_loc: 0.0141 | Total Loss: 0.8326\n",
      "Epoch 0292 | loss_cls: 0.2449 | loss_box_reg: 0.6185 | loss_mask: 0.0795 | loss_rpn_cls: 0.1135 | loss_rpn_loc: 0.0528 | Total Loss: 1.1092\n",
      "Epoch 0293 | loss_cls: 0.1432 | loss_box_reg: 0.2500 | loss_mask: 0.2179 | loss_rpn_cls: 0.0049 | loss_rpn_loc: 0.1487 | Total Loss: 0.7648\n",
      "Epoch 0294 | loss_cls: 0.2339 | loss_box_reg: 0.7333 | loss_mask: 0.1847 | loss_rpn_cls: 1.2044 | loss_rpn_loc: 1.0152 | Total Loss: 3.3714\n",
      "Epoch 0295 | loss_cls: 0.1427 | loss_box_reg: 0.1985 | loss_mask: 0.6052 | loss_rpn_cls: 0.0150 | loss_rpn_loc: 0.1044 | Total Loss: 1.0656\n",
      "Epoch 0296 | loss_cls: 0.2461 | loss_box_reg: 0.6166 | loss_mask: 0.2115 | loss_rpn_cls: 0.0345 | loss_rpn_loc: 0.1015 | Total Loss: 1.2102\n",
      "Epoch 0297 | loss_cls: 0.3372 | loss_box_reg: 0.9818 | loss_mask: 0.1576 | loss_rpn_cls: 0.1097 | loss_rpn_loc: 0.0862 | Total Loss: 1.6725\n",
      "Epoch 0298 | loss_cls: 0.1387 | loss_box_reg: 0.4478 | loss_mask: 0.1879 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.0191 | Total Loss: 0.7949\n",
      "Epoch 0299 | loss_cls: 0.2019 | loss_box_reg: 0.5180 | loss_mask: 0.1772 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.0532 | Total Loss: 0.9536\n",
      "\u001b[32m[07/29 18:22:51 d2.utils.events]: \u001b[0m eta: 0:15:43  iter: 299      time: 0.3269  last_time: 0.3865   lr: 7.4925e-05  max_mem: 2291M\n",
      "Epoch 0300 | loss_cls: 0.2415 | loss_box_reg: 0.3709 | loss_mask: 0.1909 | loss_rpn_cls: 0.0523 | loss_rpn_loc: 0.0411 | Total Loss: 0.8968\n",
      "Epoch 0301 | loss_cls: 0.2122 | loss_box_reg: 0.6288 | loss_mask: 0.1883 | loss_rpn_cls: 0.0119 | loss_rpn_loc: 0.1945 | Total Loss: 1.2358\n",
      "Epoch 0302 | loss_cls: 0.1641 | loss_box_reg: 0.6749 | loss_mask: 0.1475 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.0283 | Total Loss: 1.0184\n",
      "Epoch 0303 | loss_cls: 0.1802 | loss_box_reg: 0.5802 | loss_mask: 0.2245 | loss_rpn_cls: 0.0628 | loss_rpn_loc: 0.2600 | Total Loss: 1.3076\n",
      "Epoch 0304 | loss_cls: 0.1598 | loss_box_reg: 0.2634 | loss_mask: 0.2327 | loss_rpn_cls: 0.0087 | loss_rpn_loc: 0.2188 | Total Loss: 0.8834\n",
      "Epoch 0305 | loss_cls: 0.2948 | loss_box_reg: 0.9513 | loss_mask: 0.2162 | loss_rpn_cls: 0.0867 | loss_rpn_loc: 0.1657 | Total Loss: 1.7148\n",
      "Epoch 0306 | loss_cls: 0.2338 | loss_box_reg: 0.7307 | loss_mask: 0.1771 | loss_rpn_cls: 0.0158 | loss_rpn_loc: 0.0446 | Total Loss: 1.2020\n",
      "Epoch 0307 | loss_cls: 0.1876 | loss_box_reg: 0.7417 | loss_mask: 0.1874 | loss_rpn_cls: 0.0256 | loss_rpn_loc: 0.1369 | Total Loss: 1.2793\n",
      "Epoch 0308 | loss_cls: 0.0943 | loss_box_reg: 0.2852 | loss_mask: 0.0899 | loss_rpn_cls: 0.0035 | loss_rpn_loc: 0.0171 | Total Loss: 0.4900\n",
      " Best model saved at Epoch 308 | Total Loss: 0.4900\n",
      "Epoch 0309 | loss_cls: 0.1723 | loss_box_reg: 0.3022 | loss_mask: 0.2702 | loss_rpn_cls: 0.0081 | loss_rpn_loc: 0.2124 | Total Loss: 0.9653\n",
      "Epoch 0310 | loss_cls: 0.2604 | loss_box_reg: 0.7951 | loss_mask: 0.1559 | loss_rpn_cls: 0.0272 | loss_rpn_loc: 0.0081 | Total Loss: 1.2466\n",
      "Epoch 0311 | loss_cls: 0.1350 | loss_box_reg: 0.3462 | loss_mask: 0.1018 | loss_rpn_cls: 0.0303 | loss_rpn_loc: 0.1060 | Total Loss: 0.7194\n",
      "Epoch 0312 | loss_cls: 0.1312 | loss_box_reg: 0.3908 | loss_mask: 0.2391 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.1390 | Total Loss: 0.9050\n",
      "Epoch 0313 | loss_cls: 0.1881 | loss_box_reg: 0.7888 | loss_mask: 0.1611 | loss_rpn_cls: 0.0016 | loss_rpn_loc: 0.0144 | Total Loss: 1.1540\n",
      "Epoch 0314 | loss_cls: 0.1904 | loss_box_reg: 0.4527 | loss_mask: 0.1228 | loss_rpn_cls: 0.0656 | loss_rpn_loc: 0.3056 | Total Loss: 1.1371\n",
      "Epoch 0315 | loss_cls: 0.2748 | loss_box_reg: 0.7681 | loss_mask: 0.2486 | loss_rpn_cls: 0.0043 | loss_rpn_loc: 0.0728 | Total Loss: 1.3685\n",
      "Epoch 0316 | loss_cls: 0.1416 | loss_box_reg: 0.3502 | loss_mask: 0.1497 | loss_rpn_cls: 0.0280 | loss_rpn_loc: 0.0612 | Total Loss: 0.7308\n",
      "Epoch 0317 | loss_cls: 0.1240 | loss_box_reg: 0.4426 | loss_mask: 0.1093 | loss_rpn_cls: 0.0071 | loss_rpn_loc: 0.0094 | Total Loss: 0.6925\n",
      "Epoch 0318 | loss_cls: 0.2052 | loss_box_reg: 0.6444 | loss_mask: 0.1167 | loss_rpn_cls: 0.0096 | loss_rpn_loc: 0.0135 | Total Loss: 0.9894\n",
      "Epoch 0319 | loss_cls: 0.1196 | loss_box_reg: 0.2297 | loss_mask: 0.2808 | loss_rpn_cls: 0.0098 | loss_rpn_loc: 0.0414 | Total Loss: 0.6812\n",
      "\u001b[32m[07/29 18:22:58 d2.utils.events]: \u001b[0m eta: 0:15:41  iter: 319      time: 0.3289  last_time: 0.3882   lr: 7.992e-05  max_mem: 2291M\n",
      "Epoch 0320 | loss_cls: 0.2141 | loss_box_reg: 0.5913 | loss_mask: 0.1299 | loss_rpn_cls: 0.0095 | loss_rpn_loc: 0.0879 | Total Loss: 1.0326\n",
      "Epoch 0321 | loss_cls: 0.1206 | loss_box_reg: 0.3944 | loss_mask: 0.1604 | loss_rpn_cls: 0.0060 | loss_rpn_loc: 0.1574 | Total Loss: 0.8387\n",
      "Epoch 0322 | loss_cls: 0.1185 | loss_box_reg: 0.3081 | loss_mask: 0.1092 | loss_rpn_cls: 0.0292 | loss_rpn_loc: 0.0091 | Total Loss: 0.5740\n",
      "Epoch 0323 | loss_cls: 0.1073 | loss_box_reg: 0.2624 | loss_mask: 0.1478 | loss_rpn_cls: 0.0060 | loss_rpn_loc: 0.0519 | Total Loss: 0.5756\n",
      "Epoch 0324 | loss_cls: 0.3073 | loss_box_reg: 0.7626 | loss_mask: 0.1148 | loss_rpn_cls: 0.0264 | loss_rpn_loc: 0.0496 | Total Loss: 1.2607\n",
      "Epoch 0325 | loss_cls: 0.1922 | loss_box_reg: 0.6425 | loss_mask: 0.1762 | loss_rpn_cls: 0.0001 | loss_rpn_loc: 0.0150 | Total Loss: 1.0260\n",
      "Epoch 0326 | loss_cls: 0.1379 | loss_box_reg: 0.2201 | loss_mask: 0.1877 | loss_rpn_cls: 0.0070 | loss_rpn_loc: 0.0188 | Total Loss: 0.5715\n",
      "Epoch 0327 | loss_cls: 0.2834 | loss_box_reg: 0.9240 | loss_mask: 0.2411 | loss_rpn_cls: 0.0109 | loss_rpn_loc: 0.0486 | Total Loss: 1.5080\n",
      "Epoch 0328 | loss_cls: 0.1473 | loss_box_reg: 0.4888 | loss_mask: 0.6125 | loss_rpn_cls: 0.0108 | loss_rpn_loc: 0.0852 | Total Loss: 1.3445\n",
      "Epoch 0329 | loss_cls: 0.1518 | loss_box_reg: 0.4062 | loss_mask: 0.1665 | loss_rpn_cls: 0.0116 | loss_rpn_loc: 0.0204 | Total Loss: 0.7566\n",
      "Epoch 0330 | loss_cls: 0.1771 | loss_box_reg: 0.3682 | loss_mask: 0.1461 | loss_rpn_cls: 0.0079 | loss_rpn_loc: 0.1935 | Total Loss: 0.8929\n",
      "Epoch 0331 | loss_cls: 0.1574 | loss_box_reg: 0.3583 | loss_mask: 0.5363 | loss_rpn_cls: 0.0192 | loss_rpn_loc: 0.1393 | Total Loss: 1.2104\n",
      "Epoch 0332 | loss_cls: 0.1919 | loss_box_reg: 0.7061 | loss_mask: 0.1341 | loss_rpn_cls: 0.0114 | loss_rpn_loc: 0.0134 | Total Loss: 1.0569\n",
      "Epoch 0333 | loss_cls: 0.1670 | loss_box_reg: 0.4280 | loss_mask: 0.1588 | loss_rpn_cls: 0.0125 | loss_rpn_loc: 0.0242 | Total Loss: 0.7905\n",
      "Epoch 0334 | loss_cls: 0.1341 | loss_box_reg: 0.3996 | loss_mask: 0.1277 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0122 | Total Loss: 0.6743\n",
      "Epoch 0335 | loss_cls: 0.1853 | loss_box_reg: 0.4201 | loss_mask: 0.0870 | loss_rpn_cls: 0.0557 | loss_rpn_loc: 0.0480 | Total Loss: 0.7962\n",
      "Epoch 0336 | loss_cls: 0.1462 | loss_box_reg: 0.5004 | loss_mask: 0.1102 | loss_rpn_cls: 0.0053 | loss_rpn_loc: 0.0800 | Total Loss: 0.8421\n",
      "Epoch 0337 | loss_cls: 0.1573 | loss_box_reg: 0.4724 | loss_mask: 0.0905 | loss_rpn_cls: 0.9997 | loss_rpn_loc: 0.8177 | Total Loss: 2.5377\n",
      "Epoch 0338 | loss_cls: 0.1107 | loss_box_reg: 0.2700 | loss_mask: 0.3368 | loss_rpn_cls: 0.0241 | loss_rpn_loc: 0.0215 | Total Loss: 0.7631\n",
      "Epoch 0339 | loss_cls: 0.1552 | loss_box_reg: 0.4847 | loss_mask: 0.2137 | loss_rpn_cls: 0.0247 | loss_rpn_loc: 0.0576 | Total Loss: 0.9359\n",
      "\u001b[32m[07/29 18:23:05 d2.utils.events]: \u001b[0m eta: 0:15:41  iter: 339      time: 0.3299  last_time: 0.3929   lr: 8.4915e-05  max_mem: 2291M\n",
      "Epoch 0340 | loss_cls: 0.1317 | loss_box_reg: 0.4681 | loss_mask: 0.0906 | loss_rpn_cls: 0.0117 | loss_rpn_loc: 0.1260 | Total Loss: 0.8282\n",
      "Epoch 0341 | loss_cls: 0.0787 | loss_box_reg: 0.1300 | loss_mask: 0.1511 | loss_rpn_cls: 0.0149 | loss_rpn_loc: 0.2719 | Total Loss: 0.6467\n",
      "Epoch 0342 | loss_cls: 0.1466 | loss_box_reg: 0.5644 | loss_mask: 0.1466 | loss_rpn_cls: 0.1324 | loss_rpn_loc: 0.1216 | Total Loss: 1.1115\n",
      "Epoch 0343 | loss_cls: 0.2016 | loss_box_reg: 0.5722 | loss_mask: 0.1466 | loss_rpn_cls: 0.1007 | loss_rpn_loc: 0.0811 | Total Loss: 1.1022\n",
      "Epoch 0344 | loss_cls: 0.1600 | loss_box_reg: 0.6256 | loss_mask: 0.1577 | loss_rpn_cls: 0.0111 | loss_rpn_loc: 0.0405 | Total Loss: 0.9949\n",
      "Epoch 0345 | loss_cls: 0.1459 | loss_box_reg: 0.3526 | loss_mask: 0.2056 | loss_rpn_cls: 0.0074 | loss_rpn_loc: 0.1232 | Total Loss: 0.8345\n",
      "Epoch 0346 | loss_cls: 0.2696 | loss_box_reg: 0.4558 | loss_mask: 0.1167 | loss_rpn_cls: 0.0148 | loss_rpn_loc: 0.1193 | Total Loss: 0.9762\n",
      "Epoch 0347 | loss_cls: 0.1403 | loss_box_reg: 0.5633 | loss_mask: 0.1367 | loss_rpn_cls: 0.0016 | loss_rpn_loc: 0.0414 | Total Loss: 0.8833\n",
      "Epoch 0348 | loss_cls: 0.2354 | loss_box_reg: 0.5376 | loss_mask: 0.2545 | loss_rpn_cls: 0.0260 | loss_rpn_loc: 0.0270 | Total Loss: 1.0805\n",
      "Epoch 0349 | loss_cls: 0.1682 | loss_box_reg: 0.6401 | loss_mask: 0.1467 | loss_rpn_cls: 0.0084 | loss_rpn_loc: 0.2197 | Total Loss: 1.1832\n",
      "Epoch 0350 | loss_cls: 0.1723 | loss_box_reg: 0.4398 | loss_mask: 0.1604 | loss_rpn_cls: 0.0255 | loss_rpn_loc: 0.0095 | Total Loss: 0.8074\n",
      "Epoch 0351 | loss_cls: 0.1296 | loss_box_reg: 0.4842 | loss_mask: 0.2258 | loss_rpn_cls: 0.0056 | loss_rpn_loc: 0.0809 | Total Loss: 0.9261\n",
      "Epoch 0352 | loss_cls: 0.2592 | loss_box_reg: 0.9814 | loss_mask: 0.2742 | loss_rpn_cls: 0.0318 | loss_rpn_loc: 0.1147 | Total Loss: 1.6612\n",
      "Epoch 0353 | loss_cls: 0.1822 | loss_box_reg: 0.5348 | loss_mask: 0.2133 | loss_rpn_cls: 0.0124 | loss_rpn_loc: 0.2421 | Total Loss: 1.1849\n",
      "Epoch 0354 | loss_cls: 0.1076 | loss_box_reg: 0.4057 | loss_mask: 0.3525 | loss_rpn_cls: 0.0073 | loss_rpn_loc: 0.0080 | Total Loss: 0.8811\n",
      "Epoch 0355 | loss_cls: 0.1879 | loss_box_reg: 0.4289 | loss_mask: 0.1574 | loss_rpn_cls: 0.0405 | loss_rpn_loc: 0.0701 | Total Loss: 0.8849\n",
      "Epoch 0356 | loss_cls: 0.2103 | loss_box_reg: 0.7330 | loss_mask: 0.1708 | loss_rpn_cls: 0.1612 | loss_rpn_loc: 0.2740 | Total Loss: 1.5493\n",
      "Epoch 0357 | loss_cls: 0.3584 | loss_box_reg: 0.8967 | loss_mask: 0.1918 | loss_rpn_cls: 0.0757 | loss_rpn_loc: 0.1350 | Total Loss: 1.6576\n",
      "Epoch 0358 | loss_cls: 0.1166 | loss_box_reg: 0.3274 | loss_mask: 0.0780 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0150 | Total Loss: 0.5376\n",
      "Epoch 0359 | loss_cls: 0.1981 | loss_box_reg: 0.7224 | loss_mask: 0.2543 | loss_rpn_cls: 0.0086 | loss_rpn_loc: 0.0791 | Total Loss: 1.2625\n",
      "\u001b[32m[07/29 18:23:11 d2.utils.events]: \u001b[0m eta: 0:15:31  iter: 359      time: 0.3288  last_time: 0.3980   lr: 8.991e-05  max_mem: 2291M\n",
      "Epoch 0360 | loss_cls: 0.2055 | loss_box_reg: 0.5064 | loss_mask: 0.2380 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.0427 | Total Loss: 0.9953\n",
      "Epoch 0361 | loss_cls: 0.2743 | loss_box_reg: 0.6949 | loss_mask: 0.1607 | loss_rpn_cls: 0.0199 | loss_rpn_loc: 0.1007 | Total Loss: 1.2504\n",
      "Epoch 0362 | loss_cls: 0.3081 | loss_box_reg: 0.6084 | loss_mask: 0.2062 | loss_rpn_cls: 0.0118 | loss_rpn_loc: 0.0719 | Total Loss: 1.2065\n",
      "Epoch 0363 | loss_cls: 0.1766 | loss_box_reg: 0.4434 | loss_mask: 0.2087 | loss_rpn_cls: 0.0110 | loss_rpn_loc: 0.1733 | Total Loss: 1.0130\n",
      "Epoch 0364 | loss_cls: 0.2052 | loss_box_reg: 0.7329 | loss_mask: 0.1673 | loss_rpn_cls: 0.0089 | loss_rpn_loc: 0.0717 | Total Loss: 1.1859\n",
      "Epoch 0365 | loss_cls: 0.1362 | loss_box_reg: 0.3918 | loss_mask: 0.2462 | loss_rpn_cls: 0.0126 | loss_rpn_loc: 0.0111 | Total Loss: 0.7979\n",
      "Epoch 0366 | loss_cls: 0.1503 | loss_box_reg: 0.5804 | loss_mask: 0.1261 | loss_rpn_cls: 0.0189 | loss_rpn_loc: 0.0127 | Total Loss: 0.8884\n",
      "Epoch 0367 | loss_cls: 0.1765 | loss_box_reg: 0.3069 | loss_mask: 0.1246 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.0282 | Total Loss: 0.6375\n",
      "Epoch 0368 | loss_cls: 0.1402 | loss_box_reg: 0.2970 | loss_mask: 0.1374 | loss_rpn_cls: 0.1502 | loss_rpn_loc: 0.2069 | Total Loss: 0.9318\n",
      "Epoch 0369 | loss_cls: 0.1413 | loss_box_reg: 0.2706 | loss_mask: 0.5281 | loss_rpn_cls: 0.0021 | loss_rpn_loc: 0.1247 | Total Loss: 1.0668\n",
      "Epoch 0370 | loss_cls: 0.1148 | loss_box_reg: 0.2555 | loss_mask: 0.1191 | loss_rpn_cls: 0.0099 | loss_rpn_loc: 0.1368 | Total Loss: 0.6361\n",
      "Epoch 0371 | loss_cls: 0.0855 | loss_box_reg: 0.1290 | loss_mask: 0.1060 | loss_rpn_cls: 0.0031 | loss_rpn_loc: 0.0113 | Total Loss: 0.3348\n",
      " Best model saved at Epoch 371 | Total Loss: 0.3348\n",
      "Epoch 0372 | loss_cls: 0.1723 | loss_box_reg: 0.4928 | loss_mask: 0.1846 | loss_rpn_cls: 0.0183 | loss_rpn_loc: 0.1122 | Total Loss: 0.9802\n",
      "Epoch 0373 | loss_cls: 0.2147 | loss_box_reg: 0.7172 | loss_mask: 0.1392 | loss_rpn_cls: 0.0208 | loss_rpn_loc: 0.0202 | Total Loss: 1.1120\n",
      "Epoch 0374 | loss_cls: 0.2523 | loss_box_reg: 0.6552 | loss_mask: 0.1046 | loss_rpn_cls: 0.0079 | loss_rpn_loc: 0.0090 | Total Loss: 1.0291\n",
      "Epoch 0375 | loss_cls: 0.0979 | loss_box_reg: 0.1461 | loss_mask: 0.2622 | loss_rpn_cls: 0.0202 | loss_rpn_loc: 0.1795 | Total Loss: 0.7060\n",
      "Epoch 0376 | loss_cls: 0.1411 | loss_box_reg: 0.1570 | loss_mask: 0.0925 | loss_rpn_cls: 0.0828 | loss_rpn_loc: 0.1470 | Total Loss: 0.6204\n",
      "Epoch 0377 | loss_cls: 0.1081 | loss_box_reg: 0.2017 | loss_mask: 0.3707 | loss_rpn_cls: 0.0174 | loss_rpn_loc: 0.1466 | Total Loss: 0.8445\n",
      "Epoch 0378 | loss_cls: 0.2039 | loss_box_reg: 0.5703 | loss_mask: 0.1896 | loss_rpn_cls: 0.0132 | loss_rpn_loc: 0.0207 | Total Loss: 0.9976\n",
      "Epoch 0379 | loss_cls: 0.1137 | loss_box_reg: 0.2041 | loss_mask: 0.8164 | loss_rpn_cls: 0.0277 | loss_rpn_loc: 0.0260 | Total Loss: 1.1879\n",
      "\u001b[32m[07/29 18:23:18 d2.utils.events]: \u001b[0m eta: 0:15:29  iter: 379      time: 0.3299  last_time: 0.2619   lr: 9.4905e-05  max_mem: 2291M\n",
      "Epoch 0380 | loss_cls: 0.1800 | loss_box_reg: 0.4287 | loss_mask: 0.1241 | loss_rpn_cls: 0.0235 | loss_rpn_loc: 0.0274 | Total Loss: 0.7836\n",
      "Epoch 0381 | loss_cls: 0.1428 | loss_box_reg: 0.5872 | loss_mask: 0.1342 | loss_rpn_cls: 0.0063 | loss_rpn_loc: 0.0125 | Total Loss: 0.8829\n",
      "Epoch 0382 | loss_cls: 0.2851 | loss_box_reg: 0.6615 | loss_mask: 0.2648 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.0883 | Total Loss: 1.3048\n",
      "Epoch 0383 | loss_cls: 0.2126 | loss_box_reg: 0.7226 | loss_mask: 0.1391 | loss_rpn_cls: 0.0437 | loss_rpn_loc: 0.1841 | Total Loss: 1.3021\n",
      "Epoch 0384 | loss_cls: 0.1206 | loss_box_reg: 0.2115 | loss_mask: 0.1183 | loss_rpn_cls: 0.0126 | loss_rpn_loc: 0.1162 | Total Loss: 0.5792\n",
      "Epoch 0385 | loss_cls: 0.1135 | loss_box_reg: 0.5469 | loss_mask: 0.0789 | loss_rpn_cls: 0.0141 | loss_rpn_loc: 0.0088 | Total Loss: 0.7623\n",
      "Epoch 0386 | loss_cls: 0.0873 | loss_box_reg: 0.2557 | loss_mask: 0.2206 | loss_rpn_cls: 0.0069 | loss_rpn_loc: 0.0184 | Total Loss: 0.5888\n",
      "Epoch 0387 | loss_cls: 0.1471 | loss_box_reg: 0.5157 | loss_mask: 0.1026 | loss_rpn_cls: 0.0099 | loss_rpn_loc: 0.0064 | Total Loss: 0.7817\n",
      "Epoch 0388 | loss_cls: 0.0946 | loss_box_reg: 0.2638 | loss_mask: 0.1293 | loss_rpn_cls: 0.0154 | loss_rpn_loc: 0.1551 | Total Loss: 0.6582\n",
      "Epoch 0389 | loss_cls: 0.0905 | loss_box_reg: 0.3019 | loss_mask: 0.2344 | loss_rpn_cls: 0.0140 | loss_rpn_loc: 0.1361 | Total Loss: 0.7769\n",
      "Epoch 0390 | loss_cls: 0.2522 | loss_box_reg: 0.6272 | loss_mask: 0.1570 | loss_rpn_cls: 0.0224 | loss_rpn_loc: 0.1009 | Total Loss: 1.1597\n",
      "Epoch 0391 | loss_cls: 0.1284 | loss_box_reg: 0.2508 | loss_mask: 0.2636 | loss_rpn_cls: 0.0297 | loss_rpn_loc: 0.1023 | Total Loss: 0.7747\n",
      "Epoch 0392 | loss_cls: 0.1449 | loss_box_reg: 0.2932 | loss_mask: 0.1181 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.0161 | Total Loss: 0.5757\n",
      "Epoch 0393 | loss_cls: 0.1058 | loss_box_reg: 0.1486 | loss_mask: 0.2884 | loss_rpn_cls: 0.0048 | loss_rpn_loc: 0.1669 | Total Loss: 0.7145\n",
      "Epoch 0394 | loss_cls: 0.1039 | loss_box_reg: 0.3712 | loss_mask: 0.1781 | loss_rpn_cls: 0.0088 | loss_rpn_loc: 0.0870 | Total Loss: 0.7491\n",
      "Epoch 0395 | loss_cls: 0.1859 | loss_box_reg: 0.4864 | loss_mask: 0.1761 | loss_rpn_cls: 0.0210 | loss_rpn_loc: 0.1640 | Total Loss: 1.0334\n",
      "Epoch 0396 | loss_cls: 0.2908 | loss_box_reg: 0.6934 | loss_mask: 0.1443 | loss_rpn_cls: 0.0087 | loss_rpn_loc: 0.0185 | Total Loss: 1.1557\n",
      "Epoch 0397 | loss_cls: 0.1633 | loss_box_reg: 0.4884 | loss_mask: 0.1070 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0159 | Total Loss: 0.7752\n",
      "Epoch 0398 | loss_cls: 0.2308 | loss_box_reg: 0.5735 | loss_mask: 0.1566 | loss_rpn_cls: 0.0154 | loss_rpn_loc: 0.0309 | Total Loss: 1.0071\n",
      "Epoch 0399 | loss_cls: 0.1475 | loss_box_reg: 0.3742 | loss_mask: 0.1736 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.1868 | Total Loss: 0.8854\n",
      "\u001b[32m[07/29 18:23:25 d2.utils.events]: \u001b[0m eta: 0:15:28  iter: 399      time: 0.3298  last_time: 0.3800   lr: 9.99e-05  max_mem: 2291M\n",
      "Epoch 0400 | loss_cls: 0.0752 | loss_box_reg: 0.1923 | loss_mask: 0.0809 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.1270 | Total Loss: 0.4804\n",
      "Epoch 0401 | loss_cls: 0.1044 | loss_box_reg: 0.1769 | loss_mask: 0.0887 | loss_rpn_cls: 0.0165 | loss_rpn_loc: 0.1216 | Total Loss: 0.5081\n",
      "Epoch 0402 | loss_cls: 0.1784 | loss_box_reg: 0.6362 | loss_mask: 0.1593 | loss_rpn_cls: 0.0217 | loss_rpn_loc: 0.0416 | Total Loss: 1.0372\n",
      "Epoch 0403 | loss_cls: 0.1374 | loss_box_reg: 0.4773 | loss_mask: 0.1839 | loss_rpn_cls: 0.0227 | loss_rpn_loc: 0.1429 | Total Loss: 0.9642\n",
      "Epoch 0404 | loss_cls: 0.1029 | loss_box_reg: 0.2224 | loss_mask: 0.0787 | loss_rpn_cls: 0.0070 | loss_rpn_loc: 0.0175 | Total Loss: 0.4284\n",
      "Epoch 0405 | loss_cls: 0.1578 | loss_box_reg: 0.5638 | loss_mask: 0.1738 | loss_rpn_cls: 0.0177 | loss_rpn_loc: 0.0187 | Total Loss: 0.9318\n",
      "Epoch 0406 | loss_cls: 0.1348 | loss_box_reg: 0.3410 | loss_mask: 0.7930 | loss_rpn_cls: 0.0018 | loss_rpn_loc: 0.1897 | Total Loss: 1.4603\n",
      "Epoch 0407 | loss_cls: 0.1776 | loss_box_reg: 0.4992 | loss_mask: 0.3776 | loss_rpn_cls: 0.0086 | loss_rpn_loc: 0.0135 | Total Loss: 1.0765\n",
      "Epoch 0408 | loss_cls: 0.1117 | loss_box_reg: 0.3948 | loss_mask: 0.1478 | loss_rpn_cls: 0.0024 | loss_rpn_loc: 0.0091 | Total Loss: 0.6657\n",
      "Epoch 0409 | loss_cls: 0.1395 | loss_box_reg: 0.4436 | loss_mask: 0.0711 | loss_rpn_cls: 0.0178 | loss_rpn_loc: 0.0188 | Total Loss: 0.6909\n",
      "Epoch 0410 | loss_cls: 0.1648 | loss_box_reg: 0.5078 | loss_mask: 0.1898 | loss_rpn_cls: 0.0116 | loss_rpn_loc: 0.0158 | Total Loss: 0.8899\n",
      "Epoch 0411 | loss_cls: 0.2255 | loss_box_reg: 0.6343 | loss_mask: 0.1845 | loss_rpn_cls: 0.0232 | loss_rpn_loc: 0.1585 | Total Loss: 1.2260\n",
      "Epoch 0412 | loss_cls: 0.2127 | loss_box_reg: 0.7446 | loss_mask: 0.1571 | loss_rpn_cls: 0.0107 | loss_rpn_loc: 0.0173 | Total Loss: 1.1424\n",
      "Epoch 0413 | loss_cls: 0.1729 | loss_box_reg: 0.3469 | loss_mask: 0.2004 | loss_rpn_cls: 0.4260 | loss_rpn_loc: 0.8771 | Total Loss: 2.0233\n",
      "Epoch 0414 | loss_cls: 0.2099 | loss_box_reg: 0.8109 | loss_mask: 0.1864 | loss_rpn_cls: 0.0140 | loss_rpn_loc: 0.0732 | Total Loss: 1.2945\n",
      "Epoch 0415 | loss_cls: 0.1430 | loss_box_reg: 0.4491 | loss_mask: 0.1402 | loss_rpn_cls: 0.0104 | loss_rpn_loc: 0.0398 | Total Loss: 0.7826\n",
      "Epoch 0416 | loss_cls: 0.1219 | loss_box_reg: 0.2231 | loss_mask: 0.2089 | loss_rpn_cls: 0.0129 | loss_rpn_loc: 0.0344 | Total Loss: 0.6012\n",
      "Epoch 0417 | loss_cls: 0.0725 | loss_box_reg: 0.1781 | loss_mask: 0.1123 | loss_rpn_cls: 0.0169 | loss_rpn_loc: 0.0251 | Total Loss: 0.4049\n",
      "Epoch 0418 | loss_cls: 0.2242 | loss_box_reg: 0.6653 | loss_mask: 0.1417 | loss_rpn_cls: 0.0894 | loss_rpn_loc: 0.1805 | Total Loss: 1.3011\n",
      "Epoch 0419 | loss_cls: 0.1622 | loss_box_reg: 0.3986 | loss_mask: 0.1896 | loss_rpn_cls: 0.0283 | loss_rpn_loc: 0.1539 | Total Loss: 0.9326\n",
      "\u001b[32m[07/29 18:23:31 d2.utils.events]: \u001b[0m eta: 0:15:22  iter: 419      time: 0.3297  last_time: 0.2549   lr: 0.0001049  max_mem: 2291M\n",
      "Epoch 0420 | loss_cls: 0.1193 | loss_box_reg: 0.3095 | loss_mask: 0.1759 | loss_rpn_cls: 0.0059 | loss_rpn_loc: 0.0052 | Total Loss: 0.6158\n",
      "Epoch 0421 | loss_cls: 0.1648 | loss_box_reg: 0.3912 | loss_mask: 0.1588 | loss_rpn_cls: 0.0016 | loss_rpn_loc: 0.0329 | Total Loss: 0.7493\n",
      "Epoch 0422 | loss_cls: 0.2183 | loss_box_reg: 0.6436 | loss_mask: 0.2677 | loss_rpn_cls: 0.0032 | loss_rpn_loc: 0.0754 | Total Loss: 1.2082\n",
      "Epoch 0423 | loss_cls: 0.1675 | loss_box_reg: 0.4880 | loss_mask: 0.1656 | loss_rpn_cls: 0.0583 | loss_rpn_loc: 0.0112 | Total Loss: 0.8905\n",
      "Epoch 0424 | loss_cls: 0.0909 | loss_box_reg: 0.2992 | loss_mask: 0.0949 | loss_rpn_cls: 0.0093 | loss_rpn_loc: 0.0663 | Total Loss: 0.5605\n",
      "Epoch 0425 | loss_cls: 0.1611 | loss_box_reg: 0.4427 | loss_mask: 0.1848 | loss_rpn_cls: 0.0299 | loss_rpn_loc: 0.0168 | Total Loss: 0.8353\n",
      "Epoch 0426 | loss_cls: 0.1554 | loss_box_reg: 0.4032 | loss_mask: 0.1747 | loss_rpn_cls: 0.0045 | loss_rpn_loc: 0.0745 | Total Loss: 0.8122\n",
      "Epoch 0427 | loss_cls: 0.1707 | loss_box_reg: 0.4410 | loss_mask: 0.3149 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.1641 | Total Loss: 1.0931\n",
      "Epoch 0428 | loss_cls: 0.0881 | loss_box_reg: 0.3153 | loss_mask: 0.0667 | loss_rpn_cls: 0.0036 | loss_rpn_loc: 0.0083 | Total Loss: 0.4820\n",
      "Epoch 0429 | loss_cls: 0.2030 | loss_box_reg: 0.4205 | loss_mask: 0.1696 | loss_rpn_cls: 0.0070 | loss_rpn_loc: 0.0272 | Total Loss: 0.8273\n",
      "Epoch 0430 | loss_cls: 0.1186 | loss_box_reg: 0.2445 | loss_mask: 0.1871 | loss_rpn_cls: 0.0120 | loss_rpn_loc: 0.0297 | Total Loss: 0.5919\n",
      "Epoch 0431 | loss_cls: 0.1801 | loss_box_reg: 0.5378 | loss_mask: 0.2567 | loss_rpn_cls: 0.0063 | loss_rpn_loc: 0.0401 | Total Loss: 1.0211\n",
      "Epoch 0432 | loss_cls: 0.1247 | loss_box_reg: 0.3788 | loss_mask: 0.1952 | loss_rpn_cls: 0.0020 | loss_rpn_loc: 0.0487 | Total Loss: 0.7493\n",
      "Epoch 0433 | loss_cls: 0.0760 | loss_box_reg: 0.2167 | loss_mask: 0.0804 | loss_rpn_cls: 0.0120 | loss_rpn_loc: 0.0171 | Total Loss: 0.4022\n",
      "Epoch 0434 | loss_cls: 0.1677 | loss_box_reg: 0.4523 | loss_mask: 0.1790 | loss_rpn_cls: 0.2855 | loss_rpn_loc: 0.3347 | Total Loss: 1.4193\n",
      "Epoch 0435 | loss_cls: 0.1660 | loss_box_reg: 0.3620 | loss_mask: 0.1647 | loss_rpn_cls: 0.0070 | loss_rpn_loc: 0.1615 | Total Loss: 0.8612\n",
      "Epoch 0436 | loss_cls: 0.1082 | loss_box_reg: 0.4118 | loss_mask: 0.1494 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.0237 | Total Loss: 0.6950\n",
      "Epoch 0437 | loss_cls: 0.1577 | loss_box_reg: 0.3987 | loss_mask: 0.1976 | loss_rpn_cls: 0.0138 | loss_rpn_loc: 0.1030 | Total Loss: 0.8709\n",
      "Epoch 0438 | loss_cls: 0.1957 | loss_box_reg: 0.4702 | loss_mask: 0.1117 | loss_rpn_cls: 0.0145 | loss_rpn_loc: 0.0149 | Total Loss: 0.8070\n",
      "Epoch 0439 | loss_cls: 0.1775 | loss_box_reg: 0.3713 | loss_mask: 0.1119 | loss_rpn_cls: 0.0278 | loss_rpn_loc: 0.1549 | Total Loss: 0.8434\n",
      "\u001b[32m[07/29 18:23:38 d2.utils.events]: \u001b[0m eta: 0:15:15  iter: 439      time: 0.3291  last_time: 0.1788   lr: 0.00010989  max_mem: 2291M\n",
      "Epoch 0440 | loss_cls: 0.2643 | loss_box_reg: 0.4276 | loss_mask: 0.1117 | loss_rpn_cls: 0.0070 | loss_rpn_loc: 0.0918 | Total Loss: 0.9023\n",
      "Epoch 0441 | loss_cls: 0.2031 | loss_box_reg: 0.5656 | loss_mask: 0.1134 | loss_rpn_cls: 0.0109 | loss_rpn_loc: 0.0347 | Total Loss: 0.9277\n",
      "Epoch 0442 | loss_cls: 0.2863 | loss_box_reg: 0.5817 | loss_mask: 0.1179 | loss_rpn_cls: 0.0455 | loss_rpn_loc: 0.0981 | Total Loss: 1.1295\n",
      "Epoch 0443 | loss_cls: 0.2236 | loss_box_reg: 0.4807 | loss_mask: 0.1827 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.0698 | Total Loss: 0.9595\n",
      "Epoch 0444 | loss_cls: 0.2821 | loss_box_reg: 0.5408 | loss_mask: 0.1831 | loss_rpn_cls: 0.0046 | loss_rpn_loc: 0.0280 | Total Loss: 1.0387\n",
      "Epoch 0445 | loss_cls: 0.1449 | loss_box_reg: 0.4459 | loss_mask: 0.1984 | loss_rpn_cls: 0.0147 | loss_rpn_loc: 0.1651 | Total Loss: 0.9690\n",
      "Epoch 0446 | loss_cls: 0.1010 | loss_box_reg: 0.1587 | loss_mask: 0.0614 | loss_rpn_cls: 0.0166 | loss_rpn_loc: 0.0222 | Total Loss: 0.3599\n",
      "Epoch 0447 | loss_cls: 0.0783 | loss_box_reg: 0.2388 | loss_mask: 0.1308 | loss_rpn_cls: 0.0046 | loss_rpn_loc: 0.0211 | Total Loss: 0.4736\n",
      "Epoch 0448 | loss_cls: 0.1567 | loss_box_reg: 0.4404 | loss_mask: 0.1944 | loss_rpn_cls: 0.0195 | loss_rpn_loc: 0.0148 | Total Loss: 0.8258\n",
      "Epoch 0449 | loss_cls: 0.1625 | loss_box_reg: 0.4969 | loss_mask: 0.1277 | loss_rpn_cls: 0.3240 | loss_rpn_loc: 0.5751 | Total Loss: 1.6862\n",
      "Epoch 0450 | loss_cls: 0.0920 | loss_box_reg: 0.2933 | loss_mask: 0.1242 | loss_rpn_cls: 0.0203 | loss_rpn_loc: 0.0666 | Total Loss: 0.5965\n",
      "Epoch 0451 | loss_cls: 0.1477 | loss_box_reg: 0.4993 | loss_mask: 0.1094 | loss_rpn_cls: 0.0076 | loss_rpn_loc: 0.0198 | Total Loss: 0.7837\n",
      "Epoch 0452 | loss_cls: 0.1305 | loss_box_reg: 0.4147 | loss_mask: 0.1633 | loss_rpn_cls: 0.0116 | loss_rpn_loc: 0.0319 | Total Loss: 0.7520\n",
      "Epoch 0453 | loss_cls: 0.0652 | loss_box_reg: 0.2493 | loss_mask: 0.1152 | loss_rpn_cls: 0.0080 | loss_rpn_loc: 0.0145 | Total Loss: 0.4522\n",
      "Epoch 0454 | loss_cls: 0.1662 | loss_box_reg: 0.3979 | loss_mask: 0.2051 | loss_rpn_cls: 0.0054 | loss_rpn_loc: 0.0543 | Total Loss: 0.8289\n",
      "Epoch 0455 | loss_cls: 0.1439 | loss_box_reg: 0.2141 | loss_mask: 0.2880 | loss_rpn_cls: 0.0255 | loss_rpn_loc: 0.0065 | Total Loss: 0.6781\n",
      "Epoch 0456 | loss_cls: 0.1735 | loss_box_reg: 0.4222 | loss_mask: 0.1130 | loss_rpn_cls: 0.0220 | loss_rpn_loc: 0.0333 | Total Loss: 0.7640\n",
      "Epoch 0457 | loss_cls: 0.1061 | loss_box_reg: 0.2543 | loss_mask: 0.1509 | loss_rpn_cls: 0.0221 | loss_rpn_loc: 0.0489 | Total Loss: 0.5823\n",
      "Epoch 0458 | loss_cls: 0.1362 | loss_box_reg: 0.3498 | loss_mask: 0.6656 | loss_rpn_cls: 0.0228 | loss_rpn_loc: 0.0075 | Total Loss: 1.1819\n",
      "Epoch 0459 | loss_cls: 0.1269 | loss_box_reg: 0.4789 | loss_mask: 0.1030 | loss_rpn_cls: 0.1792 | loss_rpn_loc: 0.2830 | Total Loss: 1.1710\n",
      "\u001b[32m[07/29 18:23:44 d2.utils.events]: \u001b[0m eta: 0:15:11  iter: 459      time: 0.3297  last_time: 0.2726   lr: 0.00011489  max_mem: 2291M\n",
      "Epoch 0460 | loss_cls: 0.1264 | loss_box_reg: 0.4057 | loss_mask: 0.0859 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0121 | Total Loss: 0.6313\n",
      "Epoch 0461 | loss_cls: 0.1435 | loss_box_reg: 0.3975 | loss_mask: 0.2276 | loss_rpn_cls: 0.0190 | loss_rpn_loc: 0.0687 | Total Loss: 0.8562\n",
      "Epoch 0462 | loss_cls: 0.0493 | loss_box_reg: 0.0926 | loss_mask: 0.0870 | loss_rpn_cls: 0.0374 | loss_rpn_loc: 0.0263 | Total Loss: 0.2926\n",
      " Best model saved at Epoch 462 | Total Loss: 0.2926\n",
      "Epoch 0463 | loss_cls: 0.1207 | loss_box_reg: 0.3904 | loss_mask: 0.0542 | loss_rpn_cls: 0.0237 | loss_rpn_loc: 0.0046 | Total Loss: 0.5934\n",
      "Epoch 0464 | loss_cls: 0.1487 | loss_box_reg: 0.3251 | loss_mask: 0.1247 | loss_rpn_cls: 0.0599 | loss_rpn_loc: 0.2919 | Total Loss: 0.9504\n",
      "Epoch 0465 | loss_cls: 0.1236 | loss_box_reg: 0.3895 | loss_mask: 0.1334 | loss_rpn_cls: 0.0608 | loss_rpn_loc: 0.1089 | Total Loss: 0.8162\n",
      "Epoch 0466 | loss_cls: 0.1782 | loss_box_reg: 0.4583 | loss_mask: 0.1721 | loss_rpn_cls: 0.0040 | loss_rpn_loc: 0.0330 | Total Loss: 0.8457\n",
      "Epoch 0467 | loss_cls: 0.1832 | loss_box_reg: 0.5609 | loss_mask: 0.0939 | loss_rpn_cls: 0.0070 | loss_rpn_loc: 0.0777 | Total Loss: 0.9227\n",
      "Epoch 0468 | loss_cls: 0.1969 | loss_box_reg: 0.3682 | loss_mask: 0.1459 | loss_rpn_cls: 0.0313 | loss_rpn_loc: 0.0807 | Total Loss: 0.8229\n",
      "Epoch 0469 | loss_cls: 0.1721 | loss_box_reg: 0.3953 | loss_mask: 0.1775 | loss_rpn_cls: 0.0168 | loss_rpn_loc: 0.0394 | Total Loss: 0.8010\n",
      "Epoch 0470 | loss_cls: 0.1208 | loss_box_reg: 0.1945 | loss_mask: 0.0705 | loss_rpn_cls: 0.0160 | loss_rpn_loc: 0.0156 | Total Loss: 0.4175\n",
      "Epoch 0471 | loss_cls: 0.1363 | loss_box_reg: 0.3728 | loss_mask: 0.0963 | loss_rpn_cls: 0.0100 | loss_rpn_loc: 0.0085 | Total Loss: 0.6238\n",
      "Epoch 0472 | loss_cls: 0.2026 | loss_box_reg: 0.4120 | loss_mask: 0.2053 | loss_rpn_cls: 0.0080 | loss_rpn_loc: 0.0933 | Total Loss: 0.9212\n",
      "Epoch 0473 | loss_cls: 0.1877 | loss_box_reg: 0.4418 | loss_mask: 0.1949 | loss_rpn_cls: 0.0076 | loss_rpn_loc: 0.0669 | Total Loss: 0.8989\n",
      "Epoch 0474 | loss_cls: 0.2610 | loss_box_reg: 0.6048 | loss_mask: 0.1413 | loss_rpn_cls: 0.0327 | loss_rpn_loc: 0.1287 | Total Loss: 1.1685\n",
      "Epoch 0475 | loss_cls: 0.0863 | loss_box_reg: 0.4161 | loss_mask: 0.0850 | loss_rpn_cls: 0.0196 | loss_rpn_loc: 0.0069 | Total Loss: 0.6139\n",
      "Epoch 0476 | loss_cls: 0.1877 | loss_box_reg: 0.4278 | loss_mask: 0.1798 | loss_rpn_cls: 0.0064 | loss_rpn_loc: 0.0581 | Total Loss: 0.8597\n",
      "Epoch 0477 | loss_cls: 0.1860 | loss_box_reg: 0.4290 | loss_mask: 0.2776 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.0148 | Total Loss: 0.9093\n",
      "Epoch 0478 | loss_cls: 0.0583 | loss_box_reg: 0.2060 | loss_mask: 0.1602 | loss_rpn_cls: 0.0172 | loss_rpn_loc: 0.0174 | Total Loss: 0.4592\n",
      "Epoch 0479 | loss_cls: 0.1396 | loss_box_reg: 0.2978 | loss_mask: 0.0690 | loss_rpn_cls: 0.0080 | loss_rpn_loc: 0.1962 | Total Loss: 0.7107\n",
      "\u001b[32m[07/29 18:23:51 d2.utils.events]: \u001b[0m eta: 0:15:05  iter: 479      time: 0.3302  last_time: 0.3961   lr: 0.00011988  max_mem: 2292M\n",
      "Epoch 0480 | loss_cls: 0.0833 | loss_box_reg: 0.2642 | loss_mask: 0.1278 | loss_rpn_cls: 0.0255 | loss_rpn_loc: 0.0177 | Total Loss: 0.5185\n",
      "Epoch 0481 | loss_cls: 0.1293 | loss_box_reg: 0.2965 | loss_mask: 0.1170 | loss_rpn_cls: 0.0432 | loss_rpn_loc: 0.0991 | Total Loss: 0.6851\n",
      "Epoch 0482 | loss_cls: 0.1597 | loss_box_reg: 0.3491 | loss_mask: 0.1948 | loss_rpn_cls: 0.0299 | loss_rpn_loc: 0.0084 | Total Loss: 0.7419\n",
      "Epoch 0483 | loss_cls: 0.0604 | loss_box_reg: 0.1433 | loss_mask: 0.3480 | loss_rpn_cls: 0.0045 | loss_rpn_loc: 0.3168 | Total Loss: 0.8730\n",
      "Epoch 0484 | loss_cls: 0.1808 | loss_box_reg: 0.5076 | loss_mask: 0.0893 | loss_rpn_cls: 0.0195 | loss_rpn_loc: 0.0155 | Total Loss: 0.8127\n",
      "Epoch 0485 | loss_cls: 0.0566 | loss_box_reg: 0.1426 | loss_mask: 0.4353 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.0656 | Total Loss: 0.7034\n",
      "Epoch 0486 | loss_cls: 0.0475 | loss_box_reg: 0.1156 | loss_mask: 0.1719 | loss_rpn_cls: 0.0136 | loss_rpn_loc: 0.1809 | Total Loss: 0.5295\n",
      "Epoch 0487 | loss_cls: 0.1339 | loss_box_reg: 0.3019 | loss_mask: 0.4099 | loss_rpn_cls: 0.0283 | loss_rpn_loc: 0.0097 | Total Loss: 0.8836\n",
      "Epoch 0488 | loss_cls: 0.1636 | loss_box_reg: 0.6520 | loss_mask: 0.2131 | loss_rpn_cls: 0.0059 | loss_rpn_loc: 0.0258 | Total Loss: 1.0604\n",
      "Epoch 0489 | loss_cls: 0.0677 | loss_box_reg: 0.1281 | loss_mask: 0.1792 | loss_rpn_cls: 0.0151 | loss_rpn_loc: 0.0218 | Total Loss: 0.4119\n",
      "Epoch 0490 | loss_cls: 0.1161 | loss_box_reg: 0.3199 | loss_mask: 0.2187 | loss_rpn_cls: 0.0056 | loss_rpn_loc: 0.0120 | Total Loss: 0.6724\n",
      "Epoch 0491 | loss_cls: 0.2421 | loss_box_reg: 0.4960 | loss_mask: 0.2796 | loss_rpn_cls: 0.0306 | loss_rpn_loc: 0.1821 | Total Loss: 1.2304\n",
      "Epoch 0492 | loss_cls: 0.0855 | loss_box_reg: 0.1655 | loss_mask: 0.5543 | loss_rpn_cls: 0.0030 | loss_rpn_loc: 0.0117 | Total Loss: 0.8201\n",
      "Epoch 0493 | loss_cls: 0.0795 | loss_box_reg: 0.2669 | loss_mask: 0.0998 | loss_rpn_cls: 0.0107 | loss_rpn_loc: 0.0177 | Total Loss: 0.4746\n",
      "Epoch 0494 | loss_cls: 0.1438 | loss_box_reg: 0.5574 | loss_mask: 0.1779 | loss_rpn_cls: 0.0121 | loss_rpn_loc: 0.1067 | Total Loss: 0.9979\n",
      "Epoch 0495 | loss_cls: 0.1964 | loss_box_reg: 0.2804 | loss_mask: 0.1364 | loss_rpn_cls: 0.0103 | loss_rpn_loc: 0.1345 | Total Loss: 0.7580\n",
      "Epoch 0496 | loss_cls: 0.1904 | loss_box_reg: 0.4549 | loss_mask: 0.0879 | loss_rpn_cls: 0.0092 | loss_rpn_loc: 0.0358 | Total Loss: 0.7782\n",
      "Epoch 0497 | loss_cls: 0.2312 | loss_box_reg: 0.6525 | loss_mask: 0.1362 | loss_rpn_cls: 0.0101 | loss_rpn_loc: 0.1706 | Total Loss: 1.2006\n",
      "Epoch 0498 | loss_cls: 0.3841 | loss_box_reg: 0.7436 | loss_mask: 0.1791 | loss_rpn_cls: 0.0461 | loss_rpn_loc: 0.1922 | Total Loss: 1.5451\n",
      "Epoch 0499 | loss_cls: 0.1377 | loss_box_reg: 0.3551 | loss_mask: 0.1432 | loss_rpn_cls: 0.0320 | loss_rpn_loc: 0.1113 | Total Loss: 0.7793\n",
      "\u001b[32m[07/29 18:23:58 d2.utils.events]: \u001b[0m eta: 0:14:58  iter: 499      time: 0.3301  last_time: 0.3941   lr: 0.00012488  max_mem: 2292M\n",
      "Epoch 0500 | loss_cls: 0.0900 | loss_box_reg: 0.3217 | loss_mask: 0.3059 | loss_rpn_cls: 0.0036 | loss_rpn_loc: 0.0064 | Total Loss: 0.7276\n",
      "Epoch 0501 | loss_cls: 0.2113 | loss_box_reg: 0.4531 | loss_mask: 0.1494 | loss_rpn_cls: 0.0116 | loss_rpn_loc: 0.0167 | Total Loss: 0.8422\n",
      "Epoch 0502 | loss_cls: 0.1029 | loss_box_reg: 0.2297 | loss_mask: 0.2923 | loss_rpn_cls: 0.0104 | loss_rpn_loc: 0.0113 | Total Loss: 0.6465\n",
      "Epoch 0503 | loss_cls: 0.0853 | loss_box_reg: 0.3408 | loss_mask: 0.1692 | loss_rpn_cls: 0.0104 | loss_rpn_loc: 0.0063 | Total Loss: 0.6121\n",
      "Epoch 0504 | loss_cls: 0.0625 | loss_box_reg: 0.1065 | loss_mask: 0.2588 | loss_rpn_cls: 0.0099 | loss_rpn_loc: 0.2266 | Total Loss: 0.6644\n",
      "Epoch 0505 | loss_cls: 0.1120 | loss_box_reg: 0.2543 | loss_mask: 0.2071 | loss_rpn_cls: 0.0227 | loss_rpn_loc: 0.0384 | Total Loss: 0.6345\n",
      "Epoch 0506 | loss_cls: 0.0710 | loss_box_reg: 0.1779 | loss_mask: 0.1350 | loss_rpn_cls: 0.0531 | loss_rpn_loc: 0.5810 | Total Loss: 1.0179\n",
      "Epoch 0507 | loss_cls: 0.1488 | loss_box_reg: 0.4804 | loss_mask: 0.1738 | loss_rpn_cls: 0.0029 | loss_rpn_loc: 0.0266 | Total Loss: 0.8326\n",
      "Epoch 0508 | loss_cls: 0.2393 | loss_box_reg: 0.5743 | loss_mask: 0.1700 | loss_rpn_cls: 0.0369 | loss_rpn_loc: 0.0106 | Total Loss: 1.0310\n",
      "Epoch 0509 | loss_cls: 0.1862 | loss_box_reg: 0.5484 | loss_mask: 0.1168 | loss_rpn_cls: 0.0070 | loss_rpn_loc: 0.0848 | Total Loss: 0.9431\n",
      "Epoch 0510 | loss_cls: 0.1709 | loss_box_reg: 0.3963 | loss_mask: 0.1469 | loss_rpn_cls: 0.0083 | loss_rpn_loc: 0.0129 | Total Loss: 0.7352\n",
      "Epoch 0511 | loss_cls: 0.1780 | loss_box_reg: 0.4120 | loss_mask: 0.1044 | loss_rpn_cls: 0.0118 | loss_rpn_loc: 0.2014 | Total Loss: 0.9077\n",
      "Epoch 0512 | loss_cls: 0.0908 | loss_box_reg: 0.1985 | loss_mask: 0.1050 | loss_rpn_cls: 0.0142 | loss_rpn_loc: 0.1154 | Total Loss: 0.5239\n",
      "Epoch 0513 | loss_cls: 0.1645 | loss_box_reg: 0.3205 | loss_mask: 0.1873 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.1650 | Total Loss: 0.8389\n",
      "Epoch 0514 | loss_cls: 0.0788 | loss_box_reg: 0.1707 | loss_mask: 0.1876 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.0844 | Total Loss: 0.5265\n",
      "Epoch 0515 | loss_cls: 0.1000 | loss_box_reg: 0.1604 | loss_mask: 0.2245 | loss_rpn_cls: 0.0155 | loss_rpn_loc: 0.0202 | Total Loss: 0.5205\n",
      "Epoch 0516 | loss_cls: 0.0467 | loss_box_reg: 0.2230 | loss_mask: 0.2334 | loss_rpn_cls: 0.0036 | loss_rpn_loc: 0.1282 | Total Loss: 0.6349\n",
      "Epoch 0517 | loss_cls: 0.2235 | loss_box_reg: 0.4109 | loss_mask: 0.1427 | loss_rpn_cls: 0.0150 | loss_rpn_loc: 0.0744 | Total Loss: 0.8665\n",
      "Epoch 0518 | loss_cls: 0.1437 | loss_box_reg: 0.4395 | loss_mask: 0.2700 | loss_rpn_cls: 0.0721 | loss_rpn_loc: 0.1001 | Total Loss: 1.0254\n",
      "Epoch 0519 | loss_cls: 0.1723 | loss_box_reg: 0.4379 | loss_mask: 0.0957 | loss_rpn_cls: 0.0072 | loss_rpn_loc: 0.0097 | Total Loss: 0.7229\n",
      "\u001b[32m[07/29 18:24:04 d2.utils.events]: \u001b[0m eta: 0:14:52  iter: 519      time: 0.3302  last_time: 0.2814   lr: 0.00012987  max_mem: 2292M\n",
      "Epoch 0520 | loss_cls: 0.0779 | loss_box_reg: 0.0727 | loss_mask: 0.1778 | loss_rpn_cls: 0.0064 | loss_rpn_loc: 0.1110 | Total Loss: 0.4458\n",
      "Epoch 0521 | loss_cls: 0.2176 | loss_box_reg: 0.6442 | loss_mask: 0.1480 | loss_rpn_cls: 0.0342 | loss_rpn_loc: 0.1206 | Total Loss: 1.1646\n",
      "Epoch 0522 | loss_cls: 0.0956 | loss_box_reg: 0.3642 | loss_mask: 0.0939 | loss_rpn_cls: 0.0191 | loss_rpn_loc: 0.0134 | Total Loss: 0.5863\n",
      "Epoch 0523 | loss_cls: 0.0467 | loss_box_reg: 0.1500 | loss_mask: 0.1452 | loss_rpn_cls: 0.0308 | loss_rpn_loc: 0.1160 | Total Loss: 0.4887\n",
      "Epoch 0524 | loss_cls: 0.1592 | loss_box_reg: 0.2972 | loss_mask: 0.3856 | loss_rpn_cls: 0.0038 | loss_rpn_loc: 0.0301 | Total Loss: 0.8758\n",
      "Epoch 0525 | loss_cls: 0.3380 | loss_box_reg: 0.6739 | loss_mask: 0.1629 | loss_rpn_cls: 0.0485 | loss_rpn_loc: 0.1120 | Total Loss: 1.3354\n",
      "Epoch 0526 | loss_cls: 0.1002 | loss_box_reg: 0.3477 | loss_mask: 0.1433 | loss_rpn_cls: 0.0247 | loss_rpn_loc: 0.1213 | Total Loss: 0.7371\n",
      "Epoch 0527 | loss_cls: 0.0714 | loss_box_reg: 0.2965 | loss_mask: 0.0812 | loss_rpn_cls: 0.0272 | loss_rpn_loc: 0.0043 | Total Loss: 0.4805\n",
      "Epoch 0528 | loss_cls: 0.2511 | loss_box_reg: 0.4887 | loss_mask: 0.1289 | loss_rpn_cls: 0.0122 | loss_rpn_loc: 0.1409 | Total Loss: 1.0218\n",
      "Epoch 0529 | loss_cls: 0.2175 | loss_box_reg: 0.4033 | loss_mask: 0.1064 | loss_rpn_cls: 0.0294 | loss_rpn_loc: 0.0058 | Total Loss: 0.7624\n",
      "Epoch 0530 | loss_cls: 0.1983 | loss_box_reg: 0.4739 | loss_mask: 0.1660 | loss_rpn_cls: 0.0080 | loss_rpn_loc: 0.0506 | Total Loss: 0.8968\n",
      "Epoch 0531 | loss_cls: 0.0977 | loss_box_reg: 0.2448 | loss_mask: 0.2452 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.1607 | Total Loss: 0.7495\n",
      "Epoch 0532 | loss_cls: 0.1675 | loss_box_reg: 0.3737 | loss_mask: 0.1716 | loss_rpn_cls: 0.0092 | loss_rpn_loc: 0.1508 | Total Loss: 0.8728\n",
      "Epoch 0533 | loss_cls: 0.0958 | loss_box_reg: 0.2036 | loss_mask: 0.0723 | loss_rpn_cls: 0.0122 | loss_rpn_loc: 0.0212 | Total Loss: 0.4051\n",
      "Epoch 0534 | loss_cls: 0.0758 | loss_box_reg: 0.2277 | loss_mask: 0.1349 | loss_rpn_cls: 0.0039 | loss_rpn_loc: 0.1393 | Total Loss: 0.5815\n",
      "Epoch 0535 | loss_cls: 0.0617 | loss_box_reg: 0.1855 | loss_mask: 0.1272 | loss_rpn_cls: 0.0187 | loss_rpn_loc: 0.0348 | Total Loss: 0.4279\n",
      "Epoch 0536 | loss_cls: 0.0943 | loss_box_reg: 0.4499 | loss_mask: 0.0835 | loss_rpn_cls: 0.0208 | loss_rpn_loc: 0.0109 | Total Loss: 0.6594\n",
      "Epoch 0537 | loss_cls: 0.0910 | loss_box_reg: 0.2071 | loss_mask: 0.0727 | loss_rpn_cls: 0.0031 | loss_rpn_loc: 0.1115 | Total Loss: 0.4854\n",
      "Epoch 0538 | loss_cls: 0.1982 | loss_box_reg: 0.4119 | loss_mask: 0.1409 | loss_rpn_cls: 0.0018 | loss_rpn_loc: 0.0156 | Total Loss: 0.7685\n",
      "Epoch 0539 | loss_cls: 0.2351 | loss_box_reg: 0.4743 | loss_mask: 0.0859 | loss_rpn_cls: 0.0109 | loss_rpn_loc: 0.0844 | Total Loss: 0.8906\n",
      "\u001b[32m[07/29 18:24:11 d2.utils.events]: \u001b[0m eta: 0:14:48  iter: 539      time: 0.3305  last_time: 0.3960   lr: 0.00013487  max_mem: 2292M\n",
      "Epoch 0540 | loss_cls: 0.1400 | loss_box_reg: 0.3941 | loss_mask: 0.6168 | loss_rpn_cls: 0.0141 | loss_rpn_loc: 0.0292 | Total Loss: 1.1941\n",
      "Epoch 0541 | loss_cls: 0.0673 | loss_box_reg: 0.1136 | loss_mask: 0.1607 | loss_rpn_cls: 0.0043 | loss_rpn_loc: 0.0433 | Total Loss: 0.3892\n",
      "Epoch 0542 | loss_cls: 0.1564 | loss_box_reg: 0.5202 | loss_mask: 0.0833 | loss_rpn_cls: 0.0462 | loss_rpn_loc: 0.2422 | Total Loss: 1.0484\n",
      "Epoch 0543 | loss_cls: 0.1413 | loss_box_reg: 0.4053 | loss_mask: 0.2046 | loss_rpn_cls: 0.0008 | loss_rpn_loc: 0.0182 | Total Loss: 0.7703\n",
      "Epoch 0544 | loss_cls: 0.2660 | loss_box_reg: 0.6004 | loss_mask: 0.1432 | loss_rpn_cls: 0.0186 | loss_rpn_loc: 0.0693 | Total Loss: 1.0975\n",
      "Epoch 0545 | loss_cls: 0.2435 | loss_box_reg: 0.5199 | loss_mask: 0.1670 | loss_rpn_cls: 0.0192 | loss_rpn_loc: 0.0993 | Total Loss: 1.0489\n",
      "Epoch 0546 | loss_cls: 0.0437 | loss_box_reg: 0.0823 | loss_mask: 0.0804 | loss_rpn_cls: 0.0326 | loss_rpn_loc: 0.1308 | Total Loss: 0.3699\n",
      "Epoch 0547 | loss_cls: 0.1435 | loss_box_reg: 0.4794 | loss_mask: 0.1760 | loss_rpn_cls: 0.0078 | loss_rpn_loc: 0.1211 | Total Loss: 0.9277\n",
      "Epoch 0548 | loss_cls: 0.1413 | loss_box_reg: 0.4040 | loss_mask: 0.2980 | loss_rpn_cls: 0.0108 | loss_rpn_loc: 0.0305 | Total Loss: 0.8847\n",
      "Epoch 0549 | loss_cls: 0.1733 | loss_box_reg: 0.2783 | loss_mask: 0.0712 | loss_rpn_cls: 0.0065 | loss_rpn_loc: 0.0452 | Total Loss: 0.5744\n",
      "Epoch 0550 | loss_cls: 0.1256 | loss_box_reg: 0.2596 | loss_mask: 0.1925 | loss_rpn_cls: 0.0061 | loss_rpn_loc: 0.0312 | Total Loss: 0.6150\n",
      "Epoch 0551 | loss_cls: 0.2356 | loss_box_reg: 0.5542 | loss_mask: 0.1343 | loss_rpn_cls: 0.0128 | loss_rpn_loc: 0.0348 | Total Loss: 0.9715\n",
      "Epoch 0552 | loss_cls: 0.0695 | loss_box_reg: 0.1211 | loss_mask: 0.4064 | loss_rpn_cls: 0.0049 | loss_rpn_loc: 0.1108 | Total Loss: 0.7127\n",
      "Epoch 0553 | loss_cls: 0.1255 | loss_box_reg: 0.3131 | loss_mask: 0.1983 | loss_rpn_cls: 0.0164 | loss_rpn_loc: 0.1357 | Total Loss: 0.7890\n",
      "Epoch 0554 | loss_cls: 0.1337 | loss_box_reg: 0.2855 | loss_mask: 0.2405 | loss_rpn_cls: 0.0150 | loss_rpn_loc: 0.1619 | Total Loss: 0.8366\n",
      "Epoch 0555 | loss_cls: 0.1864 | loss_box_reg: 0.5334 | loss_mask: 0.1980 | loss_rpn_cls: 0.0256 | loss_rpn_loc: 0.0151 | Total Loss: 0.9584\n",
      "Epoch 0556 | loss_cls: 0.1807 | loss_box_reg: 0.3500 | loss_mask: 0.1253 | loss_rpn_cls: 0.0104 | loss_rpn_loc: 0.0080 | Total Loss: 0.6744\n",
      "Epoch 0557 | loss_cls: 0.2452 | loss_box_reg: 0.5866 | loss_mask: 0.1611 | loss_rpn_cls: 0.0179 | loss_rpn_loc: 0.0713 | Total Loss: 1.0822\n",
      "Epoch 0558 | loss_cls: 0.1519 | loss_box_reg: 0.3390 | loss_mask: 0.1982 | loss_rpn_cls: 0.0115 | loss_rpn_loc: 0.0178 | Total Loss: 0.7185\n",
      "Epoch 0559 | loss_cls: 0.1170 | loss_box_reg: 0.4400 | loss_mask: 0.0920 | loss_rpn_cls: 0.1049 | loss_rpn_loc: 0.2435 | Total Loss: 0.9974\n",
      "\u001b[32m[07/29 18:24:17 d2.utils.events]: \u001b[0m eta: 0:14:38  iter: 559      time: 0.3296  last_time: 0.2794   lr: 0.00013986  max_mem: 2292M\n",
      "Epoch 0560 | loss_cls: 0.1132 | loss_box_reg: 0.3079 | loss_mask: 0.1733 | loss_rpn_cls: 0.0197 | loss_rpn_loc: 0.0314 | Total Loss: 0.6455\n",
      "Epoch 0561 | loss_cls: 0.1562 | loss_box_reg: 0.3908 | loss_mask: 0.1776 | loss_rpn_cls: 0.0133 | loss_rpn_loc: 0.0229 | Total Loss: 0.7608\n",
      "Epoch 0562 | loss_cls: 0.0663 | loss_box_reg: 0.2112 | loss_mask: 0.0887 | loss_rpn_cls: 0.0037 | loss_rpn_loc: 0.0796 | Total Loss: 0.4496\n",
      "Epoch 0563 | loss_cls: 0.0626 | loss_box_reg: 0.1602 | loss_mask: 0.1116 | loss_rpn_cls: 0.0018 | loss_rpn_loc: 0.1225 | Total Loss: 0.4587\n",
      "Epoch 0564 | loss_cls: 0.1376 | loss_box_reg: 0.4462 | loss_mask: 0.0953 | loss_rpn_cls: 0.0400 | loss_rpn_loc: 0.0881 | Total Loss: 0.8072\n",
      "Epoch 0565 | loss_cls: 0.1207 | loss_box_reg: 0.2890 | loss_mask: 0.3157 | loss_rpn_cls: 0.0138 | loss_rpn_loc: 0.0176 | Total Loss: 0.7568\n",
      "Epoch 0566 | loss_cls: 0.0666 | loss_box_reg: 0.1160 | loss_mask: 0.2602 | loss_rpn_cls: 0.0060 | loss_rpn_loc: 0.1463 | Total Loss: 0.5952\n",
      "Epoch 0567 | loss_cls: 0.1125 | loss_box_reg: 0.2740 | loss_mask: 0.1500 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.0166 | Total Loss: 0.5546\n",
      "Epoch 0568 | loss_cls: 0.0604 | loss_box_reg: 0.1343 | loss_mask: 0.0993 | loss_rpn_cls: 0.0326 | loss_rpn_loc: 0.0149 | Total Loss: 0.3415\n",
      "Epoch 0569 | loss_cls: 0.0473 | loss_box_reg: 0.0960 | loss_mask: 0.0985 | loss_rpn_cls: 0.0315 | loss_rpn_loc: 0.0349 | Total Loss: 0.3083\n",
      "Epoch 0570 | loss_cls: 0.1409 | loss_box_reg: 0.4530 | loss_mask: 0.2016 | loss_rpn_cls: 0.0024 | loss_rpn_loc: 0.0074 | Total Loss: 0.8053\n",
      "Epoch 0571 | loss_cls: 0.2327 | loss_box_reg: 0.6297 | loss_mask: 0.2159 | loss_rpn_cls: 0.0196 | loss_rpn_loc: 0.0213 | Total Loss: 1.1191\n",
      "Epoch 0572 | loss_cls: 0.0877 | loss_box_reg: 0.0982 | loss_mask: 0.2002 | loss_rpn_cls: 0.0160 | loss_rpn_loc: 0.1345 | Total Loss: 0.5365\n",
      "Epoch 0573 | loss_cls: 0.1039 | loss_box_reg: 0.3140 | loss_mask: 0.2970 | loss_rpn_cls: 0.0248 | loss_rpn_loc: 0.0215 | Total Loss: 0.7611\n",
      "Epoch 0574 | loss_cls: 0.0470 | loss_box_reg: 0.0725 | loss_mask: 0.3452 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.1330 | Total Loss: 0.5992\n",
      "Epoch 0575 | loss_cls: 0.1857 | loss_box_reg: 0.4089 | loss_mask: 0.1061 | loss_rpn_cls: 0.0297 | loss_rpn_loc: 0.2717 | Total Loss: 1.0021\n",
      "Epoch 0576 | loss_cls: 0.1459 | loss_box_reg: 0.3572 | loss_mask: 0.1147 | loss_rpn_cls: 0.0187 | loss_rpn_loc: 0.0793 | Total Loss: 0.7157\n",
      "Epoch 0577 | loss_cls: 0.0677 | loss_box_reg: 0.1565 | loss_mask: 0.1285 | loss_rpn_cls: 0.0255 | loss_rpn_loc: 0.0192 | Total Loss: 0.3974\n",
      "Epoch 0578 | loss_cls: 0.0893 | loss_box_reg: 0.3248 | loss_mask: 0.1025 | loss_rpn_cls: 0.0218 | loss_rpn_loc: 0.0354 | Total Loss: 0.5739\n",
      "Epoch 0579 | loss_cls: 0.0816 | loss_box_reg: 0.3591 | loss_mask: 0.1425 | loss_rpn_cls: 0.0098 | loss_rpn_loc: 0.0668 | Total Loss: 0.6597\n",
      "\u001b[32m[07/29 18:24:24 d2.utils.events]: \u001b[0m eta: 0:14:30  iter: 579      time: 0.3291  last_time: 0.3902   lr: 0.00014486  max_mem: 2292M\n",
      "Epoch 0580 | loss_cls: 0.1658 | loss_box_reg: 0.3861 | loss_mask: 0.1946 | loss_rpn_cls: 0.0192 | loss_rpn_loc: 0.0243 | Total Loss: 0.7901\n",
      "Epoch 0581 | loss_cls: 0.0898 | loss_box_reg: 0.2408 | loss_mask: 0.2177 | loss_rpn_cls: 0.0096 | loss_rpn_loc: 0.1403 | Total Loss: 0.6982\n",
      "Epoch 0582 | loss_cls: 0.0952 | loss_box_reg: 0.4358 | loss_mask: 0.1560 | loss_rpn_cls: 0.0113 | loss_rpn_loc: 0.0128 | Total Loss: 0.7110\n",
      "Epoch 0583 | loss_cls: 0.0886 | loss_box_reg: 0.2689 | loss_mask: 0.6025 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0361 | Total Loss: 0.9965\n",
      "Epoch 0584 | loss_cls: 0.0899 | loss_box_reg: 0.4170 | loss_mask: 0.1100 | loss_rpn_cls: 0.0230 | loss_rpn_loc: 0.0082 | Total Loss: 0.6480\n",
      "Epoch 0585 | loss_cls: 0.1759 | loss_box_reg: 0.3944 | loss_mask: 0.1346 | loss_rpn_cls: 0.0480 | loss_rpn_loc: 0.1368 | Total Loss: 0.8897\n",
      "Epoch 0586 | loss_cls: 0.0806 | loss_box_reg: 0.1867 | loss_mask: 0.1010 | loss_rpn_cls: 0.0114 | loss_rpn_loc: 0.0188 | Total Loss: 0.3985\n",
      "Epoch 0587 | loss_cls: 0.2161 | loss_box_reg: 0.4596 | loss_mask: 0.1218 | loss_rpn_cls: 0.0052 | loss_rpn_loc: 0.0262 | Total Loss: 0.8289\n",
      "Epoch 0588 | loss_cls: 0.0579 | loss_box_reg: 0.2037 | loss_mask: 0.2955 | loss_rpn_cls: 0.0182 | loss_rpn_loc: 0.1394 | Total Loss: 0.7146\n",
      "Epoch 0589 | loss_cls: 0.2029 | loss_box_reg: 0.5335 | loss_mask: 0.1630 | loss_rpn_cls: 0.0109 | loss_rpn_loc: 0.0558 | Total Loss: 0.9662\n",
      "Epoch 0590 | loss_cls: 0.2676 | loss_box_reg: 0.5144 | loss_mask: 0.1196 | loss_rpn_cls: 0.0128 | loss_rpn_loc: 0.0757 | Total Loss: 0.9901\n",
      "Epoch 0591 | loss_cls: 0.2206 | loss_box_reg: 0.2938 | loss_mask: 0.1210 | loss_rpn_cls: 0.0129 | loss_rpn_loc: 0.1555 | Total Loss: 0.8038\n",
      "Epoch 0592 | loss_cls: 0.1568 | loss_box_reg: 0.2999 | loss_mask: 0.0755 | loss_rpn_cls: 0.0266 | loss_rpn_loc: 0.0712 | Total Loss: 0.6301\n",
      "Epoch 0593 | loss_cls: 0.0746 | loss_box_reg: 0.2121 | loss_mask: 0.0609 | loss_rpn_cls: 0.0105 | loss_rpn_loc: 0.0808 | Total Loss: 0.4388\n",
      "Epoch 0594 | loss_cls: 0.0734 | loss_box_reg: 0.2983 | loss_mask: 0.1487 | loss_rpn_cls: 0.0452 | loss_rpn_loc: 0.0946 | Total Loss: 0.6602\n",
      "Epoch 0595 | loss_cls: 0.1284 | loss_box_reg: 0.3197 | loss_mask: 0.0722 | loss_rpn_cls: 0.0482 | loss_rpn_loc: 0.0058 | Total Loss: 0.5742\n",
      "Epoch 0596 | loss_cls: 0.1118 | loss_box_reg: 0.5037 | loss_mask: 0.0964 | loss_rpn_cls: 0.0032 | loss_rpn_loc: 0.0414 | Total Loss: 0.7564\n",
      "Epoch 0597 | loss_cls: 0.1563 | loss_box_reg: 0.2963 | loss_mask: 0.1710 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.0204 | Total Loss: 0.6450\n",
      "Epoch 0598 | loss_cls: 0.0936 | loss_box_reg: 0.3008 | loss_mask: 0.3001 | loss_rpn_cls: 0.0046 | loss_rpn_loc: 0.1320 | Total Loss: 0.8312\n",
      "Epoch 0599 | loss_cls: 0.1414 | loss_box_reg: 0.2962 | loss_mask: 0.2512 | loss_rpn_cls: 0.0121 | loss_rpn_loc: 0.0170 | Total Loss: 0.7181\n",
      "\u001b[32m[07/29 18:24:31 d2.utils.events]: \u001b[0m eta: 0:14:27  iter: 599      time: 0.3301  last_time: 0.2597   lr: 0.00014985  max_mem: 2292M\n",
      "Epoch 0600 | loss_cls: 0.0615 | loss_box_reg: 0.1381 | loss_mask: 0.4564 | loss_rpn_cls: 0.0113 | loss_rpn_loc: 0.0782 | Total Loss: 0.7454\n",
      "Epoch 0601 | loss_cls: 0.2335 | loss_box_reg: 0.5759 | loss_mask: 0.1587 | loss_rpn_cls: 0.0124 | loss_rpn_loc: 0.0425 | Total Loss: 1.0230\n",
      "Epoch 0602 | loss_cls: 0.1478 | loss_box_reg: 0.4143 | loss_mask: 0.1297 | loss_rpn_cls: 0.0525 | loss_rpn_loc: 0.5701 | Total Loss: 1.3143\n",
      "Epoch 0603 | loss_cls: 0.1582 | loss_box_reg: 0.2641 | loss_mask: 0.1400 | loss_rpn_cls: 0.0227 | loss_rpn_loc: 0.0191 | Total Loss: 0.6041\n",
      "Epoch 0604 | loss_cls: 0.0611 | loss_box_reg: 0.2287 | loss_mask: 0.1547 | loss_rpn_cls: 0.0059 | loss_rpn_loc: 0.0233 | Total Loss: 0.4737\n",
      "Epoch 0605 | loss_cls: 0.1024 | loss_box_reg: 0.1949 | loss_mask: 0.0768 | loss_rpn_cls: 0.0184 | loss_rpn_loc: 0.0174 | Total Loss: 0.4100\n",
      "Epoch 0606 | loss_cls: 0.2331 | loss_box_reg: 0.6656 | loss_mask: 0.1180 | loss_rpn_cls: 0.0216 | loss_rpn_loc: 0.2255 | Total Loss: 1.2638\n",
      "Epoch 0607 | loss_cls: 0.1390 | loss_box_reg: 0.2494 | loss_mask: 0.1521 | loss_rpn_cls: 0.0316 | loss_rpn_loc: 0.2174 | Total Loss: 0.7894\n",
      "Epoch 0608 | loss_cls: 0.1067 | loss_box_reg: 0.3552 | loss_mask: 0.1700 | loss_rpn_cls: 0.0029 | loss_rpn_loc: 0.0395 | Total Loss: 0.6744\n",
      "Epoch 0609 | loss_cls: 0.0485 | loss_box_reg: 0.1120 | loss_mask: 0.2330 | loss_rpn_cls: 0.0144 | loss_rpn_loc: 0.1744 | Total Loss: 0.5821\n",
      "Epoch 0610 | loss_cls: 0.1183 | loss_box_reg: 0.3279 | loss_mask: 0.1255 | loss_rpn_cls: 0.0095 | loss_rpn_loc: 0.0153 | Total Loss: 0.5965\n",
      "Epoch 0611 | loss_cls: 0.1608 | loss_box_reg: 0.5101 | loss_mask: 0.1436 | loss_rpn_cls: 0.0296 | loss_rpn_loc: 0.0126 | Total Loss: 0.8568\n",
      "Epoch 0612 | loss_cls: 0.1066 | loss_box_reg: 0.1397 | loss_mask: 0.1659 | loss_rpn_cls: 0.0055 | loss_rpn_loc: 0.1177 | Total Loss: 0.5354\n",
      "Epoch 0613 | loss_cls: 0.0577 | loss_box_reg: 0.1803 | loss_mask: 0.2038 | loss_rpn_cls: 0.0039 | loss_rpn_loc: 0.1129 | Total Loss: 0.5585\n",
      "Epoch 0614 | loss_cls: 0.0685 | loss_box_reg: 0.1788 | loss_mask: 0.1775 | loss_rpn_cls: 0.0178 | loss_rpn_loc: 0.1634 | Total Loss: 0.6060\n",
      "Epoch 0615 | loss_cls: 0.1125 | loss_box_reg: 0.4044 | loss_mask: 0.1494 | loss_rpn_cls: 0.0053 | loss_rpn_loc: 0.0932 | Total Loss: 0.7648\n",
      "Epoch 0616 | loss_cls: 0.1192 | loss_box_reg: 0.3743 | loss_mask: 0.0887 | loss_rpn_cls: 0.0160 | loss_rpn_loc: 0.2179 | Total Loss: 0.8160\n",
      "Epoch 0617 | loss_cls: 0.2278 | loss_box_reg: 0.5660 | loss_mask: 0.1258 | loss_rpn_cls: 0.0176 | loss_rpn_loc: 0.0436 | Total Loss: 0.9809\n",
      "Epoch 0618 | loss_cls: 0.0822 | loss_box_reg: 0.3294 | loss_mask: 0.2282 | loss_rpn_cls: 0.0278 | loss_rpn_loc: 0.0107 | Total Loss: 0.6783\n",
      "Epoch 0619 | loss_cls: 0.1182 | loss_box_reg: 0.3183 | loss_mask: 0.0796 | loss_rpn_cls: 0.0159 | loss_rpn_loc: 0.0086 | Total Loss: 0.5406\n",
      "\u001b[32m[07/29 18:24:38 d2.utils.events]: \u001b[0m eta: 0:14:20  iter: 619      time: 0.3303  last_time: 0.2664   lr: 0.00015485  max_mem: 2292M\n",
      "Epoch 0620 | loss_cls: 0.1172 | loss_box_reg: 0.2144 | loss_mask: 0.1693 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.0638 | Total Loss: 0.5698\n",
      "Epoch 0621 | loss_cls: 0.0472 | loss_box_reg: 0.2227 | loss_mask: 0.1041 | loss_rpn_cls: 0.0092 | loss_rpn_loc: 0.0835 | Total Loss: 0.4666\n",
      "Epoch 0622 | loss_cls: 0.1139 | loss_box_reg: 0.3219 | loss_mask: 0.1733 | loss_rpn_cls: 0.0074 | loss_rpn_loc: 0.0095 | Total Loss: 0.6261\n",
      "Epoch 0623 | loss_cls: 0.1733 | loss_box_reg: 0.3535 | loss_mask: 0.1358 | loss_rpn_cls: 0.0470 | loss_rpn_loc: 0.0344 | Total Loss: 0.7441\n",
      "Epoch 0624 | loss_cls: 0.0625 | loss_box_reg: 0.0720 | loss_mask: 0.2379 | loss_rpn_cls: 0.0222 | loss_rpn_loc: 0.0283 | Total Loss: 0.4229\n",
      "Epoch 0625 | loss_cls: 0.0865 | loss_box_reg: 0.2275 | loss_mask: 0.0782 | loss_rpn_cls: 0.0260 | loss_rpn_loc: 0.0039 | Total Loss: 0.4221\n",
      "Epoch 0626 | loss_cls: 0.1645 | loss_box_reg: 0.2974 | loss_mask: 0.1072 | loss_rpn_cls: 0.0065 | loss_rpn_loc: 0.1061 | Total Loss: 0.6818\n",
      "Epoch 0627 | loss_cls: 0.1678 | loss_box_reg: 0.3071 | loss_mask: 0.2935 | loss_rpn_cls: 0.0048 | loss_rpn_loc: 0.1589 | Total Loss: 0.9322\n",
      "Epoch 0628 | loss_cls: 0.0873 | loss_box_reg: 0.2126 | loss_mask: 0.4111 | loss_rpn_cls: 0.0297 | loss_rpn_loc: 0.0327 | Total Loss: 0.7734\n",
      "Epoch 0629 | loss_cls: 0.2582 | loss_box_reg: 0.3460 | loss_mask: 0.0844 | loss_rpn_cls: 0.2331 | loss_rpn_loc: 0.3444 | Total Loss: 1.2661\n",
      "Epoch 0630 | loss_cls: 0.1968 | loss_box_reg: 0.2876 | loss_mask: 0.1035 | loss_rpn_cls: 0.3649 | loss_rpn_loc: 0.5703 | Total Loss: 1.5231\n",
      "Epoch 0631 | loss_cls: 0.0417 | loss_box_reg: 0.1384 | loss_mask: 0.0793 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.0052 | Total Loss: 0.2680\n",
      " Best model saved at Epoch 631 | Total Loss: 0.2680\n",
      "Epoch 0632 | loss_cls: 0.2536 | loss_box_reg: 0.5056 | loss_mask: 0.2592 | loss_rpn_cls: 0.0114 | loss_rpn_loc: 0.0859 | Total Loss: 1.1157\n",
      "Epoch 0633 | loss_cls: 0.0893 | loss_box_reg: 0.3987 | loss_mask: 0.0845 | loss_rpn_cls: 0.0089 | loss_rpn_loc: 0.0289 | Total Loss: 0.6103\n",
      "Epoch 0634 | loss_cls: 0.0845 | loss_box_reg: 0.2997 | loss_mask: 0.1403 | loss_rpn_cls: 0.0143 | loss_rpn_loc: 0.0733 | Total Loss: 0.6120\n",
      "Epoch 0635 | loss_cls: 0.2204 | loss_box_reg: 0.3677 | loss_mask: 0.1020 | loss_rpn_cls: 0.0178 | loss_rpn_loc: 0.0304 | Total Loss: 0.7382\n",
      "Epoch 0636 | loss_cls: 0.1172 | loss_box_reg: 0.2699 | loss_mask: 0.1640 | loss_rpn_cls: 0.0638 | loss_rpn_loc: 0.0082 | Total Loss: 0.6231\n",
      "Epoch 0637 | loss_cls: 0.0556 | loss_box_reg: 0.1153 | loss_mask: 0.0899 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.1079 | Total Loss: 0.3738\n",
      "Epoch 0638 | loss_cls: 0.0878 | loss_box_reg: 0.2531 | loss_mask: 0.1259 | loss_rpn_cls: 0.0158 | loss_rpn_loc: 0.0729 | Total Loss: 0.5555\n",
      "Epoch 0639 | loss_cls: 0.1650 | loss_box_reg: 0.5354 | loss_mask: 0.1006 | loss_rpn_cls: 0.0151 | loss_rpn_loc: 0.0144 | Total Loss: 0.8305\n",
      "\u001b[32m[07/29 18:24:44 d2.utils.events]: \u001b[0m eta: 0:14:12  iter: 639      time: 0.3298  last_time: 0.4148   lr: 0.00015984  max_mem: 2292M\n",
      "Epoch 0640 | loss_cls: 0.1226 | loss_box_reg: 0.3898 | loss_mask: 0.2143 | loss_rpn_cls: 0.0279 | loss_rpn_loc: 0.0048 | Total Loss: 0.7595\n",
      "Epoch 0641 | loss_cls: 0.0936 | loss_box_reg: 0.1728 | loss_mask: 0.1454 | loss_rpn_cls: 0.0069 | loss_rpn_loc: 0.0899 | Total Loss: 0.5086\n",
      "Epoch 0642 | loss_cls: 0.1324 | loss_box_reg: 0.3103 | loss_mask: 0.0783 | loss_rpn_cls: 0.0369 | loss_rpn_loc: 0.0937 | Total Loss: 0.6517\n",
      "Epoch 0643 | loss_cls: 0.0964 | loss_box_reg: 0.2259 | loss_mask: 0.1169 | loss_rpn_cls: 0.0276 | loss_rpn_loc: 0.0171 | Total Loss: 0.4839\n",
      "Epoch 0644 | loss_cls: 0.1441 | loss_box_reg: 0.2303 | loss_mask: 0.1447 | loss_rpn_cls: 0.0048 | loss_rpn_loc: 0.1242 | Total Loss: 0.6482\n",
      "Epoch 0645 | loss_cls: 0.0890 | loss_box_reg: 0.3753 | loss_mask: 0.1203 | loss_rpn_cls: 0.0440 | loss_rpn_loc: 0.0096 | Total Loss: 0.6383\n",
      "Epoch 0646 | loss_cls: 0.1439 | loss_box_reg: 0.2605 | loss_mask: 0.1440 | loss_rpn_cls: 0.0138 | loss_rpn_loc: 0.1029 | Total Loss: 0.6651\n",
      "Epoch 0647 | loss_cls: 0.0806 | loss_box_reg: 0.2194 | loss_mask: 0.0934 | loss_rpn_cls: 0.0152 | loss_rpn_loc: 0.0582 | Total Loss: 0.4668\n",
      "Epoch 0648 | loss_cls: 0.2141 | loss_box_reg: 0.3619 | loss_mask: 0.1293 | loss_rpn_cls: 0.0269 | loss_rpn_loc: 0.0151 | Total Loss: 0.7473\n",
      "Epoch 0649 | loss_cls: 0.0506 | loss_box_reg: 0.0649 | loss_mask: 0.3607 | loss_rpn_cls: 0.0155 | loss_rpn_loc: 0.0291 | Total Loss: 0.5209\n",
      "Epoch 0650 | loss_cls: 0.1125 | loss_box_reg: 0.3444 | loss_mask: 0.1343 | loss_rpn_cls: 0.0129 | loss_rpn_loc: 0.0195 | Total Loss: 0.6236\n",
      "Epoch 0651 | loss_cls: 0.0589 | loss_box_reg: 0.1401 | loss_mask: 0.1744 | loss_rpn_cls: 0.0163 | loss_rpn_loc: 0.0097 | Total Loss: 0.3993\n",
      "Epoch 0652 | loss_cls: 0.1108 | loss_box_reg: 0.3149 | loss_mask: 0.1967 | loss_rpn_cls: 0.0186 | loss_rpn_loc: 0.0764 | Total Loss: 0.7175\n",
      "Epoch 0653 | loss_cls: 0.1235 | loss_box_reg: 0.2684 | loss_mask: 0.0705 | loss_rpn_cls: 0.0405 | loss_rpn_loc: 0.0595 | Total Loss: 0.5624\n",
      "Epoch 0654 | loss_cls: 0.1786 | loss_box_reg: 0.4250 | loss_mask: 0.2471 | loss_rpn_cls: 0.0132 | loss_rpn_loc: 0.0132 | Total Loss: 0.8772\n",
      "Epoch 0655 | loss_cls: 0.2045 | loss_box_reg: 0.4773 | loss_mask: 0.1944 | loss_rpn_cls: 0.0278 | loss_rpn_loc: 0.0285 | Total Loss: 0.9325\n",
      "Epoch 0656 | loss_cls: 0.1243 | loss_box_reg: 0.3218 | loss_mask: 0.2574 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.0473 | Total Loss: 0.7532\n",
      "Epoch 0657 | loss_cls: 0.0844 | loss_box_reg: 0.2063 | loss_mask: 0.0936 | loss_rpn_cls: 0.0219 | loss_rpn_loc: 0.1724 | Total Loss: 0.5787\n",
      "Epoch 0658 | loss_cls: 0.1650 | loss_box_reg: 0.3525 | loss_mask: 0.1256 | loss_rpn_cls: 0.0210 | loss_rpn_loc: 0.0895 | Total Loss: 0.7537\n",
      "Epoch 0659 | loss_cls: 0.1342 | loss_box_reg: 0.3000 | loss_mask: 0.0985 | loss_rpn_cls: 0.0101 | loss_rpn_loc: 0.1082 | Total Loss: 0.6508\n",
      "\u001b[32m[07/29 18:24:50 d2.utils.events]: \u001b[0m eta: 0:14:02  iter: 659      time: 0.3289  last_time: 0.3888   lr: 0.00016484  max_mem: 2292M\n",
      "Epoch 0660 | loss_cls: 0.3326 | loss_box_reg: 0.6129 | loss_mask: 0.1455 | loss_rpn_cls: 0.0357 | loss_rpn_loc: 0.1514 | Total Loss: 1.2782\n",
      "Epoch 0661 | loss_cls: 0.0401 | loss_box_reg: 0.1112 | loss_mask: 0.1785 | loss_rpn_cls: 0.0104 | loss_rpn_loc: 0.2730 | Total Loss: 0.6132\n",
      "Epoch 0662 | loss_cls: 0.1115 | loss_box_reg: 0.5024 | loss_mask: 0.1121 | loss_rpn_cls: 0.0162 | loss_rpn_loc: 0.0142 | Total Loss: 0.7564\n",
      "Epoch 0663 | loss_cls: 0.1103 | loss_box_reg: 0.3223 | loss_mask: 0.1603 | loss_rpn_cls: 0.0129 | loss_rpn_loc: 0.1471 | Total Loss: 0.7530\n",
      "Epoch 0664 | loss_cls: 0.0659 | loss_box_reg: 0.1950 | loss_mask: 0.0772 | loss_rpn_cls: 0.0176 | loss_rpn_loc: 0.0837 | Total Loss: 0.4394\n",
      "Epoch 0665 | loss_cls: 0.1206 | loss_box_reg: 0.2525 | loss_mask: 0.0953 | loss_rpn_cls: 0.0044 | loss_rpn_loc: 0.0353 | Total Loss: 0.5080\n",
      "Epoch 0666 | loss_cls: 0.0878 | loss_box_reg: 0.2573 | loss_mask: 0.1763 | loss_rpn_cls: 0.0090 | loss_rpn_loc: 0.0729 | Total Loss: 0.6033\n",
      "Epoch 0667 | loss_cls: 0.0816 | loss_box_reg: 0.1721 | loss_mask: 0.0783 | loss_rpn_cls: 0.0120 | loss_rpn_loc: 0.1589 | Total Loss: 0.5029\n",
      "Epoch 0668 | loss_cls: 0.1431 | loss_box_reg: 0.3654 | loss_mask: 0.1685 | loss_rpn_cls: 0.0222 | loss_rpn_loc: 0.1964 | Total Loss: 0.8957\n",
      "Epoch 0669 | loss_cls: 0.1747 | loss_box_reg: 0.2953 | loss_mask: 0.1334 | loss_rpn_cls: 0.0045 | loss_rpn_loc: 0.0493 | Total Loss: 0.6571\n",
      "Epoch 0670 | loss_cls: 0.0690 | loss_box_reg: 0.1128 | loss_mask: 0.8961 | loss_rpn_cls: 0.0052 | loss_rpn_loc: 0.1057 | Total Loss: 1.1888\n",
      "Epoch 0671 | loss_cls: 0.1888 | loss_box_reg: 0.2697 | loss_mask: 0.1794 | loss_rpn_cls: 0.0110 | loss_rpn_loc: 0.0166 | Total Loss: 0.6655\n",
      "Epoch 0672 | loss_cls: 0.1056 | loss_box_reg: 0.2348 | loss_mask: 0.2465 | loss_rpn_cls: 0.0041 | loss_rpn_loc: 0.0348 | Total Loss: 0.6258\n",
      "Epoch 0673 | loss_cls: 0.1736 | loss_box_reg: 0.3467 | loss_mask: 0.0865 | loss_rpn_cls: 0.0329 | loss_rpn_loc: 0.0131 | Total Loss: 0.6528\n",
      "Epoch 0674 | loss_cls: 0.0798 | loss_box_reg: 0.0934 | loss_mask: 0.1467 | loss_rpn_cls: 0.0172 | loss_rpn_loc: 0.0207 | Total Loss: 0.3577\n",
      "Epoch 0675 | loss_cls: 0.0603 | loss_box_reg: 0.0929 | loss_mask: 0.1637 | loss_rpn_cls: 0.0047 | loss_rpn_loc: 0.1299 | Total Loss: 0.4516\n",
      "Epoch 0676 | loss_cls: 0.0589 | loss_box_reg: 0.1809 | loss_mask: 0.0896 | loss_rpn_cls: 0.0030 | loss_rpn_loc: 0.0775 | Total Loss: 0.4099\n",
      "Epoch 0677 | loss_cls: 0.1204 | loss_box_reg: 0.2797 | loss_mask: 0.1314 | loss_rpn_cls: 0.0245 | loss_rpn_loc: 0.1315 | Total Loss: 0.6875\n",
      "Epoch 0678 | loss_cls: 0.1210 | loss_box_reg: 0.4053 | loss_mask: 0.2213 | loss_rpn_cls: 0.0201 | loss_rpn_loc: 0.0196 | Total Loss: 0.7873\n",
      "Epoch 0679 | loss_cls: 0.1282 | loss_box_reg: 0.2307 | loss_mask: 0.0879 | loss_rpn_cls: 0.0047 | loss_rpn_loc: 0.0109 | Total Loss: 0.4624\n",
      "\u001b[32m[07/29 18:24:57 d2.utils.events]: \u001b[0m eta: 0:13:57  iter: 679      time: 0.3290  last_time: 0.2825   lr: 0.00016983  max_mem: 2292M\n",
      "Epoch 0680 | loss_cls: 0.0808 | loss_box_reg: 0.3017 | loss_mask: 0.1603 | loss_rpn_cls: 0.0056 | loss_rpn_loc: 0.0045 | Total Loss: 0.5530\n",
      "Epoch 0681 | loss_cls: 0.1071 | loss_box_reg: 0.1765 | loss_mask: 0.1242 | loss_rpn_cls: 0.0222 | loss_rpn_loc: 0.0252 | Total Loss: 0.4552\n",
      "Epoch 0682 | loss_cls: 0.1611 | loss_box_reg: 0.4965 | loss_mask: 0.1290 | loss_rpn_cls: 0.0295 | loss_rpn_loc: 0.0556 | Total Loss: 0.8717\n",
      "Epoch 0683 | loss_cls: 0.0550 | loss_box_reg: 0.2600 | loss_mask: 0.1116 | loss_rpn_cls: 0.0092 | loss_rpn_loc: 0.0059 | Total Loss: 0.4417\n",
      "Epoch 0684 | loss_cls: 0.1978 | loss_box_reg: 0.4388 | loss_mask: 0.1803 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.1152 | Total Loss: 0.9372\n",
      "Epoch 0685 | loss_cls: 0.1326 | loss_box_reg: 0.3428 | loss_mask: 0.1416 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.0074 | Total Loss: 0.6296\n",
      "Epoch 0686 | loss_cls: 0.1070 | loss_box_reg: 0.3422 | loss_mask: 0.1481 | loss_rpn_cls: 0.0118 | loss_rpn_loc: 0.0378 | Total Loss: 0.6469\n",
      "Epoch 0687 | loss_cls: 0.1446 | loss_box_reg: 0.3140 | loss_mask: 0.0702 | loss_rpn_cls: 0.0226 | loss_rpn_loc: 0.0803 | Total Loss: 0.6318\n",
      "Epoch 0688 | loss_cls: 0.1510 | loss_box_reg: 0.5170 | loss_mask: 0.2709 | loss_rpn_cls: 0.0132 | loss_rpn_loc: 0.0198 | Total Loss: 0.9719\n",
      "Epoch 0689 | loss_cls: 0.1894 | loss_box_reg: 0.2654 | loss_mask: 0.1789 | loss_rpn_cls: 0.0460 | loss_rpn_loc: 0.6456 | Total Loss: 1.3252\n",
      "Epoch 0690 | loss_cls: 0.1511 | loss_box_reg: 0.2595 | loss_mask: 0.1087 | loss_rpn_cls: 0.0064 | loss_rpn_loc: 0.0293 | Total Loss: 0.5549\n",
      "Epoch 0691 | loss_cls: 0.0471 | loss_box_reg: 0.1498 | loss_mask: 0.0731 | loss_rpn_cls: 0.0112 | loss_rpn_loc: 0.0482 | Total Loss: 0.3294\n",
      "Epoch 0692 | loss_cls: 0.1558 | loss_box_reg: 0.2533 | loss_mask: 0.1293 | loss_rpn_cls: 0.0133 | loss_rpn_loc: 0.0298 | Total Loss: 0.5813\n",
      "Epoch 0693 | loss_cls: 0.1130 | loss_box_reg: 0.3328 | loss_mask: 0.1300 | loss_rpn_cls: 0.0258 | loss_rpn_loc: 0.1969 | Total Loss: 0.7984\n",
      "Epoch 0694 | loss_cls: 0.0406 | loss_box_reg: 0.0509 | loss_mask: 0.1007 | loss_rpn_cls: 0.0061 | loss_rpn_loc: 0.1532 | Total Loss: 0.3516\n",
      "Epoch 0695 | loss_cls: 0.1091 | loss_box_reg: 0.4060 | loss_mask: 0.2461 | loss_rpn_cls: 0.0038 | loss_rpn_loc: 0.0068 | Total Loss: 0.7718\n",
      "Epoch 0696 | loss_cls: 0.1623 | loss_box_reg: 0.3557 | loss_mask: 0.1304 | loss_rpn_cls: 0.0029 | loss_rpn_loc: 0.0088 | Total Loss: 0.6602\n",
      "Epoch 0697 | loss_cls: 0.1177 | loss_box_reg: 0.3330 | loss_mask: 0.1178 | loss_rpn_cls: 0.0093 | loss_rpn_loc: 0.0556 | Total Loss: 0.6334\n",
      "Epoch 0698 | loss_cls: 0.1367 | loss_box_reg: 0.4411 | loss_mask: 0.1059 | loss_rpn_cls: 0.0157 | loss_rpn_loc: 0.0925 | Total Loss: 0.7917\n",
      "Epoch 0699 | loss_cls: 0.1028 | loss_box_reg: 0.1661 | loss_mask: 0.2152 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.0826 | Total Loss: 0.5689\n",
      "\u001b[32m[07/29 18:25:03 d2.utils.events]: \u001b[0m eta: 0:13:49  iter: 699      time: 0.3287  last_time: 0.3825   lr: 0.00017483  max_mem: 2292M\n",
      "Epoch 0700 | loss_cls: 0.1189 | loss_box_reg: 0.2123 | loss_mask: 0.0561 | loss_rpn_cls: 0.0435 | loss_rpn_loc: 0.0595 | Total Loss: 0.4903\n",
      "Epoch 0701 | loss_cls: 0.0929 | loss_box_reg: 0.3083 | loss_mask: 0.1486 | loss_rpn_cls: 0.0082 | loss_rpn_loc: 0.0740 | Total Loss: 0.6321\n",
      "Epoch 0702 | loss_cls: 0.1259 | loss_box_reg: 0.3871 | loss_mask: 0.1644 | loss_rpn_cls: 0.0042 | loss_rpn_loc: 0.1555 | Total Loss: 0.8371\n",
      "Epoch 0703 | loss_cls: 0.1282 | loss_box_reg: 0.3146 | loss_mask: 0.1419 | loss_rpn_cls: 0.0079 | loss_rpn_loc: 0.0913 | Total Loss: 0.6839\n",
      "Epoch 0704 | loss_cls: 0.1808 | loss_box_reg: 0.4552 | loss_mask: 0.1248 | loss_rpn_cls: 0.0515 | loss_rpn_loc: 0.1014 | Total Loss: 0.9137\n",
      "Epoch 0705 | loss_cls: 0.3231 | loss_box_reg: 0.4624 | loss_mask: 0.1165 | loss_rpn_cls: 0.0096 | loss_rpn_loc: 0.3325 | Total Loss: 1.2441\n",
      "Epoch 0706 | loss_cls: 0.0637 | loss_box_reg: 0.1675 | loss_mask: 0.2297 | loss_rpn_cls: 0.0164 | loss_rpn_loc: 0.0466 | Total Loss: 0.5239\n",
      "Epoch 0707 | loss_cls: 0.1325 | loss_box_reg: 0.2523 | loss_mask: 0.2887 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.0131 | Total Loss: 0.6899\n",
      "Epoch 0708 | loss_cls: 0.1153 | loss_box_reg: 0.3561 | loss_mask: 0.0923 | loss_rpn_cls: 0.0061 | loss_rpn_loc: 0.0320 | Total Loss: 0.6017\n",
      "Epoch 0709 | loss_cls: 0.1073 | loss_box_reg: 0.2859 | loss_mask: 0.0849 | loss_rpn_cls: 0.0079 | loss_rpn_loc: 0.0783 | Total Loss: 0.5643\n",
      "Epoch 0710 | loss_cls: 0.1042 | loss_box_reg: 0.2148 | loss_mask: 0.2518 | loss_rpn_cls: 0.0241 | loss_rpn_loc: 0.0068 | Total Loss: 0.6016\n",
      "Epoch 0711 | loss_cls: 0.0490 | loss_box_reg: 0.1487 | loss_mask: 0.0871 | loss_rpn_cls: 0.0204 | loss_rpn_loc: 0.0163 | Total Loss: 0.3215\n",
      "Epoch 0712 | loss_cls: 0.1317 | loss_box_reg: 0.2544 | loss_mask: 0.2164 | loss_rpn_cls: 0.0052 | loss_rpn_loc: 0.0351 | Total Loss: 0.6428\n",
      "Epoch 0713 | loss_cls: 0.1450 | loss_box_reg: 0.4306 | loss_mask: 0.1181 | loss_rpn_cls: 0.0158 | loss_rpn_loc: 0.1638 | Total Loss: 0.8734\n",
      "Epoch 0714 | loss_cls: 0.1386 | loss_box_reg: 0.3414 | loss_mask: 0.1366 | loss_rpn_cls: 0.0028 | loss_rpn_loc: 0.0220 | Total Loss: 0.6412\n",
      "Epoch 0715 | loss_cls: 0.0532 | loss_box_reg: 0.2639 | loss_mask: 0.1152 | loss_rpn_cls: 0.0064 | loss_rpn_loc: 0.1491 | Total Loss: 0.5878\n",
      "Epoch 0716 | loss_cls: 0.0773 | loss_box_reg: 0.2383 | loss_mask: 0.0638 | loss_rpn_cls: 0.0074 | loss_rpn_loc: 0.0255 | Total Loss: 0.4122\n",
      "Epoch 0717 | loss_cls: 0.1211 | loss_box_reg: 0.2512 | loss_mask: 0.1017 | loss_rpn_cls: 0.0136 | loss_rpn_loc: 0.0083 | Total Loss: 0.4959\n",
      "Epoch 0718 | loss_cls: 0.0446 | loss_box_reg: 0.0899 | loss_mask: 0.1225 | loss_rpn_cls: 0.0256 | loss_rpn_loc: 0.0137 | Total Loss: 0.2963\n",
      "Epoch 0719 | loss_cls: 0.0639 | loss_box_reg: 0.2323 | loss_mask: 0.1966 | loss_rpn_cls: 0.0043 | loss_rpn_loc: 0.0394 | Total Loss: 0.5365\n",
      "\u001b[32m[07/29 18:25:10 d2.utils.events]: \u001b[0m eta: 0:13:44  iter: 719      time: 0.3294  last_time: 0.3920   lr: 0.00017982  max_mem: 2292M\n",
      "Epoch 0720 | loss_cls: 0.1761 | loss_box_reg: 0.4138 | loss_mask: 0.0618 | loss_rpn_cls: 0.0112 | loss_rpn_loc: 0.0229 | Total Loss: 0.6858\n",
      "Epoch 0721 | loss_cls: 0.1835 | loss_box_reg: 0.4752 | loss_mask: 0.0953 | loss_rpn_cls: 0.0292 | loss_rpn_loc: 0.0614 | Total Loss: 0.8446\n",
      "Epoch 0722 | loss_cls: 0.1385 | loss_box_reg: 0.2379 | loss_mask: 0.1062 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.0070 | Total Loss: 0.4948\n",
      "Epoch 0723 | loss_cls: 0.0737 | loss_box_reg: 0.0986 | loss_mask: 0.2427 | loss_rpn_cls: 0.0082 | loss_rpn_loc: 0.0189 | Total Loss: 0.4421\n",
      "Epoch 0724 | loss_cls: 0.0580 | loss_box_reg: 0.1324 | loss_mask: 0.0969 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.0029 | Total Loss: 0.2928\n",
      "Epoch 0725 | loss_cls: 0.1610 | loss_box_reg: 0.3673 | loss_mask: 0.1534 | loss_rpn_cls: 0.0062 | loss_rpn_loc: 0.0158 | Total Loss: 0.7036\n",
      "Epoch 0726 | loss_cls: 0.1637 | loss_box_reg: 0.4491 | loss_mask: 0.2166 | loss_rpn_cls: 0.0084 | loss_rpn_loc: 0.0464 | Total Loss: 0.8843\n",
      "Epoch 0727 | loss_cls: 0.0674 | loss_box_reg: 0.1870 | loss_mask: 0.1328 | loss_rpn_cls: 0.0217 | loss_rpn_loc: 0.0629 | Total Loss: 0.4717\n",
      "Epoch 0728 | loss_cls: 0.1207 | loss_box_reg: 0.2999 | loss_mask: 0.0945 | loss_rpn_cls: 0.0866 | loss_rpn_loc: 0.2402 | Total Loss: 0.8419\n",
      "Epoch 0729 | loss_cls: 0.0487 | loss_box_reg: 0.1974 | loss_mask: 0.1634 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.1827 | Total Loss: 0.5949\n",
      "Epoch 0730 | loss_cls: 0.0514 | loss_box_reg: 0.1496 | loss_mask: 0.0725 | loss_rpn_cls: 0.0265 | loss_rpn_loc: 0.0631 | Total Loss: 0.3631\n",
      "Epoch 0731 | loss_cls: 0.0376 | loss_box_reg: 0.0776 | loss_mask: 0.1162 | loss_rpn_cls: 0.0215 | loss_rpn_loc: 0.1525 | Total Loss: 0.4055\n",
      "Epoch 0732 | loss_cls: 0.1612 | loss_box_reg: 0.3890 | loss_mask: 0.1286 | loss_rpn_cls: 0.0228 | loss_rpn_loc: 0.1128 | Total Loss: 0.8145\n",
      "Epoch 0733 | loss_cls: 0.1542 | loss_box_reg: 0.4008 | loss_mask: 0.1036 | loss_rpn_cls: 0.0306 | loss_rpn_loc: 0.0798 | Total Loss: 0.7690\n",
      "Epoch 0734 | loss_cls: 0.1107 | loss_box_reg: 0.3088 | loss_mask: 0.1132 | loss_rpn_cls: 0.0042 | loss_rpn_loc: 0.0114 | Total Loss: 0.5483\n",
      "Epoch 0735 | loss_cls: 0.2340 | loss_box_reg: 0.3111 | loss_mask: 0.1169 | loss_rpn_cls: 0.1301 | loss_rpn_loc: 0.6570 | Total Loss: 1.4491\n",
      "Epoch 0736 | loss_cls: 0.0951 | loss_box_reg: 0.2819 | loss_mask: 0.1024 | loss_rpn_cls: 0.0356 | loss_rpn_loc: 0.0095 | Total Loss: 0.5246\n",
      "Epoch 0737 | loss_cls: 0.1362 | loss_box_reg: 0.3438 | loss_mask: 0.0891 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.0300 | Total Loss: 0.6015\n",
      "Epoch 0738 | loss_cls: 0.1006 | loss_box_reg: 0.4182 | loss_mask: 0.3218 | loss_rpn_cls: 0.0206 | loss_rpn_loc: 0.0816 | Total Loss: 0.9429\n",
      "Epoch 0739 | loss_cls: 0.0832 | loss_box_reg: 0.2347 | loss_mask: 0.1440 | loss_rpn_cls: 0.0072 | loss_rpn_loc: 0.1441 | Total Loss: 0.6132\n",
      "\u001b[32m[07/29 18:25:17 d2.utils.events]: \u001b[0m eta: 0:13:39  iter: 739      time: 0.3297  last_time: 0.3822   lr: 0.00018482  max_mem: 2292M\n",
      "Epoch 0740 | loss_cls: 0.0776 | loss_box_reg: 0.1568 | loss_mask: 0.1797 | loss_rpn_cls: 0.0179 | loss_rpn_loc: 0.0110 | Total Loss: 0.4431\n",
      "Epoch 0741 | loss_cls: 0.1687 | loss_box_reg: 0.4057 | loss_mask: 0.0849 | loss_rpn_cls: 0.0072 | loss_rpn_loc: 0.0564 | Total Loss: 0.7229\n",
      "Epoch 0742 | loss_cls: 0.0519 | loss_box_reg: 0.1693 | loss_mask: 0.6849 | loss_rpn_cls: 0.0165 | loss_rpn_loc: 0.0177 | Total Loss: 0.9403\n",
      "Epoch 0743 | loss_cls: 0.0815 | loss_box_reg: 0.2692 | loss_mask: 0.0949 | loss_rpn_cls: 0.0095 | loss_rpn_loc: 0.1255 | Total Loss: 0.5806\n",
      "Epoch 0744 | loss_cls: 0.1754 | loss_box_reg: 0.3125 | loss_mask: 0.1250 | loss_rpn_cls: 0.0175 | loss_rpn_loc: 0.0558 | Total Loss: 0.6861\n",
      "Epoch 0745 | loss_cls: 0.0899 | loss_box_reg: 0.2295 | loss_mask: 0.1219 | loss_rpn_cls: 0.0158 | loss_rpn_loc: 0.0139 | Total Loss: 0.4710\n",
      "Epoch 0746 | loss_cls: 0.0409 | loss_box_reg: 0.0987 | loss_mask: 0.1419 | loss_rpn_cls: 0.0094 | loss_rpn_loc: 0.2231 | Total Loss: 0.5140\n",
      "Epoch 0747 | loss_cls: 0.1202 | loss_box_reg: 0.2534 | loss_mask: 0.1600 | loss_rpn_cls: 0.0125 | loss_rpn_loc: 0.1272 | Total Loss: 0.6733\n",
      "Epoch 0748 | loss_cls: 0.0926 | loss_box_reg: 0.3289 | loss_mask: 0.2245 | loss_rpn_cls: 0.0194 | loss_rpn_loc: 0.0408 | Total Loss: 0.7062\n",
      "Epoch 0749 | loss_cls: 0.1202 | loss_box_reg: 0.2257 | loss_mask: 0.0876 | loss_rpn_cls: 0.0180 | loss_rpn_loc: 0.2788 | Total Loss: 0.7303\n",
      "Epoch 0750 | loss_cls: 0.1018 | loss_box_reg: 0.3626 | loss_mask: 0.0730 | loss_rpn_cls: 0.0063 | loss_rpn_loc: 0.0112 | Total Loss: 0.5550\n",
      "Epoch 0751 | loss_cls: 0.0582 | loss_box_reg: 0.1876 | loss_mask: 0.1059 | loss_rpn_cls: 0.0075 | loss_rpn_loc: 0.0972 | Total Loss: 0.4564\n",
      "Epoch 0752 | loss_cls: 0.1173 | loss_box_reg: 0.2918 | loss_mask: 0.1988 | loss_rpn_cls: 0.0230 | loss_rpn_loc: 0.0088 | Total Loss: 0.6396\n",
      "Epoch 0753 | loss_cls: 0.1584 | loss_box_reg: 0.4137 | loss_mask: 0.1803 | loss_rpn_cls: 0.0259 | loss_rpn_loc: 0.0652 | Total Loss: 0.8435\n",
      "Epoch 0754 | loss_cls: 0.0505 | loss_box_reg: 0.1073 | loss_mask: 0.1490 | loss_rpn_cls: 0.0044 | loss_rpn_loc: 0.1297 | Total Loss: 0.4409\n",
      "Epoch 0755 | loss_cls: 0.0826 | loss_box_reg: 0.2506 | loss_mask: 0.1434 | loss_rpn_cls: 0.0150 | loss_rpn_loc: 0.0388 | Total Loss: 0.5304\n",
      "Epoch 0756 | loss_cls: 0.1045 | loss_box_reg: 0.1632 | loss_mask: 0.3261 | loss_rpn_cls: 0.0240 | loss_rpn_loc: 0.0069 | Total Loss: 0.6246\n",
      "Epoch 0757 | loss_cls: 0.0850 | loss_box_reg: 0.3313 | loss_mask: 0.1147 | loss_rpn_cls: 0.0272 | loss_rpn_loc: 0.1658 | Total Loss: 0.7239\n",
      "Epoch 0758 | loss_cls: 0.1817 | loss_box_reg: 0.2459 | loss_mask: 0.0871 | loss_rpn_cls: 0.0041 | loss_rpn_loc: 0.0191 | Total Loss: 0.5379\n",
      "Epoch 0759 | loss_cls: 0.0395 | loss_box_reg: 0.1690 | loss_mask: 0.3013 | loss_rpn_cls: 0.0069 | loss_rpn_loc: 0.0322 | Total Loss: 0.5489\n",
      "\u001b[32m[07/29 18:25:23 d2.utils.events]: \u001b[0m eta: 0:13:37  iter: 759      time: 0.3298  last_time: 0.4021   lr: 0.00018981  max_mem: 2292M\n",
      "Epoch 0760 | loss_cls: 0.1375 | loss_box_reg: 0.3124 | loss_mask: 0.0967 | loss_rpn_cls: 0.0135 | loss_rpn_loc: 0.1494 | Total Loss: 0.7096\n",
      "Epoch 0761 | loss_cls: 0.1615 | loss_box_reg: 0.3960 | loss_mask: 0.0813 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.0100 | Total Loss: 0.6539\n",
      "Epoch 0762 | loss_cls: 0.0730 | loss_box_reg: 0.1343 | loss_mask: 0.1352 | loss_rpn_cls: 0.0283 | loss_rpn_loc: 0.1375 | Total Loss: 0.5082\n",
      "Epoch 0763 | loss_cls: 0.2247 | loss_box_reg: 0.4466 | loss_mask: 0.2010 | loss_rpn_cls: 0.0081 | loss_rpn_loc: 0.0523 | Total Loss: 0.9326\n",
      "Epoch 0764 | loss_cls: 0.1707 | loss_box_reg: 0.3428 | loss_mask: 0.1252 | loss_rpn_cls: 0.0071 | loss_rpn_loc: 0.0500 | Total Loss: 0.6957\n",
      "Epoch 0765 | loss_cls: 0.1279 | loss_box_reg: 0.3093 | loss_mask: 0.2031 | loss_rpn_cls: 0.0106 | loss_rpn_loc: 0.0080 | Total Loss: 0.6590\n",
      "Epoch 0766 | loss_cls: 0.0795 | loss_box_reg: 0.3153 | loss_mask: 0.2292 | loss_rpn_cls: 0.0029 | loss_rpn_loc: 0.1296 | Total Loss: 0.7566\n",
      "Epoch 0767 | loss_cls: 0.0379 | loss_box_reg: 0.1291 | loss_mask: 0.1345 | loss_rpn_cls: 0.0067 | loss_rpn_loc: 0.0206 | Total Loss: 0.3288\n",
      "Epoch 0768 | loss_cls: 0.1508 | loss_box_reg: 0.2776 | loss_mask: 0.1070 | loss_rpn_cls: 0.0197 | loss_rpn_loc: 0.0067 | Total Loss: 0.5619\n",
      "Epoch 0769 | loss_cls: 0.0341 | loss_box_reg: 0.1783 | loss_mask: 0.1582 | loss_rpn_cls: 0.0038 | loss_rpn_loc: 0.0736 | Total Loss: 0.4480\n",
      "Epoch 0770 | loss_cls: 0.0588 | loss_box_reg: 0.0498 | loss_mask: 0.1047 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.0258 | Total Loss: 0.2442\n",
      " Best model saved at Epoch 770 | Total Loss: 0.2442\n",
      "Epoch 0771 | loss_cls: 0.0798 | loss_box_reg: 0.1639 | loss_mask: 0.0881 | loss_rpn_cls: 0.0144 | loss_rpn_loc: 0.0239 | Total Loss: 0.3700\n",
      "Epoch 0772 | loss_cls: 0.0839 | loss_box_reg: 0.2139 | loss_mask: 0.1549 | loss_rpn_cls: 0.0053 | loss_rpn_loc: 0.0757 | Total Loss: 0.5337\n",
      "Epoch 0773 | loss_cls: 0.0351 | loss_box_reg: 0.1060 | loss_mask: 0.0824 | loss_rpn_cls: 0.0133 | loss_rpn_loc: 0.0228 | Total Loss: 0.2596\n",
      "Epoch 0774 | loss_cls: 0.0585 | loss_box_reg: 0.1510 | loss_mask: 0.0858 | loss_rpn_cls: 0.0217 | loss_rpn_loc: 0.0029 | Total Loss: 0.3200\n",
      "Epoch 0775 | loss_cls: 0.1491 | loss_box_reg: 0.2791 | loss_mask: 0.2432 | loss_rpn_cls: 0.0204 | loss_rpn_loc: 0.0150 | Total Loss: 0.7066\n",
      "Epoch 0776 | loss_cls: 0.1902 | loss_box_reg: 0.3845 | loss_mask: 0.0796 | loss_rpn_cls: 0.0140 | loss_rpn_loc: 0.1780 | Total Loss: 0.8463\n",
      "Epoch 0777 | loss_cls: 0.0713 | loss_box_reg: 0.2153 | loss_mask: 0.0590 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.0222 | Total Loss: 0.3698\n",
      "Epoch 0778 | loss_cls: 0.0838 | loss_box_reg: 0.2964 | loss_mask: 0.1230 | loss_rpn_cls: 0.0167 | loss_rpn_loc: 0.0265 | Total Loss: 0.5465\n",
      "Epoch 0779 | loss_cls: 0.0417 | loss_box_reg: 0.1453 | loss_mask: 0.0531 | loss_rpn_cls: 0.0100 | loss_rpn_loc: 0.0091 | Total Loss: 0.2591\n",
      "\u001b[32m[07/29 18:25:30 d2.utils.events]: \u001b[0m eta: 0:13:27  iter: 779      time: 0.3296  last_time: 0.2740   lr: 0.00019481  max_mem: 2292M\n",
      "Epoch 0780 | loss_cls: 0.1250 | loss_box_reg: 0.3644 | loss_mask: 0.0966 | loss_rpn_cls: 0.0129 | loss_rpn_loc: 0.1106 | Total Loss: 0.7096\n",
      "Epoch 0781 | loss_cls: 0.1282 | loss_box_reg: 0.2512 | loss_mask: 0.0826 | loss_rpn_cls: 0.0109 | loss_rpn_loc: 0.0406 | Total Loss: 0.5134\n",
      "Epoch 0782 | loss_cls: 0.1510 | loss_box_reg: 0.3365 | loss_mask: 0.2112 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.3241 | Total Loss: 1.0244\n",
      "Epoch 0783 | loss_cls: 0.0954 | loss_box_reg: 0.0970 | loss_mask: 0.0996 | loss_rpn_cls: 0.0021 | loss_rpn_loc: 0.0401 | Total Loss: 0.3343\n",
      "Epoch 0784 | loss_cls: 0.0972 | loss_box_reg: 0.3674 | loss_mask: 0.1089 | loss_rpn_cls: 0.0241 | loss_rpn_loc: 0.0287 | Total Loss: 0.6264\n",
      "Epoch 0785 | loss_cls: 0.0772 | loss_box_reg: 0.2030 | loss_mask: 0.3690 | loss_rpn_cls: 0.0111 | loss_rpn_loc: 0.0510 | Total Loss: 0.7112\n",
      "Epoch 0786 | loss_cls: 0.0612 | loss_box_reg: 0.1705 | loss_mask: 0.3138 | loss_rpn_cls: 0.0060 | loss_rpn_loc: 0.2065 | Total Loss: 0.7580\n",
      "Epoch 0787 | loss_cls: 0.1607 | loss_box_reg: 0.2705 | loss_mask: 0.0993 | loss_rpn_cls: 0.0063 | loss_rpn_loc: 0.0187 | Total Loss: 0.5554\n",
      "Epoch 0788 | loss_cls: 0.0704 | loss_box_reg: 0.2659 | loss_mask: 0.1101 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.0083 | Total Loss: 0.4552\n",
      "Epoch 0789 | loss_cls: 0.0416 | loss_box_reg: 0.1207 | loss_mask: 0.0812 | loss_rpn_cls: 0.0234 | loss_rpn_loc: 0.0530 | Total Loss: 0.3199\n",
      "Epoch 0790 | loss_cls: 0.0489 | loss_box_reg: 0.1299 | loss_mask: 0.1831 | loss_rpn_cls: 0.0026 | loss_rpn_loc: 0.0041 | Total Loss: 0.3685\n",
      "Epoch 0791 | loss_cls: 0.1096 | loss_box_reg: 0.1443 | loss_mask: 0.0708 | loss_rpn_cls: 0.0213 | loss_rpn_loc: 0.1650 | Total Loss: 0.5109\n",
      "Epoch 0792 | loss_cls: 0.1237 | loss_box_reg: 0.3082 | loss_mask: 0.0981 | loss_rpn_cls: 0.0419 | loss_rpn_loc: 0.0103 | Total Loss: 0.5822\n",
      "Epoch 0793 | loss_cls: 0.0539 | loss_box_reg: 0.1225 | loss_mask: 0.2364 | loss_rpn_cls: 0.0028 | loss_rpn_loc: 0.0040 | Total Loss: 0.4195\n",
      "Epoch 0794 | loss_cls: 0.1005 | loss_box_reg: 0.2592 | loss_mask: 0.1688 | loss_rpn_cls: 0.0071 | loss_rpn_loc: 0.1899 | Total Loss: 0.7255\n",
      "Epoch 0795 | loss_cls: 0.1280 | loss_box_reg: 0.2337 | loss_mask: 0.1332 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0405 | Total Loss: 0.5365\n",
      "Epoch 0796 | loss_cls: 0.1137 | loss_box_reg: 0.5226 | loss_mask: 0.1457 | loss_rpn_cls: 0.0290 | loss_rpn_loc: 0.1018 | Total Loss: 0.9128\n",
      "Epoch 0797 | loss_cls: 0.0405 | loss_box_reg: 0.1126 | loss_mask: 0.0820 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.0729 | Total Loss: 0.3114\n",
      "Epoch 0798 | loss_cls: 0.1631 | loss_box_reg: 0.2841 | loss_mask: 0.1167 | loss_rpn_cls: 0.0269 | loss_rpn_loc: 0.1177 | Total Loss: 0.7084\n",
      "Epoch 0799 | loss_cls: 0.1585 | loss_box_reg: 0.4388 | loss_mask: 0.1811 | loss_rpn_cls: 0.0180 | loss_rpn_loc: 0.0545 | Total Loss: 0.8510\n",
      "\u001b[32m[07/29 18:25:37 d2.utils.events]: \u001b[0m eta: 0:13:24  iter: 799      time: 0.3298  last_time: 0.2707   lr: 0.0001998  max_mem: 2292M\n",
      "Epoch 0800 | loss_cls: 0.1095 | loss_box_reg: 0.3766 | loss_mask: 0.1546 | loss_rpn_cls: 0.0044 | loss_rpn_loc: 0.0202 | Total Loss: 0.6653\n",
      "Epoch 0801 | loss_cls: 0.1855 | loss_box_reg: 0.3441 | loss_mask: 0.1000 | loss_rpn_cls: 0.0422 | loss_rpn_loc: 0.0568 | Total Loss: 0.7286\n",
      "Epoch 0802 | loss_cls: 0.0899 | loss_box_reg: 0.1567 | loss_mask: 0.2365 | loss_rpn_cls: 0.0029 | loss_rpn_loc: 0.1168 | Total Loss: 0.6029\n",
      "Epoch 0803 | loss_cls: 0.0744 | loss_box_reg: 0.1858 | loss_mask: 0.0758 | loss_rpn_cls: 0.0090 | loss_rpn_loc: 0.0120 | Total Loss: 0.3570\n",
      "Epoch 0804 | loss_cls: 0.1507 | loss_box_reg: 0.2633 | loss_mask: 0.1050 | loss_rpn_cls: 0.0096 | loss_rpn_loc: 0.0136 | Total Loss: 0.5422\n",
      "Epoch 0805 | loss_cls: 0.0427 | loss_box_reg: 0.0751 | loss_mask: 0.1258 | loss_rpn_cls: 0.0076 | loss_rpn_loc: 0.1265 | Total Loss: 0.3777\n",
      "Epoch 0806 | loss_cls: 0.0548 | loss_box_reg: 0.2091 | loss_mask: 0.0771 | loss_rpn_cls: 0.0105 | loss_rpn_loc: 0.0595 | Total Loss: 0.4110\n",
      "Epoch 0807 | loss_cls: 0.1339 | loss_box_reg: 0.3799 | loss_mask: 0.1080 | loss_rpn_cls: 0.0171 | loss_rpn_loc: 0.0256 | Total Loss: 0.6645\n",
      "Epoch 0808 | loss_cls: 0.1354 | loss_box_reg: 0.4741 | loss_mask: 0.1545 | loss_rpn_cls: 0.0056 | loss_rpn_loc: 0.0141 | Total Loss: 0.7837\n",
      "Epoch 0809 | loss_cls: 0.0701 | loss_box_reg: 0.1679 | loss_mask: 0.0750 | loss_rpn_cls: 0.0111 | loss_rpn_loc: 0.0731 | Total Loss: 0.3971\n",
      "Epoch 0810 | loss_cls: 0.1780 | loss_box_reg: 0.3131 | loss_mask: 0.0726 | loss_rpn_cls: 0.0046 | loss_rpn_loc: 0.2215 | Total Loss: 0.7898\n",
      "Epoch 0811 | loss_cls: 0.0637 | loss_box_reg: 0.1846 | loss_mask: 0.1465 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.0207 | Total Loss: 0.4169\n",
      "Epoch 0812 | loss_cls: 0.1786 | loss_box_reg: 0.3834 | loss_mask: 0.1018 | loss_rpn_cls: 0.0070 | loss_rpn_loc: 0.2085 | Total Loss: 0.8793\n",
      "Epoch 0813 | loss_cls: 0.0713 | loss_box_reg: 0.2059 | loss_mask: 0.3696 | loss_rpn_cls: 0.0129 | loss_rpn_loc: 0.0062 | Total Loss: 0.6659\n",
      "Epoch 0814 | loss_cls: 0.1359 | loss_box_reg: 0.3200 | loss_mask: 0.0605 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0718 | Total Loss: 0.5888\n",
      "Epoch 0815 | loss_cls: 0.1508 | loss_box_reg: 0.3591 | loss_mask: 0.2235 | loss_rpn_cls: 0.0158 | loss_rpn_loc: 0.1034 | Total Loss: 0.8525\n",
      "Epoch 0816 | loss_cls: 0.0739 | loss_box_reg: 0.0879 | loss_mask: 0.0780 | loss_rpn_cls: 0.0090 | loss_rpn_loc: 0.0090 | Total Loss: 0.2579\n",
      "Epoch 0817 | loss_cls: 0.1181 | loss_box_reg: 0.2148 | loss_mask: 0.0638 | loss_rpn_cls: 0.0131 | loss_rpn_loc: 0.3802 | Total Loss: 0.7900\n",
      "Epoch 0818 | loss_cls: 0.0981 | loss_box_reg: 0.2314 | loss_mask: 0.0775 | loss_rpn_cls: 0.0078 | loss_rpn_loc: 0.0508 | Total Loss: 0.4655\n",
      "Epoch 0819 | loss_cls: 0.1502 | loss_box_reg: 0.2060 | loss_mask: 0.1787 | loss_rpn_cls: 0.0068 | loss_rpn_loc: 0.0231 | Total Loss: 0.5648\n",
      "\u001b[32m[07/29 18:25:44 d2.utils.events]: \u001b[0m eta: 0:13:18  iter: 819      time: 0.3302  last_time: 0.2794   lr: 0.0002048  max_mem: 2292M\n",
      "Epoch 0820 | loss_cls: 0.1424 | loss_box_reg: 0.1449 | loss_mask: 0.0759 | loss_rpn_cls: 0.0113 | loss_rpn_loc: 0.1711 | Total Loss: 0.5455\n",
      "Epoch 0821 | loss_cls: 0.1876 | loss_box_reg: 0.4463 | loss_mask: 0.1614 | loss_rpn_cls: 0.0102 | loss_rpn_loc: 0.0291 | Total Loss: 0.8345\n",
      "Epoch 0822 | loss_cls: 0.0777 | loss_box_reg: 0.1877 | loss_mask: 0.2414 | loss_rpn_cls: 0.0018 | loss_rpn_loc: 0.1340 | Total Loss: 0.6425\n",
      "Epoch 0823 | loss_cls: 0.0518 | loss_box_reg: 0.1191 | loss_mask: 0.1937 | loss_rpn_cls: 0.0298 | loss_rpn_loc: 0.0038 | Total Loss: 0.3982\n",
      "Epoch 0824 | loss_cls: 0.0776 | loss_box_reg: 0.1806 | loss_mask: 0.1825 | loss_rpn_cls: 0.0061 | loss_rpn_loc: 0.0167 | Total Loss: 0.4634\n",
      "Epoch 0825 | loss_cls: 0.0401 | loss_box_reg: 0.1061 | loss_mask: 0.1526 | loss_rpn_cls: 0.0031 | loss_rpn_loc: 0.0990 | Total Loss: 0.4009\n",
      "Epoch 0826 | loss_cls: 0.1101 | loss_box_reg: 0.3334 | loss_mask: 0.1111 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.0052 | Total Loss: 0.5649\n",
      "Epoch 0827 | loss_cls: 0.0243 | loss_box_reg: 0.0465 | loss_mask: 0.0957 | loss_rpn_cls: 0.0146 | loss_rpn_loc: 0.1087 | Total Loss: 0.2897\n",
      "Epoch 0828 | loss_cls: 0.1334 | loss_box_reg: 0.3404 | loss_mask: 0.2182 | loss_rpn_cls: 0.0164 | loss_rpn_loc: 0.0178 | Total Loss: 0.7263\n",
      "Epoch 0829 | loss_cls: 0.0527 | loss_box_reg: 0.1883 | loss_mask: 0.1648 | loss_rpn_cls: 0.0129 | loss_rpn_loc: 0.0365 | Total Loss: 0.4552\n",
      "Epoch 0830 | loss_cls: 0.2050 | loss_box_reg: 0.3738 | loss_mask: 0.1099 | loss_rpn_cls: 0.0408 | loss_rpn_loc: 0.1202 | Total Loss: 0.8496\n",
      "Epoch 0831 | loss_cls: 0.0431 | loss_box_reg: 0.1008 | loss_mask: 0.1766 | loss_rpn_cls: 0.0176 | loss_rpn_loc: 0.0038 | Total Loss: 0.3419\n",
      "Epoch 0832 | loss_cls: 0.1080 | loss_box_reg: 0.3493 | loss_mask: 0.1172 | loss_rpn_cls: 0.0245 | loss_rpn_loc: 0.0296 | Total Loss: 0.6286\n",
      "Epoch 0833 | loss_cls: 0.2787 | loss_box_reg: 0.4310 | loss_mask: 0.0542 | loss_rpn_cls: 0.0145 | loss_rpn_loc: 0.1004 | Total Loss: 0.8788\n",
      "Epoch 0834 | loss_cls: 0.0877 | loss_box_reg: 0.2517 | loss_mask: 0.0685 | loss_rpn_cls: 0.0041 | loss_rpn_loc: 0.0038 | Total Loss: 0.4158\n",
      "Epoch 0835 | loss_cls: 0.1058 | loss_box_reg: 0.3033 | loss_mask: 0.1242 | loss_rpn_cls: 0.0086 | loss_rpn_loc: 0.0132 | Total Loss: 0.5552\n",
      "Epoch 0836 | loss_cls: 0.1254 | loss_box_reg: 0.3369 | loss_mask: 0.2948 | loss_rpn_cls: 0.0106 | loss_rpn_loc: 0.1432 | Total Loss: 0.9109\n",
      "Epoch 0837 | loss_cls: 0.0929 | loss_box_reg: 0.3857 | loss_mask: 0.0933 | loss_rpn_cls: 0.0244 | loss_rpn_loc: 0.0859 | Total Loss: 0.6822\n",
      "Epoch 0838 | loss_cls: 0.1386 | loss_box_reg: 0.3565 | loss_mask: 0.1290 | loss_rpn_cls: 0.0101 | loss_rpn_loc: 0.0450 | Total Loss: 0.6793\n",
      "Epoch 0839 | loss_cls: 0.1720 | loss_box_reg: 0.2349 | loss_mask: 0.0738 | loss_rpn_cls: 0.0042 | loss_rpn_loc: 0.0059 | Total Loss: 0.4908\n",
      "\u001b[32m[07/29 18:25:50 d2.utils.events]: \u001b[0m eta: 0:13:11  iter: 839      time: 0.3299  last_time: 0.2649   lr: 0.00020979  max_mem: 2292M\n",
      "Epoch 0840 | loss_cls: 0.0687 | loss_box_reg: 0.0532 | loss_mask: 0.2094 | loss_rpn_cls: 0.0228 | loss_rpn_loc: 0.2733 | Total Loss: 0.6274\n",
      "Epoch 0841 | loss_cls: 0.0256 | loss_box_reg: 0.1170 | loss_mask: 0.1837 | loss_rpn_cls: 0.0178 | loss_rpn_loc: 0.0171 | Total Loss: 0.3611\n",
      "Epoch 0842 | loss_cls: 0.1347 | loss_box_reg: 0.2119 | loss_mask: 0.1114 | loss_rpn_cls: 0.0075 | loss_rpn_loc: 0.0283 | Total Loss: 0.4939\n",
      "Epoch 0843 | loss_cls: 0.1033 | loss_box_reg: 0.2503 | loss_mask: 0.1017 | loss_rpn_cls: 0.0140 | loss_rpn_loc: 0.0088 | Total Loss: 0.4782\n",
      "Epoch 0844 | loss_cls: 0.0857 | loss_box_reg: 0.2102 | loss_mask: 0.1214 | loss_rpn_cls: 0.0120 | loss_rpn_loc: 0.0268 | Total Loss: 0.4563\n",
      "Epoch 0845 | loss_cls: 0.0881 | loss_box_reg: 0.0747 | loss_mask: 0.4412 | loss_rpn_cls: 0.0109 | loss_rpn_loc: 0.0182 | Total Loss: 0.6331\n",
      "Epoch 0846 | loss_cls: 0.1929 | loss_box_reg: 0.3658 | loss_mask: 0.1406 | loss_rpn_cls: 0.0132 | loss_rpn_loc: 0.1231 | Total Loss: 0.8357\n",
      "Epoch 0847 | loss_cls: 0.1704 | loss_box_reg: 0.4132 | loss_mask: 0.1751 | loss_rpn_cls: 0.0146 | loss_rpn_loc: 0.0932 | Total Loss: 0.8665\n",
      "Epoch 0848 | loss_cls: 0.1812 | loss_box_reg: 0.4057 | loss_mask: 0.2189 | loss_rpn_cls: 0.0170 | loss_rpn_loc: 0.2301 | Total Loss: 1.0528\n",
      "Epoch 0849 | loss_cls: 0.0672 | loss_box_reg: 0.1425 | loss_mask: 0.0604 | loss_rpn_cls: 0.0037 | loss_rpn_loc: 0.0210 | Total Loss: 0.2949\n",
      "Epoch 0850 | loss_cls: 0.0527 | loss_box_reg: 0.2903 | loss_mask: 0.0977 | loss_rpn_cls: 0.0077 | loss_rpn_loc: 0.0146 | Total Loss: 0.4630\n",
      "Epoch 0851 | loss_cls: 0.0593 | loss_box_reg: 0.2100 | loss_mask: 0.0902 | loss_rpn_cls: 0.0042 | loss_rpn_loc: 0.1374 | Total Loss: 0.5010\n",
      "Epoch 0852 | loss_cls: 0.0821 | loss_box_reg: 0.1077 | loss_mask: 0.0494 | loss_rpn_cls: 0.0137 | loss_rpn_loc: 0.1370 | Total Loss: 0.3900\n",
      "Epoch 0853 | loss_cls: 0.0917 | loss_box_reg: 0.2020 | loss_mask: 0.2161 | loss_rpn_cls: 0.0048 | loss_rpn_loc: 0.0778 | Total Loss: 0.5925\n",
      "Epoch 0854 | loss_cls: 0.0663 | loss_box_reg: 0.2584 | loss_mask: 0.3792 | loss_rpn_cls: 0.0056 | loss_rpn_loc: 0.0839 | Total Loss: 0.7934\n",
      "Epoch 0855 | loss_cls: 0.2094 | loss_box_reg: 0.5108 | loss_mask: 0.0945 | loss_rpn_cls: 0.0478 | loss_rpn_loc: 0.1567 | Total Loss: 1.0191\n",
      "Epoch 0856 | loss_cls: 0.0877 | loss_box_reg: 0.1099 | loss_mask: 0.1591 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0049 | Total Loss: 0.3623\n",
      "Epoch 0857 | loss_cls: 0.1320 | loss_box_reg: 0.2290 | loss_mask: 0.0802 | loss_rpn_cls: 0.0105 | loss_rpn_loc: 0.0256 | Total Loss: 0.4772\n",
      "Epoch 0858 | loss_cls: 0.0560 | loss_box_reg: 0.2760 | loss_mask: 0.1837 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.1909 | Total Loss: 0.7084\n",
      "Epoch 0859 | loss_cls: 0.0231 | loss_box_reg: 0.0697 | loss_mask: 0.1970 | loss_rpn_cls: 0.0056 | loss_rpn_loc: 0.1168 | Total Loss: 0.4122\n",
      "\u001b[32m[07/29 18:25:57 d2.utils.events]: \u001b[0m eta: 0:13:05  iter: 859      time: 0.3301  last_time: 0.3972   lr: 0.00021479  max_mem: 2292M\n",
      "Epoch 0860 | loss_cls: 0.0705 | loss_box_reg: 0.2232 | loss_mask: 0.1356 | loss_rpn_cls: 0.0180 | loss_rpn_loc: 0.0415 | Total Loss: 0.4888\n",
      "Epoch 0861 | loss_cls: 0.0404 | loss_box_reg: 0.1378 | loss_mask: 0.1131 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.0193 | Total Loss: 0.3155\n",
      "Epoch 0862 | loss_cls: 0.1009 | loss_box_reg: 0.2716 | loss_mask: 0.1425 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.1631 | Total Loss: 0.6789\n",
      "Epoch 0863 | loss_cls: 0.0959 | loss_box_reg: 0.3062 | loss_mask: 0.0714 | loss_rpn_cls: 0.0146 | loss_rpn_loc: 0.0288 | Total Loss: 0.5170\n",
      "Epoch 0864 | loss_cls: 0.1371 | loss_box_reg: 0.2978 | loss_mask: 0.0758 | loss_rpn_cls: 0.0115 | loss_rpn_loc: 0.1817 | Total Loss: 0.7040\n",
      "Epoch 0865 | loss_cls: 0.1372 | loss_box_reg: 0.3800 | loss_mask: 0.1315 | loss_rpn_cls: 0.0105 | loss_rpn_loc: 0.0114 | Total Loss: 0.6705\n",
      "Epoch 0866 | loss_cls: 0.1808 | loss_box_reg: 0.3148 | loss_mask: 0.1169 | loss_rpn_cls: 0.0743 | loss_rpn_loc: 0.1232 | Total Loss: 0.8100\n",
      "Epoch 0867 | loss_cls: 0.0678 | loss_box_reg: 0.1162 | loss_mask: 0.1090 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0205 | Total Loss: 0.3140\n",
      "Epoch 0868 | loss_cls: 0.0978 | loss_box_reg: 0.1696 | loss_mask: 0.1502 | loss_rpn_cls: 0.0182 | loss_rpn_loc: 0.0128 | Total Loss: 0.4486\n",
      "Epoch 0869 | loss_cls: 0.0951 | loss_box_reg: 0.1558 | loss_mask: 0.2301 | loss_rpn_cls: 0.0238 | loss_rpn_loc: 0.1256 | Total Loss: 0.6304\n",
      "Epoch 0870 | loss_cls: 0.0619 | loss_box_reg: 0.1608 | loss_mask: 0.0694 | loss_rpn_cls: 0.0008 | loss_rpn_loc: 0.0306 | Total Loss: 0.3234\n",
      "Epoch 0871 | loss_cls: 0.0865 | loss_box_reg: 0.2194 | loss_mask: 0.0847 | loss_rpn_cls: 0.0044 | loss_rpn_loc: 0.0814 | Total Loss: 0.4764\n",
      "Epoch 0872 | loss_cls: 0.0731 | loss_box_reg: 0.1673 | loss_mask: 0.0676 | loss_rpn_cls: 0.0093 | loss_rpn_loc: 0.0273 | Total Loss: 0.3445\n",
      "Epoch 0873 | loss_cls: 0.1131 | loss_box_reg: 0.1597 | loss_mask: 0.0800 | loss_rpn_cls: 0.0038 | loss_rpn_loc: 0.0291 | Total Loss: 0.3858\n",
      "Epoch 0874 | loss_cls: 0.0447 | loss_box_reg: 0.0977 | loss_mask: 0.0680 | loss_rpn_cls: 0.0076 | loss_rpn_loc: 0.1146 | Total Loss: 0.3326\n",
      "Epoch 0875 | loss_cls: 0.1133 | loss_box_reg: 0.3159 | loss_mask: 0.1705 | loss_rpn_cls: 0.0097 | loss_rpn_loc: 0.0380 | Total Loss: 0.6475\n",
      "Epoch 0876 | loss_cls: 0.0955 | loss_box_reg: 0.2107 | loss_mask: 0.1676 | loss_rpn_cls: 0.0080 | loss_rpn_loc: 0.0133 | Total Loss: 0.4952\n",
      "Epoch 0877 | loss_cls: 0.0986 | loss_box_reg: 0.2320 | loss_mask: 0.1459 | loss_rpn_cls: 0.1209 | loss_rpn_loc: 0.4593 | Total Loss: 1.0568\n",
      "Epoch 0878 | loss_cls: 0.0389 | loss_box_reg: 0.0908 | loss_mask: 0.1764 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.0030 | Total Loss: 0.3125\n",
      "Epoch 0879 | loss_cls: 0.0715 | loss_box_reg: 0.1789 | loss_mask: 0.0877 | loss_rpn_cls: 0.0068 | loss_rpn_loc: 0.0799 | Total Loss: 0.4248\n",
      "\u001b[32m[07/29 18:26:04 d2.utils.events]: \u001b[0m eta: 0:12:58  iter: 879      time: 0.3305  last_time: 0.2798   lr: 0.00021978  max_mem: 2292M\n",
      "Epoch 0880 | loss_cls: 0.1358 | loss_box_reg: 0.2520 | loss_mask: 0.2799 | loss_rpn_cls: 0.0147 | loss_rpn_loc: 0.1879 | Total Loss: 0.8703\n",
      "Epoch 0881 | loss_cls: 0.0805 | loss_box_reg: 0.2997 | loss_mask: 0.0770 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.0673 | Total Loss: 0.5262\n",
      "Epoch 0882 | loss_cls: 0.1394 | loss_box_reg: 0.3870 | loss_mask: 0.1428 | loss_rpn_cls: 0.0099 | loss_rpn_loc: 0.1195 | Total Loss: 0.7986\n",
      "Epoch 0883 | loss_cls: 0.1159 | loss_box_reg: 0.3597 | loss_mask: 0.1431 | loss_rpn_cls: 0.0176 | loss_rpn_loc: 0.0323 | Total Loss: 0.6686\n",
      "Epoch 0884 | loss_cls: 0.0964 | loss_box_reg: 0.2424 | loss_mask: 0.0868 | loss_rpn_cls: 0.0061 | loss_rpn_loc: 0.0123 | Total Loss: 0.4440\n",
      "Epoch 0885 | loss_cls: 0.1809 | loss_box_reg: 0.3160 | loss_mask: 0.1160 | loss_rpn_cls: 0.0118 | loss_rpn_loc: 0.0603 | Total Loss: 0.6851\n",
      "Epoch 0886 | loss_cls: 0.0547 | loss_box_reg: 0.0922 | loss_mask: 0.9396 | loss_rpn_cls: 0.0017 | loss_rpn_loc: 0.1324 | Total Loss: 1.2206\n",
      "Epoch 0887 | loss_cls: 0.0977 | loss_box_reg: 0.2822 | loss_mask: 0.1273 | loss_rpn_cls: 0.0008 | loss_rpn_loc: 0.0046 | Total Loss: 0.5125\n",
      "Epoch 0888 | loss_cls: 0.1549 | loss_box_reg: 0.3974 | loss_mask: 0.1380 | loss_rpn_cls: 0.0262 | loss_rpn_loc: 0.0962 | Total Loss: 0.8126\n",
      "Epoch 0889 | loss_cls: 0.0366 | loss_box_reg: 0.0859 | loss_mask: 0.4105 | loss_rpn_cls: 0.0032 | loss_rpn_loc: 0.1070 | Total Loss: 0.6431\n",
      "Epoch 0890 | loss_cls: 0.1832 | loss_box_reg: 0.2869 | loss_mask: 0.1748 | loss_rpn_cls: 0.0165 | loss_rpn_loc: 0.2219 | Total Loss: 0.8834\n",
      "Epoch 0891 | loss_cls: 0.0761 | loss_box_reg: 0.2649 | loss_mask: 0.2586 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0041 | Total Loss: 0.6047\n",
      "Epoch 0892 | loss_cls: 0.0886 | loss_box_reg: 0.2215 | loss_mask: 0.3393 | loss_rpn_cls: 0.0059 | loss_rpn_loc: 0.0207 | Total Loss: 0.6760\n",
      "Epoch 0893 | loss_cls: 0.1484 | loss_box_reg: 0.4611 | loss_mask: 0.2863 | loss_rpn_cls: 0.0082 | loss_rpn_loc: 0.1523 | Total Loss: 1.0563\n",
      "Epoch 0894 | loss_cls: 0.0978 | loss_box_reg: 0.2332 | loss_mask: 0.0845 | loss_rpn_cls: 0.0085 | loss_rpn_loc: 0.0422 | Total Loss: 0.4663\n",
      "Epoch 0895 | loss_cls: 0.0865 | loss_box_reg: 0.3234 | loss_mask: 0.1253 | loss_rpn_cls: 0.0121 | loss_rpn_loc: 0.0040 | Total Loss: 0.5513\n",
      "Epoch 0896 | loss_cls: 0.0902 | loss_box_reg: 0.2147 | loss_mask: 0.2610 | loss_rpn_cls: 0.0061 | loss_rpn_loc: 0.0808 | Total Loss: 0.6529\n",
      "Epoch 0897 | loss_cls: 0.1030 | loss_box_reg: 0.2987 | loss_mask: 0.0795 | loss_rpn_cls: 0.0049 | loss_rpn_loc: 0.1236 | Total Loss: 0.6097\n",
      "Epoch 0898 | loss_cls: 0.1184 | loss_box_reg: 0.3258 | loss_mask: 0.2105 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.0818 | Total Loss: 0.7415\n",
      "Epoch 0899 | loss_cls: 0.0652 | loss_box_reg: 0.0930 | loss_mask: 0.0892 | loss_rpn_cls: 0.0120 | loss_rpn_loc: 0.0176 | Total Loss: 0.2770\n",
      "\u001b[32m[07/29 18:26:10 d2.utils.events]: \u001b[0m eta: 0:12:52  iter: 899      time: 0.3307  last_time: 0.2769   lr: 0.00022478  max_mem: 2292M\n",
      "Epoch 0900 | loss_cls: 0.0552 | loss_box_reg: 0.0391 | loss_mask: 0.2478 | loss_rpn_cls: 0.0294 | loss_rpn_loc: 0.0365 | Total Loss: 0.4080\n",
      "Epoch 0901 | loss_cls: 0.1291 | loss_box_reg: 0.3515 | loss_mask: 0.0616 | loss_rpn_cls: 0.0126 | loss_rpn_loc: 0.0179 | Total Loss: 0.5728\n",
      "Epoch 0902 | loss_cls: 0.1108 | loss_box_reg: 0.2907 | loss_mask: 0.1041 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.0382 | Total Loss: 0.5462\n",
      "Epoch 0903 | loss_cls: 0.1359 | loss_box_reg: 0.2306 | loss_mask: 0.2367 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.1045 | Total Loss: 0.7128\n",
      "Epoch 0904 | loss_cls: 0.0784 | loss_box_reg: 0.2252 | loss_mask: 0.1518 | loss_rpn_cls: 0.0158 | loss_rpn_loc: 0.1383 | Total Loss: 0.6094\n",
      "Epoch 0905 | loss_cls: 0.0369 | loss_box_reg: 0.1050 | loss_mask: 0.0665 | loss_rpn_cls: 0.0052 | loss_rpn_loc: 0.0862 | Total Loss: 0.2998\n",
      "Epoch 0906 | loss_cls: 0.0593 | loss_box_reg: 0.1446 | loss_mask: 0.0670 | loss_rpn_cls: 0.0049 | loss_rpn_loc: 0.0018 | Total Loss: 0.2776\n",
      "Epoch 0907 | loss_cls: 0.0577 | loss_box_reg: 0.2658 | loss_mask: 0.1484 | loss_rpn_cls: 0.0090 | loss_rpn_loc: 0.0578 | Total Loss: 0.5386\n",
      "Epoch 0908 | loss_cls: 0.0486 | loss_box_reg: 0.1256 | loss_mask: 0.1027 | loss_rpn_cls: 0.0064 | loss_rpn_loc: 0.1266 | Total Loss: 0.4098\n",
      "Epoch 0909 | loss_cls: 0.0750 | loss_box_reg: 0.4135 | loss_mask: 0.0816 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.0631 | Total Loss: 0.6383\n",
      "Epoch 0910 | loss_cls: 0.1075 | loss_box_reg: 0.3471 | loss_mask: 0.1254 | loss_rpn_cls: 0.0020 | loss_rpn_loc: 0.0155 | Total Loss: 0.5974\n",
      "Epoch 0911 | loss_cls: 0.0811 | loss_box_reg: 0.2097 | loss_mask: 0.1258 | loss_rpn_cls: 0.0209 | loss_rpn_loc: 0.0098 | Total Loss: 0.4473\n",
      "Epoch 0912 | loss_cls: 0.0676 | loss_box_reg: 0.1490 | loss_mask: 0.0867 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.0099 | Total Loss: 0.3144\n",
      "Epoch 0913 | loss_cls: 0.2312 | loss_box_reg: 0.2792 | loss_mask: 0.1430 | loss_rpn_cls: 0.0321 | loss_rpn_loc: 0.1535 | Total Loss: 0.8389\n",
      "Epoch 0914 | loss_cls: 0.1140 | loss_box_reg: 0.3318 | loss_mask: 0.1166 | loss_rpn_cls: 0.0173 | loss_rpn_loc: 0.0120 | Total Loss: 0.5917\n",
      "Epoch 0915 | loss_cls: 0.0907 | loss_box_reg: 0.2530 | loss_mask: 0.1707 | loss_rpn_cls: 0.0116 | loss_rpn_loc: 0.0469 | Total Loss: 0.5729\n",
      "Epoch 0916 | loss_cls: 0.0436 | loss_box_reg: 0.1550 | loss_mask: 0.0987 | loss_rpn_cls: 0.0024 | loss_rpn_loc: 0.1497 | Total Loss: 0.4494\n",
      "Epoch 0917 | loss_cls: 0.0606 | loss_box_reg: 0.1792 | loss_mask: 0.3477 | loss_rpn_cls: 0.0091 | loss_rpn_loc: 0.1351 | Total Loss: 0.7316\n",
      "Epoch 0918 | loss_cls: 0.1891 | loss_box_reg: 0.3979 | loss_mask: 0.0883 | loss_rpn_cls: 0.0734 | loss_rpn_loc: 0.3574 | Total Loss: 1.1061\n",
      "Epoch 0919 | loss_cls: 0.2086 | loss_box_reg: 0.2805 | loss_mask: 0.0611 | loss_rpn_cls: 0.0095 | loss_rpn_loc: 0.0797 | Total Loss: 0.6394\n",
      "\u001b[32m[07/29 18:26:17 d2.utils.events]: \u001b[0m eta: 0:12:44  iter: 919      time: 0.3305  last_time: 0.2699   lr: 0.00022977  max_mem: 2292M\n",
      "Epoch 0920 | loss_cls: 0.1123 | loss_box_reg: 0.2118 | loss_mask: 0.1153 | loss_rpn_cls: 0.0039 | loss_rpn_loc: 0.0403 | Total Loss: 0.4836\n",
      "Epoch 0921 | loss_cls: 0.1021 | loss_box_reg: 0.2093 | loss_mask: 0.0795 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.0091 | Total Loss: 0.4050\n",
      "Epoch 0922 | loss_cls: 0.1536 | loss_box_reg: 0.3751 | loss_mask: 0.1468 | loss_rpn_cls: 0.0348 | loss_rpn_loc: 0.0286 | Total Loss: 0.7389\n",
      "Epoch 0923 | loss_cls: 0.1533 | loss_box_reg: 0.1875 | loss_mask: 0.1548 | loss_rpn_cls: 0.0049 | loss_rpn_loc: 0.1754 | Total Loss: 0.6759\n",
      "Epoch 0924 | loss_cls: 0.0693 | loss_box_reg: 0.1590 | loss_mask: 0.0984 | loss_rpn_cls: 0.0110 | loss_rpn_loc: 0.1292 | Total Loss: 0.4669\n",
      "Epoch 0925 | loss_cls: 0.1038 | loss_box_reg: 0.2468 | loss_mask: 0.0945 | loss_rpn_cls: 0.0077 | loss_rpn_loc: 0.0276 | Total Loss: 0.4804\n",
      "Epoch 0926 | loss_cls: 0.1154 | loss_box_reg: 0.2071 | loss_mask: 0.1499 | loss_rpn_cls: 0.0106 | loss_rpn_loc: 0.0092 | Total Loss: 0.4922\n",
      "Epoch 0927 | loss_cls: 0.0770 | loss_box_reg: 0.2339 | loss_mask: 0.1143 | loss_rpn_cls: 0.0226 | loss_rpn_loc: 0.1577 | Total Loss: 0.6055\n",
      "Epoch 0928 | loss_cls: 0.1027 | loss_box_reg: 0.2443 | loss_mask: 0.1052 | loss_rpn_cls: 0.0206 | loss_rpn_loc: 0.0573 | Total Loss: 0.5301\n",
      "Epoch 0929 | loss_cls: 0.0985 | loss_box_reg: 0.2538 | loss_mask: 0.1104 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.0142 | Total Loss: 0.4796\n",
      "Epoch 0930 | loss_cls: 0.1067 | loss_box_reg: 0.2941 | loss_mask: 0.0981 | loss_rpn_cls: 0.0923 | loss_rpn_loc: 0.2997 | Total Loss: 0.8909\n",
      "Epoch 0931 | loss_cls: 0.1066 | loss_box_reg: 0.3200 | loss_mask: 0.0728 | loss_rpn_cls: 0.0074 | loss_rpn_loc: 0.0081 | Total Loss: 0.5150\n",
      "Epoch 0932 | loss_cls: 0.0610 | loss_box_reg: 0.2330 | loss_mask: 0.0631 | loss_rpn_cls: 0.0155 | loss_rpn_loc: 0.0188 | Total Loss: 0.3913\n",
      "Epoch 0933 | loss_cls: 0.0487 | loss_box_reg: 0.0759 | loss_mask: 0.3393 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.1120 | Total Loss: 0.5784\n",
      "Epoch 0934 | loss_cls: 0.1615 | loss_box_reg: 0.1514 | loss_mask: 0.1799 | loss_rpn_cls: 0.0136 | loss_rpn_loc: 0.1232 | Total Loss: 0.6297\n",
      "Epoch 0935 | loss_cls: 0.1127 | loss_box_reg: 0.1983 | loss_mask: 0.1103 | loss_rpn_cls: 0.0261 | loss_rpn_loc: 0.0092 | Total Loss: 0.4567\n",
      "Epoch 0936 | loss_cls: 0.0477 | loss_box_reg: 0.1397 | loss_mask: 0.3358 | loss_rpn_cls: 0.0177 | loss_rpn_loc: 0.0037 | Total Loss: 0.5445\n",
      "Epoch 0937 | loss_cls: 0.0576 | loss_box_reg: 0.1407 | loss_mask: 0.0631 | loss_rpn_cls: 0.0087 | loss_rpn_loc: 0.0049 | Total Loss: 0.2751\n",
      "Epoch 0938 | loss_cls: 0.0715 | loss_box_reg: 0.1940 | loss_mask: 0.1742 | loss_rpn_cls: 0.0221 | loss_rpn_loc: 0.1164 | Total Loss: 0.5783\n",
      "Epoch 0939 | loss_cls: 0.0523 | loss_box_reg: 0.1191 | loss_mask: 0.0379 | loss_rpn_cls: 0.0074 | loss_rpn_loc: 0.0771 | Total Loss: 0.2938\n",
      "\u001b[32m[07/29 18:26:23 d2.utils.events]: \u001b[0m eta: 0:12:37  iter: 939      time: 0.3305  last_time: 0.3985   lr: 0.00023477  max_mem: 2292M\n",
      "Epoch 0940 | loss_cls: 0.0642 | loss_box_reg: 0.2330 | loss_mask: 0.0682 | loss_rpn_cls: 0.0022 | loss_rpn_loc: 0.0122 | Total Loss: 0.3799\n",
      "Epoch 0941 | loss_cls: 0.0932 | loss_box_reg: 0.2391 | loss_mask: 0.1616 | loss_rpn_cls: 0.0069 | loss_rpn_loc: 0.0970 | Total Loss: 0.5978\n",
      "Epoch 0942 | loss_cls: 0.1072 | loss_box_reg: 0.2472 | loss_mask: 0.0656 | loss_rpn_cls: 0.0002 | loss_rpn_loc: 0.0148 | Total Loss: 0.4350\n",
      "Epoch 0943 | loss_cls: 0.0623 | loss_box_reg: 0.1582 | loss_mask: 0.0848 | loss_rpn_cls: 0.0099 | loss_rpn_loc: 0.1046 | Total Loss: 0.4198\n",
      "Epoch 0944 | loss_cls: 0.0692 | loss_box_reg: 0.2013 | loss_mask: 0.1625 | loss_rpn_cls: 0.0072 | loss_rpn_loc: 0.1133 | Total Loss: 0.5536\n",
      "Epoch 0945 | loss_cls: 0.0589 | loss_box_reg: 0.2774 | loss_mask: 0.1391 | loss_rpn_cls: 0.0122 | loss_rpn_loc: 0.1491 | Total Loss: 0.6366\n",
      "Epoch 0946 | loss_cls: 0.2223 | loss_box_reg: 0.4580 | loss_mask: 0.1994 | loss_rpn_cls: 0.0102 | loss_rpn_loc: 0.0838 | Total Loss: 0.9738\n",
      "Epoch 0947 | loss_cls: 0.0417 | loss_box_reg: 0.0822 | loss_mask: 0.2609 | loss_rpn_cls: 0.0018 | loss_rpn_loc: 0.1654 | Total Loss: 0.5520\n",
      "Epoch 0948 | loss_cls: 0.1704 | loss_box_reg: 0.1977 | loss_mask: 0.0767 | loss_rpn_cls: 0.0287 | loss_rpn_loc: 0.0053 | Total Loss: 0.4787\n",
      "Epoch 0949 | loss_cls: 0.0566 | loss_box_reg: 0.1780 | loss_mask: 0.2372 | loss_rpn_cls: 0.0017 | loss_rpn_loc: 0.1243 | Total Loss: 0.5978\n",
      "Epoch 0950 | loss_cls: 0.1446 | loss_box_reg: 0.3633 | loss_mask: 0.1267 | loss_rpn_cls: 0.0452 | loss_rpn_loc: 0.2426 | Total Loss: 0.9224\n",
      "Epoch 0951 | loss_cls: 0.1099 | loss_box_reg: 0.3553 | loss_mask: 0.1380 | loss_rpn_cls: 0.0340 | loss_rpn_loc: 0.0707 | Total Loss: 0.7079\n",
      "Epoch 0952 | loss_cls: 0.1815 | loss_box_reg: 0.3486 | loss_mask: 0.1800 | loss_rpn_cls: 0.0082 | loss_rpn_loc: 0.0373 | Total Loss: 0.7556\n",
      "Epoch 0953 | loss_cls: 0.0503 | loss_box_reg: 0.1044 | loss_mask: 0.1441 | loss_rpn_cls: 0.0144 | loss_rpn_loc: 0.0094 | Total Loss: 0.3226\n",
      "Epoch 0954 | loss_cls: 0.1475 | loss_box_reg: 0.2803 | loss_mask: 0.1813 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.1402 | Total Loss: 0.7525\n",
      "Epoch 0955 | loss_cls: 0.0418 | loss_box_reg: 0.1043 | loss_mask: 0.0990 | loss_rpn_cls: 0.0021 | loss_rpn_loc: 0.0187 | Total Loss: 0.2658\n",
      "Epoch 0956 | loss_cls: 0.0808 | loss_box_reg: 0.3066 | loss_mask: 0.0690 | loss_rpn_cls: 0.0055 | loss_rpn_loc: 0.1148 | Total Loss: 0.5768\n",
      "Epoch 0957 | loss_cls: 0.0989 | loss_box_reg: 0.2034 | loss_mask: 0.1757 | loss_rpn_cls: 0.0028 | loss_rpn_loc: 0.0038 | Total Loss: 0.4846\n",
      "Epoch 0958 | loss_cls: 0.0625 | loss_box_reg: 0.1667 | loss_mask: 0.1703 | loss_rpn_cls: 0.0026 | loss_rpn_loc: 0.0032 | Total Loss: 0.4054\n",
      "Epoch 0959 | loss_cls: 0.1427 | loss_box_reg: 0.3313 | loss_mask: 0.1200 | loss_rpn_cls: 0.0058 | loss_rpn_loc: 0.0388 | Total Loss: 0.6387\n",
      "\u001b[32m[07/29 18:26:30 d2.utils.events]: \u001b[0m eta: 0:12:30  iter: 959      time: 0.3305  last_time: 0.4072   lr: 0.00023976  max_mem: 2292M\n",
      "Epoch 0960 | loss_cls: 0.0515 | loss_box_reg: 0.1665 | loss_mask: 0.0897 | loss_rpn_cls: 0.0030 | loss_rpn_loc: 0.0111 | Total Loss: 0.3218\n",
      "Epoch 0961 | loss_cls: 0.0722 | loss_box_reg: 0.1840 | loss_mask: 0.0808 | loss_rpn_cls: 0.0127 | loss_rpn_loc: 0.0897 | Total Loss: 0.4393\n",
      "Epoch 0962 | loss_cls: 0.0553 | loss_box_reg: 0.1040 | loss_mask: 0.1006 | loss_rpn_cls: 0.0087 | loss_rpn_loc: 0.0252 | Total Loss: 0.2938\n",
      "Epoch 0963 | loss_cls: 0.0602 | loss_box_reg: 0.1264 | loss_mask: 0.0543 | loss_rpn_cls: 0.0079 | loss_rpn_loc: 0.0887 | Total Loss: 0.3375\n",
      "Epoch 0964 | loss_cls: 0.0803 | loss_box_reg: 0.1705 | loss_mask: 0.0625 | loss_rpn_cls: 0.0257 | loss_rpn_loc: 0.0335 | Total Loss: 0.3726\n",
      "Epoch 0965 | loss_cls: 0.0771 | loss_box_reg: 0.1765 | loss_mask: 0.0643 | loss_rpn_cls: 0.0206 | loss_rpn_loc: 0.0056 | Total Loss: 0.3441\n",
      "Epoch 0966 | loss_cls: 0.0375 | loss_box_reg: 0.1423 | loss_mask: 0.1205 | loss_rpn_cls: 0.0059 | loss_rpn_loc: 0.1629 | Total Loss: 0.4691\n",
      "Epoch 0967 | loss_cls: 0.0924 | loss_box_reg: 0.2191 | loss_mask: 0.1605 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0135 | Total Loss: 0.4865\n",
      "Epoch 0968 | loss_cls: 0.0776 | loss_box_reg: 0.2417 | loss_mask: 0.0881 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.0059 | Total Loss: 0.4184\n",
      "Epoch 0969 | loss_cls: 0.1983 | loss_box_reg: 0.2862 | loss_mask: 0.0836 | loss_rpn_cls: 0.0245 | loss_rpn_loc: 0.2615 | Total Loss: 0.8541\n",
      "Epoch 0970 | loss_cls: 0.0490 | loss_box_reg: 0.0849 | loss_mask: 0.1235 | loss_rpn_cls: 0.0021 | loss_rpn_loc: 0.0103 | Total Loss: 0.2698\n",
      "Epoch 0971 | loss_cls: 0.1049 | loss_box_reg: 0.1904 | loss_mask: 0.0835 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.1356 | Total Loss: 0.5193\n",
      "Epoch 0972 | loss_cls: 0.0565 | loss_box_reg: 0.1448 | loss_mask: 0.1879 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.0168 | Total Loss: 0.4111\n",
      "Epoch 0973 | loss_cls: 0.0695 | loss_box_reg: 0.2127 | loss_mask: 0.1230 | loss_rpn_cls: 0.0082 | loss_rpn_loc: 0.1749 | Total Loss: 0.5883\n",
      "Epoch 0974 | loss_cls: 0.1071 | loss_box_reg: 0.4128 | loss_mask: 0.1469 | loss_rpn_cls: 0.0024 | loss_rpn_loc: 0.0148 | Total Loss: 0.6840\n",
      "Epoch 0975 | loss_cls: 0.1007 | loss_box_reg: 0.2125 | loss_mask: 0.1526 | loss_rpn_cls: 0.0048 | loss_rpn_loc: 0.0680 | Total Loss: 0.5386\n",
      "Epoch 0976 | loss_cls: 0.1501 | loss_box_reg: 0.1570 | loss_mask: 0.1723 | loss_rpn_cls: 0.0095 | loss_rpn_loc: 0.0836 | Total Loss: 0.5726\n",
      "Epoch 0977 | loss_cls: 0.0685 | loss_box_reg: 0.1079 | loss_mask: 0.0731 | loss_rpn_cls: 0.0017 | loss_rpn_loc: 0.1049 | Total Loss: 0.3561\n",
      "Epoch 0978 | loss_cls: 0.0702 | loss_box_reg: 0.1776 | loss_mask: 0.1659 | loss_rpn_cls: 0.0024 | loss_rpn_loc: 0.0816 | Total Loss: 0.4977\n",
      "Epoch 0979 | loss_cls: 0.2026 | loss_box_reg: 0.4551 | loss_mask: 0.1275 | loss_rpn_cls: 0.0020 | loss_rpn_loc: 0.0973 | Total Loss: 0.8844\n",
      "\u001b[32m[07/29 18:26:37 d2.utils.events]: \u001b[0m eta: 0:12:24  iter: 979      time: 0.3305  last_time: 0.1970   lr: 0.00024476  max_mem: 2292M\n",
      "Epoch 0980 | loss_cls: 0.1552 | loss_box_reg: 0.3966 | loss_mask: 0.2224 | loss_rpn_cls: 0.0064 | loss_rpn_loc: 0.0169 | Total Loss: 0.7975\n",
      "Epoch 0981 | loss_cls: 0.1031 | loss_box_reg: 0.1630 | loss_mask: 0.0615 | loss_rpn_cls: 0.0104 | loss_rpn_loc: 0.1477 | Total Loss: 0.4856\n",
      "Epoch 0982 | loss_cls: 0.1045 | loss_box_reg: 0.1498 | loss_mask: 0.0599 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.0071 | Total Loss: 0.3225\n",
      "Epoch 0983 | loss_cls: 0.0945 | loss_box_reg: 0.2803 | loss_mask: 0.1085 | loss_rpn_cls: 0.0044 | loss_rpn_loc: 0.1638 | Total Loss: 0.6515\n",
      "Epoch 0984 | loss_cls: 0.1793 | loss_box_reg: 0.2825 | loss_mask: 0.0550 | loss_rpn_cls: 0.0120 | loss_rpn_loc: 0.0245 | Total Loss: 0.5533\n",
      "Epoch 0985 | loss_cls: 0.0811 | loss_box_reg: 0.2844 | loss_mask: 0.0954 | loss_rpn_cls: 0.0168 | loss_rpn_loc: 0.0130 | Total Loss: 0.4907\n",
      "Epoch 0986 | loss_cls: 0.0634 | loss_box_reg: 0.2079 | loss_mask: 0.1590 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0201 | Total Loss: 0.4509\n",
      "Epoch 0987 | loss_cls: 0.1315 | loss_box_reg: 0.2617 | loss_mask: 0.1250 | loss_rpn_cls: 0.0170 | loss_rpn_loc: 0.0452 | Total Loss: 0.5802\n",
      "Epoch 0988 | loss_cls: 0.1481 | loss_box_reg: 0.2853 | loss_mask: 0.1107 | loss_rpn_cls: 0.0001 | loss_rpn_loc: 0.0098 | Total Loss: 0.5540\n",
      "Epoch 0989 | loss_cls: 0.0405 | loss_box_reg: 0.1663 | loss_mask: 0.1467 | loss_rpn_cls: 0.0049 | loss_rpn_loc: 0.0060 | Total Loss: 0.3643\n",
      "Epoch 0990 | loss_cls: 0.0781 | loss_box_reg: 0.1687 | loss_mask: 0.0832 | loss_rpn_cls: 0.0954 | loss_rpn_loc: 0.2324 | Total Loss: 0.6578\n",
      "Epoch 0991 | loss_cls: 0.0625 | loss_box_reg: 0.0925 | loss_mask: 0.1637 | loss_rpn_cls: 0.0080 | loss_rpn_loc: 0.0234 | Total Loss: 0.3501\n",
      "Epoch 0992 | loss_cls: 0.0832 | loss_box_reg: 0.2243 | loss_mask: 0.1083 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.0160 | Total Loss: 0.4331\n",
      "Epoch 0993 | loss_cls: 0.0948 | loss_box_reg: 0.3182 | loss_mask: 0.1340 | loss_rpn_cls: 0.0135 | loss_rpn_loc: 0.1392 | Total Loss: 0.6997\n",
      "Epoch 0994 | loss_cls: 0.1108 | loss_box_reg: 0.3720 | loss_mask: 0.1457 | loss_rpn_cls: 0.0037 | loss_rpn_loc: 0.0340 | Total Loss: 0.6663\n",
      "Epoch 0995 | loss_cls: 0.0539 | loss_box_reg: 0.1468 | loss_mask: 0.1707 | loss_rpn_cls: 0.0058 | loss_rpn_loc: 0.0169 | Total Loss: 0.3941\n",
      "Epoch 0996 | loss_cls: 0.0435 | loss_box_reg: 0.1312 | loss_mask: 0.0968 | loss_rpn_cls: 0.0026 | loss_rpn_loc: 0.1346 | Total Loss: 0.4087\n",
      "Epoch 0997 | loss_cls: 0.0816 | loss_box_reg: 0.0994 | loss_mask: 0.3783 | loss_rpn_cls: 0.0031 | loss_rpn_loc: 0.1443 | Total Loss: 0.7068\n",
      "Epoch 0998 | loss_cls: 0.1119 | loss_box_reg: 0.2812 | loss_mask: 0.0713 | loss_rpn_cls: 0.0222 | loss_rpn_loc: 0.2204 | Total Loss: 0.7070\n",
      "Epoch 0999 | loss_cls: 0.0637 | loss_box_reg: 0.3054 | loss_mask: 0.0468 | loss_rpn_cls: 0.0194 | loss_rpn_loc: 0.0048 | Total Loss: 0.4401\n",
      "\u001b[32m[07/29 18:26:43 d2.utils.events]: \u001b[0m eta: 0:12:15  iter: 999      time: 0.3304  last_time: 0.1823   lr: 0.00024975  max_mem: 2292M\n",
      "Epoch 1000 | loss_cls: 0.0758 | loss_box_reg: 0.1929 | loss_mask: 0.0897 | loss_rpn_cls: 0.0102 | loss_rpn_loc: 0.0265 | Total Loss: 0.3951\n",
      "Epoch 1001 | loss_cls: 0.0565 | loss_box_reg: 0.1393 | loss_mask: 0.0693 | loss_rpn_cls: 0.0102 | loss_rpn_loc: 0.0201 | Total Loss: 0.2954\n",
      "Epoch 1002 | loss_cls: 0.0684 | loss_box_reg: 0.1464 | loss_mask: 0.1711 | loss_rpn_cls: 0.0044 | loss_rpn_loc: 0.1359 | Total Loss: 0.5261\n",
      "Epoch 1003 | loss_cls: 0.0711 | loss_box_reg: 0.2365 | loss_mask: 0.1365 | loss_rpn_cls: 0.0135 | loss_rpn_loc: 0.0809 | Total Loss: 0.5384\n",
      "Epoch 1004 | loss_cls: 0.0812 | loss_box_reg: 0.1933 | loss_mask: 0.1122 | loss_rpn_cls: 0.0085 | loss_rpn_loc: 0.1827 | Total Loss: 0.5778\n",
      "Epoch 1005 | loss_cls: 0.1076 | loss_box_reg: 0.3506 | loss_mask: 0.1234 | loss_rpn_cls: 0.0036 | loss_rpn_loc: 0.0643 | Total Loss: 0.6494\n",
      "Epoch 1006 | loss_cls: 0.0872 | loss_box_reg: 0.2044 | loss_mask: 0.1080 | loss_rpn_cls: 0.0043 | loss_rpn_loc: 0.0443 | Total Loss: 0.4483\n",
      "Epoch 1007 | loss_cls: 0.1542 | loss_box_reg: 0.2943 | loss_mask: 0.1167 | loss_rpn_cls: 0.0212 | loss_rpn_loc: 0.3566 | Total Loss: 0.9430\n",
      "Epoch 1008 | loss_cls: 0.1819 | loss_box_reg: 0.3163 | loss_mask: 0.0775 | loss_rpn_cls: 0.0046 | loss_rpn_loc: 0.0969 | Total Loss: 0.6773\n",
      "Epoch 1009 | loss_cls: 0.0673 | loss_box_reg: 0.1371 | loss_mask: 0.1945 | loss_rpn_cls: 0.0266 | loss_rpn_loc: 0.0113 | Total Loss: 0.4367\n",
      "Epoch 1010 | loss_cls: 0.0666 | loss_box_reg: 0.2298 | loss_mask: 0.1390 | loss_rpn_cls: 0.0136 | loss_rpn_loc: 0.0922 | Total Loss: 0.5411\n",
      "Epoch 1011 | loss_cls: 0.0804 | loss_box_reg: 0.2349 | loss_mask: 0.2096 | loss_rpn_cls: 0.0187 | loss_rpn_loc: 0.0182 | Total Loss: 0.5618\n",
      "Epoch 1012 | loss_cls: 0.0788 | loss_box_reg: 0.2382 | loss_mask: 0.0757 | loss_rpn_cls: 0.0207 | loss_rpn_loc: 0.0055 | Total Loss: 0.4190\n",
      "Epoch 1013 | loss_cls: 0.1751 | loss_box_reg: 0.4979 | loss_mask: 0.0646 | loss_rpn_cls: 0.0021 | loss_rpn_loc: 0.0429 | Total Loss: 0.7826\n",
      "Epoch 1014 | loss_cls: 0.0991 | loss_box_reg: 0.2014 | loss_mask: 0.1130 | loss_rpn_cls: 0.0216 | loss_rpn_loc: 0.0711 | Total Loss: 0.5062\n",
      "Epoch 1015 | loss_cls: 0.0277 | loss_box_reg: 0.0631 | loss_mask: 0.1038 | loss_rpn_cls: 0.0032 | loss_rpn_loc: 0.0183 | Total Loss: 0.2162\n",
      " Best model saved at Epoch 1015 | Total Loss: 0.2162\n",
      "Epoch 1016 | loss_cls: 0.0529 | loss_box_reg: 0.0952 | loss_mask: 0.1117 | loss_rpn_cls: 0.0003 | loss_rpn_loc: 0.0088 | Total Loss: 0.2689\n",
      "Epoch 1017 | loss_cls: 0.0228 | loss_box_reg: 0.1196 | loss_mask: 0.1391 | loss_rpn_cls: 0.0338 | loss_rpn_loc: 0.0318 | Total Loss: 0.3472\n",
      "Epoch 1018 | loss_cls: 0.0747 | loss_box_reg: 0.1326 | loss_mask: 0.0938 | loss_rpn_cls: 0.0146 | loss_rpn_loc: 0.1418 | Total Loss: 0.4576\n",
      "Epoch 1019 | loss_cls: 0.0463 | loss_box_reg: 0.0724 | loss_mask: 0.0604 | loss_rpn_cls: 0.0118 | loss_rpn_loc: 0.1223 | Total Loss: 0.3133\n",
      "\u001b[32m[07/29 18:26:50 d2.utils.events]: \u001b[0m eta: 0:12:12  iter: 1019      time: 0.3307  last_time: 0.3957   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1020 | loss_cls: 0.0754 | loss_box_reg: 0.1316 | loss_mask: 0.0770 | loss_rpn_cls: 0.0080 | loss_rpn_loc: 0.0248 | Total Loss: 0.3168\n",
      "Epoch 1021 | loss_cls: 0.1132 | loss_box_reg: 0.2061 | loss_mask: 0.0697 | loss_rpn_cls: 0.0073 | loss_rpn_loc: 0.0380 | Total Loss: 0.4342\n",
      "Epoch 1022 | loss_cls: 0.0234 | loss_box_reg: 0.0856 | loss_mask: 0.0783 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0933 | Total Loss: 0.2814\n",
      "Epoch 1023 | loss_cls: 0.0734 | loss_box_reg: 0.1858 | loss_mask: 0.2014 | loss_rpn_cls: 0.0079 | loss_rpn_loc: 0.1162 | Total Loss: 0.5847\n",
      "Epoch 1024 | loss_cls: 0.0565 | loss_box_reg: 0.1601 | loss_mask: 0.2152 | loss_rpn_cls: 0.0257 | loss_rpn_loc: 0.0246 | Total Loss: 0.4821\n",
      "Epoch 1025 | loss_cls: 0.1486 | loss_box_reg: 0.2333 | loss_mask: 0.0884 | loss_rpn_cls: 0.0071 | loss_rpn_loc: 0.1831 | Total Loss: 0.6605\n",
      "Epoch 1026 | loss_cls: 0.0716 | loss_box_reg: 0.1952 | loss_mask: 0.1939 | loss_rpn_cls: 0.0032 | loss_rpn_loc: 0.0198 | Total Loss: 0.4838\n",
      "Epoch 1027 | loss_cls: 0.1076 | loss_box_reg: 0.5148 | loss_mask: 0.2330 | loss_rpn_cls: 0.0283 | loss_rpn_loc: 0.0069 | Total Loss: 0.8906\n",
      "Epoch 1028 | loss_cls: 0.0904 | loss_box_reg: 0.1925 | loss_mask: 0.1234 | loss_rpn_cls: 0.0168 | loss_rpn_loc: 0.1465 | Total Loss: 0.5697\n",
      "Epoch 1029 | loss_cls: 0.0729 | loss_box_reg: 0.2433 | loss_mask: 0.0916 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.1327 | Total Loss: 0.5437\n",
      "Epoch 1030 | loss_cls: 0.0698 | loss_box_reg: 0.3463 | loss_mask: 0.1664 | loss_rpn_cls: 0.0057 | loss_rpn_loc: 0.0124 | Total Loss: 0.6007\n",
      "Epoch 1031 | loss_cls: 0.0806 | loss_box_reg: 0.1449 | loss_mask: 0.4972 | loss_rpn_cls: 0.0089 | loss_rpn_loc: 0.0033 | Total Loss: 0.7349\n",
      "Epoch 1032 | loss_cls: 0.1108 | loss_box_reg: 0.2113 | loss_mask: 0.0967 | loss_rpn_cls: 0.0067 | loss_rpn_loc: 0.1552 | Total Loss: 0.5806\n",
      "Epoch 1033 | loss_cls: 0.0461 | loss_box_reg: 0.1936 | loss_mask: 0.0868 | loss_rpn_cls: 0.0188 | loss_rpn_loc: 0.0195 | Total Loss: 0.3648\n",
      "Epoch 1034 | loss_cls: 0.0580 | loss_box_reg: 0.2667 | loss_mask: 0.1576 | loss_rpn_cls: 0.0001 | loss_rpn_loc: 0.0052 | Total Loss: 0.4877\n",
      "Epoch 1035 | loss_cls: 0.0700 | loss_box_reg: 0.1199 | loss_mask: 0.0657 | loss_rpn_cls: 0.0138 | loss_rpn_loc: 0.0056 | Total Loss: 0.2752\n",
      "Epoch 1036 | loss_cls: 0.0546 | loss_box_reg: 0.2493 | loss_mask: 0.0950 | loss_rpn_cls: 0.0093 | loss_rpn_loc: 0.0047 | Total Loss: 0.4129\n",
      "Epoch 1037 | loss_cls: 0.1601 | loss_box_reg: 0.4080 | loss_mask: 0.0726 | loss_rpn_cls: 0.0288 | loss_rpn_loc: 0.2000 | Total Loss: 0.8694\n",
      "Epoch 1038 | loss_cls: 0.1712 | loss_box_reg: 0.1477 | loss_mask: 0.1184 | loss_rpn_cls: 0.0264 | loss_rpn_loc: 0.6366 | Total Loss: 1.1001\n",
      "Epoch 1039 | loss_cls: 0.1038 | loss_box_reg: 0.3351 | loss_mask: 0.1774 | loss_rpn_cls: 0.0204 | loss_rpn_loc: 0.1048 | Total Loss: 0.7415\n",
      "\u001b[32m[07/29 18:26:57 d2.utils.events]: \u001b[0m eta: 0:12:11  iter: 1039      time: 0.3308  last_time: 0.4147   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1040 | loss_cls: 0.0721 | loss_box_reg: 0.1400 | loss_mask: 0.1202 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0075 | Total Loss: 0.3404\n",
      "Epoch 1041 | loss_cls: 0.1510 | loss_box_reg: 0.3885 | loss_mask: 0.1460 | loss_rpn_cls: 0.0109 | loss_rpn_loc: 0.0389 | Total Loss: 0.7353\n",
      "Epoch 1042 | loss_cls: 0.0514 | loss_box_reg: 0.2004 | loss_mask: 0.1995 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0416 | Total Loss: 0.4934\n",
      "Epoch 1043 | loss_cls: 0.1074 | loss_box_reg: 0.3152 | loss_mask: 0.0458 | loss_rpn_cls: 0.0097 | loss_rpn_loc: 0.0064 | Total Loss: 0.4845\n",
      "Epoch 1044 | loss_cls: 0.1191 | loss_box_reg: 0.1930 | loss_mask: 0.0976 | loss_rpn_cls: 0.0412 | loss_rpn_loc: 0.0160 | Total Loss: 0.4668\n",
      "Epoch 1045 | loss_cls: 0.0543 | loss_box_reg: 0.2900 | loss_mask: 0.1094 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.0060 | Total Loss: 0.4607\n",
      "Epoch 1046 | loss_cls: 0.1282 | loss_box_reg: 0.2226 | loss_mask: 0.0591 | loss_rpn_cls: 0.0300 | loss_rpn_loc: 0.2310 | Total Loss: 0.6709\n",
      "Epoch 1047 | loss_cls: 0.1178 | loss_box_reg: 0.3327 | loss_mask: 0.0860 | loss_rpn_cls: 0.0088 | loss_rpn_loc: 0.0204 | Total Loss: 0.5657\n",
      "Epoch 1048 | loss_cls: 0.0707 | loss_box_reg: 0.1308 | loss_mask: 0.0421 | loss_rpn_cls: 0.0140 | loss_rpn_loc: 0.1320 | Total Loss: 0.3896\n",
      "Epoch 1049 | loss_cls: 0.0601 | loss_box_reg: 0.1727 | loss_mask: 0.1215 | loss_rpn_cls: 0.0113 | loss_rpn_loc: 0.1155 | Total Loss: 0.4811\n",
      "Epoch 1050 | loss_cls: 0.1049 | loss_box_reg: 0.1801 | loss_mask: 0.0862 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.1128 | Total Loss: 0.4867\n",
      "Epoch 1051 | loss_cls: 0.1153 | loss_box_reg: 0.2925 | loss_mask: 0.1793 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0172 | Total Loss: 0.6055\n",
      "Epoch 1052 | loss_cls: 0.0341 | loss_box_reg: 0.0957 | loss_mask: 0.1411 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.1179 | Total Loss: 0.3939\n",
      "Epoch 1053 | loss_cls: 0.0304 | loss_box_reg: 0.0636 | loss_mask: 0.4314 | loss_rpn_cls: 0.0121 | loss_rpn_loc: 0.1309 | Total Loss: 0.6685\n",
      "Epoch 1054 | loss_cls: 0.0655 | loss_box_reg: 0.1145 | loss_mask: 0.0843 | loss_rpn_cls: 0.0193 | loss_rpn_loc: 0.1611 | Total Loss: 0.4447\n",
      "Epoch 1055 | loss_cls: 0.0286 | loss_box_reg: 0.2206 | loss_mask: 0.1022 | loss_rpn_cls: 0.0002 | loss_rpn_loc: 0.0300 | Total Loss: 0.3816\n",
      "Epoch 1056 | loss_cls: 0.1190 | loss_box_reg: 0.2510 | loss_mask: 0.0425 | loss_rpn_cls: 0.0282 | loss_rpn_loc: 0.1349 | Total Loss: 0.5757\n",
      "Epoch 1057 | loss_cls: 0.1702 | loss_box_reg: 0.2753 | loss_mask: 0.0892 | loss_rpn_cls: 0.0174 | loss_rpn_loc: 0.1592 | Total Loss: 0.7113\n",
      "Epoch 1058 | loss_cls: 0.1519 | loss_box_reg: 0.2237 | loss_mask: 0.1423 | loss_rpn_cls: 0.0278 | loss_rpn_loc: 0.2104 | Total Loss: 0.7561\n",
      "Epoch 1059 | loss_cls: 0.0805 | loss_box_reg: 0.2070 | loss_mask: 0.0815 | loss_rpn_cls: 0.0071 | loss_rpn_loc: 0.0407 | Total Loss: 0.4167\n",
      "\u001b[32m[07/29 18:27:04 d2.utils.events]: \u001b[0m eta: 0:12:07  iter: 1059      time: 0.3312  last_time: 0.2769   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1060 | loss_cls: 0.0836 | loss_box_reg: 0.1745 | loss_mask: 0.0924 | loss_rpn_cls: 0.0190 | loss_rpn_loc: 0.0367 | Total Loss: 0.4063\n",
      "Epoch 1061 | loss_cls: 0.1381 | loss_box_reg: 0.4019 | loss_mask: 0.0764 | loss_rpn_cls: 0.0120 | loss_rpn_loc: 0.1258 | Total Loss: 0.7541\n",
      "Epoch 1062 | loss_cls: 0.1280 | loss_box_reg: 0.2603 | loss_mask: 0.1833 | loss_rpn_cls: 0.0082 | loss_rpn_loc: 0.1783 | Total Loss: 0.7581\n",
      "Epoch 1063 | loss_cls: 0.0498 | loss_box_reg: 0.1498 | loss_mask: 0.1161 | loss_rpn_cls: 0.0148 | loss_rpn_loc: 0.0589 | Total Loss: 0.3895\n",
      "Epoch 1064 | loss_cls: 0.0604 | loss_box_reg: 0.1504 | loss_mask: 0.1532 | loss_rpn_cls: 0.0049 | loss_rpn_loc: 0.0282 | Total Loss: 0.3971\n",
      "Epoch 1065 | loss_cls: 0.0319 | loss_box_reg: 0.1566 | loss_mask: 0.1320 | loss_rpn_cls: 0.0026 | loss_rpn_loc: 0.1330 | Total Loss: 0.4561\n",
      "Epoch 1066 | loss_cls: 0.0865 | loss_box_reg: 0.1452 | loss_mask: 0.0608 | loss_rpn_cls: 0.0182 | loss_rpn_loc: 0.0277 | Total Loss: 0.3383\n",
      "Epoch 1067 | loss_cls: 0.0825 | loss_box_reg: 0.1986 | loss_mask: 0.0776 | loss_rpn_cls: 0.0121 | loss_rpn_loc: 0.0052 | Total Loss: 0.3760\n",
      "Epoch 1068 | loss_cls: 0.1345 | loss_box_reg: 0.2093 | loss_mask: 0.0584 | loss_rpn_cls: 0.0114 | loss_rpn_loc: 0.0094 | Total Loss: 0.4230\n",
      "Epoch 1069 | loss_cls: 0.1460 | loss_box_reg: 0.1301 | loss_mask: 0.1669 | loss_rpn_cls: 0.0225 | loss_rpn_loc: 0.0085 | Total Loss: 0.4739\n",
      "Epoch 1070 | loss_cls: 0.1089 | loss_box_reg: 0.1924 | loss_mask: 0.0975 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.1110 | Total Loss: 0.5147\n",
      "Epoch 1071 | loss_cls: 0.1155 | loss_box_reg: 0.3413 | loss_mask: 0.1243 | loss_rpn_cls: 0.0059 | loss_rpn_loc: 0.0194 | Total Loss: 0.6063\n",
      "Epoch 1072 | loss_cls: 0.0341 | loss_box_reg: 0.0942 | loss_mask: 0.1466 | loss_rpn_cls: 0.0018 | loss_rpn_loc: 0.0095 | Total Loss: 0.2862\n",
      "Epoch 1073 | loss_cls: 0.1042 | loss_box_reg: 0.2927 | loss_mask: 0.0978 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.0315 | Total Loss: 0.5276\n",
      "Epoch 1074 | loss_cls: 0.0257 | loss_box_reg: 0.1112 | loss_mask: 0.3672 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.2213 | Total Loss: 0.7277\n",
      "Epoch 1075 | loss_cls: 0.1582 | loss_box_reg: 0.2268 | loss_mask: 0.1476 | loss_rpn_cls: 0.0078 | loss_rpn_loc: 0.0653 | Total Loss: 0.6057\n",
      "Epoch 1076 | loss_cls: 0.0782 | loss_box_reg: 0.3212 | loss_mask: 0.1804 | loss_rpn_cls: 0.0178 | loss_rpn_loc: 0.0117 | Total Loss: 0.6093\n",
      "Epoch 1077 | loss_cls: 0.0933 | loss_box_reg: 0.1768 | loss_mask: 0.1096 | loss_rpn_cls: 0.0031 | loss_rpn_loc: 0.1004 | Total Loss: 0.4833\n",
      "Epoch 1078 | loss_cls: 0.0897 | loss_box_reg: 0.2673 | loss_mask: 0.0873 | loss_rpn_cls: 0.0061 | loss_rpn_loc: 0.0342 | Total Loss: 0.4846\n",
      "Epoch 1079 | loss_cls: 0.0271 | loss_box_reg: 0.0478 | loss_mask: 0.1265 | loss_rpn_cls: 0.0102 | loss_rpn_loc: 0.1154 | Total Loss: 0.3270\n",
      "\u001b[32m[07/29 18:27:10 d2.utils.events]: \u001b[0m eta: 0:12:01  iter: 1079      time: 0.3311  last_time: 0.3967   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1080 | loss_cls: 0.0812 | loss_box_reg: 0.2553 | loss_mask: 0.1781 | loss_rpn_cls: 0.0199 | loss_rpn_loc: 0.0157 | Total Loss: 0.5502\n",
      "Epoch 1081 | loss_cls: 0.0883 | loss_box_reg: 0.1778 | loss_mask: 0.0743 | loss_rpn_cls: 0.0217 | loss_rpn_loc: 0.0814 | Total Loss: 0.4435\n",
      "Epoch 1082 | loss_cls: 0.0293 | loss_box_reg: 0.1436 | loss_mask: 0.0664 | loss_rpn_cls: 0.0088 | loss_rpn_loc: 0.0920 | Total Loss: 0.3401\n",
      "Epoch 1083 | loss_cls: 0.0640 | loss_box_reg: 0.2006 | loss_mask: 0.1023 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.1059 | Total Loss: 0.4740\n",
      "Epoch 1084 | loss_cls: 0.2012 | loss_box_reg: 0.3884 | loss_mask: 0.1355 | loss_rpn_cls: 0.0891 | loss_rpn_loc: 0.2772 | Total Loss: 1.0914\n",
      "Epoch 1085 | loss_cls: 0.0660 | loss_box_reg: 0.2103 | loss_mask: 0.0840 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.0067 | Total Loss: 0.3688\n",
      "Epoch 1086 | loss_cls: 0.0664 | loss_box_reg: 0.3632 | loss_mask: 0.1697 | loss_rpn_cls: 0.0085 | loss_rpn_loc: 0.0061 | Total Loss: 0.6138\n",
      "Epoch 1087 | loss_cls: 0.0553 | loss_box_reg: 0.1925 | loss_mask: 0.1846 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.0767 | Total Loss: 0.5116\n",
      "Epoch 1088 | loss_cls: 0.0717 | loss_box_reg: 0.1823 | loss_mask: 0.1683 | loss_rpn_cls: 0.0128 | loss_rpn_loc: 0.1675 | Total Loss: 0.6026\n",
      "Epoch 1089 | loss_cls: 0.0472 | loss_box_reg: 0.1942 | loss_mask: 0.0650 | loss_rpn_cls: 0.0063 | loss_rpn_loc: 0.0095 | Total Loss: 0.3221\n",
      "Epoch 1090 | loss_cls: 0.0453 | loss_box_reg: 0.0920 | loss_mask: 0.2600 | loss_rpn_cls: 0.0016 | loss_rpn_loc: 0.0171 | Total Loss: 0.4160\n",
      "Epoch 1091 | loss_cls: 0.0503 | loss_box_reg: 0.1580 | loss_mask: 0.0756 | loss_rpn_cls: 0.0020 | loss_rpn_loc: 0.0036 | Total Loss: 0.2896\n",
      "Epoch 1092 | loss_cls: 0.0315 | loss_box_reg: 0.0878 | loss_mask: 0.1611 | loss_rpn_cls: 0.0125 | loss_rpn_loc: 0.0771 | Total Loss: 0.3701\n",
      "Epoch 1093 | loss_cls: 0.0897 | loss_box_reg: 0.1708 | loss_mask: 0.1321 | loss_rpn_cls: 0.0111 | loss_rpn_loc: 0.0107 | Total Loss: 0.4144\n",
      "Epoch 1094 | loss_cls: 0.0474 | loss_box_reg: 0.1443 | loss_mask: 0.1348 | loss_rpn_cls: 0.0090 | loss_rpn_loc: 0.0024 | Total Loss: 0.3378\n",
      "Epoch 1095 | loss_cls: 0.0417 | loss_box_reg: 0.1181 | loss_mask: 0.1223 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.1361 | Total Loss: 0.4189\n",
      "Epoch 1096 | loss_cls: 0.0287 | loss_box_reg: 0.0683 | loss_mask: 0.0698 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0192 | Total Loss: 0.1864\n",
      " Best model saved at Epoch 1096 | Total Loss: 0.1864\n",
      "Epoch 1097 | loss_cls: 0.1376 | loss_box_reg: 0.2782 | loss_mask: 0.1365 | loss_rpn_cls: 0.0138 | loss_rpn_loc: 0.0971 | Total Loss: 0.6631\n",
      "Epoch 1098 | loss_cls: 0.0621 | loss_box_reg: 0.2042 | loss_mask: 0.1616 | loss_rpn_cls: 0.0073 | loss_rpn_loc: 0.1788 | Total Loss: 0.6140\n",
      "Epoch 1099 | loss_cls: 0.0423 | loss_box_reg: 0.1773 | loss_mask: 0.1209 | loss_rpn_cls: 0.0121 | loss_rpn_loc: 0.0517 | Total Loss: 0.4042\n",
      "\u001b[32m[07/29 18:27:18 d2.utils.events]: \u001b[0m eta: 0:11:58  iter: 1099      time: 0.3319  last_time: 0.4119   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1100 | loss_cls: 0.0347 | loss_box_reg: 0.1099 | loss_mask: 0.4360 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.0104 | Total Loss: 0.5925\n",
      "Epoch 1101 | loss_cls: 0.0512 | loss_box_reg: 0.1034 | loss_mask: 0.2024 | loss_rpn_cls: 0.0046 | loss_rpn_loc: 0.1215 | Total Loss: 0.4831\n",
      "Epoch 1102 | loss_cls: 0.1030 | loss_box_reg: 0.1828 | loss_mask: 0.0781 | loss_rpn_cls: 0.0108 | loss_rpn_loc: 0.0134 | Total Loss: 0.3881\n",
      "Epoch 1103 | loss_cls: 0.1054 | loss_box_reg: 0.2805 | loss_mask: 0.1101 | loss_rpn_cls: 0.0056 | loss_rpn_loc: 0.1176 | Total Loss: 0.6193\n",
      "Epoch 1104 | loss_cls: 0.1132 | loss_box_reg: 0.2493 | loss_mask: 0.0883 | loss_rpn_cls: 0.0039 | loss_rpn_loc: 0.0694 | Total Loss: 0.5242\n",
      "Epoch 1105 | loss_cls: 0.1085 | loss_box_reg: 0.1315 | loss_mask: 0.1244 | loss_rpn_cls: 0.0172 | loss_rpn_loc: 0.1504 | Total Loss: 0.5321\n",
      "Epoch 1106 | loss_cls: 0.0628 | loss_box_reg: 0.1534 | loss_mask: 0.1391 | loss_rpn_cls: 0.0076 | loss_rpn_loc: 0.0052 | Total Loss: 0.3681\n",
      "Epoch 1107 | loss_cls: 0.0652 | loss_box_reg: 0.2189 | loss_mask: 0.2010 | loss_rpn_cls: 0.0122 | loss_rpn_loc: 0.0275 | Total Loss: 0.5247\n",
      "Epoch 1108 | loss_cls: 0.0991 | loss_box_reg: 0.2264 | loss_mask: 0.0885 | loss_rpn_cls: 0.0069 | loss_rpn_loc: 0.0118 | Total Loss: 0.4326\n",
      "Epoch 1109 | loss_cls: 0.0997 | loss_box_reg: 0.1992 | loss_mask: 0.0583 | loss_rpn_cls: 0.0327 | loss_rpn_loc: 0.0264 | Total Loss: 0.4163\n",
      "Epoch 1110 | loss_cls: 0.0937 | loss_box_reg: 0.2191 | loss_mask: 0.0674 | loss_rpn_cls: 0.0215 | loss_rpn_loc: 0.4807 | Total Loss: 0.8824\n",
      "Epoch 1111 | loss_cls: 0.1326 | loss_box_reg: 0.3416 | loss_mask: 0.0516 | loss_rpn_cls: 0.0148 | loss_rpn_loc: 0.0263 | Total Loss: 0.5668\n",
      "Epoch 1112 | loss_cls: 0.0640 | loss_box_reg: 0.1568 | loss_mask: 0.1031 | loss_rpn_cls: 0.0157 | loss_rpn_loc: 0.0089 | Total Loss: 0.3485\n",
      "Epoch 1113 | loss_cls: 0.0791 | loss_box_reg: 0.3586 | loss_mask: 0.1492 | loss_rpn_cls: 0.0100 | loss_rpn_loc: 0.1019 | Total Loss: 0.6988\n",
      "Epoch 1114 | loss_cls: 0.0488 | loss_box_reg: 0.1666 | loss_mask: 0.0956 | loss_rpn_cls: 0.0035 | loss_rpn_loc: 0.1122 | Total Loss: 0.4267\n",
      "Epoch 1115 | loss_cls: 0.1258 | loss_box_reg: 0.3044 | loss_mask: 0.0629 | loss_rpn_cls: 0.0233 | loss_rpn_loc: 0.0929 | Total Loss: 0.6093\n",
      "Epoch 1116 | loss_cls: 0.1267 | loss_box_reg: 0.3073 | loss_mask: 0.1184 | loss_rpn_cls: 0.0196 | loss_rpn_loc: 0.1446 | Total Loss: 0.7168\n",
      "Epoch 1117 | loss_cls: 0.0571 | loss_box_reg: 0.1031 | loss_mask: 0.0562 | loss_rpn_cls: 0.0341 | loss_rpn_loc: 0.0820 | Total Loss: 0.3325\n",
      "Epoch 1118 | loss_cls: 0.0695 | loss_box_reg: 0.2350 | loss_mask: 0.1988 | loss_rpn_cls: 0.0017 | loss_rpn_loc: 0.0364 | Total Loss: 0.5415\n",
      "Epoch 1119 | loss_cls: 0.1213 | loss_box_reg: 0.2879 | loss_mask: 0.2206 | loss_rpn_cls: 0.0056 | loss_rpn_loc: 0.0505 | Total Loss: 0.6859\n",
      "\u001b[32m[07/29 18:27:25 d2.utils.events]: \u001b[0m eta: 0:11:53  iter: 1119      time: 0.3319  last_time: 0.2777   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1120 | loss_cls: 0.0810 | loss_box_reg: 0.1778 | loss_mask: 0.0789 | loss_rpn_cls: 0.0114 | loss_rpn_loc: 0.0119 | Total Loss: 0.3612\n",
      "Epoch 1121 | loss_cls: 0.0356 | loss_box_reg: 0.0449 | loss_mask: 0.1387 | loss_rpn_cls: 0.0018 | loss_rpn_loc: 0.1161 | Total Loss: 0.3372\n",
      "Epoch 1122 | loss_cls: 0.0505 | loss_box_reg: 0.1009 | loss_mask: 0.0525 | loss_rpn_cls: 0.0069 | loss_rpn_loc: 0.1113 | Total Loss: 0.3222\n",
      "Epoch 1123 | loss_cls: 0.0693 | loss_box_reg: 0.2910 | loss_mask: 0.0660 | loss_rpn_cls: 0.0217 | loss_rpn_loc: 0.0762 | Total Loss: 0.5242\n",
      "Epoch 1124 | loss_cls: 0.0533 | loss_box_reg: 0.1029 | loss_mask: 0.2978 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.0214 | Total Loss: 0.4759\n",
      "Epoch 1125 | loss_cls: 0.0613 | loss_box_reg: 0.1706 | loss_mask: 0.1170 | loss_rpn_cls: 0.0068 | loss_rpn_loc: 0.1426 | Total Loss: 0.4983\n",
      "Epoch 1126 | loss_cls: 0.1114 | loss_box_reg: 0.2214 | loss_mask: 0.0921 | loss_rpn_cls: 0.0052 | loss_rpn_loc: 0.0411 | Total Loss: 0.4711\n",
      "Epoch 1127 | loss_cls: 0.0274 | loss_box_reg: 0.1003 | loss_mask: 0.0861 | loss_rpn_cls: 0.0186 | loss_rpn_loc: 0.0038 | Total Loss: 0.2361\n",
      "Epoch 1128 | loss_cls: 0.1038 | loss_box_reg: 0.2394 | loss_mask: 0.0966 | loss_rpn_cls: 0.0094 | loss_rpn_loc: 0.0189 | Total Loss: 0.4680\n",
      "Epoch 1129 | loss_cls: 0.0364 | loss_box_reg: 0.1162 | loss_mask: 0.1508 | loss_rpn_cls: 0.0063 | loss_rpn_loc: 0.1232 | Total Loss: 0.4329\n",
      "Epoch 1130 | loss_cls: 0.0361 | loss_box_reg: 0.0805 | loss_mask: 0.1289 | loss_rpn_cls: 0.0017 | loss_rpn_loc: 0.0032 | Total Loss: 0.2504\n",
      "Epoch 1131 | loss_cls: 0.0769 | loss_box_reg: 0.1449 | loss_mask: 0.0597 | loss_rpn_cls: 0.0129 | loss_rpn_loc: 0.0684 | Total Loss: 0.3628\n",
      "Epoch 1132 | loss_cls: 0.0310 | loss_box_reg: 0.1066 | loss_mask: 0.1859 | loss_rpn_cls: 0.0159 | loss_rpn_loc: 0.1423 | Total Loss: 0.4816\n",
      "Epoch 1133 | loss_cls: 0.0539 | loss_box_reg: 0.0979 | loss_mask: 0.0866 | loss_rpn_cls: 0.0009 | loss_rpn_loc: 0.0200 | Total Loss: 0.2593\n",
      "Epoch 1134 | loss_cls: 0.0511 | loss_box_reg: 0.1664 | loss_mask: 0.0530 | loss_rpn_cls: 0.1412 | loss_rpn_loc: 0.2201 | Total Loss: 0.6318\n",
      "Epoch 1135 | loss_cls: 0.1119 | loss_box_reg: 0.3368 | loss_mask: 0.2253 | loss_rpn_cls: 0.0002 | loss_rpn_loc: 0.0130 | Total Loss: 0.6873\n",
      "Epoch 1136 | loss_cls: 0.0914 | loss_box_reg: 0.3723 | loss_mask: 0.0792 | loss_rpn_cls: 0.0022 | loss_rpn_loc: 0.0079 | Total Loss: 0.5529\n",
      "Epoch 1137 | loss_cls: 0.0586 | loss_box_reg: 0.0884 | loss_mask: 0.1976 | loss_rpn_cls: 0.0119 | loss_rpn_loc: 0.0799 | Total Loss: 0.4364\n",
      "Epoch 1138 | loss_cls: 0.0375 | loss_box_reg: 0.0953 | loss_mask: 0.0625 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.0211 | Total Loss: 0.2168\n",
      "Epoch 1139 | loss_cls: 0.0676 | loss_box_reg: 0.0930 | loss_mask: 0.0895 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.1219 | Total Loss: 0.3735\n",
      "\u001b[32m[07/29 18:27:31 d2.utils.events]: \u001b[0m eta: 0:11:46  iter: 1139      time: 0.3319  last_time: 0.3910   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1140 | loss_cls: 0.1149 | loss_box_reg: 0.3091 | loss_mask: 0.1730 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.0838 | Total Loss: 0.6841\n",
      "Epoch 1141 | loss_cls: 0.1947 | loss_box_reg: 0.3108 | loss_mask: 0.0987 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.0599 | Total Loss: 0.6660\n",
      "Epoch 1142 | loss_cls: 0.1378 | loss_box_reg: 0.2773 | loss_mask: 0.0945 | loss_rpn_cls: 0.0040 | loss_rpn_loc: 0.0963 | Total Loss: 0.6099\n",
      "Epoch 1143 | loss_cls: 0.0700 | loss_box_reg: 0.1142 | loss_mask: 0.0865 | loss_rpn_cls: 0.0127 | loss_rpn_loc: 0.0318 | Total Loss: 0.3151\n",
      "Epoch 1144 | loss_cls: 0.1266 | loss_box_reg: 0.2290 | loss_mask: 0.1507 | loss_rpn_cls: 0.0156 | loss_rpn_loc: 0.1275 | Total Loss: 0.6495\n",
      "Epoch 1145 | loss_cls: 0.0431 | loss_box_reg: 0.0362 | loss_mask: 0.1460 | loss_rpn_cls: 0.0020 | loss_rpn_loc: 0.1534 | Total Loss: 0.3807\n",
      "Epoch 1146 | loss_cls: 0.0525 | loss_box_reg: 0.1670 | loss_mask: 0.2072 | loss_rpn_cls: 0.0178 | loss_rpn_loc: 0.0994 | Total Loss: 0.5439\n",
      "Epoch 1147 | loss_cls: 0.0596 | loss_box_reg: 0.2628 | loss_mask: 0.1331 | loss_rpn_cls: 0.0026 | loss_rpn_loc: 0.0882 | Total Loss: 0.5463\n",
      "Epoch 1148 | loss_cls: 0.0505 | loss_box_reg: 0.1814 | loss_mask: 0.1041 | loss_rpn_cls: 0.0037 | loss_rpn_loc: 0.0049 | Total Loss: 0.3445\n",
      "Epoch 1149 | loss_cls: 0.1367 | loss_box_reg: 0.4491 | loss_mask: 0.0725 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0069 | Total Loss: 0.6663\n",
      "Epoch 1150 | loss_cls: 0.0333 | loss_box_reg: 0.1190 | loss_mask: 0.0970 | loss_rpn_cls: 0.0088 | loss_rpn_loc: 0.1695 | Total Loss: 0.4275\n",
      "Epoch 1151 | loss_cls: 0.0810 | loss_box_reg: 0.1504 | loss_mask: 0.1242 | loss_rpn_cls: 0.0106 | loss_rpn_loc: 0.1450 | Total Loss: 0.5112\n",
      "Epoch 1152 | loss_cls: 0.0568 | loss_box_reg: 0.1607 | loss_mask: 0.0746 | loss_rpn_cls: 0.0400 | loss_rpn_loc: 0.0045 | Total Loss: 0.3366\n",
      "Epoch 1153 | loss_cls: 0.0520 | loss_box_reg: 0.1334 | loss_mask: 0.1921 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0487 | Total Loss: 0.4269\n",
      "Epoch 1154 | loss_cls: 0.0415 | loss_box_reg: 0.0530 | loss_mask: 0.1370 | loss_rpn_cls: 0.0222 | loss_rpn_loc: 0.1063 | Total Loss: 0.3598\n",
      "Epoch 1155 | loss_cls: 0.1537 | loss_box_reg: 0.2006 | loss_mask: 0.0610 | loss_rpn_cls: 0.0022 | loss_rpn_loc: 0.0089 | Total Loss: 0.4264\n",
      "Epoch 1156 | loss_cls: 0.0493 | loss_box_reg: 0.1499 | loss_mask: 0.1013 | loss_rpn_cls: 0.0107 | loss_rpn_loc: 0.0312 | Total Loss: 0.3424\n",
      "Epoch 1157 | loss_cls: 0.0672 | loss_box_reg: 0.2018 | loss_mask: 0.1183 | loss_rpn_cls: 0.0001 | loss_rpn_loc: 0.0121 | Total Loss: 0.3994\n",
      "Epoch 1158 | loss_cls: 0.1163 | loss_box_reg: 0.2244 | loss_mask: 0.0728 | loss_rpn_cls: 0.0177 | loss_rpn_loc: 0.0048 | Total Loss: 0.4359\n",
      "Epoch 1159 | loss_cls: 0.1511 | loss_box_reg: 0.2561 | loss_mask: 0.2198 | loss_rpn_cls: 0.0194 | loss_rpn_loc: 0.1596 | Total Loss: 0.8059\n",
      "\u001b[32m[07/29 18:27:38 d2.utils.events]: \u001b[0m eta: 0:11:40  iter: 1159      time: 0.3324  last_time: 0.4259   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1160 | loss_cls: 0.0471 | loss_box_reg: 0.1074 | loss_mask: 0.0591 | loss_rpn_cls: 0.0017 | loss_rpn_loc: 0.0914 | Total Loss: 0.3068\n",
      "Epoch 1161 | loss_cls: 0.1263 | loss_box_reg: 0.3534 | loss_mask: 0.2506 | loss_rpn_cls: 0.0126 | loss_rpn_loc: 0.0538 | Total Loss: 0.7967\n",
      "Epoch 1162 | loss_cls: 0.2157 | loss_box_reg: 0.2846 | loss_mask: 0.0476 | loss_rpn_cls: 0.0723 | loss_rpn_loc: 0.4155 | Total Loss: 1.0356\n",
      "Epoch 1163 | loss_cls: 0.0496 | loss_box_reg: 0.1051 | loss_mask: 0.1084 | loss_rpn_cls: 0.0182 | loss_rpn_loc: 0.1131 | Total Loss: 0.3944\n",
      "Epoch 1164 | loss_cls: 0.1367 | loss_box_reg: 0.3109 | loss_mask: 0.1281 | loss_rpn_cls: 0.0085 | loss_rpn_loc: 0.1872 | Total Loss: 0.7715\n",
      "Epoch 1165 | loss_cls: 0.0963 | loss_box_reg: 0.4133 | loss_mask: 0.0532 | loss_rpn_cls: 0.0136 | loss_rpn_loc: 0.0442 | Total Loss: 0.6206\n",
      "Epoch 1166 | loss_cls: 0.0573 | loss_box_reg: 0.2696 | loss_mask: 0.1323 | loss_rpn_cls: 0.0071 | loss_rpn_loc: 0.0187 | Total Loss: 0.4850\n",
      "Epoch 1167 | loss_cls: 0.1369 | loss_box_reg: 0.1530 | loss_mask: 0.0861 | loss_rpn_cls: 0.0057 | loss_rpn_loc: 0.0057 | Total Loss: 0.3874\n",
      "Epoch 1168 | loss_cls: 0.0875 | loss_box_reg: 0.2634 | loss_mask: 0.1371 | loss_rpn_cls: 0.0127 | loss_rpn_loc: 0.1146 | Total Loss: 0.6154\n",
      "Epoch 1169 | loss_cls: 0.0890 | loss_box_reg: 0.1871 | loss_mask: 0.1518 | loss_rpn_cls: 0.0302 | loss_rpn_loc: 0.0223 | Total Loss: 0.4803\n",
      "Epoch 1170 | loss_cls: 0.1233 | loss_box_reg: 0.2962 | loss_mask: 0.1040 | loss_rpn_cls: 0.1121 | loss_rpn_loc: 0.2931 | Total Loss: 0.9287\n",
      "Epoch 1171 | loss_cls: 0.0629 | loss_box_reg: 0.2533 | loss_mask: 0.0971 | loss_rpn_cls: 0.0118 | loss_rpn_loc: 0.0479 | Total Loss: 0.4731\n",
      "Epoch 1172 | loss_cls: 0.0756 | loss_box_reg: 0.1247 | loss_mask: 0.0710 | loss_rpn_cls: 0.0125 | loss_rpn_loc: 0.1143 | Total Loss: 0.3982\n",
      "Epoch 1173 | loss_cls: 0.0572 | loss_box_reg: 0.1520 | loss_mask: 0.0749 | loss_rpn_cls: 0.0263 | loss_rpn_loc: 0.0091 | Total Loss: 0.3196\n",
      "Epoch 1174 | loss_cls: 0.1335 | loss_box_reg: 0.4240 | loss_mask: 0.2565 | loss_rpn_cls: 0.0177 | loss_rpn_loc: 0.0069 | Total Loss: 0.8387\n",
      "Epoch 1175 | loss_cls: 0.0704 | loss_box_reg: 0.1708 | loss_mask: 0.1806 | loss_rpn_cls: 0.0022 | loss_rpn_loc: 0.0580 | Total Loss: 0.4821\n",
      "Epoch 1176 | loss_cls: 0.0276 | loss_box_reg: 0.0929 | loss_mask: 0.5625 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.0178 | Total Loss: 0.7013\n",
      "Epoch 1177 | loss_cls: 0.1047 | loss_box_reg: 0.2615 | loss_mask: 0.0769 | loss_rpn_cls: 0.0074 | loss_rpn_loc: 0.0496 | Total Loss: 0.5000\n",
      "Epoch 1178 | loss_cls: 0.1619 | loss_box_reg: 0.2027 | loss_mask: 0.0819 | loss_rpn_cls: 0.0002 | loss_rpn_loc: 0.0153 | Total Loss: 0.4620\n",
      "Epoch 1179 | loss_cls: 0.0772 | loss_box_reg: 0.1479 | loss_mask: 0.1432 | loss_rpn_cls: 0.0122 | loss_rpn_loc: 0.0128 | Total Loss: 0.3933\n",
      "\u001b[32m[07/29 18:27:45 d2.utils.events]: \u001b[0m eta: 0:11:32  iter: 1179      time: 0.3319  last_time: 0.1908   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1180 | loss_cls: 0.0535 | loss_box_reg: 0.2005 | loss_mask: 0.0493 | loss_rpn_cls: 0.0323 | loss_rpn_loc: 0.0066 | Total Loss: 0.3422\n",
      "Epoch 1181 | loss_cls: 0.1329 | loss_box_reg: 0.2607 | loss_mask: 0.1297 | loss_rpn_cls: 0.0045 | loss_rpn_loc: 0.0170 | Total Loss: 0.5449\n",
      "Epoch 1182 | loss_cls: 0.0786 | loss_box_reg: 0.1185 | loss_mask: 0.1165 | loss_rpn_cls: 0.0043 | loss_rpn_loc: 0.1344 | Total Loss: 0.4523\n",
      "Epoch 1183 | loss_cls: 0.0662 | loss_box_reg: 0.1888 | loss_mask: 0.1216 | loss_rpn_cls: 0.0180 | loss_rpn_loc: 0.0324 | Total Loss: 0.4270\n",
      "Epoch 1184 | loss_cls: 0.0274 | loss_box_reg: 0.1168 | loss_mask: 0.1194 | loss_rpn_cls: 0.0210 | loss_rpn_loc: 0.0033 | Total Loss: 0.2880\n",
      "Epoch 1185 | loss_cls: 0.0964 | loss_box_reg: 0.1617 | loss_mask: 0.0843 | loss_rpn_cls: 0.0039 | loss_rpn_loc: 0.0431 | Total Loss: 0.3895\n",
      "Epoch 1186 | loss_cls: 0.1049 | loss_box_reg: 0.3542 | loss_mask: 0.3078 | loss_rpn_cls: 0.0224 | loss_rpn_loc: 0.0079 | Total Loss: 0.7971\n",
      "Epoch 1187 | loss_cls: 0.1050 | loss_box_reg: 0.3364 | loss_mask: 0.0691 | loss_rpn_cls: 0.0073 | loss_rpn_loc: 0.0243 | Total Loss: 0.5420\n",
      "Epoch 1188 | loss_cls: 0.1194 | loss_box_reg: 0.1996 | loss_mask: 0.0794 | loss_rpn_cls: 0.0149 | loss_rpn_loc: 0.0740 | Total Loss: 0.4872\n",
      "Epoch 1189 | loss_cls: 0.1563 | loss_box_reg: 0.2285 | loss_mask: 0.1331 | loss_rpn_cls: 0.0288 | loss_rpn_loc: 0.0225 | Total Loss: 0.5692\n",
      "Epoch 1190 | loss_cls: 0.0683 | loss_box_reg: 0.1258 | loss_mask: 0.2191 | loss_rpn_cls: 0.0213 | loss_rpn_loc: 0.0266 | Total Loss: 0.4612\n",
      "Epoch 1191 | loss_cls: 0.0399 | loss_box_reg: 0.0615 | loss_mask: 0.0853 | loss_rpn_cls: 0.0224 | loss_rpn_loc: 0.0168 | Total Loss: 0.2260\n",
      "Epoch 1192 | loss_cls: 0.1574 | loss_box_reg: 0.2898 | loss_mask: 0.1044 | loss_rpn_cls: 0.0092 | loss_rpn_loc: 0.1350 | Total Loss: 0.6958\n",
      "Epoch 1193 | loss_cls: 0.2924 | loss_box_reg: 0.4310 | loss_mask: 0.0555 | loss_rpn_cls: 0.0303 | loss_rpn_loc: 0.1142 | Total Loss: 0.9234\n",
      "Epoch 1194 | loss_cls: 0.0448 | loss_box_reg: 0.0766 | loss_mask: 0.1709 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.0220 | Total Loss: 0.3193\n",
      "Epoch 1195 | loss_cls: 0.0661 | loss_box_reg: 0.1198 | loss_mask: 0.0916 | loss_rpn_cls: 0.0127 | loss_rpn_loc: 0.1158 | Total Loss: 0.4060\n",
      "Epoch 1196 | loss_cls: 0.0259 | loss_box_reg: 0.0392 | loss_mask: 0.2472 | loss_rpn_cls: 0.0039 | loss_rpn_loc: 0.1154 | Total Loss: 0.4315\n",
      "Epoch 1197 | loss_cls: 0.0546 | loss_box_reg: 0.0612 | loss_mask: 0.0642 | loss_rpn_cls: 0.0214 | loss_rpn_loc: 0.0176 | Total Loss: 0.2190\n",
      "Epoch 1198 | loss_cls: 0.0937 | loss_box_reg: 0.1907 | loss_mask: 0.0809 | loss_rpn_cls: 0.0333 | loss_rpn_loc: 0.1230 | Total Loss: 0.5215\n",
      "Epoch 1199 | loss_cls: 0.0301 | loss_box_reg: 0.1019 | loss_mask: 0.0906 | loss_rpn_cls: 0.0157 | loss_rpn_loc: 0.0156 | Total Loss: 0.2538\n",
      "\u001b[32m[07/29 18:27:50 d2.utils.events]: \u001b[0m eta: 0:11:24  iter: 1199      time: 0.3311  last_time: 0.2814   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1200 | loss_cls: 0.0413 | loss_box_reg: 0.1442 | loss_mask: 0.0578 | loss_rpn_cls: 0.0029 | loss_rpn_loc: 0.0105 | Total Loss: 0.2567\n",
      "Epoch 1201 | loss_cls: 0.0587 | loss_box_reg: 0.2363 | loss_mask: 0.2990 | loss_rpn_cls: 0.0008 | loss_rpn_loc: 0.0079 | Total Loss: 0.6027\n",
      "Epoch 1202 | loss_cls: 0.0876 | loss_box_reg: 0.2624 | loss_mask: 0.1049 | loss_rpn_cls: 0.0350 | loss_rpn_loc: 0.1722 | Total Loss: 0.6622\n",
      "Epoch 1203 | loss_cls: 0.0432 | loss_box_reg: 0.0484 | loss_mask: 0.0765 | loss_rpn_cls: 0.0112 | loss_rpn_loc: 0.1177 | Total Loss: 0.2971\n",
      "Epoch 1204 | loss_cls: 0.0770 | loss_box_reg: 0.2053 | loss_mask: 0.4039 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.0108 | Total Loss: 0.7004\n",
      "Epoch 1205 | loss_cls: 0.0571 | loss_box_reg: 0.2276 | loss_mask: 0.1230 | loss_rpn_cls: 0.0114 | loss_rpn_loc: 0.0078 | Total Loss: 0.4269\n",
      "Epoch 1206 | loss_cls: 0.0866 | loss_box_reg: 0.1682 | loss_mask: 0.0837 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.1137 | Total Loss: 0.4572\n",
      "Epoch 1207 | loss_cls: 0.0856 | loss_box_reg: 0.3212 | loss_mask: 0.0833 | loss_rpn_cls: 0.0044 | loss_rpn_loc: 0.0384 | Total Loss: 0.5329\n",
      "Epoch 1208 | loss_cls: 0.0633 | loss_box_reg: 0.1917 | loss_mask: 0.0805 | loss_rpn_cls: 0.0189 | loss_rpn_loc: 0.2272 | Total Loss: 0.5816\n",
      "Epoch 1209 | loss_cls: 0.0537 | loss_box_reg: 0.1384 | loss_mask: 0.0745 | loss_rpn_cls: 0.0046 | loss_rpn_loc: 0.1212 | Total Loss: 0.3923\n",
      "Epoch 1210 | loss_cls: 0.0798 | loss_box_reg: 0.1338 | loss_mask: 0.1685 | loss_rpn_cls: 0.0165 | loss_rpn_loc: 0.2061 | Total Loss: 0.6047\n",
      "Epoch 1211 | loss_cls: 0.0655 | loss_box_reg: 0.0943 | loss_mask: 0.0466 | loss_rpn_cls: 0.0077 | loss_rpn_loc: 0.0089 | Total Loss: 0.2230\n",
      "Epoch 1212 | loss_cls: 0.0497 | loss_box_reg: 0.2226 | loss_mask: 0.0716 | loss_rpn_cls: 0.0055 | loss_rpn_loc: 0.0471 | Total Loss: 0.3966\n",
      "Epoch 1213 | loss_cls: 0.0514 | loss_box_reg: 0.0978 | loss_mask: 0.2732 | loss_rpn_cls: 0.0108 | loss_rpn_loc: 0.1032 | Total Loss: 0.5363\n",
      "Epoch 1214 | loss_cls: 0.1276 | loss_box_reg: 0.3212 | loss_mask: 0.0690 | loss_rpn_cls: 0.0090 | loss_rpn_loc: 0.0097 | Total Loss: 0.5365\n",
      "Epoch 1215 | loss_cls: 0.1366 | loss_box_reg: 0.2833 | loss_mask: 0.0768 | loss_rpn_cls: 0.0107 | loss_rpn_loc: 0.0097 | Total Loss: 0.5169\n",
      "Epoch 1216 | loss_cls: 0.1279 | loss_box_reg: 0.3054 | loss_mask: 0.1060 | loss_rpn_cls: 0.0157 | loss_rpn_loc: 0.1146 | Total Loss: 0.6695\n",
      "Epoch 1217 | loss_cls: 0.1002 | loss_box_reg: 0.1936 | loss_mask: 0.0713 | loss_rpn_cls: 0.0043 | loss_rpn_loc: 0.0329 | Total Loss: 0.4024\n",
      "Epoch 1218 | loss_cls: 0.0302 | loss_box_reg: 0.0683 | loss_mask: 0.1257 | loss_rpn_cls: 0.0090 | loss_rpn_loc: 0.1325 | Total Loss: 0.3657\n",
      "Epoch 1219 | loss_cls: 0.0298 | loss_box_reg: 0.0949 | loss_mask: 0.2199 | loss_rpn_cls: 0.0056 | loss_rpn_loc: 0.1288 | Total Loss: 0.4789\n",
      "\u001b[32m[07/29 18:27:57 d2.utils.events]: \u001b[0m eta: 0:11:17  iter: 1219      time: 0.3314  last_time: 0.3968   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1220 | loss_cls: 0.1399 | loss_box_reg: 0.3018 | loss_mask: 0.1179 | loss_rpn_cls: 0.0151 | loss_rpn_loc: 0.0731 | Total Loss: 0.6477\n",
      "Epoch 1221 | loss_cls: 0.0849 | loss_box_reg: 0.2855 | loss_mask: 0.1517 | loss_rpn_cls: 0.0297 | loss_rpn_loc: 0.1058 | Total Loss: 0.6576\n",
      "Epoch 1222 | loss_cls: 0.0271 | loss_box_reg: 0.0892 | loss_mask: 0.1076 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0033 | Total Loss: 0.2275\n",
      "Epoch 1223 | loss_cls: 0.0771 | loss_box_reg: 0.1566 | loss_mask: 0.0621 | loss_rpn_cls: 0.0071 | loss_rpn_loc: 0.0480 | Total Loss: 0.3510\n",
      "Epoch 1224 | loss_cls: 0.0460 | loss_box_reg: 0.0667 | loss_mask: 0.3608 | loss_rpn_cls: 0.0068 | loss_rpn_loc: 0.1034 | Total Loss: 0.5837\n",
      "Epoch 1225 | loss_cls: 0.0677 | loss_box_reg: 0.3044 | loss_mask: 0.1596 | loss_rpn_cls: 0.0030 | loss_rpn_loc: 0.0059 | Total Loss: 0.5406\n",
      "Epoch 1226 | loss_cls: 0.1199 | loss_box_reg: 0.3324 | loss_mask: 0.1243 | loss_rpn_cls: 0.0099 | loss_rpn_loc: 0.0910 | Total Loss: 0.6775\n",
      "Epoch 1227 | loss_cls: 0.0216 | loss_box_reg: 0.0816 | loss_mask: 0.1099 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.0947 | Total Loss: 0.3112\n",
      "Epoch 1228 | loss_cls: 0.0616 | loss_box_reg: 0.1443 | loss_mask: 0.0477 | loss_rpn_cls: 0.0078 | loss_rpn_loc: 0.0176 | Total Loss: 0.2790\n",
      "Epoch 1229 | loss_cls: 0.0902 | loss_box_reg: 0.1583 | loss_mask: 0.0695 | loss_rpn_cls: 0.0030 | loss_rpn_loc: 0.0096 | Total Loss: 0.3306\n",
      "Epoch 1230 | loss_cls: 0.0765 | loss_box_reg: 0.1673 | loss_mask: 0.0521 | loss_rpn_cls: 0.0139 | loss_rpn_loc: 0.1912 | Total Loss: 0.5011\n",
      "Epoch 1231 | loss_cls: 0.1542 | loss_box_reg: 0.2280 | loss_mask: 0.1272 | loss_rpn_cls: 0.0463 | loss_rpn_loc: 0.1197 | Total Loss: 0.6753\n",
      "Epoch 1232 | loss_cls: 0.0248 | loss_box_reg: 0.0681 | loss_mask: 0.1626 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.0193 | Total Loss: 0.2753\n",
      "Epoch 1233 | loss_cls: 0.0549 | loss_box_reg: 0.2069 | loss_mask: 0.1956 | loss_rpn_cls: 0.0303 | loss_rpn_loc: 0.0532 | Total Loss: 0.5409\n",
      "Epoch 1234 | loss_cls: 0.0490 | loss_box_reg: 0.0656 | loss_mask: 0.0485 | loss_rpn_cls: 0.0242 | loss_rpn_loc: 0.0997 | Total Loss: 0.2869\n",
      "Epoch 1235 | loss_cls: 0.0324 | loss_box_reg: 0.1055 | loss_mask: 0.1435 | loss_rpn_cls: 0.0037 | loss_rpn_loc: 0.0032 | Total Loss: 0.2884\n",
      "Epoch 1236 | loss_cls: 0.0237 | loss_box_reg: 0.0740 | loss_mask: 0.0538 | loss_rpn_cls: 0.0022 | loss_rpn_loc: 0.1078 | Total Loss: 0.2614\n",
      "Epoch 1237 | loss_cls: 0.1121 | loss_box_reg: 0.1739 | loss_mask: 0.1212 | loss_rpn_cls: 0.0510 | loss_rpn_loc: 0.1886 | Total Loss: 0.6469\n",
      "Epoch 1238 | loss_cls: 0.1888 | loss_box_reg: 0.3494 | loss_mask: 0.0908 | loss_rpn_cls: 0.0056 | loss_rpn_loc: 0.1969 | Total Loss: 0.8315\n",
      "Epoch 1239 | loss_cls: 0.0592 | loss_box_reg: 0.1830 | loss_mask: 0.1079 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.0344 | Total Loss: 0.3873\n",
      "\u001b[32m[07/29 18:28:03 d2.utils.events]: \u001b[0m eta: 0:11:09  iter: 1239      time: 0.3310  last_time: 0.4089   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1240 | loss_cls: 0.0541 | loss_box_reg: 0.1394 | loss_mask: 0.0786 | loss_rpn_cls: 0.0032 | loss_rpn_loc: 0.0088 | Total Loss: 0.2839\n",
      "Epoch 1241 | loss_cls: 0.1826 | loss_box_reg: 0.3555 | loss_mask: 0.1043 | loss_rpn_cls: 0.0048 | loss_rpn_loc: 0.0140 | Total Loss: 0.6611\n",
      "Epoch 1242 | loss_cls: 0.1550 | loss_box_reg: 0.3621 | loss_mask: 0.2044 | loss_rpn_cls: 0.0124 | loss_rpn_loc: 0.0576 | Total Loss: 0.7916\n",
      "Epoch 1243 | loss_cls: 0.0744 | loss_box_reg: 0.1832 | loss_mask: 0.2158 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.0848 | Total Loss: 0.5595\n",
      "Epoch 1244 | loss_cls: 0.0805 | loss_box_reg: 0.1151 | loss_mask: 0.2077 | loss_rpn_cls: 0.0030 | loss_rpn_loc: 0.1316 | Total Loss: 0.5379\n",
      "Epoch 1245 | loss_cls: 0.0835 | loss_box_reg: 0.2842 | loss_mask: 0.1183 | loss_rpn_cls: 0.0235 | loss_rpn_loc: 0.0718 | Total Loss: 0.5812\n",
      "Epoch 1246 | loss_cls: 0.0602 | loss_box_reg: 0.2011 | loss_mask: 0.2206 | loss_rpn_cls: 0.0008 | loss_rpn_loc: 0.0096 | Total Loss: 0.4923\n",
      "Epoch 1247 | loss_cls: 0.0596 | loss_box_reg: 0.1862 | loss_mask: 0.0808 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.0048 | Total Loss: 0.3328\n",
      "Epoch 1248 | loss_cls: 0.0943 | loss_box_reg: 0.2705 | loss_mask: 0.1572 | loss_rpn_cls: 0.0144 | loss_rpn_loc: 0.0160 | Total Loss: 0.5524\n",
      "Epoch 1249 | loss_cls: 0.0726 | loss_box_reg: 0.1332 | loss_mask: 0.1235 | loss_rpn_cls: 0.0274 | loss_rpn_loc: 0.0150 | Total Loss: 0.3716\n",
      "Epoch 1250 | loss_cls: 0.0726 | loss_box_reg: 0.1172 | loss_mask: 0.2824 | loss_rpn_cls: 0.0060 | loss_rpn_loc: 0.0034 | Total Loss: 0.4815\n",
      "Epoch 1251 | loss_cls: 0.1042 | loss_box_reg: 0.2916 | loss_mask: 0.0863 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.0088 | Total Loss: 0.4921\n",
      "Epoch 1252 | loss_cls: 0.0553 | loss_box_reg: 0.1605 | loss_mask: 0.1648 | loss_rpn_cls: 0.0058 | loss_rpn_loc: 0.1163 | Total Loss: 0.5027\n",
      "Epoch 1253 | loss_cls: 0.1275 | loss_box_reg: 0.1806 | loss_mask: 0.1154 | loss_rpn_cls: 0.0024 | loss_rpn_loc: 0.0285 | Total Loss: 0.4545\n",
      "Epoch 1254 | loss_cls: 0.0678 | loss_box_reg: 0.1286 | loss_mask: 0.0837 | loss_rpn_cls: 0.0229 | loss_rpn_loc: 0.0061 | Total Loss: 0.3093\n",
      "Epoch 1255 | loss_cls: 0.1353 | loss_box_reg: 0.1837 | loss_mask: 0.0846 | loss_rpn_cls: 0.0212 | loss_rpn_loc: 0.0358 | Total Loss: 0.4605\n",
      "Epoch 1256 | loss_cls: 0.0436 | loss_box_reg: 0.0932 | loss_mask: 0.0459 | loss_rpn_cls: 0.0089 | loss_rpn_loc: 0.0017 | Total Loss: 0.1934\n",
      "Epoch 1257 | loss_cls: 0.1075 | loss_box_reg: 0.1220 | loss_mask: 0.0977 | loss_rpn_cls: 0.0116 | loss_rpn_loc: 0.0411 | Total Loss: 0.3798\n",
      "Epoch 1258 | loss_cls: 0.0312 | loss_box_reg: 0.0662 | loss_mask: 0.2254 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.0151 | Total Loss: 0.3392\n",
      "Epoch 1259 | loss_cls: 0.0829 | loss_box_reg: 0.1859 | loss_mask: 0.1427 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.0453 | Total Loss: 0.4577\n",
      "\u001b[32m[07/29 18:28:09 d2.utils.events]: \u001b[0m eta: 0:11:02  iter: 1259      time: 0.3305  last_time: 0.2760   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1260 | loss_cls: 0.1127 | loss_box_reg: 0.1619 | loss_mask: 0.0472 | loss_rpn_cls: 0.0161 | loss_rpn_loc: 0.0775 | Total Loss: 0.4154\n",
      "Epoch 1261 | loss_cls: 0.0502 | loss_box_reg: 0.1610 | loss_mask: 0.1347 | loss_rpn_cls: 0.0036 | loss_rpn_loc: 0.1373 | Total Loss: 0.4867\n",
      "Epoch 1262 | loss_cls: 0.1183 | loss_box_reg: 0.1565 | loss_mask: 0.0877 | loss_rpn_cls: 0.0109 | loss_rpn_loc: 0.0189 | Total Loss: 0.3922\n",
      "Epoch 1263 | loss_cls: 0.1417 | loss_box_reg: 0.1915 | loss_mask: 0.0859 | loss_rpn_cls: 0.0043 | loss_rpn_loc: 0.0442 | Total Loss: 0.4675\n",
      "Epoch 1264 | loss_cls: 0.0267 | loss_box_reg: 0.0600 | loss_mask: 0.0720 | loss_rpn_cls: 0.0109 | loss_rpn_loc: 0.0967 | Total Loss: 0.2663\n",
      "Epoch 1265 | loss_cls: 0.1114 | loss_box_reg: 0.1574 | loss_mask: 0.1332 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.1946 | Total Loss: 0.6016\n",
      "Epoch 1266 | loss_cls: 0.0549 | loss_box_reg: 0.0876 | loss_mask: 0.0571 | loss_rpn_cls: 0.0009 | loss_rpn_loc: 0.0716 | Total Loss: 0.2722\n",
      "Epoch 1267 | loss_cls: 0.0613 | loss_box_reg: 0.2245 | loss_mask: 0.1189 | loss_rpn_cls: 0.0162 | loss_rpn_loc: 0.0660 | Total Loss: 0.4869\n",
      "Epoch 1268 | loss_cls: 0.1271 | loss_box_reg: 0.2627 | loss_mask: 0.0800 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.0412 | Total Loss: 0.5137\n",
      "Epoch 1269 | loss_cls: 0.0438 | loss_box_reg: 0.1137 | loss_mask: 0.1014 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.0190 | Total Loss: 0.2829\n",
      "Epoch 1270 | loss_cls: 0.0511 | loss_box_reg: 0.1981 | loss_mask: 0.0771 | loss_rpn_cls: 0.0191 | loss_rpn_loc: 0.0657 | Total Loss: 0.4110\n",
      "Epoch 1271 | loss_cls: 0.0940 | loss_box_reg: 0.2404 | loss_mask: 0.0795 | loss_rpn_cls: 0.0055 | loss_rpn_loc: 0.0199 | Total Loss: 0.4392\n",
      "Epoch 1272 | loss_cls: 0.0270 | loss_box_reg: 0.0958 | loss_mask: 0.0846 | loss_rpn_cls: 0.0100 | loss_rpn_loc: 0.0078 | Total Loss: 0.2252\n",
      "Epoch 1273 | loss_cls: 0.0651 | loss_box_reg: 0.2550 | loss_mask: 0.0723 | loss_rpn_cls: 0.0164 | loss_rpn_loc: 0.0047 | Total Loss: 0.4135\n",
      "Epoch 1274 | loss_cls: 0.0632 | loss_box_reg: 0.1932 | loss_mask: 0.0670 | loss_rpn_cls: 0.0035 | loss_rpn_loc: 0.0223 | Total Loss: 0.3492\n",
      "Epoch 1275 | loss_cls: 0.0141 | loss_box_reg: 0.0685 | loss_mask: 0.0847 | loss_rpn_cls: 0.0026 | loss_rpn_loc: 0.1293 | Total Loss: 0.2993\n",
      "Epoch 1276 | loss_cls: 0.0738 | loss_box_reg: 0.1273 | loss_mask: 0.0520 | loss_rpn_cls: 0.0009 | loss_rpn_loc: 0.0092 | Total Loss: 0.2633\n",
      "Epoch 1277 | loss_cls: 0.1045 | loss_box_reg: 0.1753 | loss_mask: 0.0670 | loss_rpn_cls: 0.0311 | loss_rpn_loc: 0.0154 | Total Loss: 0.3933\n",
      "Epoch 1278 | loss_cls: 0.0663 | loss_box_reg: 0.1923 | loss_mask: 0.0566 | loss_rpn_cls: 0.0134 | loss_rpn_loc: 0.0715 | Total Loss: 0.4001\n",
      "Epoch 1279 | loss_cls: 0.0205 | loss_box_reg: 0.1467 | loss_mask: 0.0715 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.0039 | Total Loss: 0.2437\n",
      "\u001b[32m[07/29 18:28:16 d2.utils.events]: \u001b[0m eta: 0:10:56  iter: 1279      time: 0.3307  last_time: 0.4080   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1280 | loss_cls: 0.1305 | loss_box_reg: 0.3272 | loss_mask: 0.0441 | loss_rpn_cls: 0.0058 | loss_rpn_loc: 0.0702 | Total Loss: 0.5777\n",
      "Epoch 1281 | loss_cls: 0.0402 | loss_box_reg: 0.1161 | loss_mask: 0.0734 | loss_rpn_cls: 0.0238 | loss_rpn_loc: 0.1067 | Total Loss: 0.3603\n",
      "Epoch 1282 | loss_cls: 0.1319 | loss_box_reg: 0.2646 | loss_mask: 0.0998 | loss_rpn_cls: 0.0114 | loss_rpn_loc: 0.0910 | Total Loss: 0.5988\n",
      "Epoch 1283 | loss_cls: 0.1349 | loss_box_reg: 0.1904 | loss_mask: 0.1260 | loss_rpn_cls: 0.0043 | loss_rpn_loc: 0.2925 | Total Loss: 0.7481\n",
      "Epoch 1284 | loss_cls: 0.1877 | loss_box_reg: 0.2897 | loss_mask: 0.0843 | loss_rpn_cls: 0.0273 | loss_rpn_loc: 0.0796 | Total Loss: 0.6685\n",
      "Epoch 1285 | loss_cls: 0.1792 | loss_box_reg: 0.2244 | loss_mask: 0.1827 | loss_rpn_cls: 0.0055 | loss_rpn_loc: 0.0461 | Total Loss: 0.6379\n",
      "Epoch 1286 | loss_cls: 0.0600 | loss_box_reg: 0.1668 | loss_mask: 0.1679 | loss_rpn_cls: 0.0044 | loss_rpn_loc: 0.1185 | Total Loss: 0.5177\n",
      "Epoch 1287 | loss_cls: 0.1277 | loss_box_reg: 0.3023 | loss_mask: 0.1081 | loss_rpn_cls: 0.0043 | loss_rpn_loc: 0.0318 | Total Loss: 0.5742\n",
      "Epoch 1288 | loss_cls: 0.0854 | loss_box_reg: 0.3220 | loss_mask: 0.0686 | loss_rpn_cls: 0.0153 | loss_rpn_loc: 0.0042 | Total Loss: 0.4954\n",
      "Epoch 1289 | loss_cls: 0.0851 | loss_box_reg: 0.1178 | loss_mask: 0.0891 | loss_rpn_cls: 0.0183 | loss_rpn_loc: 0.0092 | Total Loss: 0.3195\n",
      "Epoch 1290 | loss_cls: 0.0543 | loss_box_reg: 0.1993 | loss_mask: 0.0841 | loss_rpn_cls: 0.0162 | loss_rpn_loc: 0.0866 | Total Loss: 0.4406\n",
      "Epoch 1291 | loss_cls: 0.0336 | loss_box_reg: 0.0339 | loss_mask: 0.2114 | loss_rpn_cls: 0.0060 | loss_rpn_loc: 0.2236 | Total Loss: 0.5085\n",
      "Epoch 1292 | loss_cls: 0.0958 | loss_box_reg: 0.1833 | loss_mask: 0.0489 | loss_rpn_cls: 0.0016 | loss_rpn_loc: 0.0259 | Total Loss: 0.3556\n",
      "Epoch 1293 | loss_cls: 0.0207 | loss_box_reg: 0.1445 | loss_mask: 0.2100 | loss_rpn_cls: 0.0122 | loss_rpn_loc: 0.1035 | Total Loss: 0.4910\n",
      "Epoch 1294 | loss_cls: 0.0299 | loss_box_reg: 0.0898 | loss_mask: 0.1740 | loss_rpn_cls: 0.0097 | loss_rpn_loc: 0.0078 | Total Loss: 0.3111\n",
      "Epoch 1295 | loss_cls: 0.1033 | loss_box_reg: 0.3331 | loss_mask: 0.0957 | loss_rpn_cls: 0.0037 | loss_rpn_loc: 0.0250 | Total Loss: 0.5610\n",
      "Epoch 1296 | loss_cls: 0.0363 | loss_box_reg: 0.1426 | loss_mask: 0.1294 | loss_rpn_cls: 0.0093 | loss_rpn_loc: 0.1293 | Total Loss: 0.4468\n",
      "Epoch 1297 | loss_cls: 0.2141 | loss_box_reg: 0.3476 | loss_mask: 0.0969 | loss_rpn_cls: 0.0514 | loss_rpn_loc: 0.2172 | Total Loss: 0.9272\n",
      "Epoch 1298 | loss_cls: 0.0527 | loss_box_reg: 0.1139 | loss_mask: 0.1106 | loss_rpn_cls: 0.0031 | loss_rpn_loc: 0.0257 | Total Loss: 0.3060\n",
      "Epoch 1299 | loss_cls: 0.0593 | loss_box_reg: 0.0927 | loss_mask: 0.0978 | loss_rpn_cls: 0.0049 | loss_rpn_loc: 0.1674 | Total Loss: 0.4220\n",
      "\u001b[32m[07/29 18:28:24 d2.utils.events]: \u001b[0m eta: 0:10:50  iter: 1299      time: 0.3312  last_time: 0.4067   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1300 | loss_cls: 0.0751 | loss_box_reg: 0.2424 | loss_mask: 0.1993 | loss_rpn_cls: 0.0048 | loss_rpn_loc: 0.0112 | Total Loss: 0.5328\n",
      "Epoch 1301 | loss_cls: 0.0353 | loss_box_reg: 0.0865 | loss_mask: 0.0763 | loss_rpn_cls: 0.0072 | loss_rpn_loc: 0.1013 | Total Loss: 0.3066\n",
      "Epoch 1302 | loss_cls: 0.0774 | loss_box_reg: 0.1523 | loss_mask: 0.0999 | loss_rpn_cls: 0.0365 | loss_rpn_loc: 0.0973 | Total Loss: 0.4634\n",
      "Epoch 1303 | loss_cls: 0.0713 | loss_box_reg: 0.1334 | loss_mask: 0.0451 | loss_rpn_cls: 0.0183 | loss_rpn_loc: 0.1527 | Total Loss: 0.4209\n",
      "Epoch 1304 | loss_cls: 0.0414 | loss_box_reg: 0.1009 | loss_mask: 0.1874 | loss_rpn_cls: 0.0073 | loss_rpn_loc: 0.1156 | Total Loss: 0.4526\n",
      "Epoch 1305 | loss_cls: 0.0462 | loss_box_reg: 0.2163 | loss_mask: 0.1686 | loss_rpn_cls: 0.0206 | loss_rpn_loc: 0.0883 | Total Loss: 0.5399\n",
      "Epoch 1306 | loss_cls: 0.1024 | loss_box_reg: 0.3336 | loss_mask: 0.1724 | loss_rpn_cls: 0.0064 | loss_rpn_loc: 0.0405 | Total Loss: 0.6553\n",
      "Epoch 1307 | loss_cls: 0.0457 | loss_box_reg: 0.0922 | loss_mask: 0.1183 | loss_rpn_cls: 0.0159 | loss_rpn_loc: 0.0130 | Total Loss: 0.2852\n",
      "Epoch 1308 | loss_cls: 0.1037 | loss_box_reg: 0.2065 | loss_mask: 0.0420 | loss_rpn_cls: 0.0686 | loss_rpn_loc: 0.3216 | Total Loss: 0.7424\n",
      "Epoch 1309 | loss_cls: 0.0677 | loss_box_reg: 0.1706 | loss_mask: 0.0738 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.0208 | Total Loss: 0.3379\n",
      "Epoch 1310 | loss_cls: 0.0767 | loss_box_reg: 0.3596 | loss_mask: 0.2121 | loss_rpn_cls: 0.0180 | loss_rpn_loc: 0.0404 | Total Loss: 0.7068\n",
      "Epoch 1311 | loss_cls: 0.0531 | loss_box_reg: 0.1876 | loss_mask: 0.1074 | loss_rpn_cls: 0.0125 | loss_rpn_loc: 0.0347 | Total Loss: 0.3954\n",
      "Epoch 1312 | loss_cls: 0.0940 | loss_box_reg: 0.1561 | loss_mask: 0.0637 | loss_rpn_cls: 0.0058 | loss_rpn_loc: 0.0048 | Total Loss: 0.3243\n",
      "Epoch 1313 | loss_cls: 0.0270 | loss_box_reg: 0.0635 | loss_mask: 0.0583 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.1366 | Total Loss: 0.2879\n",
      "Epoch 1314 | loss_cls: 0.0458 | loss_box_reg: 0.1446 | loss_mask: 0.0841 | loss_rpn_cls: 0.0083 | loss_rpn_loc: 0.0069 | Total Loss: 0.2897\n",
      "Epoch 1315 | loss_cls: 0.0445 | loss_box_reg: 0.2516 | loss_mask: 0.1203 | loss_rpn_cls: 0.0133 | loss_rpn_loc: 0.0747 | Total Loss: 0.5044\n",
      "Epoch 1316 | loss_cls: 0.1040 | loss_box_reg: 0.3469 | loss_mask: 0.1923 | loss_rpn_cls: 0.0119 | loss_rpn_loc: 0.2554 | Total Loss: 0.9105\n",
      "Epoch 1317 | loss_cls: 0.1071 | loss_box_reg: 0.2666 | loss_mask: 0.1494 | loss_rpn_cls: 0.0210 | loss_rpn_loc: 0.1063 | Total Loss: 0.6504\n",
      "Epoch 1318 | loss_cls: 0.0735 | loss_box_reg: 0.2420 | loss_mask: 0.0827 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.0097 | Total Loss: 0.4084\n",
      "Epoch 1319 | loss_cls: 0.0516 | loss_box_reg: 0.0537 | loss_mask: 0.0861 | loss_rpn_cls: 0.0080 | loss_rpn_loc: 0.1177 | Total Loss: 0.3170\n",
      "\u001b[32m[07/29 18:28:30 d2.utils.events]: \u001b[0m eta: 0:10:43  iter: 1319      time: 0.3314  last_time: 0.3861   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1320 | loss_cls: 0.0401 | loss_box_reg: 0.0680 | loss_mask: 0.2578 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.0911 | Total Loss: 0.4603\n",
      "Epoch 1321 | loss_cls: 0.0688 | loss_box_reg: 0.1075 | loss_mask: 0.0706 | loss_rpn_cls: 0.0056 | loss_rpn_loc: 0.0998 | Total Loss: 0.3523\n",
      "Epoch 1322 | loss_cls: 0.0771 | loss_box_reg: 0.2959 | loss_mask: 0.1072 | loss_rpn_cls: 0.0121 | loss_rpn_loc: 0.0124 | Total Loss: 0.5047\n",
      "Epoch 1323 | loss_cls: 0.0472 | loss_box_reg: 0.1397 | loss_mask: 0.0550 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.1097 | Total Loss: 0.3528\n",
      "Epoch 1324 | loss_cls: 0.0411 | loss_box_reg: 0.0793 | loss_mask: 0.0498 | loss_rpn_cls: 0.0043 | loss_rpn_loc: 0.0023 | Total Loss: 0.1768\n",
      " Best model saved at Epoch 1324 | Total Loss: 0.1768\n",
      "Epoch 1325 | loss_cls: 0.0770 | loss_box_reg: 0.1727 | loss_mask: 0.0992 | loss_rpn_cls: 0.0098 | loss_rpn_loc: 0.0337 | Total Loss: 0.3925\n",
      "Epoch 1326 | loss_cls: 0.0553 | loss_box_reg: 0.1323 | loss_mask: 0.2575 | loss_rpn_cls: 0.0029 | loss_rpn_loc: 0.0031 | Total Loss: 0.4512\n",
      "Epoch 1327 | loss_cls: 0.0204 | loss_box_reg: 0.0396 | loss_mask: 0.1439 | loss_rpn_cls: 0.0084 | loss_rpn_loc: 0.1206 | Total Loss: 0.3328\n",
      "Epoch 1328 | loss_cls: 0.0158 | loss_box_reg: 0.0725 | loss_mask: 0.2727 | loss_rpn_cls: 0.0024 | loss_rpn_loc: 0.1156 | Total Loss: 0.4790\n",
      "Epoch 1329 | loss_cls: 0.1004 | loss_box_reg: 0.3047 | loss_mask: 0.0712 | loss_rpn_cls: 0.0163 | loss_rpn_loc: 0.1303 | Total Loss: 0.6230\n",
      "Epoch 1330 | loss_cls: 0.0416 | loss_box_reg: 0.1222 | loss_mask: 0.2013 | loss_rpn_cls: 0.0048 | loss_rpn_loc: 0.0339 | Total Loss: 0.4038\n",
      "Epoch 1331 | loss_cls: 0.1277 | loss_box_reg: 0.3676 | loss_mask: 0.0618 | loss_rpn_cls: 0.0076 | loss_rpn_loc: 0.0927 | Total Loss: 0.6575\n",
      "Epoch 1332 | loss_cls: 0.0422 | loss_box_reg: 0.1322 | loss_mask: 0.0766 | loss_rpn_cls: 0.0042 | loss_rpn_loc: 0.1642 | Total Loss: 0.4195\n",
      "Epoch 1333 | loss_cls: 0.1024 | loss_box_reg: 0.1798 | loss_mask: 0.0668 | loss_rpn_cls: 0.0020 | loss_rpn_loc: 0.0084 | Total Loss: 0.3593\n",
      "Epoch 1334 | loss_cls: 0.0249 | loss_box_reg: 0.0661 | loss_mask: 0.1243 | loss_rpn_cls: 0.0024 | loss_rpn_loc: 0.1145 | Total Loss: 0.3323\n",
      "Epoch 1335 | loss_cls: 0.0906 | loss_box_reg: 0.1390 | loss_mask: 0.2102 | loss_rpn_cls: 0.0123 | loss_rpn_loc: 0.0953 | Total Loss: 0.5474\n",
      "Epoch 1336 | loss_cls: 0.0481 | loss_box_reg: 0.1192 | loss_mask: 0.0625 | loss_rpn_cls: 0.0141 | loss_rpn_loc: 0.0052 | Total Loss: 0.2492\n",
      "Epoch 1337 | loss_cls: 0.0391 | loss_box_reg: 0.1678 | loss_mask: 0.0759 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.0400 | Total Loss: 0.3241\n",
      "Epoch 1338 | loss_cls: 0.0550 | loss_box_reg: 0.1298 | loss_mask: 0.1604 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.0230 | Total Loss: 0.3717\n",
      "Epoch 1339 | loss_cls: 0.0849 | loss_box_reg: 0.2014 | loss_mask: 0.0759 | loss_rpn_cls: 0.0086 | loss_rpn_loc: 0.0377 | Total Loss: 0.4086\n",
      "\u001b[32m[07/29 18:28:37 d2.utils.events]: \u001b[0m eta: 0:10:36  iter: 1339      time: 0.3315  last_time: 0.2868   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1340 | loss_cls: 0.1273 | loss_box_reg: 0.2385 | loss_mask: 0.0415 | loss_rpn_cls: 0.0225 | loss_rpn_loc: 0.0891 | Total Loss: 0.5189\n",
      "Epoch 1341 | loss_cls: 0.0295 | loss_box_reg: 0.1255 | loss_mask: 0.4820 | loss_rpn_cls: 0.0029 | loss_rpn_loc: 0.2211 | Total Loss: 0.8609\n",
      "Epoch 1342 | loss_cls: 0.1184 | loss_box_reg: 0.1988 | loss_mask: 0.0770 | loss_rpn_cls: 0.0100 | loss_rpn_loc: 0.1967 | Total Loss: 0.6009\n",
      "Epoch 1343 | loss_cls: 0.0708 | loss_box_reg: 0.1106 | loss_mask: 0.0913 | loss_rpn_cls: 0.0057 | loss_rpn_loc: 0.0411 | Total Loss: 0.3195\n",
      "Epoch 1344 | loss_cls: 0.0473 | loss_box_reg: 0.0260 | loss_mask: 0.0784 | loss_rpn_cls: 0.0120 | loss_rpn_loc: 0.0202 | Total Loss: 0.1839\n",
      "Epoch 1345 | loss_cls: 0.0559 | loss_box_reg: 0.0876 | loss_mask: 0.0845 | loss_rpn_cls: 0.0026 | loss_rpn_loc: 0.1159 | Total Loss: 0.3464\n",
      "Epoch 1346 | loss_cls: 0.0562 | loss_box_reg: 0.1265 | loss_mask: 0.1392 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.0026 | Total Loss: 0.3268\n",
      "Epoch 1347 | loss_cls: 0.0886 | loss_box_reg: 0.1913 | loss_mask: 0.0990 | loss_rpn_cls: 0.0044 | loss_rpn_loc: 0.1426 | Total Loss: 0.5259\n",
      "Epoch 1348 | loss_cls: 0.0252 | loss_box_reg: 0.0378 | loss_mask: 0.0609 | loss_rpn_cls: 0.0017 | loss_rpn_loc: 0.0089 | Total Loss: 0.1346\n",
      " Best model saved at Epoch 1348 | Total Loss: 0.1346\n",
      "Epoch 1349 | loss_cls: 0.1720 | loss_box_reg: 0.4189 | loss_mask: 0.0667 | loss_rpn_cls: 0.0047 | loss_rpn_loc: 0.0065 | Total Loss: 0.6688\n",
      "Epoch 1350 | loss_cls: 0.1776 | loss_box_reg: 0.4090 | loss_mask: 0.0747 | loss_rpn_cls: 0.0031 | loss_rpn_loc: 0.0103 | Total Loss: 0.6747\n",
      "Epoch 1351 | loss_cls: 0.1334 | loss_box_reg: 0.2127 | loss_mask: 0.0782 | loss_rpn_cls: 0.0018 | loss_rpn_loc: 0.0516 | Total Loss: 0.4777\n",
      "Epoch 1352 | loss_cls: 0.0839 | loss_box_reg: 0.2699 | loss_mask: 0.1595 | loss_rpn_cls: 0.0077 | loss_rpn_loc: 0.0116 | Total Loss: 0.5326\n",
      "Epoch 1353 | loss_cls: 0.0802 | loss_box_reg: 0.1818 | loss_mask: 0.0745 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.0380 | Total Loss: 0.3767\n",
      "Epoch 1354 | loss_cls: 0.1043 | loss_box_reg: 0.2643 | loss_mask: 0.1278 | loss_rpn_cls: 0.0056 | loss_rpn_loc: 0.0142 | Total Loss: 0.5162\n",
      "Epoch 1355 | loss_cls: 0.0525 | loss_box_reg: 0.1213 | loss_mask: 0.1200 | loss_rpn_cls: 0.0161 | loss_rpn_loc: 0.0385 | Total Loss: 0.3483\n",
      "Epoch 1356 | loss_cls: 0.0714 | loss_box_reg: 0.1338 | loss_mask: 0.4442 | loss_rpn_cls: 0.0035 | loss_rpn_loc: 0.0037 | Total Loss: 0.6565\n",
      "Epoch 1357 | loss_cls: 0.1083 | loss_box_reg: 0.1936 | loss_mask: 0.1697 | loss_rpn_cls: 0.0064 | loss_rpn_loc: 0.1531 | Total Loss: 0.6312\n",
      "Epoch 1358 | loss_cls: 0.0661 | loss_box_reg: 0.2053 | loss_mask: 0.0752 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0222 | Total Loss: 0.3693\n",
      "Epoch 1359 | loss_cls: 0.0489 | loss_box_reg: 0.1849 | loss_mask: 0.1017 | loss_rpn_cls: 0.0218 | loss_rpn_loc: 0.0051 | Total Loss: 0.3624\n",
      "\u001b[32m[07/29 18:28:44 d2.utils.events]: \u001b[0m eta: 0:10:28  iter: 1359      time: 0.3315  last_time: 0.1920   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1360 | loss_cls: 0.1052 | loss_box_reg: 0.2962 | loss_mask: 0.1113 | loss_rpn_cls: 0.0166 | loss_rpn_loc: 0.0529 | Total Loss: 0.5822\n",
      "Epoch 1361 | loss_cls: 0.0476 | loss_box_reg: 0.1873 | loss_mask: 0.1233 | loss_rpn_cls: 0.0136 | loss_rpn_loc: 0.0070 | Total Loss: 0.3788\n",
      "Epoch 1362 | loss_cls: 0.0588 | loss_box_reg: 0.1639 | loss_mask: 0.0642 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0281 | Total Loss: 0.3155\n",
      "Epoch 1363 | loss_cls: 0.0593 | loss_box_reg: 0.1306 | loss_mask: 0.1389 | loss_rpn_cls: 0.0073 | loss_rpn_loc: 0.0256 | Total Loss: 0.3616\n",
      "Epoch 1364 | loss_cls: 0.0833 | loss_box_reg: 0.1975 | loss_mask: 0.1008 | loss_rpn_cls: 0.0149 | loss_rpn_loc: 0.1025 | Total Loss: 0.4991\n",
      "Epoch 1365 | loss_cls: 0.1156 | loss_box_reg: 0.2851 | loss_mask: 0.1282 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.0486 | Total Loss: 0.5826\n",
      "Epoch 1366 | loss_cls: 0.0566 | loss_box_reg: 0.1645 | loss_mask: 0.0773 | loss_rpn_cls: 0.0336 | loss_rpn_loc: 0.0236 | Total Loss: 0.3556\n",
      "Epoch 1367 | loss_cls: 0.0455 | loss_box_reg: 0.1063 | loss_mask: 0.2173 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.0911 | Total Loss: 0.4630\n",
      "Epoch 1368 | loss_cls: 0.0912 | loss_box_reg: 0.2188 | loss_mask: 0.1374 | loss_rpn_cls: 0.0079 | loss_rpn_loc: 0.0136 | Total Loss: 0.4690\n",
      "Epoch 1369 | loss_cls: 0.0697 | loss_box_reg: 0.3183 | loss_mask: 0.0865 | loss_rpn_cls: 0.0003 | loss_rpn_loc: 0.0138 | Total Loss: 0.4887\n",
      "Epoch 1370 | loss_cls: 0.0820 | loss_box_reg: 0.2161 | loss_mask: 0.1595 | loss_rpn_cls: 0.0125 | loss_rpn_loc: 0.1801 | Total Loss: 0.6502\n",
      "Epoch 1371 | loss_cls: 0.0125 | loss_box_reg: 0.0364 | loss_mask: 0.1240 | loss_rpn_cls: 0.0029 | loss_rpn_loc: 0.1036 | Total Loss: 0.2793\n",
      "Epoch 1372 | loss_cls: 0.1021 | loss_box_reg: 0.2632 | loss_mask: 0.2649 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0405 | Total Loss: 0.6718\n",
      "Epoch 1373 | loss_cls: 0.0397 | loss_box_reg: 0.0820 | loss_mask: 0.0833 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.0163 | Total Loss: 0.2223\n",
      "Epoch 1374 | loss_cls: 0.0609 | loss_box_reg: 0.1845 | loss_mask: 0.0469 | loss_rpn_cls: 0.0287 | loss_rpn_loc: 0.1295 | Total Loss: 0.4504\n",
      "Epoch 1375 | loss_cls: 0.0537 | loss_box_reg: 0.1825 | loss_mask: 0.0475 | loss_rpn_cls: 0.0142 | loss_rpn_loc: 0.0543 | Total Loss: 0.3522\n",
      "Epoch 1376 | loss_cls: 0.0177 | loss_box_reg: 0.0835 | loss_mask: 0.0804 | loss_rpn_cls: 0.0073 | loss_rpn_loc: 0.1770 | Total Loss: 0.3659\n",
      "Epoch 1377 | loss_cls: 0.0654 | loss_box_reg: 0.1610 | loss_mask: 0.0666 | loss_rpn_cls: 0.0046 | loss_rpn_loc: 0.0098 | Total Loss: 0.3074\n",
      "Epoch 1378 | loss_cls: 0.0769 | loss_box_reg: 0.1783 | loss_mask: 0.1064 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.0123 | Total Loss: 0.3754\n",
      "Epoch 1379 | loss_cls: 0.0253 | loss_box_reg: 0.1527 | loss_mask: 0.1272 | loss_rpn_cls: 0.0009 | loss_rpn_loc: 0.1201 | Total Loss: 0.4262\n",
      "\u001b[32m[07/29 18:28:50 d2.utils.events]: \u001b[0m eta: 0:10:20  iter: 1379      time: 0.3314  last_time: 0.3951   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1380 | loss_cls: 0.0455 | loss_box_reg: 0.1935 | loss_mask: 0.0504 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.0025 | Total Loss: 0.2930\n",
      "Epoch 1381 | loss_cls: 0.3002 | loss_box_reg: 0.3257 | loss_mask: 0.0739 | loss_rpn_cls: 0.0442 | loss_rpn_loc: 0.5199 | Total Loss: 1.2639\n",
      "Epoch 1382 | loss_cls: 0.0507 | loss_box_reg: 0.1868 | loss_mask: 0.0832 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.0361 | Total Loss: 0.3580\n",
      "Epoch 1383 | loss_cls: 0.0644 | loss_box_reg: 0.1665 | loss_mask: 0.0548 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.0425 | Total Loss: 0.3314\n",
      "Epoch 1384 | loss_cls: 0.0805 | loss_box_reg: 0.1510 | loss_mask: 0.0387 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0057 | Total Loss: 0.2765\n",
      "Epoch 1385 | loss_cls: 0.0888 | loss_box_reg: 0.3632 | loss_mask: 0.1675 | loss_rpn_cls: 0.0186 | loss_rpn_loc: 0.0077 | Total Loss: 0.6458\n",
      "Epoch 1386 | loss_cls: 0.0371 | loss_box_reg: 0.0507 | loss_mask: 0.0496 | loss_rpn_cls: 0.0017 | loss_rpn_loc: 0.0866 | Total Loss: 0.2258\n",
      "Epoch 1387 | loss_cls: 0.0445 | loss_box_reg: 0.1203 | loss_mask: 0.0566 | loss_rpn_cls: 0.0044 | loss_rpn_loc: 0.0117 | Total Loss: 0.2374\n",
      "Epoch 1388 | loss_cls: 0.0626 | loss_box_reg: 0.1174 | loss_mask: 0.0949 | loss_rpn_cls: 0.0130 | loss_rpn_loc: 0.0257 | Total Loss: 0.3136\n",
      "Epoch 1389 | loss_cls: 0.0773 | loss_box_reg: 0.1926 | loss_mask: 0.1831 | loss_rpn_cls: 0.0179 | loss_rpn_loc: 0.0493 | Total Loss: 0.5202\n",
      "Epoch 1390 | loss_cls: 0.0545 | loss_box_reg: 0.0910 | loss_mask: 0.1007 | loss_rpn_cls: 0.0211 | loss_rpn_loc: 0.0120 | Total Loss: 0.2793\n",
      "Epoch 1391 | loss_cls: 0.0881 | loss_box_reg: 0.2576 | loss_mask: 0.0935 | loss_rpn_cls: 0.0265 | loss_rpn_loc: 0.1144 | Total Loss: 0.5801\n",
      "Epoch 1392 | loss_cls: 0.0514 | loss_box_reg: 0.2656 | loss_mask: 0.1046 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.0105 | Total Loss: 0.4335\n",
      "Epoch 1393 | loss_cls: 0.0585 | loss_box_reg: 0.1679 | loss_mask: 0.0353 | loss_rpn_cls: 0.0063 | loss_rpn_loc: 0.1133 | Total Loss: 0.3814\n",
      "Epoch 1394 | loss_cls: 0.1041 | loss_box_reg: 0.2786 | loss_mask: 0.2008 | loss_rpn_cls: 0.0044 | loss_rpn_loc: 0.0898 | Total Loss: 0.6778\n",
      "Epoch 1395 | loss_cls: 0.0339 | loss_box_reg: 0.2013 | loss_mask: 0.0606 | loss_rpn_cls: 0.0003 | loss_rpn_loc: 0.0042 | Total Loss: 0.3004\n",
      "Epoch 1396 | loss_cls: 0.1318 | loss_box_reg: 0.3423 | loss_mask: 0.0991 | loss_rpn_cls: 0.0170 | loss_rpn_loc: 0.0191 | Total Loss: 0.6093\n",
      "Epoch 1397 | loss_cls: 0.0416 | loss_box_reg: 0.1428 | loss_mask: 0.0781 | loss_rpn_cls: 0.0002 | loss_rpn_loc: 0.0198 | Total Loss: 0.2825\n",
      "Epoch 1398 | loss_cls: 0.1176 | loss_box_reg: 0.1762 | loss_mask: 0.1344 | loss_rpn_cls: 0.0155 | loss_rpn_loc: 0.0092 | Total Loss: 0.4529\n",
      "Epoch 1399 | loss_cls: 0.0688 | loss_box_reg: 0.3000 | loss_mask: 0.0930 | loss_rpn_cls: 0.0159 | loss_rpn_loc: 0.0533 | Total Loss: 0.5311\n",
      "\u001b[32m[07/29 18:28:56 d2.utils.events]: \u001b[0m eta: 0:10:13  iter: 1399      time: 0.3310  last_time: 0.3877   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1400 | loss_cls: 0.0506 | loss_box_reg: 0.0461 | loss_mask: 0.2082 | loss_rpn_cls: 0.0131 | loss_rpn_loc: 0.1392 | Total Loss: 0.4572\n",
      "Epoch 1401 | loss_cls: 0.0670 | loss_box_reg: 0.2254 | loss_mask: 0.0586 | loss_rpn_cls: 0.0210 | loss_rpn_loc: 0.0517 | Total Loss: 0.4237\n",
      "Epoch 1402 | loss_cls: 0.1040 | loss_box_reg: 0.2025 | loss_mask: 0.1492 | loss_rpn_cls: 0.0110 | loss_rpn_loc: 0.0818 | Total Loss: 0.5485\n",
      "Epoch 1403 | loss_cls: 0.0710 | loss_box_reg: 0.2502 | loss_mask: 0.2463 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.0359 | Total Loss: 0.6044\n",
      "Epoch 1404 | loss_cls: 0.0759 | loss_box_reg: 0.1826 | loss_mask: 0.0839 | loss_rpn_cls: 0.0035 | loss_rpn_loc: 0.0290 | Total Loss: 0.3748\n",
      "Epoch 1405 | loss_cls: 0.0418 | loss_box_reg: 0.1033 | loss_mask: 0.2277 | loss_rpn_cls: 0.0049 | loss_rpn_loc: 0.0316 | Total Loss: 0.4093\n",
      "Epoch 1406 | loss_cls: 0.0592 | loss_box_reg: 0.1148 | loss_mask: 0.1013 | loss_rpn_cls: 0.0299 | loss_rpn_loc: 0.0990 | Total Loss: 0.4043\n",
      "Epoch 1407 | loss_cls: 0.0608 | loss_box_reg: 0.2057 | loss_mask: 0.0595 | loss_rpn_cls: 0.0099 | loss_rpn_loc: 0.0538 | Total Loss: 0.3898\n",
      "Epoch 1408 | loss_cls: 0.0522 | loss_box_reg: 0.1512 | loss_mask: 0.0768 | loss_rpn_cls: 0.0213 | loss_rpn_loc: 0.1304 | Total Loss: 0.4320\n",
      "Epoch 1409 | loss_cls: 0.0996 | loss_box_reg: 0.3149 | loss_mask: 0.1142 | loss_rpn_cls: 0.0059 | loss_rpn_loc: 0.1893 | Total Loss: 0.7239\n",
      "Epoch 1410 | loss_cls: 0.0361 | loss_box_reg: 0.0613 | loss_mask: 0.0643 | loss_rpn_cls: 0.0052 | loss_rpn_loc: 0.1192 | Total Loss: 0.2861\n",
      "Epoch 1411 | loss_cls: 0.0354 | loss_box_reg: 0.0965 | loss_mask: 0.0490 | loss_rpn_cls: 0.0032 | loss_rpn_loc: 0.0943 | Total Loss: 0.2784\n",
      "Epoch 1412 | loss_cls: 0.1204 | loss_box_reg: 0.1396 | loss_mask: 0.1288 | loss_rpn_cls: 0.0030 | loss_rpn_loc: 0.0259 | Total Loss: 0.4177\n",
      "Epoch 1413 | loss_cls: 0.1456 | loss_box_reg: 0.2359 | loss_mask: 0.0916 | loss_rpn_cls: 0.0182 | loss_rpn_loc: 0.0476 | Total Loss: 0.5389\n",
      "Epoch 1414 | loss_cls: 0.0987 | loss_box_reg: 0.2186 | loss_mask: 0.0744 | loss_rpn_cls: 0.0137 | loss_rpn_loc: 0.0520 | Total Loss: 0.4574\n",
      "Epoch 1415 | loss_cls: 0.1625 | loss_box_reg: 0.3392 | loss_mask: 0.1128 | loss_rpn_cls: 0.0170 | loss_rpn_loc: 0.1167 | Total Loss: 0.7482\n",
      "Epoch 1416 | loss_cls: 0.0360 | loss_box_reg: 0.1663 | loss_mask: 0.2227 | loss_rpn_cls: 0.0059 | loss_rpn_loc: 0.0747 | Total Loss: 0.5056\n",
      "Epoch 1417 | loss_cls: 0.0846 | loss_box_reg: 0.1389 | loss_mask: 0.1092 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.0372 | Total Loss: 0.3709\n",
      "Epoch 1418 | loss_cls: 0.1274 | loss_box_reg: 0.3558 | loss_mask: 0.1485 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.0284 | Total Loss: 0.6634\n",
      "Epoch 1419 | loss_cls: 0.0301 | loss_box_reg: 0.0947 | loss_mask: 0.0635 | loss_rpn_cls: 0.0024 | loss_rpn_loc: 0.0022 | Total Loss: 0.1928\n",
      "\u001b[32m[07/29 18:29:03 d2.utils.events]: \u001b[0m eta: 0:10:06  iter: 1419      time: 0.3310  last_time: 0.1803   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1420 | loss_cls: 0.0385 | loss_box_reg: 0.1105 | loss_mask: 0.0618 | loss_rpn_cls: 0.0029 | loss_rpn_loc: 0.0118 | Total Loss: 0.2254\n",
      "Epoch 1421 | loss_cls: 0.0465 | loss_box_reg: 0.0592 | loss_mask: 0.0794 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.2088 | Total Loss: 0.3966\n",
      "Epoch 1422 | loss_cls: 0.0506 | loss_box_reg: 0.1346 | loss_mask: 0.1212 | loss_rpn_cls: 0.0102 | loss_rpn_loc: 0.0058 | Total Loss: 0.3223\n",
      "Epoch 1423 | loss_cls: 0.0491 | loss_box_reg: 0.1144 | loss_mask: 0.0628 | loss_rpn_cls: 0.0291 | loss_rpn_loc: 0.0726 | Total Loss: 0.3280\n",
      "Epoch 1424 | loss_cls: 0.0404 | loss_box_reg: 0.1397 | loss_mask: 0.0565 | loss_rpn_cls: 0.0047 | loss_rpn_loc: 0.0534 | Total Loss: 0.2947\n",
      "Epoch 1425 | loss_cls: 0.1328 | loss_box_reg: 0.1739 | loss_mask: 0.0801 | loss_rpn_cls: 0.0188 | loss_rpn_loc: 0.1420 | Total Loss: 0.5476\n",
      "Epoch 1426 | loss_cls: 0.0365 | loss_box_reg: 0.1269 | loss_mask: 0.0642 | loss_rpn_cls: 0.0090 | loss_rpn_loc: 0.0343 | Total Loss: 0.2709\n",
      "Epoch 1427 | loss_cls: 0.1533 | loss_box_reg: 0.2927 | loss_mask: 0.0873 | loss_rpn_cls: 0.0179 | loss_rpn_loc: 0.2532 | Total Loss: 0.8044\n",
      "Epoch 1428 | loss_cls: 0.1149 | loss_box_reg: 0.2026 | loss_mask: 0.0753 | loss_rpn_cls: 0.0322 | loss_rpn_loc: 0.4063 | Total Loss: 0.8313\n",
      "Epoch 1429 | loss_cls: 0.0520 | loss_box_reg: 0.0594 | loss_mask: 0.2659 | loss_rpn_cls: 0.0021 | loss_rpn_loc: 0.0177 | Total Loss: 0.3971\n",
      "Epoch 1430 | loss_cls: 0.0811 | loss_box_reg: 0.1810 | loss_mask: 0.1033 | loss_rpn_cls: 0.0179 | loss_rpn_loc: 0.2005 | Total Loss: 0.5838\n",
      "Epoch 1431 | loss_cls: 0.1586 | loss_box_reg: 0.2562 | loss_mask: 0.1984 | loss_rpn_cls: 0.0253 | loss_rpn_loc: 0.0781 | Total Loss: 0.7166\n",
      "Epoch 1432 | loss_cls: 0.0653 | loss_box_reg: 0.1461 | loss_mask: 0.0826 | loss_rpn_cls: 0.0016 | loss_rpn_loc: 0.0081 | Total Loss: 0.3037\n",
      "Epoch 1433 | loss_cls: 0.0976 | loss_box_reg: 0.1492 | loss_mask: 0.0671 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.0333 | Total Loss: 0.3524\n",
      "Epoch 1434 | loss_cls: 0.0991 | loss_box_reg: 0.1691 | loss_mask: 0.0722 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.0041 | Total Loss: 0.3457\n",
      "Epoch 1435 | loss_cls: 0.0885 | loss_box_reg: 0.0855 | loss_mask: 0.2543 | loss_rpn_cls: 0.0275 | loss_rpn_loc: 0.1008 | Total Loss: 0.5565\n",
      "Epoch 1436 | loss_cls: 0.1313 | loss_box_reg: 0.2384 | loss_mask: 0.0890 | loss_rpn_cls: 0.0104 | loss_rpn_loc: 0.0751 | Total Loss: 0.5442\n",
      "Epoch 1437 | loss_cls: 0.0543 | loss_box_reg: 0.2901 | loss_mask: 0.1169 | loss_rpn_cls: 0.0018 | loss_rpn_loc: 0.0073 | Total Loss: 0.4705\n",
      "Epoch 1438 | loss_cls: 0.0532 | loss_box_reg: 0.1861 | loss_mask: 0.1071 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.0122 | Total Loss: 0.3609\n",
      "Epoch 1439 | loss_cls: 0.0789 | loss_box_reg: 0.2205 | loss_mask: 0.0809 | loss_rpn_cls: 0.0218 | loss_rpn_loc: 0.1212 | Total Loss: 0.5234\n",
      "\u001b[32m[07/29 18:29:10 d2.utils.events]: \u001b[0m eta: 0:09:58  iter: 1439      time: 0.3309  last_time: 0.4081   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1440 | loss_cls: 0.0538 | loss_box_reg: 0.1348 | loss_mask: 0.2555 | loss_rpn_cls: 0.0043 | loss_rpn_loc: 0.1805 | Total Loss: 0.6290\n",
      "Epoch 1441 | loss_cls: 0.0276 | loss_box_reg: 0.1531 | loss_mask: 0.2646 | loss_rpn_cls: 0.0233 | loss_rpn_loc: 0.0903 | Total Loss: 0.5589\n",
      "Epoch 1442 | loss_cls: 0.0802 | loss_box_reg: 0.2208 | loss_mask: 0.3411 | loss_rpn_cls: 0.0146 | loss_rpn_loc: 0.0046 | Total Loss: 0.6613\n",
      "Epoch 1443 | loss_cls: 0.0467 | loss_box_reg: 0.1169 | loss_mask: 0.0926 | loss_rpn_cls: 0.0045 | loss_rpn_loc: 0.0406 | Total Loss: 0.3013\n",
      "Epoch 1444 | loss_cls: 0.0524 | loss_box_reg: 0.0998 | loss_mask: 0.1196 | loss_rpn_cls: 0.0069 | loss_rpn_loc: 0.1376 | Total Loss: 0.4162\n",
      "Epoch 1445 | loss_cls: 0.0804 | loss_box_reg: 0.1287 | loss_mask: 0.1706 | loss_rpn_cls: 0.0075 | loss_rpn_loc: 0.1559 | Total Loss: 0.5431\n",
      "Epoch 1446 | loss_cls: 0.0983 | loss_box_reg: 0.1693 | loss_mask: 0.0968 | loss_rpn_cls: 0.0129 | loss_rpn_loc: 0.0127 | Total Loss: 0.3901\n",
      "Epoch 1447 | loss_cls: 0.1229 | loss_box_reg: 0.2707 | loss_mask: 0.1411 | loss_rpn_cls: 0.0039 | loss_rpn_loc: 0.0715 | Total Loss: 0.6100\n",
      "Epoch 1448 | loss_cls: 0.0925 | loss_box_reg: 0.2475 | loss_mask: 0.0876 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.1636 | Total Loss: 0.5939\n",
      "Epoch 1449 | loss_cls: 0.0725 | loss_box_reg: 0.1924 | loss_mask: 0.1171 | loss_rpn_cls: 0.0046 | loss_rpn_loc: 0.0021 | Total Loss: 0.3887\n",
      "Epoch 1450 | loss_cls: 0.0403 | loss_box_reg: 0.1105 | loss_mask: 0.2108 | loss_rpn_cls: 0.0008 | loss_rpn_loc: 0.0809 | Total Loss: 0.4434\n",
      "Epoch 1451 | loss_cls: 0.1072 | loss_box_reg: 0.2633 | loss_mask: 0.0764 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.0894 | Total Loss: 0.5413\n",
      "Epoch 1452 | loss_cls: 0.0585 | loss_box_reg: 0.1925 | loss_mask: 0.0502 | loss_rpn_cls: 0.0128 | loss_rpn_loc: 0.2595 | Total Loss: 0.5736\n",
      "Epoch 1453 | loss_cls: 0.0760 | loss_box_reg: 0.1343 | loss_mask: 0.0431 | loss_rpn_cls: 0.0128 | loss_rpn_loc: 0.1149 | Total Loss: 0.3811\n",
      "Epoch 1454 | loss_cls: 0.0527 | loss_box_reg: 0.0821 | loss_mask: 0.1194 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.1080 | Total Loss: 0.3632\n",
      "Epoch 1455 | loss_cls: 0.0796 | loss_box_reg: 0.2023 | loss_mask: 0.2934 | loss_rpn_cls: 0.0111 | loss_rpn_loc: 0.0199 | Total Loss: 0.6064\n",
      "Epoch 1456 | loss_cls: 0.0623 | loss_box_reg: 0.1421 | loss_mask: 0.1793 | loss_rpn_cls: 0.0035 | loss_rpn_loc: 0.0983 | Total Loss: 0.4855\n",
      "Epoch 1457 | loss_cls: 0.0792 | loss_box_reg: 0.2072 | loss_mask: 0.1217 | loss_rpn_cls: 0.0131 | loss_rpn_loc: 0.0192 | Total Loss: 0.4403\n",
      "Epoch 1458 | loss_cls: 0.0810 | loss_box_reg: 0.1671 | loss_mask: 0.0727 | loss_rpn_cls: 0.0101 | loss_rpn_loc: 0.1989 | Total Loss: 0.5299\n",
      "Epoch 1459 | loss_cls: 0.0526 | loss_box_reg: 0.2109 | loss_mask: 0.1159 | loss_rpn_cls: 0.0056 | loss_rpn_loc: 0.0367 | Total Loss: 0.4217\n",
      "\u001b[32m[07/29 18:29:17 d2.utils.events]: \u001b[0m eta: 0:09:50  iter: 1459      time: 0.3312  last_time: 0.4189   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1460 | loss_cls: 0.0422 | loss_box_reg: 0.0955 | loss_mask: 0.0548 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.0029 | Total Loss: 0.1989\n",
      "Epoch 1461 | loss_cls: 0.0496 | loss_box_reg: 0.1401 | loss_mask: 0.1415 | loss_rpn_cls: 0.0119 | loss_rpn_loc: 0.1023 | Total Loss: 0.4455\n",
      "Epoch 1462 | loss_cls: 0.1091 | loss_box_reg: 0.1812 | loss_mask: 0.1012 | loss_rpn_cls: 0.0048 | loss_rpn_loc: 0.0224 | Total Loss: 0.4187\n",
      "Epoch 1463 | loss_cls: 0.0261 | loss_box_reg: 0.0898 | loss_mask: 0.1454 | loss_rpn_cls: 0.0039 | loss_rpn_loc: 0.0096 | Total Loss: 0.2749\n",
      "Epoch 1464 | loss_cls: 0.1342 | loss_box_reg: 0.1936 | loss_mask: 0.0731 | loss_rpn_cls: 0.0049 | loss_rpn_loc: 0.0466 | Total Loss: 0.4524\n",
      "Epoch 1465 | loss_cls: 0.1055 | loss_box_reg: 0.1560 | loss_mask: 0.0599 | loss_rpn_cls: 0.0009 | loss_rpn_loc: 0.0964 | Total Loss: 0.4187\n",
      "Epoch 1466 | loss_cls: 0.0643 | loss_box_reg: 0.1660 | loss_mask: 0.1400 | loss_rpn_cls: 0.0183 | loss_rpn_loc: 0.2176 | Total Loss: 0.6062\n",
      "Epoch 1467 | loss_cls: 0.0246 | loss_box_reg: 0.0751 | loss_mask: 0.0762 | loss_rpn_cls: 0.0097 | loss_rpn_loc: 0.0831 | Total Loss: 0.2687\n",
      "Epoch 1468 | loss_cls: 0.0410 | loss_box_reg: 0.0820 | loss_mask: 0.4390 | loss_rpn_cls: 0.0167 | loss_rpn_loc: 0.1102 | Total Loss: 0.6888\n",
      "Epoch 1469 | loss_cls: 0.0397 | loss_box_reg: 0.0875 | loss_mask: 0.0473 | loss_rpn_cls: 0.0042 | loss_rpn_loc: 0.0840 | Total Loss: 0.2626\n",
      "Epoch 1470 | loss_cls: 0.0650 | loss_box_reg: 0.2194 | loss_mask: 0.0773 | loss_rpn_cls: 0.0078 | loss_rpn_loc: 0.1425 | Total Loss: 0.5120\n",
      "Epoch 1471 | loss_cls: 0.0553 | loss_box_reg: 0.2604 | loss_mask: 0.1009 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0356 | Total Loss: 0.4526\n",
      "Epoch 1472 | loss_cls: 0.0374 | loss_box_reg: 0.1144 | loss_mask: 0.0442 | loss_rpn_cls: 0.0067 | loss_rpn_loc: 0.0648 | Total Loss: 0.2674\n",
      "Epoch 1473 | loss_cls: 0.1074 | loss_box_reg: 0.2341 | loss_mask: 0.0600 | loss_rpn_cls: 0.0069 | loss_rpn_loc: 0.3200 | Total Loss: 0.7284\n",
      "Epoch 1474 | loss_cls: 0.0941 | loss_box_reg: 0.1908 | loss_mask: 0.0691 | loss_rpn_cls: 0.0099 | loss_rpn_loc: 0.1476 | Total Loss: 0.5116\n",
      "Epoch 1475 | loss_cls: 0.0851 | loss_box_reg: 0.2952 | loss_mask: 0.1145 | loss_rpn_cls: 0.0069 | loss_rpn_loc: 0.0308 | Total Loss: 0.5325\n",
      "Epoch 1476 | loss_cls: 0.0596 | loss_box_reg: 0.0902 | loss_mask: 0.0552 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.0802 | Total Loss: 0.2865\n",
      "Epoch 1477 | loss_cls: 0.1643 | loss_box_reg: 0.3110 | loss_mask: 0.1026 | loss_rpn_cls: 0.0222 | loss_rpn_loc: 0.0612 | Total Loss: 0.6612\n",
      "Epoch 1478 | loss_cls: 0.0607 | loss_box_reg: 0.1121 | loss_mask: 0.1040 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0270 | Total Loss: 0.3044\n",
      "Epoch 1479 | loss_cls: 0.0775 | loss_box_reg: 0.1181 | loss_mask: 0.1282 | loss_rpn_cls: 0.0150 | loss_rpn_loc: 0.1270 | Total Loss: 0.4659\n",
      "\u001b[32m[07/29 18:29:24 d2.utils.events]: \u001b[0m eta: 0:09:43  iter: 1479      time: 0.3317  last_time: 0.3878   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1480 | loss_cls: 0.1090 | loss_box_reg: 0.2000 | loss_mask: 0.0506 | loss_rpn_cls: 0.0035 | loss_rpn_loc: 0.1713 | Total Loss: 0.5345\n",
      "Epoch 1481 | loss_cls: 0.0570 | loss_box_reg: 0.1603 | loss_mask: 0.1302 | loss_rpn_cls: 0.0057 | loss_rpn_loc: 0.0464 | Total Loss: 0.3997\n",
      "Epoch 1482 | loss_cls: 0.0325 | loss_box_reg: 0.1120 | loss_mask: 0.0567 | loss_rpn_cls: 0.0037 | loss_rpn_loc: 0.0346 | Total Loss: 0.2395\n",
      "Epoch 1483 | loss_cls: 0.0674 | loss_box_reg: 0.2005 | loss_mask: 0.0483 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.0730 | Total Loss: 0.3907\n",
      "Epoch 1484 | loss_cls: 0.1358 | loss_box_reg: 0.3618 | loss_mask: 0.0926 | loss_rpn_cls: 0.0125 | loss_rpn_loc: 0.1191 | Total Loss: 0.7217\n",
      "Epoch 1485 | loss_cls: 0.1081 | loss_box_reg: 0.2057 | loss_mask: 0.0739 | loss_rpn_cls: 0.0055 | loss_rpn_loc: 0.0220 | Total Loss: 0.4153\n",
      "Epoch 1486 | loss_cls: 0.0428 | loss_box_reg: 0.0272 | loss_mask: 0.1719 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.1160 | Total Loss: 0.3593\n",
      "Epoch 1487 | loss_cls: 0.0909 | loss_box_reg: 0.2787 | loss_mask: 0.2028 | loss_rpn_cls: 0.0170 | loss_rpn_loc: 0.0743 | Total Loss: 0.6638\n",
      "Epoch 1488 | loss_cls: 0.1463 | loss_box_reg: 0.1558 | loss_mask: 0.0835 | loss_rpn_cls: 0.0054 | loss_rpn_loc: 0.0224 | Total Loss: 0.4135\n",
      "Epoch 1489 | loss_cls: 0.0595 | loss_box_reg: 0.2051 | loss_mask: 0.0767 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.0136 | Total Loss: 0.3576\n",
      "Epoch 1490 | loss_cls: 0.0664 | loss_box_reg: 0.0946 | loss_mask: 0.0546 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.0098 | Total Loss: 0.2278\n",
      "Epoch 1491 | loss_cls: 0.0603 | loss_box_reg: 0.1966 | loss_mask: 0.2189 | loss_rpn_cls: 0.0173 | loss_rpn_loc: 0.1852 | Total Loss: 0.6783\n",
      "Epoch 1492 | loss_cls: 0.0366 | loss_box_reg: 0.1257 | loss_mask: 0.0794 | loss_rpn_cls: 0.0048 | loss_rpn_loc: 0.0343 | Total Loss: 0.2808\n",
      "Epoch 1493 | loss_cls: 0.0261 | loss_box_reg: 0.0513 | loss_mask: 0.1409 | loss_rpn_cls: 0.0028 | loss_rpn_loc: 0.1229 | Total Loss: 0.3440\n",
      "Epoch 1494 | loss_cls: 0.1962 | loss_box_reg: 0.4162 | loss_mask: 0.2221 | loss_rpn_cls: 0.0048 | loss_rpn_loc: 0.0114 | Total Loss: 0.8506\n",
      "Epoch 1495 | loss_cls: 0.0563 | loss_box_reg: 0.1980 | loss_mask: 0.1072 | loss_rpn_cls: 0.0201 | loss_rpn_loc: 0.0268 | Total Loss: 0.4083\n",
      "Epoch 1496 | loss_cls: 0.0716 | loss_box_reg: 0.1111 | loss_mask: 0.0866 | loss_rpn_cls: 0.0228 | loss_rpn_loc: 0.1044 | Total Loss: 0.3965\n",
      "Epoch 1497 | loss_cls: 0.0436 | loss_box_reg: 0.1167 | loss_mask: 0.0503 | loss_rpn_cls: 0.0122 | loss_rpn_loc: 0.0056 | Total Loss: 0.2284\n",
      "Epoch 1498 | loss_cls: 0.0836 | loss_box_reg: 0.1124 | loss_mask: 0.0744 | loss_rpn_cls: 0.0045 | loss_rpn_loc: 0.0215 | Total Loss: 0.2964\n",
      "Epoch 1499 | loss_cls: 0.0493 | loss_box_reg: 0.1029 | loss_mask: 0.1483 | loss_rpn_cls: 0.0056 | loss_rpn_loc: 0.0297 | Total Loss: 0.3358\n",
      "\u001b[32m[07/29 18:29:31 d2.utils.events]: \u001b[0m eta: 0:09:36  iter: 1499      time: 0.3320  last_time: 0.2787   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1500 | loss_cls: 0.0549 | loss_box_reg: 0.1706 | loss_mask: 0.0558 | loss_rpn_cls: 0.0042 | loss_rpn_loc: 0.0045 | Total Loss: 0.2901\n",
      "Epoch 1501 | loss_cls: 0.0544 | loss_box_reg: 0.0846 | loss_mask: 0.0790 | loss_rpn_cls: 0.0055 | loss_rpn_loc: 0.0099 | Total Loss: 0.2334\n",
      "Epoch 1502 | loss_cls: 0.0527 | loss_box_reg: 0.1861 | loss_mask: 0.0435 | loss_rpn_cls: 0.0078 | loss_rpn_loc: 0.0629 | Total Loss: 0.3531\n",
      "Epoch 1503 | loss_cls: 0.1135 | loss_box_reg: 0.2291 | loss_mask: 0.2456 | loss_rpn_cls: 0.0083 | loss_rpn_loc: 0.0835 | Total Loss: 0.6800\n",
      "Epoch 1504 | loss_cls: 0.0845 | loss_box_reg: 0.2715 | loss_mask: 0.2345 | loss_rpn_cls: 0.0063 | loss_rpn_loc: 0.0327 | Total Loss: 0.6295\n",
      "Epoch 1505 | loss_cls: 0.0306 | loss_box_reg: 0.0939 | loss_mask: 0.0720 | loss_rpn_cls: 0.0038 | loss_rpn_loc: 0.0155 | Total Loss: 0.2159\n",
      "Epoch 1506 | loss_cls: 0.0940 | loss_box_reg: 0.2749 | loss_mask: 0.0574 | loss_rpn_cls: 0.0106 | loss_rpn_loc: 0.0894 | Total Loss: 0.5263\n",
      "Epoch 1507 | loss_cls: 0.0672 | loss_box_reg: 0.2593 | loss_mask: 0.1031 | loss_rpn_cls: 0.0035 | loss_rpn_loc: 0.0164 | Total Loss: 0.4494\n",
      "Epoch 1508 | loss_cls: 0.1441 | loss_box_reg: 0.2948 | loss_mask: 0.1069 | loss_rpn_cls: 0.0065 | loss_rpn_loc: 0.1166 | Total Loss: 0.6690\n",
      "Epoch 1509 | loss_cls: 0.0656 | loss_box_reg: 0.1647 | loss_mask: 0.1363 | loss_rpn_cls: 0.0084 | loss_rpn_loc: 0.1047 | Total Loss: 0.4796\n",
      "Epoch 1510 | loss_cls: 0.0754 | loss_box_reg: 0.1229 | loss_mask: 0.0864 | loss_rpn_cls: 0.0146 | loss_rpn_loc: 0.1636 | Total Loss: 0.4630\n",
      "Epoch 1511 | loss_cls: 0.0391 | loss_box_reg: 0.1158 | loss_mask: 0.0879 | loss_rpn_cls: 0.0032 | loss_rpn_loc: 0.1346 | Total Loss: 0.3806\n",
      "Epoch 1512 | loss_cls: 0.0544 | loss_box_reg: 0.1504 | loss_mask: 0.1206 | loss_rpn_cls: 0.0061 | loss_rpn_loc: 0.1536 | Total Loss: 0.4850\n",
      "Epoch 1513 | loss_cls: 0.0495 | loss_box_reg: 0.1310 | loss_mask: 0.0946 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0048 | Total Loss: 0.2802\n",
      "Epoch 1514 | loss_cls: 0.0766 | loss_box_reg: 0.1114 | loss_mask: 0.1785 | loss_rpn_cls: 0.0057 | loss_rpn_loc: 0.0107 | Total Loss: 0.3828\n",
      "Epoch 1515 | loss_cls: 0.0397 | loss_box_reg: 0.1230 | loss_mask: 0.0890 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.0038 | Total Loss: 0.2570\n",
      "Epoch 1516 | loss_cls: 0.0582 | loss_box_reg: 0.1092 | loss_mask: 0.0581 | loss_rpn_cls: 0.0104 | loss_rpn_loc: 0.0047 | Total Loss: 0.2405\n",
      "Epoch 1517 | loss_cls: 0.0224 | loss_box_reg: 0.1068 | loss_mask: 0.2385 | loss_rpn_cls: 0.0116 | loss_rpn_loc: 0.0296 | Total Loss: 0.4090\n",
      "Epoch 1518 | loss_cls: 0.0325 | loss_box_reg: 0.2048 | loss_mask: 0.2014 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.1220 | Total Loss: 0.5622\n",
      "Epoch 1519 | loss_cls: 0.0544 | loss_box_reg: 0.1840 | loss_mask: 0.1496 | loss_rpn_cls: 0.0042 | loss_rpn_loc: 0.0236 | Total Loss: 0.4158\n",
      "\u001b[32m[07/29 18:29:37 d2.utils.events]: \u001b[0m eta: 0:09:28  iter: 1519      time: 0.3318  last_time: 0.2565   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1520 | loss_cls: 0.0746 | loss_box_reg: 0.1224 | loss_mask: 0.1142 | loss_rpn_cls: 0.0016 | loss_rpn_loc: 0.0465 | Total Loss: 0.3593\n",
      "Epoch 1521 | loss_cls: 0.0777 | loss_box_reg: 0.1954 | loss_mask: 0.1141 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.0540 | Total Loss: 0.4463\n",
      "Epoch 1522 | loss_cls: 0.0842 | loss_box_reg: 0.2876 | loss_mask: 0.1059 | loss_rpn_cls: 0.0055 | loss_rpn_loc: 0.0082 | Total Loss: 0.4915\n",
      "Epoch 1523 | loss_cls: 0.1050 | loss_box_reg: 0.1563 | loss_mask: 0.0755 | loss_rpn_cls: 0.0136 | loss_rpn_loc: 0.0124 | Total Loss: 0.3627\n",
      "Epoch 1524 | loss_cls: 0.1214 | loss_box_reg: 0.3539 | loss_mask: 0.1274 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.0032 | Total Loss: 0.6082\n",
      "Epoch 1525 | loss_cls: 0.0910 | loss_box_reg: 0.1722 | loss_mask: 0.0731 | loss_rpn_cls: 0.0009 | loss_rpn_loc: 0.0142 | Total Loss: 0.3514\n",
      "Epoch 1526 | loss_cls: 0.0649 | loss_box_reg: 0.1344 | loss_mask: 0.0633 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.0518 | Total Loss: 0.3154\n",
      "Epoch 1527 | loss_cls: 0.1290 | loss_box_reg: 0.2416 | loss_mask: 0.0462 | loss_rpn_cls: 0.0105 | loss_rpn_loc: 0.1141 | Total Loss: 0.5414\n",
      "Epoch 1528 | loss_cls: 0.0319 | loss_box_reg: 0.1471 | loss_mask: 0.0708 | loss_rpn_cls: 0.0125 | loss_rpn_loc: 0.0845 | Total Loss: 0.3469\n",
      "Epoch 1529 | loss_cls: 0.1449 | loss_box_reg: 0.3365 | loss_mask: 0.1660 | loss_rpn_cls: 0.0042 | loss_rpn_loc: 0.0458 | Total Loss: 0.6974\n",
      "Epoch 1530 | loss_cls: 0.0540 | loss_box_reg: 0.1366 | loss_mask: 0.0862 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.0244 | Total Loss: 0.3022\n",
      "Epoch 1531 | loss_cls: 0.0299 | loss_box_reg: 0.0778 | loss_mask: 0.5713 | loss_rpn_cls: 0.0064 | loss_rpn_loc: 0.1072 | Total Loss: 0.7926\n",
      "Epoch 1532 | loss_cls: 0.0983 | loss_box_reg: 0.1488 | loss_mask: 0.0525 | loss_rpn_cls: 0.0140 | loss_rpn_loc: 0.0720 | Total Loss: 0.3855\n",
      "Epoch 1533 | loss_cls: 0.0861 | loss_box_reg: 0.2410 | loss_mask: 0.0727 | loss_rpn_cls: 0.0664 | loss_rpn_loc: 0.0858 | Total Loss: 0.5520\n",
      "Epoch 1534 | loss_cls: 0.0555 | loss_box_reg: 0.1443 | loss_mask: 0.0795 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.0160 | Total Loss: 0.2964\n",
      "Epoch 1535 | loss_cls: 0.0374 | loss_box_reg: 0.0994 | loss_mask: 0.1354 | loss_rpn_cls: 0.0043 | loss_rpn_loc: 0.0196 | Total Loss: 0.2961\n",
      "Epoch 1536 | loss_cls: 0.0627 | loss_box_reg: 0.0827 | loss_mask: 0.0815 | loss_rpn_cls: 0.0059 | loss_rpn_loc: 0.0194 | Total Loss: 0.2522\n",
      "Epoch 1537 | loss_cls: 0.0500 | loss_box_reg: 0.1573 | loss_mask: 0.1408 | loss_rpn_cls: 0.0035 | loss_rpn_loc: 0.0051 | Total Loss: 0.3566\n",
      "Epoch 1538 | loss_cls: 0.0565 | loss_box_reg: 0.1736 | loss_mask: 0.1209 | loss_rpn_cls: 0.0058 | loss_rpn_loc: 0.0859 | Total Loss: 0.4426\n",
      "Epoch 1539 | loss_cls: 0.0996 | loss_box_reg: 0.2024 | loss_mask: 0.0813 | loss_rpn_cls: 0.0073 | loss_rpn_loc: 0.1821 | Total Loss: 0.5727\n",
      "\u001b[32m[07/29 18:29:44 d2.utils.events]: \u001b[0m eta: 0:09:20  iter: 1539      time: 0.3317  last_time: 0.4079   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1540 | loss_cls: 0.0348 | loss_box_reg: 0.1045 | loss_mask: 0.1927 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.0723 | Total Loss: 0.4076\n",
      "Epoch 1541 | loss_cls: 0.0903 | loss_box_reg: 0.2109 | loss_mask: 0.1054 | loss_rpn_cls: 0.0053 | loss_rpn_loc: 0.1628 | Total Loss: 0.5746\n",
      "Epoch 1542 | loss_cls: 0.0751 | loss_box_reg: 0.1716 | loss_mask: 0.0589 | loss_rpn_cls: 0.0090 | loss_rpn_loc: 0.0885 | Total Loss: 0.4030\n",
      "Epoch 1543 | loss_cls: 0.0417 | loss_box_reg: 0.2791 | loss_mask: 0.1028 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0171 | Total Loss: 0.4418\n",
      "Epoch 1544 | loss_cls: 0.0325 | loss_box_reg: 0.0684 | loss_mask: 0.0594 | loss_rpn_cls: 0.0144 | loss_rpn_loc: 0.0103 | Total Loss: 0.1849\n",
      "Epoch 1545 | loss_cls: 0.0552 | loss_box_reg: 0.1044 | loss_mask: 0.0942 | loss_rpn_cls: 0.0022 | loss_rpn_loc: 0.1642 | Total Loss: 0.4202\n",
      "Epoch 1546 | loss_cls: 0.0707 | loss_box_reg: 0.1196 | loss_mask: 0.1394 | loss_rpn_cls: 0.0068 | loss_rpn_loc: 0.1236 | Total Loss: 0.4601\n",
      "Epoch 1547 | loss_cls: 0.1006 | loss_box_reg: 0.3347 | loss_mask: 0.0676 | loss_rpn_cls: 0.0204 | loss_rpn_loc: 0.4082 | Total Loss: 0.9315\n",
      "Epoch 1548 | loss_cls: 0.1179 | loss_box_reg: 0.1892 | loss_mask: 0.0876 | loss_rpn_cls: 0.0102 | loss_rpn_loc: 0.0739 | Total Loss: 0.4788\n",
      "Epoch 1549 | loss_cls: 0.0403 | loss_box_reg: 0.1155 | loss_mask: 0.0608 | loss_rpn_cls: 0.0008 | loss_rpn_loc: 0.0047 | Total Loss: 0.2221\n",
      "Epoch 1550 | loss_cls: 0.0840 | loss_box_reg: 0.1110 | loss_mask: 0.0688 | loss_rpn_cls: 0.0082 | loss_rpn_loc: 0.0347 | Total Loss: 0.3067\n",
      "Epoch 1551 | loss_cls: 0.0857 | loss_box_reg: 0.1751 | loss_mask: 0.0544 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.0411 | Total Loss: 0.3583\n",
      "Epoch 1552 | loss_cls: 0.0401 | loss_box_reg: 0.0687 | loss_mask: 0.0774 | loss_rpn_cls: 0.0002 | loss_rpn_loc: 0.0075 | Total Loss: 0.1939\n",
      "Epoch 1553 | loss_cls: 0.0671 | loss_box_reg: 0.2515 | loss_mask: 0.1042 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.0863 | Total Loss: 0.5113\n",
      "Epoch 1554 | loss_cls: 0.0403 | loss_box_reg: 0.0681 | loss_mask: 0.1719 | loss_rpn_cls: 0.0074 | loss_rpn_loc: 0.1460 | Total Loss: 0.4336\n",
      "Epoch 1555 | loss_cls: 0.0747 | loss_box_reg: 0.3217 | loss_mask: 0.1909 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0687 | Total Loss: 0.6572\n",
      "Epoch 1556 | loss_cls: 0.1032 | loss_box_reg: 0.3959 | loss_mask: 0.0738 | loss_rpn_cls: 0.0068 | loss_rpn_loc: 0.0488 | Total Loss: 0.6286\n",
      "Epoch 1557 | loss_cls: 0.0264 | loss_box_reg: 0.1000 | loss_mask: 0.1057 | loss_rpn_cls: 0.0047 | loss_rpn_loc: 0.1103 | Total Loss: 0.3471\n",
      "Epoch 1558 | loss_cls: 0.0401 | loss_box_reg: 0.0730 | loss_mask: 0.0866 | loss_rpn_cls: 0.0009 | loss_rpn_loc: 0.1157 | Total Loss: 0.3163\n",
      "Epoch 1559 | loss_cls: 0.0554 | loss_box_reg: 0.1328 | loss_mask: 0.1278 | loss_rpn_cls: 0.0079 | loss_rpn_loc: 0.0227 | Total Loss: 0.3466\n",
      "\u001b[32m[07/29 18:29:51 d2.utils.events]: \u001b[0m eta: 0:09:13  iter: 1559      time: 0.3320  last_time: 0.4042   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1560 | loss_cls: 0.0475 | loss_box_reg: 0.0621 | loss_mask: 0.0933 | loss_rpn_cls: 0.0078 | loss_rpn_loc: 0.1032 | Total Loss: 0.3140\n",
      "Epoch 1561 | loss_cls: 0.0522 | loss_box_reg: 0.1419 | loss_mask: 0.0869 | loss_rpn_cls: 0.0089 | loss_rpn_loc: 0.0198 | Total Loss: 0.3098\n",
      "Epoch 1562 | loss_cls: 0.0455 | loss_box_reg: 0.1491 | loss_mask: 0.0721 | loss_rpn_cls: 0.0117 | loss_rpn_loc: 0.1068 | Total Loss: 0.3852\n",
      "Epoch 1563 | loss_cls: 0.0518 | loss_box_reg: 0.1113 | loss_mask: 0.0672 | loss_rpn_cls: 0.0087 | loss_rpn_loc: 0.0813 | Total Loss: 0.3202\n",
      "Epoch 1564 | loss_cls: 0.0269 | loss_box_reg: 0.0999 | loss_mask: 0.1092 | loss_rpn_cls: 0.0022 | loss_rpn_loc: 0.1096 | Total Loss: 0.3478\n",
      "Epoch 1565 | loss_cls: 0.0786 | loss_box_reg: 0.1962 | loss_mask: 0.0561 | loss_rpn_cls: 0.0332 | loss_rpn_loc: 0.1915 | Total Loss: 0.5555\n",
      "Epoch 1566 | loss_cls: 0.1038 | loss_box_reg: 0.3169 | loss_mask: 0.0473 | loss_rpn_cls: 0.0044 | loss_rpn_loc: 0.0976 | Total Loss: 0.5700\n",
      "Epoch 1567 | loss_cls: 0.0865 | loss_box_reg: 0.3069 | loss_mask: 0.0832 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.0045 | Total Loss: 0.4837\n",
      "Epoch 1568 | loss_cls: 0.1639 | loss_box_reg: 0.2666 | loss_mask: 0.0721 | loss_rpn_cls: 0.0133 | loss_rpn_loc: 0.0161 | Total Loss: 0.5320\n",
      "Epoch 1569 | loss_cls: 0.0755 | loss_box_reg: 0.2375 | loss_mask: 0.1331 | loss_rpn_cls: 0.0003 | loss_rpn_loc: 0.0546 | Total Loss: 0.5011\n",
      "Epoch 1570 | loss_cls: 0.0519 | loss_box_reg: 0.1249 | loss_mask: 0.1157 | loss_rpn_cls: 0.0235 | loss_rpn_loc: 0.1283 | Total Loss: 0.4442\n",
      "Epoch 1571 | loss_cls: 0.0977 | loss_box_reg: 0.1898 | loss_mask: 0.0637 | loss_rpn_cls: 0.0398 | loss_rpn_loc: 0.1781 | Total Loss: 0.5690\n",
      "Epoch 1572 | loss_cls: 0.0184 | loss_box_reg: 0.1005 | loss_mask: 0.0946 | loss_rpn_cls: 0.0001 | loss_rpn_loc: 0.0049 | Total Loss: 0.2184\n",
      "Epoch 1573 | loss_cls: 0.0351 | loss_box_reg: 0.1274 | loss_mask: 0.2026 | loss_rpn_cls: 0.0086 | loss_rpn_loc: 0.1131 | Total Loss: 0.4867\n",
      "Epoch 1574 | loss_cls: 0.0476 | loss_box_reg: 0.2419 | loss_mask: 0.1061 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0366 | Total Loss: 0.4330\n",
      "Epoch 1575 | loss_cls: 0.0754 | loss_box_reg: 0.1558 | loss_mask: 0.1149 | loss_rpn_cls: 0.0241 | loss_rpn_loc: 0.0184 | Total Loss: 0.3887\n",
      "Epoch 1576 | loss_cls: 0.0807 | loss_box_reg: 0.2178 | loss_mask: 0.2669 | loss_rpn_cls: 0.0201 | loss_rpn_loc: 0.1223 | Total Loss: 0.7078\n",
      "Epoch 1577 | loss_cls: 0.1880 | loss_box_reg: 0.2156 | loss_mask: 0.0501 | loss_rpn_cls: 0.0145 | loss_rpn_loc: 0.3127 | Total Loss: 0.7809\n",
      "Epoch 1578 | loss_cls: 0.0597 | loss_box_reg: 0.1561 | loss_mask: 0.0709 | loss_rpn_cls: 0.0230 | loss_rpn_loc: 0.0034 | Total Loss: 0.3131\n",
      "Epoch 1579 | loss_cls: 0.0772 | loss_box_reg: 0.1740 | loss_mask: 0.0789 | loss_rpn_cls: 0.0125 | loss_rpn_loc: 0.1096 | Total Loss: 0.4523\n",
      "\u001b[32m[07/29 18:29:58 d2.utils.events]: \u001b[0m eta: 0:09:07  iter: 1579      time: 0.3320  last_time: 0.3923   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1580 | loss_cls: 0.1336 | loss_box_reg: 0.1938 | loss_mask: 0.0887 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.0458 | Total Loss: 0.4652\n",
      "Epoch 1581 | loss_cls: 0.0784 | loss_box_reg: 0.1919 | loss_mask: 0.0886 | loss_rpn_cls: 0.0117 | loss_rpn_loc: 0.0929 | Total Loss: 0.4636\n",
      "Epoch 1582 | loss_cls: 0.0739 | loss_box_reg: 0.1240 | loss_mask: 0.0914 | loss_rpn_cls: 0.0059 | loss_rpn_loc: 0.1971 | Total Loss: 0.4924\n",
      "Epoch 1583 | loss_cls: 0.0777 | loss_box_reg: 0.2858 | loss_mask: 0.1360 | loss_rpn_cls: 0.0066 | loss_rpn_loc: 0.0159 | Total Loss: 0.5220\n",
      "Epoch 1584 | loss_cls: 0.0331 | loss_box_reg: 0.0820 | loss_mask: 0.2130 | loss_rpn_cls: 0.0039 | loss_rpn_loc: 0.1419 | Total Loss: 0.4738\n",
      "Epoch 1585 | loss_cls: 0.0956 | loss_box_reg: 0.3760 | loss_mask: 0.0486 | loss_rpn_cls: 0.0101 | loss_rpn_loc: 0.0070 | Total Loss: 0.5372\n",
      "Epoch 1586 | loss_cls: 0.0961 | loss_box_reg: 0.0908 | loss_mask: 0.0689 | loss_rpn_cls: 0.0043 | loss_rpn_loc: 0.0118 | Total Loss: 0.2719\n",
      "Epoch 1587 | loss_cls: 0.1256 | loss_box_reg: 0.2718 | loss_mask: 0.0778 | loss_rpn_cls: 0.0028 | loss_rpn_loc: 0.1841 | Total Loss: 0.6621\n",
      "Epoch 1588 | loss_cls: 0.1061 | loss_box_reg: 0.3033 | loss_mask: 0.1571 | loss_rpn_cls: 0.0089 | loss_rpn_loc: 0.0179 | Total Loss: 0.5934\n",
      "Epoch 1589 | loss_cls: 0.0495 | loss_box_reg: 0.1892 | loss_mask: 0.0725 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.0166 | Total Loss: 0.3283\n",
      "Epoch 1590 | loss_cls: 0.0285 | loss_box_reg: 0.0860 | loss_mask: 0.1488 | loss_rpn_cls: 0.0043 | loss_rpn_loc: 0.1116 | Total Loss: 0.3793\n",
      "Epoch 1591 | loss_cls: 0.1182 | loss_box_reg: 0.1737 | loss_mask: 0.0851 | loss_rpn_cls: 0.0041 | loss_rpn_loc: 0.0391 | Total Loss: 0.4202\n",
      "Epoch 1592 | loss_cls: 0.0453 | loss_box_reg: 0.1468 | loss_mask: 0.0642 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.0080 | Total Loss: 0.2666\n",
      "Epoch 1593 | loss_cls: 0.0872 | loss_box_reg: 0.1435 | loss_mask: 0.1238 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0249 | Total Loss: 0.3801\n",
      "Epoch 1594 | loss_cls: 0.0476 | loss_box_reg: 0.1668 | loss_mask: 0.0658 | loss_rpn_cls: 0.0072 | loss_rpn_loc: 0.0706 | Total Loss: 0.3580\n",
      "Epoch 1595 | loss_cls: 0.1502 | loss_box_reg: 0.2283 | loss_mask: 0.0816 | loss_rpn_cls: 0.0031 | loss_rpn_loc: 0.1700 | Total Loss: 0.6332\n",
      "Epoch 1596 | loss_cls: 0.0320 | loss_box_reg: 0.0825 | loss_mask: 0.1671 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.1994 | Total Loss: 0.4835\n",
      "Epoch 1597 | loss_cls: 0.0162 | loss_box_reg: 0.0955 | loss_mask: 0.1218 | loss_rpn_cls: 0.0146 | loss_rpn_loc: 0.1475 | Total Loss: 0.3957\n",
      "Epoch 1598 | loss_cls: 0.0649 | loss_box_reg: 0.0980 | loss_mask: 0.0346 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0269 | Total Loss: 0.2250\n",
      "Epoch 1599 | loss_cls: 0.0357 | loss_box_reg: 0.1158 | loss_mask: 0.0580 | loss_rpn_cls: 0.0087 | loss_rpn_loc: 0.0046 | Total Loss: 0.2228\n",
      "\u001b[32m[07/29 18:30:04 d2.utils.events]: \u001b[0m eta: 0:08:59  iter: 1599      time: 0.3321  last_time: 0.1859   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1600 | loss_cls: 0.1232 | loss_box_reg: 0.1204 | loss_mask: 0.0577 | loss_rpn_cls: 0.0035 | loss_rpn_loc: 0.0153 | Total Loss: 0.3201\n",
      "Epoch 1601 | loss_cls: 0.0328 | loss_box_reg: 0.1476 | loss_mask: 0.0680 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0069 | Total Loss: 0.2560\n",
      "Epoch 1602 | loss_cls: 0.0683 | loss_box_reg: 0.1086 | loss_mask: 0.1823 | loss_rpn_cls: 0.0069 | loss_rpn_loc: 0.0199 | Total Loss: 0.3861\n",
      "Epoch 1603 | loss_cls: 0.1425 | loss_box_reg: 0.2803 | loss_mask: 0.0741 | loss_rpn_cls: 0.0095 | loss_rpn_loc: 0.1117 | Total Loss: 0.6182\n",
      "Epoch 1604 | loss_cls: 0.0752 | loss_box_reg: 0.0640 | loss_mask: 0.0499 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.1079 | Total Loss: 0.2984\n",
      "Epoch 1605 | loss_cls: 0.0214 | loss_box_reg: 0.0769 | loss_mask: 0.1045 | loss_rpn_cls: 0.0148 | loss_rpn_loc: 0.1078 | Total Loss: 0.3254\n",
      "Epoch 1606 | loss_cls: 0.0536 | loss_box_reg: 0.1724 | loss_mask: 0.2438 | loss_rpn_cls: 0.0020 | loss_rpn_loc: 0.0426 | Total Loss: 0.5144\n",
      "Epoch 1607 | loss_cls: 0.0353 | loss_box_reg: 0.1118 | loss_mask: 0.0640 | loss_rpn_cls: 0.0077 | loss_rpn_loc: 0.0399 | Total Loss: 0.2586\n",
      "Epoch 1608 | loss_cls: 0.0432 | loss_box_reg: 0.0606 | loss_mask: 0.0406 | loss_rpn_cls: 0.0057 | loss_rpn_loc: 0.0089 | Total Loss: 0.1590\n",
      "Epoch 1609 | loss_cls: 0.0272 | loss_box_reg: 0.0335 | loss_mask: 0.2434 | loss_rpn_cls: 0.0017 | loss_rpn_loc: 0.1240 | Total Loss: 0.4299\n",
      "Epoch 1610 | loss_cls: 0.0689 | loss_box_reg: 0.2735 | loss_mask: 0.2183 | loss_rpn_cls: 0.0102 | loss_rpn_loc: 0.0474 | Total Loss: 0.6183\n",
      "Epoch 1611 | loss_cls: 0.1029 | loss_box_reg: 0.2731 | loss_mask: 0.1183 | loss_rpn_cls: 0.0120 | loss_rpn_loc: 0.0889 | Total Loss: 0.5952\n",
      "Epoch 1612 | loss_cls: 0.0485 | loss_box_reg: 0.1369 | loss_mask: 0.1553 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.0908 | Total Loss: 0.4324\n",
      "Epoch 1613 | loss_cls: 0.0731 | loss_box_reg: 0.1581 | loss_mask: 0.2499 | loss_rpn_cls: 0.0188 | loss_rpn_loc: 0.0392 | Total Loss: 0.5392\n",
      "Epoch 1614 | loss_cls: 0.0295 | loss_box_reg: 0.0720 | loss_mask: 0.0999 | loss_rpn_cls: 0.0089 | loss_rpn_loc: 0.0952 | Total Loss: 0.3055\n",
      "Epoch 1615 | loss_cls: 0.0869 | loss_box_reg: 0.0982 | loss_mask: 0.0856 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.0075 | Total Loss: 0.2788\n",
      "Epoch 1616 | loss_cls: 0.0535 | loss_box_reg: 0.1295 | loss_mask: 0.1716 | loss_rpn_cls: 0.0074 | loss_rpn_loc: 0.0094 | Total Loss: 0.3714\n",
      "Epoch 1617 | loss_cls: 0.1418 | loss_box_reg: 0.1980 | loss_mask: 0.0907 | loss_rpn_cls: 0.0018 | loss_rpn_loc: 0.1585 | Total Loss: 0.5907\n",
      "Epoch 1618 | loss_cls: 0.0514 | loss_box_reg: 0.0998 | loss_mask: 0.0506 | loss_rpn_cls: 0.0062 | loss_rpn_loc: 0.0023 | Total Loss: 0.2103\n",
      "Epoch 1619 | loss_cls: 0.1389 | loss_box_reg: 0.3825 | loss_mask: 0.0778 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.0126 | Total Loss: 0.6142\n",
      "\u001b[32m[07/29 18:30:11 d2.utils.events]: \u001b[0m eta: 0:08:52  iter: 1619      time: 0.3323  last_time: 0.2744   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1620 | loss_cls: 0.0586 | loss_box_reg: 0.1076 | loss_mask: 0.1399 | loss_rpn_cls: 0.0053 | loss_rpn_loc: 0.0185 | Total Loss: 0.3299\n",
      "Epoch 1621 | loss_cls: 0.0791 | loss_box_reg: 0.1195 | loss_mask: 0.0672 | loss_rpn_cls: 0.0054 | loss_rpn_loc: 0.0088 | Total Loss: 0.2800\n",
      "Epoch 1622 | loss_cls: 0.0427 | loss_box_reg: 0.1364 | loss_mask: 0.1086 | loss_rpn_cls: 0.0055 | loss_rpn_loc: 0.1126 | Total Loss: 0.4058\n",
      "Epoch 1623 | loss_cls: 0.0638 | loss_box_reg: 0.1327 | loss_mask: 0.1252 | loss_rpn_cls: 0.0049 | loss_rpn_loc: 0.0668 | Total Loss: 0.3934\n",
      "Epoch 1624 | loss_cls: 0.0266 | loss_box_reg: 0.0485 | loss_mask: 0.2323 | loss_rpn_cls: 0.0105 | loss_rpn_loc: 0.1003 | Total Loss: 0.4182\n",
      "Epoch 1625 | loss_cls: 0.0949 | loss_box_reg: 0.1928 | loss_mask: 0.0594 | loss_rpn_cls: 0.0155 | loss_rpn_loc: 0.0525 | Total Loss: 0.4151\n",
      "Epoch 1626 | loss_cls: 0.0865 | loss_box_reg: 0.1814 | loss_mask: 0.0654 | loss_rpn_cls: 0.0345 | loss_rpn_loc: 0.1393 | Total Loss: 0.5072\n",
      "Epoch 1627 | loss_cls: 0.0484 | loss_box_reg: 0.1901 | loss_mask: 0.0687 | loss_rpn_cls: 0.0095 | loss_rpn_loc: 0.0038 | Total Loss: 0.3206\n",
      "Epoch 1628 | loss_cls: 0.1502 | loss_box_reg: 0.1788 | loss_mask: 0.0481 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.0351 | Total Loss: 0.4134\n",
      "Epoch 1629 | loss_cls: 0.0917 | loss_box_reg: 0.1633 | loss_mask: 0.0887 | loss_rpn_cls: 0.0182 | loss_rpn_loc: 0.1750 | Total Loss: 0.5369\n",
      "Epoch 1630 | loss_cls: 0.0702 | loss_box_reg: 0.1172 | loss_mask: 0.1389 | loss_rpn_cls: 0.0120 | loss_rpn_loc: 0.0187 | Total Loss: 0.3570\n",
      "Epoch 1631 | loss_cls: 0.0565 | loss_box_reg: 0.2341 | loss_mask: 0.1149 | loss_rpn_cls: 0.0108 | loss_rpn_loc: 0.0328 | Total Loss: 0.4491\n",
      "Epoch 1632 | loss_cls: 0.0225 | loss_box_reg: 0.0614 | loss_mask: 0.0439 | loss_rpn_cls: 0.0159 | loss_rpn_loc: 0.0033 | Total Loss: 0.1470\n",
      "Epoch 1633 | loss_cls: 0.1532 | loss_box_reg: 0.2551 | loss_mask: 0.0798 | loss_rpn_cls: 0.0435 | loss_rpn_loc: 0.2693 | Total Loss: 0.8009\n",
      "Epoch 1634 | loss_cls: 0.0360 | loss_box_reg: 0.1587 | loss_mask: 0.0984 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.0984 | Total Loss: 0.3943\n",
      "Epoch 1635 | loss_cls: 0.0598 | loss_box_reg: 0.2104 | loss_mask: 0.1071 | loss_rpn_cls: 0.0072 | loss_rpn_loc: 0.0664 | Total Loss: 0.4509\n",
      "Epoch 1636 | loss_cls: 0.0396 | loss_box_reg: 0.0908 | loss_mask: 0.0763 | loss_rpn_cls: 0.0059 | loss_rpn_loc: 0.0704 | Total Loss: 0.2829\n",
      "Epoch 1637 | loss_cls: 0.0348 | loss_box_reg: 0.1616 | loss_mask: 0.3344 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.1346 | Total Loss: 0.6678\n",
      "Epoch 1638 | loss_cls: 0.0877 | loss_box_reg: 0.0995 | loss_mask: 0.2130 | loss_rpn_cls: 0.0099 | loss_rpn_loc: 0.0226 | Total Loss: 0.4327\n",
      "Epoch 1639 | loss_cls: 0.0650 | loss_box_reg: 0.1277 | loss_mask: 0.0900 | loss_rpn_cls: 0.0123 | loss_rpn_loc: 0.0770 | Total Loss: 0.3721\n",
      "\u001b[32m[07/29 18:30:18 d2.utils.events]: \u001b[0m eta: 0:08:45  iter: 1639      time: 0.3325  last_time: 0.4165   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1640 | loss_cls: 0.0998 | loss_box_reg: 0.2059 | loss_mask: 0.0910 | loss_rpn_cls: 0.0097 | loss_rpn_loc: 0.0175 | Total Loss: 0.4240\n",
      "Epoch 1641 | loss_cls: 0.0433 | loss_box_reg: 0.1988 | loss_mask: 0.0689 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.0052 | Total Loss: 0.3186\n",
      "Epoch 1642 | loss_cls: 0.0180 | loss_box_reg: 0.0682 | loss_mask: 0.2083 | loss_rpn_cls: 0.0155 | loss_rpn_loc: 0.0779 | Total Loss: 0.3879\n",
      "Epoch 1643 | loss_cls: 0.0348 | loss_box_reg: 0.1240 | loss_mask: 0.0731 | loss_rpn_cls: 0.0059 | loss_rpn_loc: 0.0029 | Total Loss: 0.2408\n",
      "Epoch 1644 | loss_cls: 0.0847 | loss_box_reg: 0.3358 | loss_mask: 0.1697 | loss_rpn_cls: 0.0044 | loss_rpn_loc: 0.0109 | Total Loss: 0.6054\n",
      "Epoch 1645 | loss_cls: 0.0690 | loss_box_reg: 0.1796 | loss_mask: 0.1010 | loss_rpn_cls: 0.0132 | loss_rpn_loc: 0.0649 | Total Loss: 0.4277\n",
      "Epoch 1646 | loss_cls: 0.0959 | loss_box_reg: 0.2820 | loss_mask: 0.0555 | loss_rpn_cls: 0.0326 | loss_rpn_loc: 0.2999 | Total Loss: 0.7660\n",
      "Epoch 1647 | loss_cls: 0.1326 | loss_box_reg: 0.2805 | loss_mask: 0.0616 | loss_rpn_cls: 0.0040 | loss_rpn_loc: 0.0209 | Total Loss: 0.4997\n",
      "Epoch 1648 | loss_cls: 0.0286 | loss_box_reg: 0.0866 | loss_mask: 0.0764 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.0125 | Total Loss: 0.2091\n",
      "Epoch 1649 | loss_cls: 0.1246 | loss_box_reg: 0.2962 | loss_mask: 0.1492 | loss_rpn_cls: 0.0099 | loss_rpn_loc: 0.2048 | Total Loss: 0.7847\n",
      "Epoch 1650 | loss_cls: 0.0669 | loss_box_reg: 0.1262 | loss_mask: 0.1519 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.0244 | Total Loss: 0.3707\n",
      "Epoch 1651 | loss_cls: 0.0869 | loss_box_reg: 0.1746 | loss_mask: 0.0510 | loss_rpn_cls: 0.0061 | loss_rpn_loc: 0.1544 | Total Loss: 0.4729\n",
      "Epoch 1652 | loss_cls: 0.0939 | loss_box_reg: 0.1095 | loss_mask: 0.0493 | loss_rpn_cls: 0.0057 | loss_rpn_loc: 0.1340 | Total Loss: 0.3925\n",
      "Epoch 1653 | loss_cls: 0.0482 | loss_box_reg: 0.1158 | loss_mask: 0.0492 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.0307 | Total Loss: 0.2473\n",
      "Epoch 1654 | loss_cls: 0.0452 | loss_box_reg: 0.1316 | loss_mask: 0.0941 | loss_rpn_cls: 0.0039 | loss_rpn_loc: 0.0061 | Total Loss: 0.2809\n",
      "Epoch 1655 | loss_cls: 0.0716 | loss_box_reg: 0.2372 | loss_mask: 0.0904 | loss_rpn_cls: 0.0089 | loss_rpn_loc: 0.0558 | Total Loss: 0.4638\n",
      "Epoch 1656 | loss_cls: 0.0462 | loss_box_reg: 0.1154 | loss_mask: 0.0322 | loss_rpn_cls: 0.0093 | loss_rpn_loc: 0.1224 | Total Loss: 0.3257\n",
      "Epoch 1657 | loss_cls: 0.0938 | loss_box_reg: 0.1833 | loss_mask: 0.0808 | loss_rpn_cls: 0.0114 | loss_rpn_loc: 0.0429 | Total Loss: 0.4123\n",
      "Epoch 1658 | loss_cls: 0.0556 | loss_box_reg: 0.1383 | loss_mask: 0.1039 | loss_rpn_cls: 0.0021 | loss_rpn_loc: 0.0138 | Total Loss: 0.3137\n",
      "Epoch 1659 | loss_cls: 0.0319 | loss_box_reg: 0.1187 | loss_mask: 0.0730 | loss_rpn_cls: 0.0060 | loss_rpn_loc: 0.0029 | Total Loss: 0.2325\n",
      "\u001b[32m[07/29 18:30:25 d2.utils.events]: \u001b[0m eta: 0:08:38  iter: 1659      time: 0.3324  last_time: 0.2696   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1660 | loss_cls: 0.0387 | loss_box_reg: 0.0601 | loss_mask: 0.0342 | loss_rpn_cls: 0.0179 | loss_rpn_loc: 0.0166 | Total Loss: 0.1677\n",
      "Epoch 1661 | loss_cls: 0.0341 | loss_box_reg: 0.2388 | loss_mask: 0.1677 | loss_rpn_cls: 0.0038 | loss_rpn_loc: 0.0108 | Total Loss: 0.4552\n",
      "Epoch 1662 | loss_cls: 0.0436 | loss_box_reg: 0.2392 | loss_mask: 0.1669 | loss_rpn_cls: 0.0066 | loss_rpn_loc: 0.0105 | Total Loss: 0.4669\n",
      "Epoch 1663 | loss_cls: 0.0876 | loss_box_reg: 0.1298 | loss_mask: 0.0441 | loss_rpn_cls: 0.0032 | loss_rpn_loc: 0.0183 | Total Loss: 0.2831\n",
      "Epoch 1664 | loss_cls: 0.0696 | loss_box_reg: 0.1311 | loss_mask: 0.0459 | loss_rpn_cls: 0.0150 | loss_rpn_loc: 0.1355 | Total Loss: 0.3971\n",
      "Epoch 1665 | loss_cls: 0.0507 | loss_box_reg: 0.0809 | loss_mask: 0.0383 | loss_rpn_cls: 0.0030 | loss_rpn_loc: 0.3082 | Total Loss: 0.4810\n",
      "Epoch 1666 | loss_cls: 0.0714 | loss_box_reg: 0.2953 | loss_mask: 0.1299 | loss_rpn_cls: 0.0060 | loss_rpn_loc: 0.0263 | Total Loss: 0.5289\n",
      "Epoch 1667 | loss_cls: 0.0254 | loss_box_reg: 0.0631 | loss_mask: 0.1202 | loss_rpn_cls: 0.0032 | loss_rpn_loc: 0.0151 | Total Loss: 0.2270\n",
      "Epoch 1668 | loss_cls: 0.0205 | loss_box_reg: 0.0745 | loss_mask: 0.1590 | loss_rpn_cls: 0.0073 | loss_rpn_loc: 0.1150 | Total Loss: 0.3762\n",
      "Epoch 1669 | loss_cls: 0.0403 | loss_box_reg: 0.1027 | loss_mask: 0.0664 | loss_rpn_cls: 0.0091 | loss_rpn_loc: 0.0040 | Total Loss: 0.2224\n",
      "Epoch 1670 | loss_cls: 0.0338 | loss_box_reg: 0.0934 | loss_mask: 0.1383 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.0197 | Total Loss: 0.2875\n",
      "Epoch 1671 | loss_cls: 0.0439 | loss_box_reg: 0.1314 | loss_mask: 0.0587 | loss_rpn_cls: 0.0067 | loss_rpn_loc: 0.0058 | Total Loss: 0.2465\n",
      "Epoch 1672 | loss_cls: 0.0535 | loss_box_reg: 0.0672 | loss_mask: 0.0718 | loss_rpn_cls: 0.0045 | loss_rpn_loc: 0.1237 | Total Loss: 0.3206\n",
      "Epoch 1673 | loss_cls: 0.0236 | loss_box_reg: 0.1005 | loss_mask: 0.0471 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0138 | Total Loss: 0.1856\n",
      "Epoch 1674 | loss_cls: 0.0196 | loss_box_reg: 0.0791 | loss_mask: 0.0538 | loss_rpn_cls: 0.0096 | loss_rpn_loc: 0.0141 | Total Loss: 0.1762\n",
      "Epoch 1675 | loss_cls: 0.0780 | loss_box_reg: 0.1664 | loss_mask: 0.1645 | loss_rpn_cls: 0.0031 | loss_rpn_loc: 0.0029 | Total Loss: 0.4149\n",
      "Epoch 1676 | loss_cls: 0.1067 | loss_box_reg: 0.2121 | loss_mask: 0.0820 | loss_rpn_cls: 0.0041 | loss_rpn_loc: 0.0410 | Total Loss: 0.4460\n",
      "Epoch 1677 | loss_cls: 0.0518 | loss_box_reg: 0.1032 | loss_mask: 0.1536 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.0370 | Total Loss: 0.3489\n",
      "Epoch 1678 | loss_cls: 0.1258 | loss_box_reg: 0.2407 | loss_mask: 0.1204 | loss_rpn_cls: 0.0828 | loss_rpn_loc: 0.1695 | Total Loss: 0.7392\n",
      "Epoch 1679 | loss_cls: 0.0611 | loss_box_reg: 0.1978 | loss_mask: 0.1267 | loss_rpn_cls: 0.0044 | loss_rpn_loc: 0.0108 | Total Loss: 0.4008\n",
      "\u001b[32m[07/29 18:30:31 d2.utils.events]: \u001b[0m eta: 0:08:30  iter: 1679      time: 0.3323  last_time: 0.2920   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1680 | loss_cls: 0.0812 | loss_box_reg: 0.1789 | loss_mask: 0.1337 | loss_rpn_cls: 0.0098 | loss_rpn_loc: 0.1587 | Total Loss: 0.5623\n",
      "Epoch 1681 | loss_cls: 0.0555 | loss_box_reg: 0.1416 | loss_mask: 0.0779 | loss_rpn_cls: 0.0032 | loss_rpn_loc: 0.0843 | Total Loss: 0.3626\n",
      "Epoch 1682 | loss_cls: 0.0315 | loss_box_reg: 0.0745 | loss_mask: 0.1483 | loss_rpn_cls: 0.0045 | loss_rpn_loc: 0.0208 | Total Loss: 0.2797\n",
      "Epoch 1683 | loss_cls: 0.1411 | loss_box_reg: 0.1575 | loss_mask: 0.0705 | loss_rpn_cls: 0.0305 | loss_rpn_loc: 0.2948 | Total Loss: 0.6944\n",
      "Epoch 1684 | loss_cls: 0.0365 | loss_box_reg: 0.1823 | loss_mask: 0.0811 | loss_rpn_cls: 0.0003 | loss_rpn_loc: 0.0290 | Total Loss: 0.3292\n",
      "Epoch 1685 | loss_cls: 0.0302 | loss_box_reg: 0.1055 | loss_mask: 0.1597 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.1077 | Total Loss: 0.4035\n",
      "Epoch 1686 | loss_cls: 0.1205 | loss_box_reg: 0.2241 | loss_mask: 0.1095 | loss_rpn_cls: 0.0262 | loss_rpn_loc: 0.0779 | Total Loss: 0.5582\n",
      "Epoch 1687 | loss_cls: 0.0643 | loss_box_reg: 0.1693 | loss_mask: 0.0416 | loss_rpn_cls: 0.0138 | loss_rpn_loc: 0.0184 | Total Loss: 0.3074\n",
      "Epoch 1688 | loss_cls: 0.1053 | loss_box_reg: 0.2236 | loss_mask: 0.0894 | loss_rpn_cls: 0.0002 | loss_rpn_loc: 0.0405 | Total Loss: 0.4590\n",
      "Epoch 1689 | loss_cls: 0.1861 | loss_box_reg: 0.2357 | loss_mask: 0.0624 | loss_rpn_cls: 0.0042 | loss_rpn_loc: 0.1263 | Total Loss: 0.6147\n",
      "Epoch 1690 | loss_cls: 0.0418 | loss_box_reg: 0.1494 | loss_mask: 0.1604 | loss_rpn_cls: 0.0099 | loss_rpn_loc: 0.0493 | Total Loss: 0.4109\n",
      "Epoch 1691 | loss_cls: 0.0755 | loss_box_reg: 0.1235 | loss_mask: 0.0389 | loss_rpn_cls: 0.0037 | loss_rpn_loc: 0.0234 | Total Loss: 0.2650\n",
      "Epoch 1692 | loss_cls: 0.0638 | loss_box_reg: 0.1857 | loss_mask: 0.0485 | loss_rpn_cls: 0.0044 | loss_rpn_loc: 0.0360 | Total Loss: 0.3385\n",
      "Epoch 1693 | loss_cls: 0.0682 | loss_box_reg: 0.1714 | loss_mask: 0.1370 | loss_rpn_cls: 0.0035 | loss_rpn_loc: 0.0101 | Total Loss: 0.3901\n",
      "Epoch 1694 | loss_cls: 0.0621 | loss_box_reg: 0.1324 | loss_mask: 0.1088 | loss_rpn_cls: 0.0152 | loss_rpn_loc: 0.1927 | Total Loss: 0.5113\n",
      "Epoch 1695 | loss_cls: 0.0308 | loss_box_reg: 0.0916 | loss_mask: 0.0759 | loss_rpn_cls: 0.0127 | loss_rpn_loc: 0.0710 | Total Loss: 0.2820\n",
      "Epoch 1696 | loss_cls: 0.0368 | loss_box_reg: 0.1078 | loss_mask: 0.2541 | loss_rpn_cls: 0.0042 | loss_rpn_loc: 0.0324 | Total Loss: 0.4353\n",
      "Epoch 1697 | loss_cls: 0.0279 | loss_box_reg: 0.1149 | loss_mask: 0.0439 | loss_rpn_cls: 0.0125 | loss_rpn_loc: 0.0436 | Total Loss: 0.2427\n",
      "Epoch 1698 | loss_cls: 0.0703 | loss_box_reg: 0.1284 | loss_mask: 0.0577 | loss_rpn_cls: 0.0064 | loss_rpn_loc: 0.0503 | Total Loss: 0.3131\n",
      "Epoch 1699 | loss_cls: 0.0737 | loss_box_reg: 0.1572 | loss_mask: 0.0627 | loss_rpn_cls: 0.0097 | loss_rpn_loc: 0.0855 | Total Loss: 0.3888\n",
      "\u001b[32m[07/29 18:30:38 d2.utils.events]: \u001b[0m eta: 0:08:23  iter: 1699      time: 0.3323  last_time: 0.1987   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1700 | loss_cls: 0.0845 | loss_box_reg: 0.1840 | loss_mask: 0.1873 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.0304 | Total Loss: 0.4882\n",
      "Epoch 1701 | loss_cls: 0.0707 | loss_box_reg: 0.1599 | loss_mask: 0.1606 | loss_rpn_cls: 0.0086 | loss_rpn_loc: 0.2304 | Total Loss: 0.6302\n",
      "Epoch 1702 | loss_cls: 0.0653 | loss_box_reg: 0.3122 | loss_mask: 0.1577 | loss_rpn_cls: 0.0234 | loss_rpn_loc: 0.0046 | Total Loss: 0.5633\n",
      "Epoch 1703 | loss_cls: 0.1048 | loss_box_reg: 0.1422 | loss_mask: 0.0529 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.0200 | Total Loss: 0.3232\n",
      "Epoch 1704 | loss_cls: 0.1204 | loss_box_reg: 0.2187 | loss_mask: 0.0915 | loss_rpn_cls: 0.0053 | loss_rpn_loc: 0.0740 | Total Loss: 0.5100\n",
      "Epoch 1705 | loss_cls: 0.1098 | loss_box_reg: 0.1441 | loss_mask: 0.1210 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.1368 | Total Loss: 0.5151\n",
      "Epoch 1706 | loss_cls: 0.0176 | loss_box_reg: 0.0466 | loss_mask: 0.2027 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.1923 | Total Loss: 0.4626\n",
      "Epoch 1707 | loss_cls: 0.0825 | loss_box_reg: 0.2242 | loss_mask: 0.0811 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0420 | Total Loss: 0.4301\n",
      "Epoch 1708 | loss_cls: 0.0589 | loss_box_reg: 0.1635 | loss_mask: 0.0720 | loss_rpn_cls: 0.0032 | loss_rpn_loc: 0.0318 | Total Loss: 0.3294\n",
      "Epoch 1709 | loss_cls: 0.0806 | loss_box_reg: 0.0961 | loss_mask: 0.0706 | loss_rpn_cls: 0.0171 | loss_rpn_loc: 0.1100 | Total Loss: 0.3744\n",
      "Epoch 1710 | loss_cls: 0.0802 | loss_box_reg: 0.2697 | loss_mask: 0.0707 | loss_rpn_cls: 0.0044 | loss_rpn_loc: 0.0964 | Total Loss: 0.5214\n",
      "Epoch 1711 | loss_cls: 0.0502 | loss_box_reg: 0.0842 | loss_mask: 0.0793 | loss_rpn_cls: 0.0070 | loss_rpn_loc: 0.1039 | Total Loss: 0.3247\n",
      "Epoch 1712 | loss_cls: 0.0567 | loss_box_reg: 0.0759 | loss_mask: 0.1466 | loss_rpn_cls: 0.0001 | loss_rpn_loc: 0.0131 | Total Loss: 0.2924\n",
      "Epoch 1713 | loss_cls: 0.0708 | loss_box_reg: 0.1896 | loss_mask: 0.2280 | loss_rpn_cls: 0.0030 | loss_rpn_loc: 0.0582 | Total Loss: 0.5495\n",
      "Epoch 1714 | loss_cls: 0.0531 | loss_box_reg: 0.1130 | loss_mask: 0.0700 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.1263 | Total Loss: 0.3634\n",
      "Epoch 1715 | loss_cls: 0.0817 | loss_box_reg: 0.1860 | loss_mask: 0.0811 | loss_rpn_cls: 0.0016 | loss_rpn_loc: 0.0552 | Total Loss: 0.4056\n",
      "Epoch 1716 | loss_cls: 0.0787 | loss_box_reg: 0.1429 | loss_mask: 0.0584 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.0121 | Total Loss: 0.2948\n",
      "Epoch 1717 | loss_cls: 0.0632 | loss_box_reg: 0.1920 | loss_mask: 0.0891 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.0094 | Total Loss: 0.3547\n",
      "Epoch 1718 | loss_cls: 0.0418 | loss_box_reg: 0.1407 | loss_mask: 0.0903 | loss_rpn_cls: 0.0058 | loss_rpn_loc: 0.0475 | Total Loss: 0.3262\n",
      "Epoch 1719 | loss_cls: 0.0484 | loss_box_reg: 0.1695 | loss_mask: 0.0560 | loss_rpn_cls: 0.0018 | loss_rpn_loc: 0.0099 | Total Loss: 0.2856\n",
      "\u001b[32m[07/29 18:30:45 d2.utils.events]: \u001b[0m eta: 0:08:15  iter: 1719      time: 0.3325  last_time: 0.2793   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1720 | loss_cls: 0.0301 | loss_box_reg: 0.0473 | loss_mask: 0.0989 | loss_rpn_cls: 0.0018 | loss_rpn_loc: 0.0168 | Total Loss: 0.1948\n",
      "Epoch 1721 | loss_cls: 0.0743 | loss_box_reg: 0.1887 | loss_mask: 0.0721 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.1525 | Total Loss: 0.4911\n",
      "Epoch 1722 | loss_cls: 0.0278 | loss_box_reg: 0.0806 | loss_mask: 0.0847 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.0227 | Total Loss: 0.2184\n",
      "Epoch 1723 | loss_cls: 0.0540 | loss_box_reg: 0.1890 | loss_mask: 0.0795 | loss_rpn_cls: 0.0098 | loss_rpn_loc: 0.1108 | Total Loss: 0.4431\n",
      "Epoch 1724 | loss_cls: 0.0674 | loss_box_reg: 0.1582 | loss_mask: 0.0676 | loss_rpn_cls: 0.0135 | loss_rpn_loc: 0.0708 | Total Loss: 0.3776\n",
      "Epoch 1725 | loss_cls: 0.1024 | loss_box_reg: 0.2618 | loss_mask: 0.1178 | loss_rpn_cls: 0.0153 | loss_rpn_loc: 0.0628 | Total Loss: 0.5600\n",
      "Epoch 1726 | loss_cls: 0.0368 | loss_box_reg: 0.0956 | loss_mask: 0.2533 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.0037 | Total Loss: 0.3907\n",
      "Epoch 1727 | loss_cls: 0.0948 | loss_box_reg: 0.1218 | loss_mask: 0.0874 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.0357 | Total Loss: 0.3413\n",
      "Epoch 1728 | loss_cls: 0.1019 | loss_box_reg: 0.1554 | loss_mask: 0.1075 | loss_rpn_cls: 0.0017 | loss_rpn_loc: 0.0074 | Total Loss: 0.3739\n",
      "Epoch 1729 | loss_cls: 0.0431 | loss_box_reg: 0.0948 | loss_mask: 0.0366 | loss_rpn_cls: 0.0038 | loss_rpn_loc: 0.2572 | Total Loss: 0.4355\n",
      "Epoch 1730 | loss_cls: 0.0367 | loss_box_reg: 0.1131 | loss_mask: 0.1661 | loss_rpn_cls: 0.0018 | loss_rpn_loc: 0.0107 | Total Loss: 0.3285\n",
      "Epoch 1731 | loss_cls: 0.0485 | loss_box_reg: 0.0839 | loss_mask: 0.1439 | loss_rpn_cls: 0.0061 | loss_rpn_loc: 0.0023 | Total Loss: 0.2847\n",
      "Epoch 1732 | loss_cls: 0.0920 | loss_box_reg: 0.2649 | loss_mask: 0.0562 | loss_rpn_cls: 0.0045 | loss_rpn_loc: 0.1729 | Total Loss: 0.5904\n",
      "Epoch 1733 | loss_cls: 0.0419 | loss_box_reg: 0.1544 | loss_mask: 0.1919 | loss_rpn_cls: 0.0065 | loss_rpn_loc: 0.0744 | Total Loss: 0.4691\n",
      "Epoch 1734 | loss_cls: 0.0379 | loss_box_reg: 0.0943 | loss_mask: 0.1739 | loss_rpn_cls: 0.0016 | loss_rpn_loc: 0.0175 | Total Loss: 0.3252\n",
      "Epoch 1735 | loss_cls: 0.0574 | loss_box_reg: 0.1103 | loss_mask: 0.0514 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.0086 | Total Loss: 0.2302\n",
      "Epoch 1736 | loss_cls: 0.0232 | loss_box_reg: 0.0814 | loss_mask: 0.0796 | loss_rpn_cls: 0.0002 | loss_rpn_loc: 0.0140 | Total Loss: 0.1983\n",
      "Epoch 1737 | loss_cls: 0.1172 | loss_box_reg: 0.1717 | loss_mask: 0.0677 | loss_rpn_cls: 0.0068 | loss_rpn_loc: 0.0275 | Total Loss: 0.3909\n",
      "Epoch 1738 | loss_cls: 0.0303 | loss_box_reg: 0.0957 | loss_mask: 0.1689 | loss_rpn_cls: 0.0058 | loss_rpn_loc: 0.0166 | Total Loss: 0.3173\n",
      "Epoch 1739 | loss_cls: 0.0485 | loss_box_reg: 0.0853 | loss_mask: 0.0593 | loss_rpn_cls: 0.0673 | loss_rpn_loc: 0.2637 | Total Loss: 0.5241\n",
      "\u001b[32m[07/29 18:30:52 d2.utils.events]: \u001b[0m eta: 0:08:08  iter: 1739      time: 0.3324  last_time: 0.3966   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1740 | loss_cls: 0.0368 | loss_box_reg: 0.0904 | loss_mask: 0.0442 | loss_rpn_cls: 0.0048 | loss_rpn_loc: 0.0713 | Total Loss: 0.2475\n",
      "Epoch 1741 | loss_cls: 0.0468 | loss_box_reg: 0.0872 | loss_mask: 0.0574 | loss_rpn_cls: 0.0109 | loss_rpn_loc: 0.0142 | Total Loss: 0.2164\n",
      "Epoch 1742 | loss_cls: 0.0711 | loss_box_reg: 0.1015 | loss_mask: 0.0861 | loss_rpn_cls: 0.0179 | loss_rpn_loc: 0.1197 | Total Loss: 0.3963\n",
      "Epoch 1743 | loss_cls: 0.1464 | loss_box_reg: 0.2651 | loss_mask: 0.0607 | loss_rpn_cls: 0.0176 | loss_rpn_loc: 0.3694 | Total Loss: 0.8592\n",
      "Epoch 1744 | loss_cls: 0.1002 | loss_box_reg: 0.1682 | loss_mask: 0.0663 | loss_rpn_cls: 0.0143 | loss_rpn_loc: 0.0292 | Total Loss: 0.3782\n",
      "Epoch 1745 | loss_cls: 0.0915 | loss_box_reg: 0.1682 | loss_mask: 0.0491 | loss_rpn_cls: 0.0002 | loss_rpn_loc: 0.0073 | Total Loss: 0.3162\n",
      "Epoch 1746 | loss_cls: 0.0689 | loss_box_reg: 0.1762 | loss_mask: 0.0727 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.1796 | Total Loss: 0.4986\n",
      "Epoch 1747 | loss_cls: 0.1289 | loss_box_reg: 0.1553 | loss_mask: 0.2062 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.0050 | Total Loss: 0.4988\n",
      "Epoch 1748 | loss_cls: 0.0244 | loss_box_reg: 0.0643 | loss_mask: 0.0989 | loss_rpn_cls: 0.0046 | loss_rpn_loc: 0.1355 | Total Loss: 0.3276\n",
      "Epoch 1749 | loss_cls: 0.0376 | loss_box_reg: 0.0855 | loss_mask: 0.0958 | loss_rpn_cls: 0.0020 | loss_rpn_loc: 0.0069 | Total Loss: 0.2277\n",
      "Epoch 1750 | loss_cls: 0.0765 | loss_box_reg: 0.2713 | loss_mask: 0.1019 | loss_rpn_cls: 0.0081 | loss_rpn_loc: 0.2189 | Total Loss: 0.6766\n",
      "Epoch 1751 | loss_cls: 0.1249 | loss_box_reg: 0.2061 | loss_mask: 0.1409 | loss_rpn_cls: 0.0056 | loss_rpn_loc: 0.0867 | Total Loss: 0.5643\n",
      "Epoch 1752 | loss_cls: 0.0289 | loss_box_reg: 0.1444 | loss_mask: 0.0871 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.0213 | Total Loss: 0.2829\n",
      "Epoch 1753 | loss_cls: 0.0526 | loss_box_reg: 0.1452 | loss_mask: 0.0682 | loss_rpn_cls: 0.0038 | loss_rpn_loc: 0.0236 | Total Loss: 0.2934\n",
      "Epoch 1754 | loss_cls: 0.1162 | loss_box_reg: 0.2993 | loss_mask: 0.1213 | loss_rpn_cls: 0.0053 | loss_rpn_loc: 0.1611 | Total Loss: 0.7033\n",
      "Epoch 1755 | loss_cls: 0.1027 | loss_box_reg: 0.2999 | loss_mask: 0.0392 | loss_rpn_cls: 0.0003 | loss_rpn_loc: 0.0101 | Total Loss: 0.4523\n",
      "Epoch 1756 | loss_cls: 0.0670 | loss_box_reg: 0.2089 | loss_mask: 0.0750 | loss_rpn_cls: 0.0088 | loss_rpn_loc: 0.1132 | Total Loss: 0.4730\n",
      "Epoch 1757 | loss_cls: 0.0358 | loss_box_reg: 0.1024 | loss_mask: 0.2281 | loss_rpn_cls: 0.0094 | loss_rpn_loc: 0.0693 | Total Loss: 0.4450\n",
      "Epoch 1758 | loss_cls: 0.0296 | loss_box_reg: 0.1162 | loss_mask: 0.0588 | loss_rpn_cls: 0.0079 | loss_rpn_loc: 0.1103 | Total Loss: 0.3228\n",
      "Epoch 1759 | loss_cls: 0.0364 | loss_box_reg: 0.1085 | loss_mask: 0.0346 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.0026 | Total Loss: 0.1836\n",
      "\u001b[32m[07/29 18:30:58 d2.utils.events]: \u001b[0m eta: 0:08:00  iter: 1759      time: 0.3325  last_time: 0.4216   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1760 | loss_cls: 0.1025 | loss_box_reg: 0.2985 | loss_mask: 0.2769 | loss_rpn_cls: 0.0087 | loss_rpn_loc: 0.0155 | Total Loss: 0.7021\n",
      "Epoch 1761 | loss_cls: 0.0509 | loss_box_reg: 0.2041 | loss_mask: 0.0626 | loss_rpn_cls: 0.0142 | loss_rpn_loc: 0.0032 | Total Loss: 0.3351\n",
      "Epoch 1762 | loss_cls: 0.0702 | loss_box_reg: 0.1346 | loss_mask: 0.1024 | loss_rpn_cls: 0.0058 | loss_rpn_loc: 0.0080 | Total Loss: 0.3210\n",
      "Epoch 1763 | loss_cls: 0.0662 | loss_box_reg: 0.1143 | loss_mask: 0.1302 | loss_rpn_cls: 0.0198 | loss_rpn_loc: 0.1146 | Total Loss: 0.4452\n",
      "Epoch 1764 | loss_cls: 0.1396 | loss_box_reg: 0.1471 | loss_mask: 0.0819 | loss_rpn_cls: 0.0273 | loss_rpn_loc: 0.0191 | Total Loss: 0.4150\n",
      "Epoch 1765 | loss_cls: 0.0798 | loss_box_reg: 0.2041 | loss_mask: 0.1316 | loss_rpn_cls: 0.0047 | loss_rpn_loc: 0.0330 | Total Loss: 0.4532\n",
      "Epoch 1766 | loss_cls: 0.0798 | loss_box_reg: 0.1636 | loss_mask: 0.0749 | loss_rpn_cls: 0.0073 | loss_rpn_loc: 0.1071 | Total Loss: 0.4328\n",
      "Epoch 1767 | loss_cls: 0.0743 | loss_box_reg: 0.1284 | loss_mask: 0.1064 | loss_rpn_cls: 0.0054 | loss_rpn_loc: 0.0209 | Total Loss: 0.3356\n",
      "Epoch 1768 | loss_cls: 0.0875 | loss_box_reg: 0.1903 | loss_mask: 0.1008 | loss_rpn_cls: 0.0235 | loss_rpn_loc: 0.0557 | Total Loss: 0.4577\n",
      "Epoch 1769 | loss_cls: 0.0180 | loss_box_reg: 0.0557 | loss_mask: 0.0992 | loss_rpn_cls: 0.0192 | loss_rpn_loc: 0.2187 | Total Loss: 0.4108\n",
      "Epoch 1770 | loss_cls: 0.0219 | loss_box_reg: 0.0626 | loss_mask: 0.0845 | loss_rpn_cls: 0.0045 | loss_rpn_loc: 0.1092 | Total Loss: 0.2827\n",
      "Epoch 1771 | loss_cls: 0.0755 | loss_box_reg: 0.2006 | loss_mask: 0.2165 | loss_rpn_cls: 0.0056 | loss_rpn_loc: 0.1475 | Total Loss: 0.6456\n",
      "Epoch 1772 | loss_cls: 0.0920 | loss_box_reg: 0.2544 | loss_mask: 0.1453 | loss_rpn_cls: 0.0121 | loss_rpn_loc: 0.0464 | Total Loss: 0.5502\n",
      "Epoch 1773 | loss_cls: 0.0741 | loss_box_reg: 0.1418 | loss_mask: 0.1734 | loss_rpn_cls: 0.0154 | loss_rpn_loc: 0.1335 | Total Loss: 0.5382\n",
      "Epoch 1774 | loss_cls: 0.0651 | loss_box_reg: 0.1989 | loss_mask: 0.1003 | loss_rpn_cls: 0.0046 | loss_rpn_loc: 0.0808 | Total Loss: 0.4497\n",
      "Epoch 1775 | loss_cls: 0.0243 | loss_box_reg: 0.0854 | loss_mask: 0.0385 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.0025 | Total Loss: 0.1512\n",
      "Epoch 1776 | loss_cls: 0.0392 | loss_box_reg: 0.1442 | loss_mask: 0.0643 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.0031 | Total Loss: 0.2559\n",
      "Epoch 1777 | loss_cls: 0.0624 | loss_box_reg: 0.1065 | loss_mask: 0.0899 | loss_rpn_cls: 0.0121 | loss_rpn_loc: 0.0054 | Total Loss: 0.2763\n",
      "Epoch 1778 | loss_cls: 0.0601 | loss_box_reg: 0.2472 | loss_mask: 0.0325 | loss_rpn_cls: 0.0046 | loss_rpn_loc: 0.0547 | Total Loss: 0.3991\n",
      "Epoch 1779 | loss_cls: 0.0398 | loss_box_reg: 0.1311 | loss_mask: 0.0979 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.0129 | Total Loss: 0.2832\n",
      "\u001b[32m[07/29 18:31:05 d2.utils.events]: \u001b[0m eta: 0:07:52  iter: 1779      time: 0.3325  last_time: 0.3912   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1780 | loss_cls: 0.0818 | loss_box_reg: 0.0889 | loss_mask: 0.0486 | loss_rpn_cls: 0.0045 | loss_rpn_loc: 0.0048 | Total Loss: 0.2285\n",
      "Epoch 1781 | loss_cls: 0.0611 | loss_box_reg: 0.1406 | loss_mask: 0.1105 | loss_rpn_cls: 0.0078 | loss_rpn_loc: 0.1088 | Total Loss: 0.4287\n",
      "Epoch 1782 | loss_cls: 0.0531 | loss_box_reg: 0.1685 | loss_mask: 0.1371 | loss_rpn_cls: 0.0333 | loss_rpn_loc: 0.0753 | Total Loss: 0.4673\n",
      "Epoch 1783 | loss_cls: 0.1162 | loss_box_reg: 0.2005 | loss_mask: 0.0569 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0239 | Total Loss: 0.3985\n",
      "Epoch 1784 | loss_cls: 0.0639 | loss_box_reg: 0.1254 | loss_mask: 0.0669 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.0345 | Total Loss: 0.2926\n",
      "Epoch 1785 | loss_cls: 0.0353 | loss_box_reg: 0.1552 | loss_mask: 0.1066 | loss_rpn_cls: 0.0168 | loss_rpn_loc: 0.1570 | Total Loss: 0.4710\n",
      "Epoch 1786 | loss_cls: 0.1211 | loss_box_reg: 0.1743 | loss_mask: 0.0770 | loss_rpn_cls: 0.0080 | loss_rpn_loc: 0.1594 | Total Loss: 0.5399\n",
      "Epoch 1787 | loss_cls: 0.0630 | loss_box_reg: 0.1787 | loss_mask: 0.0630 | loss_rpn_cls: 0.0088 | loss_rpn_loc: 0.0819 | Total Loss: 0.3955\n",
      "Epoch 1788 | loss_cls: 0.1230 | loss_box_reg: 0.2889 | loss_mask: 0.1329 | loss_rpn_cls: 0.0330 | loss_rpn_loc: 0.1120 | Total Loss: 0.6898\n",
      "Epoch 1789 | loss_cls: 0.0750 | loss_box_reg: 0.2994 | loss_mask: 0.0768 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.0078 | Total Loss: 0.4624\n",
      "Epoch 1790 | loss_cls: 0.0812 | loss_box_reg: 0.1954 | loss_mask: 0.0609 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.0050 | Total Loss: 0.3430\n",
      "Epoch 1791 | loss_cls: 0.0429 | loss_box_reg: 0.1182 | loss_mask: 0.1042 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0048 | Total Loss: 0.2708\n",
      "Epoch 1792 | loss_cls: 0.0500 | loss_box_reg: 0.1555 | loss_mask: 0.0681 | loss_rpn_cls: 0.0106 | loss_rpn_loc: 0.0604 | Total Loss: 0.3447\n",
      "Epoch 1793 | loss_cls: 0.0461 | loss_box_reg: 0.1415 | loss_mask: 0.0538 | loss_rpn_cls: 0.0102 | loss_rpn_loc: 0.0045 | Total Loss: 0.2561\n",
      "Epoch 1794 | loss_cls: 0.1062 | loss_box_reg: 0.1622 | loss_mask: 0.0485 | loss_rpn_cls: 0.0124 | loss_rpn_loc: 0.3339 | Total Loss: 0.6632\n",
      "Epoch 1795 | loss_cls: 0.0521 | loss_box_reg: 0.1872 | loss_mask: 0.1064 | loss_rpn_cls: 0.0167 | loss_rpn_loc: 0.0089 | Total Loss: 0.3713\n",
      "Epoch 1796 | loss_cls: 0.0633 | loss_box_reg: 0.2153 | loss_mask: 0.1032 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.0135 | Total Loss: 0.3978\n",
      "Epoch 1797 | loss_cls: 0.0969 | loss_box_reg: 0.1848 | loss_mask: 0.0500 | loss_rpn_cls: 0.0095 | loss_rpn_loc: 0.0925 | Total Loss: 0.4338\n",
      "Epoch 1798 | loss_cls: 0.0439 | loss_box_reg: 0.2451 | loss_mask: 0.2229 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.0042 | Total Loss: 0.5180\n",
      "Epoch 1799 | loss_cls: 0.1219 | loss_box_reg: 0.2184 | loss_mask: 0.0810 | loss_rpn_cls: 0.0061 | loss_rpn_loc: 0.1159 | Total Loss: 0.5434\n",
      "\u001b[32m[07/29 18:31:12 d2.utils.events]: \u001b[0m eta: 0:07:45  iter: 1799      time: 0.3325  last_time: 0.3983   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1800 | loss_cls: 0.1127 | loss_box_reg: 0.1846 | loss_mask: 0.0591 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.1391 | Total Loss: 0.5005\n",
      "Epoch 1801 | loss_cls: 0.0634 | loss_box_reg: 0.2502 | loss_mask: 0.2249 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.0217 | Total Loss: 0.5615\n",
      "Epoch 1802 | loss_cls: 0.0457 | loss_box_reg: 0.1427 | loss_mask: 0.2952 | loss_rpn_cls: 0.0161 | loss_rpn_loc: 0.0733 | Total Loss: 0.5730\n",
      "Epoch 1803 | loss_cls: 0.0562 | loss_box_reg: 0.1600 | loss_mask: 0.0449 | loss_rpn_cls: 0.0066 | loss_rpn_loc: 0.0596 | Total Loss: 0.3272\n",
      "Epoch 1804 | loss_cls: 0.0729 | loss_box_reg: 0.1948 | loss_mask: 0.0686 | loss_rpn_cls: 0.0157 | loss_rpn_loc: 0.1504 | Total Loss: 0.5025\n",
      "Epoch 1805 | loss_cls: 0.0464 | loss_box_reg: 0.0507 | loss_mask: 0.0819 | loss_rpn_cls: 0.0040 | loss_rpn_loc: 0.0134 | Total Loss: 0.1965\n",
      "Epoch 1806 | loss_cls: 0.0335 | loss_box_reg: 0.1433 | loss_mask: 0.0532 | loss_rpn_cls: 0.0047 | loss_rpn_loc: 0.1025 | Total Loss: 0.3374\n",
      "Epoch 1807 | loss_cls: 0.0811 | loss_box_reg: 0.1342 | loss_mask: 0.0745 | loss_rpn_cls: 0.0080 | loss_rpn_loc: 0.1332 | Total Loss: 0.4309\n",
      "Epoch 1808 | loss_cls: 0.0436 | loss_box_reg: 0.0781 | loss_mask: 0.2211 | loss_rpn_cls: 0.0054 | loss_rpn_loc: 0.1062 | Total Loss: 0.4544\n",
      "Epoch 1809 | loss_cls: 0.1415 | loss_box_reg: 0.2519 | loss_mask: 0.1059 | loss_rpn_cls: 0.0063 | loss_rpn_loc: 0.0116 | Total Loss: 0.5173\n",
      "Epoch 1810 | loss_cls: 0.0582 | loss_box_reg: 0.1718 | loss_mask: 0.1818 | loss_rpn_cls: 0.0003 | loss_rpn_loc: 0.0117 | Total Loss: 0.4237\n",
      "Epoch 1811 | loss_cls: 0.0241 | loss_box_reg: 0.2020 | loss_mask: 0.1531 | loss_rpn_cls: 0.0042 | loss_rpn_loc: 0.0214 | Total Loss: 0.4047\n",
      "Epoch 1812 | loss_cls: 0.0937 | loss_box_reg: 0.1196 | loss_mask: 0.0598 | loss_rpn_cls: 0.0022 | loss_rpn_loc: 0.0313 | Total Loss: 0.3065\n",
      "Epoch 1813 | loss_cls: 0.0764 | loss_box_reg: 0.1815 | loss_mask: 0.1386 | loss_rpn_cls: 0.0018 | loss_rpn_loc: 0.0264 | Total Loss: 0.4248\n",
      "Epoch 1814 | loss_cls: 0.0349 | loss_box_reg: 0.0378 | loss_mask: 0.2768 | loss_rpn_cls: 0.0061 | loss_rpn_loc: 0.1002 | Total Loss: 0.4558\n",
      "Epoch 1815 | loss_cls: 0.0773 | loss_box_reg: 0.3280 | loss_mask: 0.1833 | loss_rpn_cls: 0.0029 | loss_rpn_loc: 0.0997 | Total Loss: 0.6912\n",
      "Epoch 1816 | loss_cls: 0.0904 | loss_box_reg: 0.1758 | loss_mask: 0.1229 | loss_rpn_cls: 0.0220 | loss_rpn_loc: 0.1106 | Total Loss: 0.5217\n",
      "Epoch 1817 | loss_cls: 0.0278 | loss_box_reg: 0.1054 | loss_mask: 0.0523 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.0018 | Total Loss: 0.1878\n",
      "Epoch 1818 | loss_cls: 0.0751 | loss_box_reg: 0.2683 | loss_mask: 0.0889 | loss_rpn_cls: 0.0048 | loss_rpn_loc: 0.0101 | Total Loss: 0.4472\n",
      "Epoch 1819 | loss_cls: 0.0799 | loss_box_reg: 0.0894 | loss_mask: 0.0459 | loss_rpn_cls: 0.0091 | loss_rpn_loc: 0.0804 | Total Loss: 0.3047\n",
      "\u001b[32m[07/29 18:31:18 d2.utils.events]: \u001b[0m eta: 0:07:37  iter: 1819      time: 0.3324  last_time: 0.4035   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1820 | loss_cls: 0.0626 | loss_box_reg: 0.1908 | loss_mask: 0.0679 | loss_rpn_cls: 0.0090 | loss_rpn_loc: 0.0670 | Total Loss: 0.3973\n",
      "Epoch 1821 | loss_cls: 0.0467 | loss_box_reg: 0.1244 | loss_mask: 0.0414 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0045 | Total Loss: 0.2174\n",
      "Epoch 1822 | loss_cls: 0.1456 | loss_box_reg: 0.2600 | loss_mask: 0.2139 | loss_rpn_cls: 0.0046 | loss_rpn_loc: 0.0934 | Total Loss: 0.7175\n",
      "Epoch 1823 | loss_cls: 0.0784 | loss_box_reg: 0.1200 | loss_mask: 0.0909 | loss_rpn_cls: 0.0028 | loss_rpn_loc: 0.0277 | Total Loss: 0.3198\n",
      "Epoch 1824 | loss_cls: 0.0578 | loss_box_reg: 0.2053 | loss_mask: 0.1079 | loss_rpn_cls: 0.0017 | loss_rpn_loc: 0.0201 | Total Loss: 0.3929\n",
      "Epoch 1825 | loss_cls: 0.0457 | loss_box_reg: 0.1164 | loss_mask: 0.0830 | loss_rpn_cls: 0.0141 | loss_rpn_loc: 0.0071 | Total Loss: 0.2662\n",
      "Epoch 1826 | loss_cls: 0.0924 | loss_box_reg: 0.2147 | loss_mask: 0.2037 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.1817 | Total Loss: 0.6938\n",
      "Epoch 1827 | loss_cls: 0.0753 | loss_box_reg: 0.1042 | loss_mask: 0.0859 | loss_rpn_cls: 0.0020 | loss_rpn_loc: 0.0028 | Total Loss: 0.2703\n",
      "Epoch 1828 | loss_cls: 0.0298 | loss_box_reg: 0.1225 | loss_mask: 0.2108 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.0272 | Total Loss: 0.3953\n",
      "Epoch 1829 | loss_cls: 0.1200 | loss_box_reg: 0.2288 | loss_mask: 0.1792 | loss_rpn_cls: 0.0106 | loss_rpn_loc: 0.0947 | Total Loss: 0.6332\n",
      "Epoch 1830 | loss_cls: 0.1285 | loss_box_reg: 0.2542 | loss_mask: 0.0951 | loss_rpn_cls: 0.0049 | loss_rpn_loc: 0.0878 | Total Loss: 0.5704\n",
      "Epoch 1831 | loss_cls: 0.0425 | loss_box_reg: 0.0495 | loss_mask: 0.1129 | loss_rpn_cls: 0.0072 | loss_rpn_loc: 0.1122 | Total Loss: 0.3244\n",
      "Epoch 1832 | loss_cls: 0.0535 | loss_box_reg: 0.1385 | loss_mask: 0.0897 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.1363 | Total Loss: 0.4214\n",
      "Epoch 1833 | loss_cls: 0.0966 | loss_box_reg: 0.1306 | loss_mask: 0.0823 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.0135 | Total Loss: 0.3244\n",
      "Epoch 1834 | loss_cls: 0.0804 | loss_box_reg: 0.2642 | loss_mask: 0.0647 | loss_rpn_cls: 0.0059 | loss_rpn_loc: 0.2049 | Total Loss: 0.6200\n",
      "Epoch 1835 | loss_cls: 0.0469 | loss_box_reg: 0.1793 | loss_mask: 0.2435 | loss_rpn_cls: 0.0003 | loss_rpn_loc: 0.0107 | Total Loss: 0.4807\n",
      "Epoch 1836 | loss_cls: 0.0247 | loss_box_reg: 0.0538 | loss_mask: 0.0985 | loss_rpn_cls: 0.0029 | loss_rpn_loc: 0.1296 | Total Loss: 0.3096\n",
      "Epoch 1837 | loss_cls: 0.0533 | loss_box_reg: 0.1342 | loss_mask: 0.3251 | loss_rpn_cls: 0.0040 | loss_rpn_loc: 0.0430 | Total Loss: 0.5596\n",
      "Epoch 1838 | loss_cls: 0.0766 | loss_box_reg: 0.1448 | loss_mask: 0.1882 | loss_rpn_cls: 0.0200 | loss_rpn_loc: 0.0920 | Total Loss: 0.5216\n",
      "Epoch 1839 | loss_cls: 0.0252 | loss_box_reg: 0.0928 | loss_mask: 0.0379 | loss_rpn_cls: 0.0002 | loss_rpn_loc: 0.0019 | Total Loss: 0.1581\n",
      "\u001b[32m[07/29 18:31:25 d2.utils.events]: \u001b[0m eta: 0:07:29  iter: 1839      time: 0.3326  last_time: 0.2850   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1840 | loss_cls: 0.0232 | loss_box_reg: 0.1327 | loss_mask: 0.0762 | loss_rpn_cls: 0.0062 | loss_rpn_loc: 0.1140 | Total Loss: 0.3522\n",
      "Epoch 1841 | loss_cls: 0.0386 | loss_box_reg: 0.1680 | loss_mask: 0.0324 | loss_rpn_cls: 0.0001 | loss_rpn_loc: 0.0031 | Total Loss: 0.2421\n",
      "Epoch 1842 | loss_cls: 0.0269 | loss_box_reg: 0.1126 | loss_mask: 0.0531 | loss_rpn_cls: 0.0065 | loss_rpn_loc: 0.0799 | Total Loss: 0.2790\n",
      "Epoch 1843 | loss_cls: 0.0703 | loss_box_reg: 0.2287 | loss_mask: 0.1894 | loss_rpn_cls: 0.0017 | loss_rpn_loc: 0.1742 | Total Loss: 0.6643\n",
      "Epoch 1844 | loss_cls: 0.0815 | loss_box_reg: 0.2216 | loss_mask: 0.1010 | loss_rpn_cls: 0.0080 | loss_rpn_loc: 0.0197 | Total Loss: 0.4317\n",
      "Epoch 1845 | loss_cls: 0.0640 | loss_box_reg: 0.1471 | loss_mask: 0.0848 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0158 | Total Loss: 0.3123\n",
      "Epoch 1846 | loss_cls: 0.0764 | loss_box_reg: 0.2763 | loss_mask: 0.1530 | loss_rpn_cls: 0.0163 | loss_rpn_loc: 0.0799 | Total Loss: 0.6018\n",
      "Epoch 1847 | loss_cls: 0.0563 | loss_box_reg: 0.1598 | loss_mask: 0.0441 | loss_rpn_cls: 0.0039 | loss_rpn_loc: 0.0778 | Total Loss: 0.3419\n",
      "Epoch 1848 | loss_cls: 0.1125 | loss_box_reg: 0.2797 | loss_mask: 0.0737 | loss_rpn_cls: 0.0116 | loss_rpn_loc: 0.0711 | Total Loss: 0.5485\n",
      "Epoch 1849 | loss_cls: 0.0384 | loss_box_reg: 0.1584 | loss_mask: 0.1268 | loss_rpn_cls: 0.0030 | loss_rpn_loc: 0.0405 | Total Loss: 0.3671\n",
      "Epoch 1850 | loss_cls: 0.1122 | loss_box_reg: 0.1643 | loss_mask: 0.1218 | loss_rpn_cls: 0.0029 | loss_rpn_loc: 0.0375 | Total Loss: 0.4386\n",
      "Epoch 1851 | loss_cls: 0.0341 | loss_box_reg: 0.1193 | loss_mask: 0.0565 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.1316 | Total Loss: 0.3428\n",
      "Epoch 1852 | loss_cls: 0.0428 | loss_box_reg: 0.1130 | loss_mask: 0.0787 | loss_rpn_cls: 0.0016 | loss_rpn_loc: 0.0194 | Total Loss: 0.2555\n",
      "Epoch 1853 | loss_cls: 0.1364 | loss_box_reg: 0.2007 | loss_mask: 0.0664 | loss_rpn_cls: 0.0167 | loss_rpn_loc: 0.0326 | Total Loss: 0.4527\n",
      "Epoch 1854 | loss_cls: 0.0531 | loss_box_reg: 0.1070 | loss_mask: 0.0611 | loss_rpn_cls: 0.0079 | loss_rpn_loc: 0.0370 | Total Loss: 0.2662\n",
      "Epoch 1855 | loss_cls: 0.0439 | loss_box_reg: 0.0929 | loss_mask: 0.0894 | loss_rpn_cls: 0.0022 | loss_rpn_loc: 0.1090 | Total Loss: 0.3375\n",
      "Epoch 1856 | loss_cls: 0.0919 | loss_box_reg: 0.2185 | loss_mask: 0.1169 | loss_rpn_cls: 0.0073 | loss_rpn_loc: 0.0510 | Total Loss: 0.4856\n",
      "Epoch 1857 | loss_cls: 0.0279 | loss_box_reg: 0.0609 | loss_mask: 0.1066 | loss_rpn_cls: 0.0164 | loss_rpn_loc: 0.1074 | Total Loss: 0.3193\n",
      "Epoch 1858 | loss_cls: 0.0732 | loss_box_reg: 0.1258 | loss_mask: 0.0550 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0082 | Total Loss: 0.2625\n",
      "Epoch 1859 | loss_cls: 0.0507 | loss_box_reg: 0.1206 | loss_mask: 0.1477 | loss_rpn_cls: 0.0220 | loss_rpn_loc: 0.1845 | Total Loss: 0.5254\n",
      "\u001b[32m[07/29 18:31:32 d2.utils.events]: \u001b[0m eta: 0:07:22  iter: 1859      time: 0.3329  last_time: 0.4054   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1860 | loss_cls: 0.0441 | loss_box_reg: 0.1001 | loss_mask: 0.1136 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0235 | Total Loss: 0.2818\n",
      "Epoch 1861 | loss_cls: 0.1240 | loss_box_reg: 0.1794 | loss_mask: 0.1322 | loss_rpn_cls: 0.0185 | loss_rpn_loc: 0.0096 | Total Loss: 0.4637\n",
      "Epoch 1862 | loss_cls: 0.0461 | loss_box_reg: 0.1190 | loss_mask: 0.2016 | loss_rpn_cls: 0.0104 | loss_rpn_loc: 0.0950 | Total Loss: 0.4720\n",
      "Epoch 1863 | loss_cls: 0.0543 | loss_box_reg: 0.1503 | loss_mask: 0.1920 | loss_rpn_cls: 0.0151 | loss_rpn_loc: 0.1042 | Total Loss: 0.5158\n",
      "Epoch 1864 | loss_cls: 0.0460 | loss_box_reg: 0.1665 | loss_mask: 0.1449 | loss_rpn_cls: 0.0009 | loss_rpn_loc: 0.0425 | Total Loss: 0.4008\n",
      "Epoch 1865 | loss_cls: 0.1192 | loss_box_reg: 0.2406 | loss_mask: 0.0735 | loss_rpn_cls: 0.0167 | loss_rpn_loc: 0.0616 | Total Loss: 0.5116\n",
      "Epoch 1866 | loss_cls: 0.0314 | loss_box_reg: 0.0866 | loss_mask: 0.0865 | loss_rpn_cls: 0.0065 | loss_rpn_loc: 0.0763 | Total Loss: 0.2872\n",
      "Epoch 1867 | loss_cls: 0.0454 | loss_box_reg: 0.1101 | loss_mask: 0.0613 | loss_rpn_cls: 0.0039 | loss_rpn_loc: 0.0476 | Total Loss: 0.2683\n",
      "Epoch 1868 | loss_cls: 0.0322 | loss_box_reg: 0.1231 | loss_mask: 0.0436 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.0110 | Total Loss: 0.2133\n",
      "Epoch 1869 | loss_cls: 0.1213 | loss_box_reg: 0.1870 | loss_mask: 0.0589 | loss_rpn_cls: 0.0181 | loss_rpn_loc: 0.1339 | Total Loss: 0.5192\n",
      "Epoch 1870 | loss_cls: 0.0568 | loss_box_reg: 0.1237 | loss_mask: 0.0355 | loss_rpn_cls: 0.0093 | loss_rpn_loc: 0.0451 | Total Loss: 0.2704\n",
      "Epoch 1871 | loss_cls: 0.1264 | loss_box_reg: 0.2307 | loss_mask: 0.0577 | loss_rpn_cls: 0.0162 | loss_rpn_loc: 0.2475 | Total Loss: 0.6785\n",
      "Epoch 1872 | loss_cls: 0.0452 | loss_box_reg: 0.1562 | loss_mask: 0.1945 | loss_rpn_cls: 0.0061 | loss_rpn_loc: 0.0469 | Total Loss: 0.4489\n",
      "Epoch 1873 | loss_cls: 0.0387 | loss_box_reg: 0.0870 | loss_mask: 0.0759 | loss_rpn_cls: 0.0045 | loss_rpn_loc: 0.0167 | Total Loss: 0.2228\n",
      "Epoch 1874 | loss_cls: 0.0235 | loss_box_reg: 0.0964 | loss_mask: 0.1234 | loss_rpn_cls: 0.0020 | loss_rpn_loc: 0.0147 | Total Loss: 0.2601\n",
      "Epoch 1875 | loss_cls: 0.0498 | loss_box_reg: 0.1699 | loss_mask: 0.0681 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.0266 | Total Loss: 0.3194\n",
      "Epoch 1876 | loss_cls: 0.0300 | loss_box_reg: 0.0472 | loss_mask: 0.0542 | loss_rpn_cls: 0.0046 | loss_rpn_loc: 0.0076 | Total Loss: 0.1437\n",
      "Epoch 1877 | loss_cls: 0.0619 | loss_box_reg: 0.2033 | loss_mask: 0.0457 | loss_rpn_cls: 0.0150 | loss_rpn_loc: 0.0353 | Total Loss: 0.3612\n",
      "Epoch 1878 | loss_cls: 0.0395 | loss_box_reg: 0.0807 | loss_mask: 0.1126 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.0156 | Total Loss: 0.2494\n",
      "Epoch 1879 | loss_cls: 0.0661 | loss_box_reg: 0.2241 | loss_mask: 0.0588 | loss_rpn_cls: 0.0101 | loss_rpn_loc: 0.0824 | Total Loss: 0.4414\n",
      "\u001b[32m[07/29 18:31:39 d2.utils.events]: \u001b[0m eta: 0:07:14  iter: 1879      time: 0.3329  last_time: 0.4161   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1880 | loss_cls: 0.0973 | loss_box_reg: 0.1820 | loss_mask: 0.0511 | loss_rpn_cls: 0.1525 | loss_rpn_loc: 0.2308 | Total Loss: 0.7136\n",
      "Epoch 1881 | loss_cls: 0.1057 | loss_box_reg: 0.2655 | loss_mask: 0.0709 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.0581 | Total Loss: 0.5021\n",
      "Epoch 1882 | loss_cls: 0.0356 | loss_box_reg: 0.0552 | loss_mask: 0.1423 | loss_rpn_cls: 0.0183 | loss_rpn_loc: 0.1459 | Total Loss: 0.3973\n",
      "Epoch 1883 | loss_cls: 0.0920 | loss_box_reg: 0.0947 | loss_mask: 0.0409 | loss_rpn_cls: 0.0383 | loss_rpn_loc: 0.1693 | Total Loss: 0.4353\n",
      "Epoch 1884 | loss_cls: 0.0748 | loss_box_reg: 0.0718 | loss_mask: 0.0454 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.0086 | Total Loss: 0.2020\n",
      "Epoch 1885 | loss_cls: 0.1071 | loss_box_reg: 0.2065 | loss_mask: 0.1128 | loss_rpn_cls: 0.0079 | loss_rpn_loc: 0.1080 | Total Loss: 0.5422\n",
      "Epoch 1886 | loss_cls: 0.0633 | loss_box_reg: 0.1019 | loss_mask: 0.1503 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.0165 | Total Loss: 0.3372\n",
      "Epoch 1887 | loss_cls: 0.1089 | loss_box_reg: 0.1118 | loss_mask: 0.0865 | loss_rpn_cls: 0.0045 | loss_rpn_loc: 0.0067 | Total Loss: 0.3182\n",
      "Epoch 1888 | loss_cls: 0.0953 | loss_box_reg: 0.1352 | loss_mask: 0.0412 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.0095 | Total Loss: 0.2821\n",
      "Epoch 1889 | loss_cls: 0.0992 | loss_box_reg: 0.1050 | loss_mask: 0.0582 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.0184 | Total Loss: 0.2822\n",
      "Epoch 1890 | loss_cls: 0.0513 | loss_box_reg: 0.0592 | loss_mask: 0.0305 | loss_rpn_cls: 0.0249 | loss_rpn_loc: 0.1488 | Total Loss: 0.3147\n",
      "Epoch 1891 | loss_cls: 0.0810 | loss_box_reg: 0.1582 | loss_mask: 0.1365 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.2494 | Total Loss: 0.6300\n",
      "Epoch 1892 | loss_cls: 0.0593 | loss_box_reg: 0.1406 | loss_mask: 0.2052 | loss_rpn_cls: 0.0283 | loss_rpn_loc: 0.1547 | Total Loss: 0.5881\n",
      "Epoch 1893 | loss_cls: 0.0590 | loss_box_reg: 0.2372 | loss_mask: 0.0900 | loss_rpn_cls: 0.0133 | loss_rpn_loc: 0.0931 | Total Loss: 0.4926\n",
      "Epoch 1894 | loss_cls: 0.0659 | loss_box_reg: 0.1638 | loss_mask: 0.0559 | loss_rpn_cls: 0.0046 | loss_rpn_loc: 0.0230 | Total Loss: 0.3132\n",
      "Epoch 1895 | loss_cls: 0.0473 | loss_box_reg: 0.1187 | loss_mask: 0.0423 | loss_rpn_cls: 0.0058 | loss_rpn_loc: 0.0344 | Total Loss: 0.2485\n",
      "Epoch 1896 | loss_cls: 0.0638 | loss_box_reg: 0.1194 | loss_mask: 0.1059 | loss_rpn_cls: 0.0037 | loss_rpn_loc: 0.1341 | Total Loss: 0.4270\n",
      "Epoch 1897 | loss_cls: 0.0757 | loss_box_reg: 0.2363 | loss_mask: 0.1492 | loss_rpn_cls: 0.0124 | loss_rpn_loc: 0.1247 | Total Loss: 0.5983\n",
      "Epoch 1898 | loss_cls: 0.1126 | loss_box_reg: 0.4543 | loss_mask: 0.2675 | loss_rpn_cls: 0.0125 | loss_rpn_loc: 0.0093 | Total Loss: 0.8562\n",
      "Epoch 1899 | loss_cls: 0.1500 | loss_box_reg: 0.4014 | loss_mask: 0.1797 | loss_rpn_cls: 0.0099 | loss_rpn_loc: 0.0203 | Total Loss: 0.7613\n",
      "\u001b[32m[07/29 18:31:45 d2.utils.events]: \u001b[0m eta: 0:07:06  iter: 1899      time: 0.3327  last_time: 0.2783   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1900 | loss_cls: 0.0270 | loss_box_reg: 0.0386 | loss_mask: 0.0475 | loss_rpn_cls: 0.0107 | loss_rpn_loc: 0.1281 | Total Loss: 0.2518\n",
      "Epoch 1901 | loss_cls: 0.0334 | loss_box_reg: 0.0987 | loss_mask: 0.0604 | loss_rpn_cls: 0.0044 | loss_rpn_loc: 0.0288 | Total Loss: 0.2256\n",
      "Epoch 1902 | loss_cls: 0.0368 | loss_box_reg: 0.1067 | loss_mask: 0.1095 | loss_rpn_cls: 0.0183 | loss_rpn_loc: 0.2047 | Total Loss: 0.4760\n",
      "Epoch 1903 | loss_cls: 0.0872 | loss_box_reg: 0.1763 | loss_mask: 0.1213 | loss_rpn_cls: 0.0334 | loss_rpn_loc: 0.1613 | Total Loss: 0.5796\n",
      "Epoch 1904 | loss_cls: 0.0566 | loss_box_reg: 0.1860 | loss_mask: 0.0667 | loss_rpn_cls: 0.0082 | loss_rpn_loc: 0.0838 | Total Loss: 0.4013\n",
      "Epoch 1905 | loss_cls: 0.0748 | loss_box_reg: 0.1364 | loss_mask: 0.0929 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.2132 | Total Loss: 0.5207\n",
      "Epoch 1906 | loss_cls: 0.0750 | loss_box_reg: 0.0987 | loss_mask: 0.0437 | loss_rpn_cls: 0.0096 | loss_rpn_loc: 0.0027 | Total Loss: 0.2298\n",
      "Epoch 1907 | loss_cls: 0.0710 | loss_box_reg: 0.1902 | loss_mask: 0.0987 | loss_rpn_cls: 0.0500 | loss_rpn_loc: 0.0829 | Total Loss: 0.4929\n",
      "Epoch 1908 | loss_cls: 0.0466 | loss_box_reg: 0.1617 | loss_mask: 0.0618 | loss_rpn_cls: 0.0178 | loss_rpn_loc: 0.0690 | Total Loss: 0.3569\n",
      "Epoch 1909 | loss_cls: 0.0553 | loss_box_reg: 0.1642 | loss_mask: 0.2994 | loss_rpn_cls: 0.0116 | loss_rpn_loc: 0.0026 | Total Loss: 0.5332\n",
      "Epoch 1910 | loss_cls: 0.0566 | loss_box_reg: 0.1343 | loss_mask: 0.1475 | loss_rpn_cls: 0.0058 | loss_rpn_loc: 0.0084 | Total Loss: 0.3526\n",
      "Epoch 1911 | loss_cls: 0.0507 | loss_box_reg: 0.2030 | loss_mask: 0.0846 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.0050 | Total Loss: 0.3439\n",
      "Epoch 1912 | loss_cls: 0.0385 | loss_box_reg: 0.0948 | loss_mask: 0.0530 | loss_rpn_cls: 0.0060 | loss_rpn_loc: 0.0481 | Total Loss: 0.2404\n",
      "Epoch 1913 | loss_cls: 0.0523 | loss_box_reg: 0.0695 | loss_mask: 0.0746 | loss_rpn_cls: 0.0123 | loss_rpn_loc: 0.1196 | Total Loss: 0.3284\n",
      "Epoch 1914 | loss_cls: 0.0656 | loss_box_reg: 0.1493 | loss_mask: 0.0534 | loss_rpn_cls: 0.0036 | loss_rpn_loc: 0.0165 | Total Loss: 0.2884\n",
      "Epoch 1915 | loss_cls: 0.0724 | loss_box_reg: 0.1300 | loss_mask: 0.2274 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.0536 | Total Loss: 0.4849\n",
      "Epoch 1916 | loss_cls: 0.0439 | loss_box_reg: 0.0474 | loss_mask: 0.1733 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0024 | Total Loss: 0.2677\n",
      "Epoch 1917 | loss_cls: 0.0445 | loss_box_reg: 0.1191 | loss_mask: 0.0687 | loss_rpn_cls: 0.0045 | loss_rpn_loc: 0.0433 | Total Loss: 0.2801\n",
      "Epoch 1918 | loss_cls: 0.0289 | loss_box_reg: 0.0925 | loss_mask: 0.1317 | loss_rpn_cls: 0.0066 | loss_rpn_loc: 0.1360 | Total Loss: 0.3958\n",
      "Epoch 1919 | loss_cls: 0.0481 | loss_box_reg: 0.1538 | loss_mask: 0.0855 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.0405 | Total Loss: 0.3313\n",
      "\u001b[32m[07/29 18:31:52 d2.utils.events]: \u001b[0m eta: 0:06:59  iter: 1919      time: 0.3327  last_time: 0.2736   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1920 | loss_cls: 0.0996 | loss_box_reg: 0.2051 | loss_mask: 0.1303 | loss_rpn_cls: 0.0046 | loss_rpn_loc: 0.1130 | Total Loss: 0.5525\n",
      "Epoch 1921 | loss_cls: 0.0596 | loss_box_reg: 0.1658 | loss_mask: 0.0936 | loss_rpn_cls: 0.0057 | loss_rpn_loc: 0.0020 | Total Loss: 0.3268\n",
      "Epoch 1922 | loss_cls: 0.0412 | loss_box_reg: 0.1502 | loss_mask: 0.0900 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.2295 | Total Loss: 0.5136\n",
      "Epoch 1923 | loss_cls: 0.1323 | loss_box_reg: 0.2423 | loss_mask: 0.0583 | loss_rpn_cls: 0.0133 | loss_rpn_loc: 0.2474 | Total Loss: 0.6936\n",
      "Epoch 1924 | loss_cls: 0.0793 | loss_box_reg: 0.2021 | loss_mask: 0.0859 | loss_rpn_cls: 0.0112 | loss_rpn_loc: 0.1309 | Total Loss: 0.5093\n",
      "Epoch 1925 | loss_cls: 0.0676 | loss_box_reg: 0.1166 | loss_mask: 0.0631 | loss_rpn_cls: 0.0285 | loss_rpn_loc: 0.0059 | Total Loss: 0.2817\n",
      "Epoch 1926 | loss_cls: 0.0418 | loss_box_reg: 0.0800 | loss_mask: 0.7392 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.0213 | Total Loss: 0.8829\n",
      "Epoch 1927 | loss_cls: 0.0301 | loss_box_reg: 0.0956 | loss_mask: 0.0704 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0103 | Total Loss: 0.2068\n",
      "Epoch 1928 | loss_cls: 0.1467 | loss_box_reg: 0.2862 | loss_mask: 0.0523 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.0225 | Total Loss: 0.5091\n",
      "Epoch 1929 | loss_cls: 0.0487 | loss_box_reg: 0.1688 | loss_mask: 0.0968 | loss_rpn_cls: 0.0169 | loss_rpn_loc: 0.0351 | Total Loss: 0.3663\n",
      "Epoch 1930 | loss_cls: 0.0369 | loss_box_reg: 0.0739 | loss_mask: 0.0579 | loss_rpn_cls: 0.0068 | loss_rpn_loc: 0.0204 | Total Loss: 0.1959\n",
      "Epoch 1931 | loss_cls: 0.0625 | loss_box_reg: 0.1413 | loss_mask: 0.0602 | loss_rpn_cls: 0.0251 | loss_rpn_loc: 0.0098 | Total Loss: 0.2988\n",
      "Epoch 1932 | loss_cls: 0.0871 | loss_box_reg: 0.2448 | loss_mask: 0.0665 | loss_rpn_cls: 0.0097 | loss_rpn_loc: 0.3600 | Total Loss: 0.7681\n",
      "Epoch 1933 | loss_cls: 0.0541 | loss_box_reg: 0.1394 | loss_mask: 0.0753 | loss_rpn_cls: 0.0035 | loss_rpn_loc: 0.0949 | Total Loss: 0.3673\n",
      "Epoch 1934 | loss_cls: 0.0414 | loss_box_reg: 0.1380 | loss_mask: 0.1611 | loss_rpn_cls: 0.0046 | loss_rpn_loc: 0.0243 | Total Loss: 0.3694\n",
      "Epoch 1935 | loss_cls: 0.0441 | loss_box_reg: 0.0622 | loss_mask: 0.2186 | loss_rpn_cls: 0.0016 | loss_rpn_loc: 0.0168 | Total Loss: 0.3433\n",
      "Epoch 1936 | loss_cls: 0.0457 | loss_box_reg: 0.1841 | loss_mask: 0.2882 | loss_rpn_cls: 0.0073 | loss_rpn_loc: 0.1057 | Total Loss: 0.6310\n",
      "Epoch 1937 | loss_cls: 0.0528 | loss_box_reg: 0.1361 | loss_mask: 0.0907 | loss_rpn_cls: 0.0022 | loss_rpn_loc: 0.0050 | Total Loss: 0.2868\n",
      "Epoch 1938 | loss_cls: 0.0444 | loss_box_reg: 0.1663 | loss_mask: 0.1761 | loss_rpn_cls: 0.0442 | loss_rpn_loc: 0.0708 | Total Loss: 0.5018\n",
      "Epoch 1939 | loss_cls: 0.0856 | loss_box_reg: 0.2198 | loss_mask: 0.0978 | loss_rpn_cls: 0.0026 | loss_rpn_loc: 0.0107 | Total Loss: 0.4166\n",
      "\u001b[32m[07/29 18:31:59 d2.utils.events]: \u001b[0m eta: 0:06:51  iter: 1939      time: 0.3327  last_time: 0.2904   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1940 | loss_cls: 0.0662 | loss_box_reg: 0.1688 | loss_mask: 0.0407 | loss_rpn_cls: 0.0115 | loss_rpn_loc: 0.1058 | Total Loss: 0.3929\n",
      "Epoch 1941 | loss_cls: 0.0492 | loss_box_reg: 0.1086 | loss_mask: 0.0726 | loss_rpn_cls: 0.0133 | loss_rpn_loc: 0.0077 | Total Loss: 0.2513\n",
      "Epoch 1942 | loss_cls: 0.0593 | loss_box_reg: 0.3616 | loss_mask: 0.0600 | loss_rpn_cls: 0.0075 | loss_rpn_loc: 0.0064 | Total Loss: 0.4947\n",
      "Epoch 1943 | loss_cls: 0.0614 | loss_box_reg: 0.1841 | loss_mask: 0.0791 | loss_rpn_cls: 0.0093 | loss_rpn_loc: 0.0072 | Total Loss: 0.3411\n",
      "Epoch 1944 | loss_cls: 0.0904 | loss_box_reg: 0.1473 | loss_mask: 0.0523 | loss_rpn_cls: 0.0127 | loss_rpn_loc: 0.0574 | Total Loss: 0.3600\n",
      "Epoch 1945 | loss_cls: 0.0435 | loss_box_reg: 0.0717 | loss_mask: 0.2897 | loss_rpn_cls: 0.0083 | loss_rpn_loc: 0.0309 | Total Loss: 0.4442\n",
      "Epoch 1946 | loss_cls: 0.0298 | loss_box_reg: 0.0746 | loss_mask: 0.0430 | loss_rpn_cls: 0.0138 | loss_rpn_loc: 0.1763 | Total Loss: 0.3375\n",
      "Epoch 1947 | loss_cls: 0.0396 | loss_box_reg: 0.0867 | loss_mask: 0.0526 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.1051 | Total Loss: 0.2850\n",
      "Epoch 1948 | loss_cls: 0.0510 | loss_box_reg: 0.1379 | loss_mask: 0.1577 | loss_rpn_cls: 0.0179 | loss_rpn_loc: 0.0240 | Total Loss: 0.3884\n",
      "Epoch 1949 | loss_cls: 0.0921 | loss_box_reg: 0.3160 | loss_mask: 0.1739 | loss_rpn_cls: 0.0053 | loss_rpn_loc: 0.0746 | Total Loss: 0.6619\n",
      "Epoch 1950 | loss_cls: 0.0578 | loss_box_reg: 0.1723 | loss_mask: 0.2087 | loss_rpn_cls: 0.0241 | loss_rpn_loc: 0.1259 | Total Loss: 0.5887\n",
      "Epoch 1951 | loss_cls: 0.0277 | loss_box_reg: 0.0853 | loss_mask: 0.0697 | loss_rpn_cls: 0.0022 | loss_rpn_loc: 0.0047 | Total Loss: 0.1896\n",
      "Epoch 1952 | loss_cls: 0.1381 | loss_box_reg: 0.4571 | loss_mask: 0.2002 | loss_rpn_cls: 0.0041 | loss_rpn_loc: 0.0341 | Total Loss: 0.8337\n",
      "Epoch 1953 | loss_cls: 0.0383 | loss_box_reg: 0.1003 | loss_mask: 0.0782 | loss_rpn_cls: 0.0084 | loss_rpn_loc: 0.0197 | Total Loss: 0.2449\n",
      "Epoch 1954 | loss_cls: 0.0559 | loss_box_reg: 0.1496 | loss_mask: 0.0949 | loss_rpn_cls: 0.0021 | loss_rpn_loc: 0.0308 | Total Loss: 0.3333\n",
      "Epoch 1955 | loss_cls: 0.1180 | loss_box_reg: 0.2202 | loss_mask: 0.0633 | loss_rpn_cls: 0.0017 | loss_rpn_loc: 0.0258 | Total Loss: 0.4290\n",
      "Epoch 1956 | loss_cls: 0.0505 | loss_box_reg: 0.0867 | loss_mask: 0.0684 | loss_rpn_cls: 0.0125 | loss_rpn_loc: 0.1037 | Total Loss: 0.3217\n",
      "Epoch 1957 | loss_cls: 0.1031 | loss_box_reg: 0.2928 | loss_mask: 0.0684 | loss_rpn_cls: 0.0182 | loss_rpn_loc: 0.2967 | Total Loss: 0.7793\n",
      "Epoch 1958 | loss_cls: 0.0479 | loss_box_reg: 0.2566 | loss_mask: 0.0799 | loss_rpn_cls: 0.0110 | loss_rpn_loc: 0.0052 | Total Loss: 0.4007\n",
      "Epoch 1959 | loss_cls: 0.1439 | loss_box_reg: 0.2730 | loss_mask: 0.0517 | loss_rpn_cls: 0.0054 | loss_rpn_loc: 0.0298 | Total Loss: 0.5039\n",
      "\u001b[32m[07/29 18:32:05 d2.utils.events]: \u001b[0m eta: 0:06:43  iter: 1959      time: 0.3327  last_time: 0.4013   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1960 | loss_cls: 0.0480 | loss_box_reg: 0.0686 | loss_mask: 0.0566 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.0795 | Total Loss: 0.2540\n",
      "Epoch 1961 | loss_cls: 0.0292 | loss_box_reg: 0.1370 | loss_mask: 0.1344 | loss_rpn_cls: 0.0130 | loss_rpn_loc: 0.0120 | Total Loss: 0.3256\n",
      "Epoch 1962 | loss_cls: 0.1053 | loss_box_reg: 0.2616 | loss_mask: 0.0925 | loss_rpn_cls: 0.0035 | loss_rpn_loc: 0.1273 | Total Loss: 0.5902\n",
      "Epoch 1963 | loss_cls: 0.0479 | loss_box_reg: 0.1072 | loss_mask: 0.1206 | loss_rpn_cls: 0.0113 | loss_rpn_loc: 0.0223 | Total Loss: 0.3093\n",
      "Epoch 1964 | loss_cls: 0.0773 | loss_box_reg: 0.1719 | loss_mask: 0.1473 | loss_rpn_cls: 0.0177 | loss_rpn_loc: 0.1403 | Total Loss: 0.5545\n",
      "Epoch 1965 | loss_cls: 0.0725 | loss_box_reg: 0.1961 | loss_mask: 0.1143 | loss_rpn_cls: 0.0054 | loss_rpn_loc: 0.1129 | Total Loss: 0.5012\n",
      "Epoch 1966 | loss_cls: 0.1525 | loss_box_reg: 0.2391 | loss_mask: 0.0882 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.1247 | Total Loss: 0.6061\n",
      "Epoch 1967 | loss_cls: 0.0573 | loss_box_reg: 0.1074 | loss_mask: 0.1852 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.0435 | Total Loss: 0.3959\n",
      "Epoch 1968 | loss_cls: 0.0722 | loss_box_reg: 0.2175 | loss_mask: 0.1461 | loss_rpn_cls: 0.0074 | loss_rpn_loc: 0.0202 | Total Loss: 0.4634\n",
      "Epoch 1969 | loss_cls: 0.0634 | loss_box_reg: 0.3290 | loss_mask: 0.1527 | loss_rpn_cls: 0.0075 | loss_rpn_loc: 0.0045 | Total Loss: 0.5570\n",
      "Epoch 1970 | loss_cls: 0.0510 | loss_box_reg: 0.1442 | loss_mask: 0.1199 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0060 | Total Loss: 0.3222\n",
      "Epoch 1971 | loss_cls: 0.0331 | loss_box_reg: 0.2330 | loss_mask: 0.0796 | loss_rpn_cls: 0.0146 | loss_rpn_loc: 0.0088 | Total Loss: 0.3692\n",
      "Epoch 1972 | loss_cls: 0.1108 | loss_box_reg: 0.2077 | loss_mask: 0.0892 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.0679 | Total Loss: 0.4789\n",
      "Epoch 1973 | loss_cls: 0.0513 | loss_box_reg: 0.1400 | loss_mask: 0.0810 | loss_rpn_cls: 0.0142 | loss_rpn_loc: 0.0430 | Total Loss: 0.3296\n",
      "Epoch 1974 | loss_cls: 0.0326 | loss_box_reg: 0.0793 | loss_mask: 0.0456 | loss_rpn_cls: 0.0018 | loss_rpn_loc: 0.0372 | Total Loss: 0.1964\n",
      "Epoch 1975 | loss_cls: 0.0485 | loss_box_reg: 0.2308 | loss_mask: 0.0629 | loss_rpn_cls: 0.0021 | loss_rpn_loc: 0.0109 | Total Loss: 0.3552\n",
      "Epoch 1976 | loss_cls: 0.0458 | loss_box_reg: 0.1986 | loss_mask: 0.0400 | loss_rpn_cls: 0.0223 | loss_rpn_loc: 0.1502 | Total Loss: 0.4568\n",
      "Epoch 1977 | loss_cls: 0.0447 | loss_box_reg: 0.2316 | loss_mask: 0.0415 | loss_rpn_cls: 0.0024 | loss_rpn_loc: 0.0027 | Total Loss: 0.3228\n",
      "Epoch 1978 | loss_cls: 0.0602 | loss_box_reg: 0.1356 | loss_mask: 0.0364 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.0024 | Total Loss: 0.2351\n",
      "Epoch 1979 | loss_cls: 0.0996 | loss_box_reg: 0.0844 | loss_mask: 0.0911 | loss_rpn_cls: 0.0042 | loss_rpn_loc: 0.0201 | Total Loss: 0.2994\n",
      "\u001b[32m[07/29 18:32:12 d2.utils.events]: \u001b[0m eta: 0:06:35  iter: 1979      time: 0.3326  last_time: 0.2704   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 1980 | loss_cls: 0.0813 | loss_box_reg: 0.2604 | loss_mask: 0.1547 | loss_rpn_cls: 0.0016 | loss_rpn_loc: 0.0073 | Total Loss: 0.5052\n",
      "Epoch 1981 | loss_cls: 0.1129 | loss_box_reg: 0.2519 | loss_mask: 0.0631 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.0141 | Total Loss: 0.4470\n",
      "Epoch 1982 | loss_cls: 0.0868 | loss_box_reg: 0.1117 | loss_mask: 0.0758 | loss_rpn_cls: 0.0135 | loss_rpn_loc: 0.0722 | Total Loss: 0.3600\n",
      "Epoch 1983 | loss_cls: 0.0457 | loss_box_reg: 0.1569 | loss_mask: 0.2849 | loss_rpn_cls: 0.0058 | loss_rpn_loc: 0.0194 | Total Loss: 0.5126\n",
      "Epoch 1984 | loss_cls: 0.0704 | loss_box_reg: 0.2069 | loss_mask: 0.0572 | loss_rpn_cls: 0.0182 | loss_rpn_loc: 0.2204 | Total Loss: 0.5730\n",
      "Epoch 1985 | loss_cls: 0.0317 | loss_box_reg: 0.0547 | loss_mask: 0.2625 | loss_rpn_cls: 0.0041 | loss_rpn_loc: 0.1005 | Total Loss: 0.4535\n",
      "Epoch 1986 | loss_cls: 0.0995 | loss_box_reg: 0.1470 | loss_mask: 0.0326 | loss_rpn_cls: 0.0071 | loss_rpn_loc: 0.1171 | Total Loss: 0.4033\n",
      "Epoch 1987 | loss_cls: 0.0759 | loss_box_reg: 0.1309 | loss_mask: 0.0493 | loss_rpn_cls: 0.0202 | loss_rpn_loc: 0.0269 | Total Loss: 0.3032\n",
      "Epoch 1988 | loss_cls: 0.0404 | loss_box_reg: 0.1574 | loss_mask: 0.1923 | loss_rpn_cls: 0.0026 | loss_rpn_loc: 0.0216 | Total Loss: 0.4142\n",
      "Epoch 1989 | loss_cls: 0.0787 | loss_box_reg: 0.1177 | loss_mask: 0.1065 | loss_rpn_cls: 0.0049 | loss_rpn_loc: 0.0051 | Total Loss: 0.3129\n",
      "Epoch 1990 | loss_cls: 0.0534 | loss_box_reg: 0.1820 | loss_mask: 0.0829 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.1190 | Total Loss: 0.4386\n",
      "Epoch 1991 | loss_cls: 0.0434 | loss_box_reg: 0.1270 | loss_mask: 0.1135 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.0117 | Total Loss: 0.2975\n",
      "Epoch 1992 | loss_cls: 0.0424 | loss_box_reg: 0.0646 | loss_mask: 0.2099 | loss_rpn_cls: 0.0055 | loss_rpn_loc: 0.1076 | Total Loss: 0.4301\n",
      "Epoch 1993 | loss_cls: 0.0504 | loss_box_reg: 0.1041 | loss_mask: 0.1049 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0697 | Total Loss: 0.3296\n",
      "Epoch 1994 | loss_cls: 0.0287 | loss_box_reg: 0.0836 | loss_mask: 0.1045 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.0184 | Total Loss: 0.2367\n",
      "Epoch 1995 | loss_cls: 0.0561 | loss_box_reg: 0.0965 | loss_mask: 0.0902 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.0799 | Total Loss: 0.3237\n",
      "Epoch 1996 | loss_cls: 0.0325 | loss_box_reg: 0.1795 | loss_mask: 0.1441 | loss_rpn_cls: 0.0044 | loss_rpn_loc: 0.0998 | Total Loss: 0.4603\n",
      "Epoch 1997 | loss_cls: 0.0241 | loss_box_reg: 0.0387 | loss_mask: 0.1368 | loss_rpn_cls: 0.0065 | loss_rpn_loc: 0.1257 | Total Loss: 0.3318\n",
      "Epoch 1998 | loss_cls: 0.0692 | loss_box_reg: 0.1570 | loss_mask: 0.0749 | loss_rpn_cls: 0.0021 | loss_rpn_loc: 0.0754 | Total Loss: 0.3787\n",
      "Epoch 1999 | loss_cls: 0.1355 | loss_box_reg: 0.2501 | loss_mask: 0.1440 | loss_rpn_cls: 0.0217 | loss_rpn_loc: 0.1177 | Total Loss: 0.6689\n",
      "\u001b[32m[07/29 18:32:18 d2.utils.events]: \u001b[0m eta: 0:06:28  iter: 1999      time: 0.3326  last_time: 0.4060   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2000 | loss_cls: 0.0222 | loss_box_reg: 0.1338 | loss_mask: 0.2219 | loss_rpn_cls: 0.0094 | loss_rpn_loc: 0.0200 | Total Loss: 0.4072\n",
      "Epoch 2001 | loss_cls: 0.0262 | loss_box_reg: 0.0619 | loss_mask: 0.1077 | loss_rpn_cls: 0.0017 | loss_rpn_loc: 0.0946 | Total Loss: 0.2920\n",
      "Epoch 2002 | loss_cls: 0.0928 | loss_box_reg: 0.3274 | loss_mask: 0.0692 | loss_rpn_cls: 0.0066 | loss_rpn_loc: 0.0031 | Total Loss: 0.4990\n",
      "Epoch 2003 | loss_cls: 0.1063 | loss_box_reg: 0.1516 | loss_mask: 0.0850 | loss_rpn_cls: 0.0113 | loss_rpn_loc: 0.0936 | Total Loss: 0.4479\n",
      "Epoch 2004 | loss_cls: 0.0825 | loss_box_reg: 0.2324 | loss_mask: 0.0663 | loss_rpn_cls: 0.0559 | loss_rpn_loc: 0.2358 | Total Loss: 0.6730\n",
      "Epoch 2005 | loss_cls: 0.0422 | loss_box_reg: 0.3100 | loss_mask: 0.0658 | loss_rpn_cls: 0.0099 | loss_rpn_loc: 0.0078 | Total Loss: 0.4357\n",
      "Epoch 2006 | loss_cls: 0.0652 | loss_box_reg: 0.0866 | loss_mask: 0.0448 | loss_rpn_cls: 0.0040 | loss_rpn_loc: 0.0172 | Total Loss: 0.2178\n",
      "Epoch 2007 | loss_cls: 0.0785 | loss_box_reg: 0.2001 | loss_mask: 0.0863 | loss_rpn_cls: 0.0058 | loss_rpn_loc: 0.0395 | Total Loss: 0.4101\n",
      "Epoch 2008 | loss_cls: 0.0399 | loss_box_reg: 0.1756 | loss_mask: 0.0650 | loss_rpn_cls: 0.0171 | loss_rpn_loc: 0.0885 | Total Loss: 0.3861\n",
      "Epoch 2009 | loss_cls: 0.0671 | loss_box_reg: 0.1266 | loss_mask: 0.0554 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0067 | Total Loss: 0.2566\n",
      "Epoch 2010 | loss_cls: 0.0247 | loss_box_reg: 0.1307 | loss_mask: 0.0701 | loss_rpn_cls: 0.0001 | loss_rpn_loc: 0.0027 | Total Loss: 0.2282\n",
      "Epoch 2011 | loss_cls: 0.0571 | loss_box_reg: 0.1145 | loss_mask: 0.0614 | loss_rpn_cls: 0.0074 | loss_rpn_loc: 0.0037 | Total Loss: 0.2442\n",
      "Epoch 2012 | loss_cls: 0.0920 | loss_box_reg: 0.1263 | loss_mask: 0.1275 | loss_rpn_cls: 0.0126 | loss_rpn_loc: 0.0078 | Total Loss: 0.3662\n",
      "Epoch 2013 | loss_cls: 0.0457 | loss_box_reg: 0.0455 | loss_mask: 0.0443 | loss_rpn_cls: 0.0077 | loss_rpn_loc: 0.0170 | Total Loss: 0.1602\n",
      "Epoch 2014 | loss_cls: 0.0416 | loss_box_reg: 0.1171 | loss_mask: 0.1155 | loss_rpn_cls: 0.0070 | loss_rpn_loc: 0.1617 | Total Loss: 0.4429\n",
      "Epoch 2015 | loss_cls: 0.0544 | loss_box_reg: 0.1913 | loss_mask: 0.1444 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.1722 | Total Loss: 0.5674\n",
      "Epoch 2016 | loss_cls: 0.0303 | loss_box_reg: 0.1753 | loss_mask: 0.0751 | loss_rpn_cls: 0.0193 | loss_rpn_loc: 0.1377 | Total Loss: 0.4377\n",
      "Epoch 2017 | loss_cls: 0.0387 | loss_box_reg: 0.1102 | loss_mask: 0.0822 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.1458 | Total Loss: 0.3794\n",
      "Epoch 2018 | loss_cls: 0.0602 | loss_box_reg: 0.1466 | loss_mask: 0.0637 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0094 | Total Loss: 0.2805\n",
      "Epoch 2019 | loss_cls: 0.0882 | loss_box_reg: 0.1036 | loss_mask: 0.0580 | loss_rpn_cls: 0.0213 | loss_rpn_loc: 0.0205 | Total Loss: 0.2916\n",
      "\u001b[32m[07/29 18:32:25 d2.utils.events]: \u001b[0m eta: 0:06:20  iter: 2019      time: 0.3327  last_time: 0.4031   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2020 | loss_cls: 0.0347 | loss_box_reg: 0.0915 | loss_mask: 0.0855 | loss_rpn_cls: 0.0128 | loss_rpn_loc: 0.0203 | Total Loss: 0.2449\n",
      "Epoch 2021 | loss_cls: 0.1787 | loss_box_reg: 0.2633 | loss_mask: 0.0462 | loss_rpn_cls: 0.0235 | loss_rpn_loc: 0.0307 | Total Loss: 0.5425\n",
      "Epoch 2022 | loss_cls: 0.1115 | loss_box_reg: 0.2358 | loss_mask: 0.0597 | loss_rpn_cls: 0.0092 | loss_rpn_loc: 0.0193 | Total Loss: 0.4355\n",
      "Epoch 2023 | loss_cls: 0.1133 | loss_box_reg: 0.2941 | loss_mask: 0.0897 | loss_rpn_cls: 0.0113 | loss_rpn_loc: 0.1053 | Total Loss: 0.6137\n",
      "Epoch 2024 | loss_cls: 0.0475 | loss_box_reg: 0.1159 | loss_mask: 0.0469 | loss_rpn_cls: 0.0053 | loss_rpn_loc: 0.1175 | Total Loss: 0.3331\n",
      "Epoch 2025 | loss_cls: 0.0444 | loss_box_reg: 0.0488 | loss_mask: 0.3235 | loss_rpn_cls: 0.0104 | loss_rpn_loc: 0.1082 | Total Loss: 0.5353\n",
      "Epoch 2026 | loss_cls: 0.0626 | loss_box_reg: 0.1620 | loss_mask: 0.1801 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.0978 | Total Loss: 0.5035\n",
      "Epoch 2027 | loss_cls: 0.0913 | loss_box_reg: 0.2514 | loss_mask: 0.1676 | loss_rpn_cls: 0.0083 | loss_rpn_loc: 0.1080 | Total Loss: 0.6265\n",
      "Epoch 2028 | loss_cls: 0.0765 | loss_box_reg: 0.1610 | loss_mask: 0.0894 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.1236 | Total Loss: 0.4555\n",
      "Epoch 2029 | loss_cls: 0.2022 | loss_box_reg: 0.2719 | loss_mask: 0.0673 | loss_rpn_cls: 0.0201 | loss_rpn_loc: 0.4150 | Total Loss: 0.9764\n",
      "Epoch 2030 | loss_cls: 0.0541 | loss_box_reg: 0.1710 | loss_mask: 0.0743 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.0928 | Total Loss: 0.3949\n",
      "Epoch 2031 | loss_cls: 0.0777 | loss_box_reg: 0.1756 | loss_mask: 0.2209 | loss_rpn_cls: 0.0260 | loss_rpn_loc: 0.0789 | Total Loss: 0.5792\n",
      "Epoch 2032 | loss_cls: 0.0564 | loss_box_reg: 0.2865 | loss_mask: 0.2422 | loss_rpn_cls: 0.0112 | loss_rpn_loc: 0.0182 | Total Loss: 0.6145\n",
      "Epoch 2033 | loss_cls: 0.0683 | loss_box_reg: 0.1944 | loss_mask: 0.1666 | loss_rpn_cls: 0.0001 | loss_rpn_loc: 0.0076 | Total Loss: 0.4371\n",
      "Epoch 2034 | loss_cls: 0.0557 | loss_box_reg: 0.2103 | loss_mask: 0.1139 | loss_rpn_cls: 0.0071 | loss_rpn_loc: 0.1617 | Total Loss: 0.5487\n",
      "Epoch 2035 | loss_cls: 0.0223 | loss_box_reg: 0.0698 | loss_mask: 0.2096 | loss_rpn_cls: 0.0060 | loss_rpn_loc: 0.0022 | Total Loss: 0.3099\n",
      "Epoch 2036 | loss_cls: 0.0956 | loss_box_reg: 0.1229 | loss_mask: 0.0456 | loss_rpn_cls: 0.0081 | loss_rpn_loc: 0.0116 | Total Loss: 0.2836\n",
      "Epoch 2037 | loss_cls: 0.0966 | loss_box_reg: 0.2737 | loss_mask: 0.0520 | loss_rpn_cls: 0.0042 | loss_rpn_loc: 0.2904 | Total Loss: 0.7169\n",
      "Epoch 2038 | loss_cls: 0.0281 | loss_box_reg: 0.0667 | loss_mask: 0.2226 | loss_rpn_cls: 0.0084 | loss_rpn_loc: 0.2824 | Total Loss: 0.6083\n",
      "Epoch 2039 | loss_cls: 0.0388 | loss_box_reg: 0.2016 | loss_mask: 0.1437 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.0889 | Total Loss: 0.4748\n",
      "\u001b[32m[07/29 18:32:32 d2.utils.events]: \u001b[0m eta: 0:06:12  iter: 2039      time: 0.3329  last_time: 0.4152   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2040 | loss_cls: 0.0627 | loss_box_reg: 0.1374 | loss_mask: 0.0554 | loss_rpn_cls: 0.0061 | loss_rpn_loc: 0.0190 | Total Loss: 0.2805\n",
      "Epoch 2041 | loss_cls: 0.0133 | loss_box_reg: 0.0626 | loss_mask: 0.0369 | loss_rpn_cls: 0.0020 | loss_rpn_loc: 0.0135 | Total Loss: 0.1284\n",
      " Best model saved at Epoch 2041 | Total Loss: 0.1284\n",
      "Epoch 2042 | loss_cls: 0.0299 | loss_box_reg: 0.0741 | loss_mask: 0.1230 | loss_rpn_cls: 0.0213 | loss_rpn_loc: 0.1942 | Total Loss: 0.4426\n",
      "Epoch 2043 | loss_cls: 0.0226 | loss_box_reg: 0.0873 | loss_mask: 0.0464 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.0031 | Total Loss: 0.1616\n",
      "Epoch 2044 | loss_cls: 0.1292 | loss_box_reg: 0.2429 | loss_mask: 0.1511 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0078 | Total Loss: 0.5316\n",
      "Epoch 2045 | loss_cls: 0.0402 | loss_box_reg: 0.1899 | loss_mask: 0.0744 | loss_rpn_cls: 0.0009 | loss_rpn_loc: 0.0364 | Total Loss: 0.3419\n",
      "Epoch 2046 | loss_cls: 0.0483 | loss_box_reg: 0.1459 | loss_mask: 0.0601 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.0407 | Total Loss: 0.2965\n",
      "Epoch 2047 | loss_cls: 0.0781 | loss_box_reg: 0.2321 | loss_mask: 0.1097 | loss_rpn_cls: 0.0037 | loss_rpn_loc: 0.0191 | Total Loss: 0.4427\n",
      "Epoch 2048 | loss_cls: 0.0373 | loss_box_reg: 0.1281 | loss_mask: 0.0607 | loss_rpn_cls: 0.0094 | loss_rpn_loc: 0.1115 | Total Loss: 0.3471\n",
      "Epoch 2049 | loss_cls: 0.0705 | loss_box_reg: 0.1338 | loss_mask: 0.1025 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.1108 | Total Loss: 0.4202\n",
      "Epoch 2050 | loss_cls: 0.1152 | loss_box_reg: 0.2539 | loss_mask: 0.0868 | loss_rpn_cls: 0.0078 | loss_rpn_loc: 0.0045 | Total Loss: 0.4683\n",
      "Epoch 2051 | loss_cls: 0.0497 | loss_box_reg: 0.1353 | loss_mask: 0.0572 | loss_rpn_cls: 0.0003 | loss_rpn_loc: 0.0177 | Total Loss: 0.2602\n",
      "Epoch 2052 | loss_cls: 0.0640 | loss_box_reg: 0.1328 | loss_mask: 0.2794 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.0033 | Total Loss: 0.4847\n",
      "Epoch 2053 | loss_cls: 0.0469 | loss_box_reg: 0.1593 | loss_mask: 0.1165 | loss_rpn_cls: 0.0022 | loss_rpn_loc: 0.0175 | Total Loss: 0.3423\n",
      "Epoch 2054 | loss_cls: 0.0404 | loss_box_reg: 0.1274 | loss_mask: 0.0546 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0280 | Total Loss: 0.2515\n",
      "Epoch 2055 | loss_cls: 0.0884 | loss_box_reg: 0.2068 | loss_mask: 0.0972 | loss_rpn_cls: 0.0103 | loss_rpn_loc: 0.0929 | Total Loss: 0.4956\n",
      "Epoch 2056 | loss_cls: 0.0401 | loss_box_reg: 0.0775 | loss_mask: 0.0489 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0195 | Total Loss: 0.1866\n",
      "Epoch 2057 | loss_cls: 0.0247 | loss_box_reg: 0.1078 | loss_mask: 0.0940 | loss_rpn_cls: 0.0041 | loss_rpn_loc: 0.1494 | Total Loss: 0.3800\n",
      "Epoch 2058 | loss_cls: 0.0986 | loss_box_reg: 0.1086 | loss_mask: 0.1049 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.0290 | Total Loss: 0.3462\n",
      "Epoch 2059 | loss_cls: 0.0371 | loss_box_reg: 0.0486 | loss_mask: 0.0962 | loss_rpn_cls: 0.0076 | loss_rpn_loc: 0.1959 | Total Loss: 0.3854\n",
      "\u001b[32m[07/29 18:32:39 d2.utils.events]: \u001b[0m eta: 0:06:05  iter: 2059      time: 0.3332  last_time: 0.4031   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2060 | loss_cls: 0.0849 | loss_box_reg: 0.1768 | loss_mask: 0.0404 | loss_rpn_cls: 0.0502 | loss_rpn_loc: 0.1734 | Total Loss: 0.5256\n",
      "Epoch 2061 | loss_cls: 0.0364 | loss_box_reg: 0.0817 | loss_mask: 0.0640 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0092 | Total Loss: 0.1924\n",
      "Epoch 2062 | loss_cls: 0.0654 | loss_box_reg: 0.1748 | loss_mask: 0.0433 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.1148 | Total Loss: 0.4008\n",
      "Epoch 2063 | loss_cls: 0.0290 | loss_box_reg: 0.0835 | loss_mask: 0.0719 | loss_rpn_cls: 0.0065 | loss_rpn_loc: 0.0049 | Total Loss: 0.1957\n",
      "Epoch 2064 | loss_cls: 0.0369 | loss_box_reg: 0.0589 | loss_mask: 0.2604 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.1019 | Total Loss: 0.4595\n",
      "Epoch 2065 | loss_cls: 0.0510 | loss_box_reg: 0.2027 | loss_mask: 0.1231 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.0421 | Total Loss: 0.4214\n",
      "Epoch 2066 | loss_cls: 0.0443 | loss_box_reg: 0.1108 | loss_mask: 0.0559 | loss_rpn_cls: 0.0093 | loss_rpn_loc: 0.0886 | Total Loss: 0.3089\n",
      "Epoch 2067 | loss_cls: 0.0614 | loss_box_reg: 0.1274 | loss_mask: 0.2349 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.0104 | Total Loss: 0.4351\n",
      "Epoch 2068 | loss_cls: 0.0508 | loss_box_reg: 0.0738 | loss_mask: 0.1628 | loss_rpn_cls: 0.0291 | loss_rpn_loc: 0.1042 | Total Loss: 0.4207\n",
      "Epoch 2069 | loss_cls: 0.0689 | loss_box_reg: 0.1271 | loss_mask: 0.0902 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0067 | Total Loss: 0.2936\n",
      "Epoch 2070 | loss_cls: 0.0645 | loss_box_reg: 0.1233 | loss_mask: 0.0576 | loss_rpn_cls: 0.0081 | loss_rpn_loc: 0.0108 | Total Loss: 0.2643\n",
      "Epoch 2071 | loss_cls: 0.0432 | loss_box_reg: 0.1912 | loss_mask: 0.0914 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0030 | Total Loss: 0.3294\n",
      "Epoch 2072 | loss_cls: 0.0519 | loss_box_reg: 0.1860 | loss_mask: 0.1677 | loss_rpn_cls: 0.0045 | loss_rpn_loc: 0.0438 | Total Loss: 0.4540\n",
      "Epoch 2073 | loss_cls: 0.0275 | loss_box_reg: 0.0946 | loss_mask: 0.0686 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0368 | Total Loss: 0.2285\n",
      "Epoch 2074 | loss_cls: 0.0162 | loss_box_reg: 0.0492 | loss_mask: 0.0724 | loss_rpn_cls: 0.0223 | loss_rpn_loc: 0.1490 | Total Loss: 0.3090\n",
      "Epoch 2075 | loss_cls: 0.0660 | loss_box_reg: 0.1249 | loss_mask: 0.0518 | loss_rpn_cls: 0.0136 | loss_rpn_loc: 0.2032 | Total Loss: 0.4594\n",
      "Epoch 2076 | loss_cls: 0.0812 | loss_box_reg: 0.1402 | loss_mask: 0.0790 | loss_rpn_cls: 0.0076 | loss_rpn_loc: 0.0049 | Total Loss: 0.3130\n",
      "Epoch 2077 | loss_cls: 0.0801 | loss_box_reg: 0.1288 | loss_mask: 0.1130 | loss_rpn_cls: 0.0107 | loss_rpn_loc: 0.2555 | Total Loss: 0.5880\n",
      "Epoch 2078 | loss_cls: 0.0608 | loss_box_reg: 0.1948 | loss_mask: 0.1085 | loss_rpn_cls: 0.0062 | loss_rpn_loc: 0.1642 | Total Loss: 0.5345\n",
      "Epoch 2079 | loss_cls: 0.1329 | loss_box_reg: 0.2858 | loss_mask: 0.2083 | loss_rpn_cls: 0.0059 | loss_rpn_loc: 0.0431 | Total Loss: 0.6761\n",
      "\u001b[32m[07/29 18:32:46 d2.utils.events]: \u001b[0m eta: 0:05:57  iter: 2079      time: 0.3331  last_time: 0.2810   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2080 | loss_cls: 0.0562 | loss_box_reg: 0.2115 | loss_mask: 0.0975 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0658 | Total Loss: 0.4313\n",
      "Epoch 2081 | loss_cls: 0.0619 | loss_box_reg: 0.1457 | loss_mask: 0.0592 | loss_rpn_cls: 0.0186 | loss_rpn_loc: 0.1968 | Total Loss: 0.4822\n",
      "Epoch 2082 | loss_cls: 0.0290 | loss_box_reg: 0.0651 | loss_mask: 0.0995 | loss_rpn_cls: 0.0003 | loss_rpn_loc: 0.0094 | Total Loss: 0.2034\n",
      "Epoch 2083 | loss_cls: 0.0823 | loss_box_reg: 0.2489 | loss_mask: 0.1346 | loss_rpn_cls: 0.0056 | loss_rpn_loc: 0.0805 | Total Loss: 0.5519\n",
      "Epoch 2084 | loss_cls: 0.0438 | loss_box_reg: 0.1221 | loss_mask: 0.0396 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0071 | Total Loss: 0.2137\n",
      "Epoch 2085 | loss_cls: 0.0377 | loss_box_reg: 0.1613 | loss_mask: 0.0465 | loss_rpn_cls: 0.0008 | loss_rpn_loc: 0.0233 | Total Loss: 0.2696\n",
      "Epoch 2086 | loss_cls: 0.1135 | loss_box_reg: 0.2161 | loss_mask: 0.0728 | loss_rpn_cls: 0.0047 | loss_rpn_loc: 0.1483 | Total Loss: 0.5554\n",
      "Epoch 2087 | loss_cls: 0.0373 | loss_box_reg: 0.1141 | loss_mask: 0.0636 | loss_rpn_cls: 0.0083 | loss_rpn_loc: 0.0536 | Total Loss: 0.2769\n",
      "Epoch 2088 | loss_cls: 0.0971 | loss_box_reg: 0.3393 | loss_mask: 0.0924 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0346 | Total Loss: 0.5640\n",
      "Epoch 2089 | loss_cls: 0.0629 | loss_box_reg: 0.2243 | loss_mask: 0.1373 | loss_rpn_cls: 0.0026 | loss_rpn_loc: 0.0327 | Total Loss: 0.4598\n",
      "Epoch 2090 | loss_cls: 0.0385 | loss_box_reg: 0.0704 | loss_mask: 0.3575 | loss_rpn_cls: 0.0057 | loss_rpn_loc: 0.2241 | Total Loss: 0.6961\n",
      "Epoch 2091 | loss_cls: 0.0562 | loss_box_reg: 0.1747 | loss_mask: 0.2220 | loss_rpn_cls: 0.0038 | loss_rpn_loc: 0.0420 | Total Loss: 0.4988\n",
      "Epoch 2092 | loss_cls: 0.0326 | loss_box_reg: 0.1102 | loss_mask: 0.0638 | loss_rpn_cls: 0.0060 | loss_rpn_loc: 0.0309 | Total Loss: 0.2436\n",
      "Epoch 2093 | loss_cls: 0.0458 | loss_box_reg: 0.2122 | loss_mask: 0.1134 | loss_rpn_cls: 0.0020 | loss_rpn_loc: 0.0392 | Total Loss: 0.4126\n",
      "Epoch 2094 | loss_cls: 0.0911 | loss_box_reg: 0.1494 | loss_mask: 0.0448 | loss_rpn_cls: 0.0414 | loss_rpn_loc: 0.0955 | Total Loss: 0.4221\n",
      "Epoch 2095 | loss_cls: 0.0583 | loss_box_reg: 0.1086 | loss_mask: 0.0652 | loss_rpn_cls: 0.0071 | loss_rpn_loc: 0.0867 | Total Loss: 0.3260\n",
      "Epoch 2096 | loss_cls: 0.0879 | loss_box_reg: 0.1022 | loss_mask: 0.1034 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.1237 | Total Loss: 0.4183\n",
      "Epoch 2097 | loss_cls: 0.1151 | loss_box_reg: 0.2201 | loss_mask: 0.0797 | loss_rpn_cls: 0.0289 | loss_rpn_loc: 0.1213 | Total Loss: 0.5651\n",
      "Epoch 2098 | loss_cls: 0.1218 | loss_box_reg: 0.2260 | loss_mask: 0.0962 | loss_rpn_cls: 0.0251 | loss_rpn_loc: 0.3456 | Total Loss: 0.8146\n",
      "Epoch 2099 | loss_cls: 0.0599 | loss_box_reg: 0.1242 | loss_mask: 0.1154 | loss_rpn_cls: 0.0036 | loss_rpn_loc: 0.0091 | Total Loss: 0.3121\n",
      "\u001b[32m[07/29 18:32:53 d2.utils.events]: \u001b[0m eta: 0:05:49  iter: 2099      time: 0.3334  last_time: 0.4287   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2100 | loss_cls: 0.1098 | loss_box_reg: 0.1095 | loss_mask: 0.0552 | loss_rpn_cls: 0.0048 | loss_rpn_loc: 0.0751 | Total Loss: 0.3544\n",
      "Epoch 2101 | loss_cls: 0.0457 | loss_box_reg: 0.0774 | loss_mask: 0.0370 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.0052 | Total Loss: 0.1666\n",
      "Epoch 2102 | loss_cls: 0.0490 | loss_box_reg: 0.1448 | loss_mask: 0.0683 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.0516 | Total Loss: 0.3170\n",
      "Epoch 2103 | loss_cls: 0.0455 | loss_box_reg: 0.1277 | loss_mask: 0.0636 | loss_rpn_cls: 0.0083 | loss_rpn_loc: 0.1466 | Total Loss: 0.3917\n",
      "Epoch 2104 | loss_cls: 0.1327 | loss_box_reg: 0.3380 | loss_mask: 0.0796 | loss_rpn_cls: 0.0192 | loss_rpn_loc: 0.0043 | Total Loss: 0.5739\n",
      "Epoch 2105 | loss_cls: 0.0498 | loss_box_reg: 0.1771 | loss_mask: 0.0413 | loss_rpn_cls: 0.0118 | loss_rpn_loc: 0.0255 | Total Loss: 0.3055\n",
      "Epoch 2106 | loss_cls: 0.0500 | loss_box_reg: 0.1137 | loss_mask: 0.1135 | loss_rpn_cls: 0.0047 | loss_rpn_loc: 0.0261 | Total Loss: 0.3081\n",
      "Epoch 2107 | loss_cls: 0.0841 | loss_box_reg: 0.1422 | loss_mask: 0.0891 | loss_rpn_cls: 0.0162 | loss_rpn_loc: 0.0148 | Total Loss: 0.3463\n",
      "Epoch 2108 | loss_cls: 0.0724 | loss_box_reg: 0.1749 | loss_mask: 0.0857 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0118 | Total Loss: 0.3454\n",
      "Epoch 2109 | loss_cls: 0.1489 | loss_box_reg: 0.2114 | loss_mask: 0.0701 | loss_rpn_cls: 0.0126 | loss_rpn_loc: 0.1339 | Total Loss: 0.5769\n",
      "Epoch 2110 | loss_cls: 0.0316 | loss_box_reg: 0.0631 | loss_mask: 0.0463 | loss_rpn_cls: 0.0124 | loss_rpn_loc: 0.1058 | Total Loss: 0.2592\n",
      "Epoch 2111 | loss_cls: 0.0321 | loss_box_reg: 0.0515 | loss_mask: 0.1048 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.1821 | Total Loss: 0.3755\n",
      "Epoch 2112 | loss_cls: 0.0564 | loss_box_reg: 0.2055 | loss_mask: 0.0674 | loss_rpn_cls: 0.0038 | loss_rpn_loc: 0.0813 | Total Loss: 0.4144\n",
      "Epoch 2113 | loss_cls: 0.0827 | loss_box_reg: 0.1882 | loss_mask: 0.0728 | loss_rpn_cls: 0.0029 | loss_rpn_loc: 0.0637 | Total Loss: 0.4102\n",
      "Epoch 2114 | loss_cls: 0.0665 | loss_box_reg: 0.2787 | loss_mask: 0.0688 | loss_rpn_cls: 0.0082 | loss_rpn_loc: 0.1163 | Total Loss: 0.5384\n",
      "Epoch 2115 | loss_cls: 0.0400 | loss_box_reg: 0.2347 | loss_mask: 0.0792 | loss_rpn_cls: 0.0081 | loss_rpn_loc: 0.0342 | Total Loss: 0.3962\n",
      "Epoch 2116 | loss_cls: 0.0186 | loss_box_reg: 0.0442 | loss_mask: 0.1198 | loss_rpn_cls: 0.0087 | loss_rpn_loc: 0.0288 | Total Loss: 0.2201\n",
      "Epoch 2117 | loss_cls: 0.0245 | loss_box_reg: 0.0821 | loss_mask: 0.0420 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0056 | Total Loss: 0.1546\n",
      "Epoch 2118 | loss_cls: 0.0776 | loss_box_reg: 0.1683 | loss_mask: 0.0861 | loss_rpn_cls: 0.0056 | loss_rpn_loc: 0.0329 | Total Loss: 0.3706\n",
      "Epoch 2119 | loss_cls: 0.0408 | loss_box_reg: 0.1837 | loss_mask: 0.1265 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.0895 | Total Loss: 0.4421\n",
      "\u001b[32m[07/29 18:33:00 d2.utils.events]: \u001b[0m eta: 0:05:42  iter: 2119      time: 0.3335  last_time: 0.4153   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2120 | loss_cls: 0.0469 | loss_box_reg: 0.1546 | loss_mask: 0.0876 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0026 | Total Loss: 0.2923\n",
      "Epoch 2121 | loss_cls: 0.0933 | loss_box_reg: 0.1286 | loss_mask: 0.0521 | loss_rpn_cls: 0.0107 | loss_rpn_loc: 0.0150 | Total Loss: 0.2996\n",
      "Epoch 2122 | loss_cls: 0.0384 | loss_box_reg: 0.1178 | loss_mask: 0.0770 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.0322 | Total Loss: 0.2667\n",
      "Epoch 2123 | loss_cls: 0.0764 | loss_box_reg: 0.1914 | loss_mask: 0.0467 | loss_rpn_cls: 0.0039 | loss_rpn_loc: 0.2398 | Total Loss: 0.5582\n",
      "Epoch 2124 | loss_cls: 0.0265 | loss_box_reg: 0.1220 | loss_mask: 0.1302 | loss_rpn_cls: 0.0180 | loss_rpn_loc: 0.1014 | Total Loss: 0.3981\n",
      "Epoch 2125 | loss_cls: 0.0390 | loss_box_reg: 0.1424 | loss_mask: 0.0846 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.1183 | Total Loss: 0.3877\n",
      "Epoch 2126 | loss_cls: 0.0292 | loss_box_reg: 0.0535 | loss_mask: 0.0536 | loss_rpn_cls: 0.0240 | loss_rpn_loc: 0.0249 | Total Loss: 0.1852\n",
      "Epoch 2127 | loss_cls: 0.0477 | loss_box_reg: 0.1501 | loss_mask: 0.0520 | loss_rpn_cls: 0.0026 | loss_rpn_loc: 0.0374 | Total Loss: 0.2898\n",
      "Epoch 2128 | loss_cls: 0.0719 | loss_box_reg: 0.1440 | loss_mask: 0.0368 | loss_rpn_cls: 0.0066 | loss_rpn_loc: 0.0430 | Total Loss: 0.3023\n",
      "Epoch 2129 | loss_cls: 0.0895 | loss_box_reg: 0.1768 | loss_mask: 0.0631 | loss_rpn_cls: 0.0159 | loss_rpn_loc: 0.0762 | Total Loss: 0.4214\n",
      "Epoch 2130 | loss_cls: 0.0668 | loss_box_reg: 0.1734 | loss_mask: 0.1412 | loss_rpn_cls: 0.0070 | loss_rpn_loc: 0.0053 | Total Loss: 0.3937\n",
      "Epoch 2131 | loss_cls: 0.0623 | loss_box_reg: 0.1696 | loss_mask: 0.1256 | loss_rpn_cls: 0.0144 | loss_rpn_loc: 0.1281 | Total Loss: 0.5001\n",
      "Epoch 2132 | loss_cls: 0.0617 | loss_box_reg: 0.2119 | loss_mask: 0.1845 | loss_rpn_cls: 0.0032 | loss_rpn_loc: 0.1693 | Total Loss: 0.6306\n",
      "Epoch 2133 | loss_cls: 0.0151 | loss_box_reg: 0.0452 | loss_mask: 0.0792 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.0200 | Total Loss: 0.1610\n",
      "Epoch 2134 | loss_cls: 0.0215 | loss_box_reg: 0.0942 | loss_mask: 0.0503 | loss_rpn_cls: 0.0016 | loss_rpn_loc: 0.0876 | Total Loss: 0.2551\n",
      "Epoch 2135 | loss_cls: 0.0537 | loss_box_reg: 0.1489 | loss_mask: 0.2139 | loss_rpn_cls: 0.0271 | loss_rpn_loc: 0.0397 | Total Loss: 0.4832\n",
      "Epoch 2136 | loss_cls: 0.0452 | loss_box_reg: 0.0685 | loss_mask: 0.0929 | loss_rpn_cls: 0.0139 | loss_rpn_loc: 0.0182 | Total Loss: 0.2388\n",
      "Epoch 2137 | loss_cls: 0.0755 | loss_box_reg: 0.1188 | loss_mask: 0.0603 | loss_rpn_cls: 0.0058 | loss_rpn_loc: 0.0104 | Total Loss: 0.2708\n",
      "Epoch 2138 | loss_cls: 0.0628 | loss_box_reg: 0.1571 | loss_mask: 0.1467 | loss_rpn_cls: 0.0008 | loss_rpn_loc: 0.1179 | Total Loss: 0.4855\n",
      "Epoch 2139 | loss_cls: 0.0699 | loss_box_reg: 0.1985 | loss_mask: 0.0552 | loss_rpn_cls: 0.0060 | loss_rpn_loc: 0.0791 | Total Loss: 0.4087\n",
      "\u001b[32m[07/29 18:33:07 d2.utils.events]: \u001b[0m eta: 0:05:35  iter: 2139      time: 0.3336  last_time: 0.4133   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2140 | loss_cls: 0.0412 | loss_box_reg: 0.1109 | loss_mask: 0.0484 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0123 | Total Loss: 0.2135\n",
      "Epoch 2141 | loss_cls: 0.1562 | loss_box_reg: 0.1525 | loss_mask: 0.0455 | loss_rpn_cls: 0.0024 | loss_rpn_loc: 0.0705 | Total Loss: 0.4271\n",
      "Epoch 2142 | loss_cls: 0.0923 | loss_box_reg: 0.1858 | loss_mask: 0.0868 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.1775 | Total Loss: 0.5435\n",
      "Epoch 2143 | loss_cls: 0.0429 | loss_box_reg: 0.0869 | loss_mask: 0.0767 | loss_rpn_cls: 0.0223 | loss_rpn_loc: 0.1012 | Total Loss: 0.3299\n",
      "Epoch 2144 | loss_cls: 0.0756 | loss_box_reg: 0.3298 | loss_mask: 0.0713 | loss_rpn_cls: 0.0084 | loss_rpn_loc: 0.0827 | Total Loss: 0.5677\n",
      "Epoch 2145 | loss_cls: 0.0436 | loss_box_reg: 0.1457 | loss_mask: 0.0598 | loss_rpn_cls: 0.0111 | loss_rpn_loc: 0.0444 | Total Loss: 0.3046\n",
      "Epoch 2146 | loss_cls: 0.0511 | loss_box_reg: 0.1137 | loss_mask: 0.0513 | loss_rpn_cls: 0.0039 | loss_rpn_loc: 0.0794 | Total Loss: 0.2995\n",
      "Epoch 2147 | loss_cls: 0.0230 | loss_box_reg: 0.0756 | loss_mask: 0.0416 | loss_rpn_cls: 0.0043 | loss_rpn_loc: 0.0108 | Total Loss: 0.1552\n",
      "Epoch 2148 | loss_cls: 0.0397 | loss_box_reg: 0.1778 | loss_mask: 0.0366 | loss_rpn_cls: 0.0109 | loss_rpn_loc: 0.0726 | Total Loss: 0.3375\n",
      "Epoch 2149 | loss_cls: 0.0468 | loss_box_reg: 0.1912 | loss_mask: 0.1274 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.1229 | Total Loss: 0.4917\n",
      "Epoch 2150 | loss_cls: 0.0764 | loss_box_reg: 0.1657 | loss_mask: 0.0401 | loss_rpn_cls: 0.0065 | loss_rpn_loc: 0.1975 | Total Loss: 0.4862\n",
      "Epoch 2151 | loss_cls: 0.0686 | loss_box_reg: 0.1830 | loss_mask: 0.0594 | loss_rpn_cls: 0.0031 | loss_rpn_loc: 0.1788 | Total Loss: 0.4928\n",
      "Epoch 2152 | loss_cls: 0.0826 | loss_box_reg: 0.1741 | loss_mask: 0.1508 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0235 | Total Loss: 0.4321\n",
      "Epoch 2153 | loss_cls: 0.0186 | loss_box_reg: 0.0621 | loss_mask: 0.2031 | loss_rpn_cls: 0.0061 | loss_rpn_loc: 0.1868 | Total Loss: 0.4768\n",
      "Epoch 2154 | loss_cls: 0.0667 | loss_box_reg: 0.1583 | loss_mask: 0.0764 | loss_rpn_cls: 0.0016 | loss_rpn_loc: 0.0409 | Total Loss: 0.3439\n",
      "Epoch 2155 | loss_cls: 0.0433 | loss_box_reg: 0.0920 | loss_mask: 0.0703 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.1260 | Total Loss: 0.3350\n",
      "Epoch 2156 | loss_cls: 0.0595 | loss_box_reg: 0.1034 | loss_mask: 0.0733 | loss_rpn_cls: 0.0078 | loss_rpn_loc: 0.0961 | Total Loss: 0.3402\n",
      "Epoch 2157 | loss_cls: 0.1112 | loss_box_reg: 0.2258 | loss_mask: 0.1356 | loss_rpn_cls: 0.0003 | loss_rpn_loc: 0.0262 | Total Loss: 0.4991\n",
      "Epoch 2158 | loss_cls: 0.0345 | loss_box_reg: 0.0290 | loss_mask: 0.1405 | loss_rpn_cls: 0.0132 | loss_rpn_loc: 0.0279 | Total Loss: 0.2450\n",
      "Epoch 2159 | loss_cls: 0.1014 | loss_box_reg: 0.3210 | loss_mask: 0.1270 | loss_rpn_cls: 0.0049 | loss_rpn_loc: 0.0041 | Total Loss: 0.5585\n",
      "\u001b[32m[07/29 18:33:14 d2.utils.events]: \u001b[0m eta: 0:05:27  iter: 2159      time: 0.3338  last_time: 0.4150   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2160 | loss_cls: 0.0405 | loss_box_reg: 0.0758 | loss_mask: 0.0743 | loss_rpn_cls: 0.0061 | loss_rpn_loc: 0.1014 | Total Loss: 0.2982\n",
      "Epoch 2161 | loss_cls: 0.0457 | loss_box_reg: 0.1115 | loss_mask: 0.1019 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0039 | Total Loss: 0.2633\n",
      "Epoch 2162 | loss_cls: 0.0672 | loss_box_reg: 0.1430 | loss_mask: 0.0896 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.0684 | Total Loss: 0.3715\n",
      "Epoch 2163 | loss_cls: 0.0506 | loss_box_reg: 0.0979 | loss_mask: 0.1119 | loss_rpn_cls: 0.0003 | loss_rpn_loc: 0.0160 | Total Loss: 0.2767\n",
      "Epoch 2164 | loss_cls: 0.1172 | loss_box_reg: 0.1268 | loss_mask: 0.1434 | loss_rpn_cls: 0.0044 | loss_rpn_loc: 0.0209 | Total Loss: 0.4128\n",
      "Epoch 2165 | loss_cls: 0.0599 | loss_box_reg: 0.1753 | loss_mask: 0.0899 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.0070 | Total Loss: 0.3371\n",
      "Epoch 2166 | loss_cls: 0.0601 | loss_box_reg: 0.1617 | loss_mask: 0.1112 | loss_rpn_cls: 0.0016 | loss_rpn_loc: 0.1341 | Total Loss: 0.4687\n",
      "Epoch 2167 | loss_cls: 0.0431 | loss_box_reg: 0.0745 | loss_mask: 0.1691 | loss_rpn_cls: 0.0026 | loss_rpn_loc: 0.0202 | Total Loss: 0.3095\n",
      "Epoch 2168 | loss_cls: 0.0617 | loss_box_reg: 0.1800 | loss_mask: 0.1850 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.0773 | Total Loss: 0.5063\n",
      "Epoch 2169 | loss_cls: 0.0328 | loss_box_reg: 0.1066 | loss_mask: 0.0691 | loss_rpn_cls: 0.0002 | loss_rpn_loc: 0.0042 | Total Loss: 0.2130\n",
      "Epoch 2170 | loss_cls: 0.0166 | loss_box_reg: 0.0373 | loss_mask: 0.1072 | loss_rpn_cls: 0.0022 | loss_rpn_loc: 0.0882 | Total Loss: 0.2515\n",
      "Epoch 2171 | loss_cls: 0.0425 | loss_box_reg: 0.1093 | loss_mask: 0.2554 | loss_rpn_cls: 0.0117 | loss_rpn_loc: 0.1741 | Total Loss: 0.5930\n",
      "Epoch 2172 | loss_cls: 0.0763 | loss_box_reg: 0.1230 | loss_mask: 0.0440 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.0113 | Total Loss: 0.2559\n",
      "Epoch 2173 | loss_cls: 0.0107 | loss_box_reg: 0.0482 | loss_mask: 0.1421 | loss_rpn_cls: 0.0048 | loss_rpn_loc: 0.1020 | Total Loss: 0.3078\n",
      "Epoch 2174 | loss_cls: 0.0345 | loss_box_reg: 0.1092 | loss_mask: 0.0713 | loss_rpn_cls: 0.0016 | loss_rpn_loc: 0.0408 | Total Loss: 0.2574\n",
      "Epoch 2175 | loss_cls: 0.0854 | loss_box_reg: 0.1600 | loss_mask: 0.0832 | loss_rpn_cls: 0.0054 | loss_rpn_loc: 0.1605 | Total Loss: 0.4944\n",
      "Epoch 2176 | loss_cls: 0.0189 | loss_box_reg: 0.1292 | loss_mask: 0.0817 | loss_rpn_cls: 0.0009 | loss_rpn_loc: 0.1061 | Total Loss: 0.3369\n",
      "Epoch 2177 | loss_cls: 0.0678 | loss_box_reg: 0.1829 | loss_mask: 0.0815 | loss_rpn_cls: 0.0021 | loss_rpn_loc: 0.0105 | Total Loss: 0.3449\n",
      "Epoch 2178 | loss_cls: 0.0344 | loss_box_reg: 0.1194 | loss_mask: 0.1455 | loss_rpn_cls: 0.0030 | loss_rpn_loc: 0.1190 | Total Loss: 0.4213\n",
      "Epoch 2179 | loss_cls: 0.0275 | loss_box_reg: 0.1122 | loss_mask: 0.0742 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.0329 | Total Loss: 0.2487\n",
      "\u001b[32m[07/29 18:33:21 d2.utils.events]: \u001b[0m eta: 0:05:20  iter: 2179      time: 0.3340  last_time: 0.3926   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2180 | loss_cls: 0.0429 | loss_box_reg: 0.2134 | loss_mask: 0.0817 | loss_rpn_cls: 0.0036 | loss_rpn_loc: 0.0182 | Total Loss: 0.3598\n",
      "Epoch 2181 | loss_cls: 0.1103 | loss_box_reg: 0.2043 | loss_mask: 0.0967 | loss_rpn_cls: 0.0064 | loss_rpn_loc: 0.0581 | Total Loss: 0.4758\n",
      "Epoch 2182 | loss_cls: 0.0183 | loss_box_reg: 0.0440 | loss_mask: 0.1109 | loss_rpn_cls: 0.0146 | loss_rpn_loc: 0.1919 | Total Loss: 0.3797\n",
      "Epoch 2183 | loss_cls: 0.0839 | loss_box_reg: 0.2284 | loss_mask: 0.0712 | loss_rpn_cls: 0.0077 | loss_rpn_loc: 0.1076 | Total Loss: 0.4989\n",
      "Epoch 2184 | loss_cls: 0.0317 | loss_box_reg: 0.0744 | loss_mask: 0.0850 | loss_rpn_cls: 0.0109 | loss_rpn_loc: 0.0687 | Total Loss: 0.2706\n",
      "Epoch 2185 | loss_cls: 0.0822 | loss_box_reg: 0.1893 | loss_mask: 0.1349 | loss_rpn_cls: 0.0028 | loss_rpn_loc: 0.1295 | Total Loss: 0.5387\n",
      "Epoch 2186 | loss_cls: 0.0226 | loss_box_reg: 0.0928 | loss_mask: 0.0719 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0026 | Total Loss: 0.1904\n",
      "Epoch 2187 | loss_cls: 0.0814 | loss_box_reg: 0.1884 | loss_mask: 0.0818 | loss_rpn_cls: 0.0169 | loss_rpn_loc: 0.0608 | Total Loss: 0.4294\n",
      "Epoch 2188 | loss_cls: 0.0743 | loss_box_reg: 0.0751 | loss_mask: 0.0764 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.0773 | Total Loss: 0.3055\n",
      "Epoch 2189 | loss_cls: 0.0879 | loss_box_reg: 0.1259 | loss_mask: 0.0489 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0124 | Total Loss: 0.2754\n",
      "Epoch 2190 | loss_cls: 0.0498 | loss_box_reg: 0.2136 | loss_mask: 0.0684 | loss_rpn_cls: 0.0209 | loss_rpn_loc: 0.0661 | Total Loss: 0.4188\n",
      "Epoch 2191 | loss_cls: 0.1344 | loss_box_reg: 0.1826 | loss_mask: 0.0994 | loss_rpn_cls: 0.0095 | loss_rpn_loc: 0.0394 | Total Loss: 0.4652\n",
      "Epoch 2192 | loss_cls: 0.1057 | loss_box_reg: 0.1141 | loss_mask: 0.0462 | loss_rpn_cls: 0.0143 | loss_rpn_loc: 0.0750 | Total Loss: 0.3553\n",
      "Epoch 2193 | loss_cls: 0.0644 | loss_box_reg: 0.1962 | loss_mask: 0.0724 | loss_rpn_cls: 0.0043 | loss_rpn_loc: 0.0589 | Total Loss: 0.3962\n",
      "Epoch 2194 | loss_cls: 0.0414 | loss_box_reg: 0.1230 | loss_mask: 0.1618 | loss_rpn_cls: 0.0155 | loss_rpn_loc: 0.1808 | Total Loss: 0.5226\n",
      "Epoch 2195 | loss_cls: 0.0754 | loss_box_reg: 0.3228 | loss_mask: 0.0427 | loss_rpn_cls: 0.0058 | loss_rpn_loc: 0.1519 | Total Loss: 0.5987\n",
      "Epoch 2196 | loss_cls: 0.0640 | loss_box_reg: 0.1621 | loss_mask: 0.0814 | loss_rpn_cls: 0.0098 | loss_rpn_loc: 0.0918 | Total Loss: 0.4090\n",
      "Epoch 2197 | loss_cls: 0.0933 | loss_box_reg: 0.1500 | loss_mask: 0.0956 | loss_rpn_cls: 0.0032 | loss_rpn_loc: 0.1945 | Total Loss: 0.5367\n",
      "Epoch 2198 | loss_cls: 0.0462 | loss_box_reg: 0.0670 | loss_mask: 0.0643 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.1081 | Total Loss: 0.2879\n",
      "Epoch 2199 | loss_cls: 0.0701 | loss_box_reg: 0.0919 | loss_mask: 0.0711 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.0054 | Total Loss: 0.2397\n",
      "\u001b[32m[07/29 18:33:29 d2.utils.events]: \u001b[0m eta: 0:05:13  iter: 2199      time: 0.3344  last_time: 0.4022   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2200 | loss_cls: 0.0404 | loss_box_reg: 0.3048 | loss_mask: 0.2381 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.1609 | Total Loss: 0.7453\n",
      "Epoch 2201 | loss_cls: 0.0693 | loss_box_reg: 0.1099 | loss_mask: 0.2518 | loss_rpn_cls: 0.0021 | loss_rpn_loc: 0.1452 | Total Loss: 0.5784\n",
      "Epoch 2202 | loss_cls: 0.0909 | loss_box_reg: 0.2201 | loss_mask: 0.0565 | loss_rpn_cls: 0.0018 | loss_rpn_loc: 0.0283 | Total Loss: 0.3976\n",
      "Epoch 2203 | loss_cls: 0.1226 | loss_box_reg: 0.1200 | loss_mask: 0.0643 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.0352 | Total Loss: 0.3443\n",
      "Epoch 2204 | loss_cls: 0.0484 | loss_box_reg: 0.1860 | loss_mask: 0.0429 | loss_rpn_cls: 0.0002 | loss_rpn_loc: 0.0037 | Total Loss: 0.2813\n",
      "Epoch 2205 | loss_cls: 0.0475 | loss_box_reg: 0.1109 | loss_mask: 0.0808 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.0971 | Total Loss: 0.3378\n",
      "Epoch 2206 | loss_cls: 0.0218 | loss_box_reg: 0.1040 | loss_mask: 0.0641 | loss_rpn_cls: 0.0008 | loss_rpn_loc: 0.0471 | Total Loss: 0.2378\n",
      "Epoch 2207 | loss_cls: 0.0303 | loss_box_reg: 0.0932 | loss_mask: 0.0803 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.0877 | Total Loss: 0.2930\n",
      "Epoch 2208 | loss_cls: 0.0782 | loss_box_reg: 0.1403 | loss_mask: 0.1394 | loss_rpn_cls: 0.0090 | loss_rpn_loc: 0.1803 | Total Loss: 0.5472\n",
      "Epoch 2209 | loss_cls: 0.0280 | loss_box_reg: 0.0842 | loss_mask: 0.0357 | loss_rpn_cls: 0.0028 | loss_rpn_loc: 0.0215 | Total Loss: 0.1723\n",
      "Epoch 2210 | loss_cls: 0.0404 | loss_box_reg: 0.1764 | loss_mask: 0.1398 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.1683 | Total Loss: 0.5283\n",
      "Epoch 2211 | loss_cls: 0.0670 | loss_box_reg: 0.1093 | loss_mask: 0.0394 | loss_rpn_cls: 0.0121 | loss_rpn_loc: 0.1479 | Total Loss: 0.3758\n",
      "Epoch 2212 | loss_cls: 0.0456 | loss_box_reg: 0.1533 | loss_mask: 0.0444 | loss_rpn_cls: 0.0548 | loss_rpn_loc: 0.2458 | Total Loss: 0.5439\n",
      "Epoch 2213 | loss_cls: 0.0486 | loss_box_reg: 0.2006 | loss_mask: 0.0695 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.0855 | Total Loss: 0.4056\n",
      "Epoch 2214 | loss_cls: 0.0456 | loss_box_reg: 0.0826 | loss_mask: 0.0698 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.0079 | Total Loss: 0.2072\n",
      "Epoch 2215 | loss_cls: 0.0289 | loss_box_reg: 0.1227 | loss_mask: 0.1582 | loss_rpn_cls: 0.0003 | loss_rpn_loc: 0.0039 | Total Loss: 0.3140\n",
      "Epoch 2216 | loss_cls: 0.0198 | loss_box_reg: 0.0937 | loss_mask: 0.0727 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.1129 | Total Loss: 0.3013\n",
      "Epoch 2217 | loss_cls: 0.0116 | loss_box_reg: 0.0517 | loss_mask: 0.1306 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0167 | Total Loss: 0.2112\n",
      "Epoch 2218 | loss_cls: 0.0490 | loss_box_reg: 0.2089 | loss_mask: 0.0301 | loss_rpn_cls: 0.0032 | loss_rpn_loc: 0.0756 | Total Loss: 0.3667\n",
      "Epoch 2219 | loss_cls: 0.0774 | loss_box_reg: 0.1856 | loss_mask: 0.1542 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0401 | Total Loss: 0.4580\n",
      "\u001b[32m[07/29 18:33:37 d2.utils.events]: \u001b[0m eta: 0:05:05  iter: 2219      time: 0.3349  last_time: 0.4111   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2220 | loss_cls: 0.0357 | loss_box_reg: 0.1084 | loss_mask: 0.1170 | loss_rpn_cls: 0.0081 | loss_rpn_loc: 0.1620 | Total Loss: 0.4313\n",
      "Epoch 2221 | loss_cls: 0.0436 | loss_box_reg: 0.1011 | loss_mask: 0.0907 | loss_rpn_cls: 0.0029 | loss_rpn_loc: 0.1824 | Total Loss: 0.4207\n",
      "Epoch 2222 | loss_cls: 0.0762 | loss_box_reg: 0.2065 | loss_mask: 0.0381 | loss_rpn_cls: 0.0084 | loss_rpn_loc: 0.0857 | Total Loss: 0.4148\n",
      "Epoch 2223 | loss_cls: 0.0363 | loss_box_reg: 0.0925 | loss_mask: 0.0961 | loss_rpn_cls: 0.0070 | loss_rpn_loc: 0.1023 | Total Loss: 0.3343\n",
      "Epoch 2224 | loss_cls: 0.0459 | loss_box_reg: 0.2538 | loss_mask: 0.0888 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0108 | Total Loss: 0.3997\n",
      "Epoch 2225 | loss_cls: 0.0442 | loss_box_reg: 0.1571 | loss_mask: 0.0928 | loss_rpn_cls: 0.0063 | loss_rpn_loc: 0.0433 | Total Loss: 0.3436\n",
      "Epoch 2226 | loss_cls: 0.0817 | loss_box_reg: 0.2076 | loss_mask: 0.0853 | loss_rpn_cls: 0.0078 | loss_rpn_loc: 0.1060 | Total Loss: 0.4885\n",
      "Epoch 2227 | loss_cls: 0.0980 | loss_box_reg: 0.1737 | loss_mask: 0.0339 | loss_rpn_cls: 0.0160 | loss_rpn_loc: 0.1698 | Total Loss: 0.4914\n",
      "Epoch 2228 | loss_cls: 0.0753 | loss_box_reg: 0.0997 | loss_mask: 0.1851 | loss_rpn_cls: 0.0090 | loss_rpn_loc: 0.1465 | Total Loss: 0.5156\n",
      "Epoch 2229 | loss_cls: 0.0888 | loss_box_reg: 0.1553 | loss_mask: 0.0494 | loss_rpn_cls: 0.0090 | loss_rpn_loc: 0.0037 | Total Loss: 0.3061\n",
      "Epoch 2230 | loss_cls: 0.0738 | loss_box_reg: 0.1931 | loss_mask: 0.0654 | loss_rpn_cls: 0.0074 | loss_rpn_loc: 0.0921 | Total Loss: 0.4317\n",
      "Epoch 2231 | loss_cls: 0.0972 | loss_box_reg: 0.2393 | loss_mask: 0.0875 | loss_rpn_cls: 0.0044 | loss_rpn_loc: 0.1349 | Total Loss: 0.5633\n",
      "Epoch 2232 | loss_cls: 0.0549 | loss_box_reg: 0.1955 | loss_mask: 0.0580 | loss_rpn_cls: 0.0003 | loss_rpn_loc: 0.0132 | Total Loss: 0.3218\n",
      "Epoch 2233 | loss_cls: 0.0509 | loss_box_reg: 0.1925 | loss_mask: 0.1262 | loss_rpn_cls: 0.0055 | loss_rpn_loc: 0.0365 | Total Loss: 0.4115\n",
      "Epoch 2234 | loss_cls: 0.0287 | loss_box_reg: 0.0402 | loss_mask: 0.0820 | loss_rpn_cls: 0.0081 | loss_rpn_loc: 0.1135 | Total Loss: 0.2725\n",
      "Epoch 2235 | loss_cls: 0.0553 | loss_box_reg: 0.1776 | loss_mask: 0.0642 | loss_rpn_cls: 0.0110 | loss_rpn_loc: 0.0323 | Total Loss: 0.3403\n",
      "Epoch 2236 | loss_cls: 0.0914 | loss_box_reg: 0.2610 | loss_mask: 0.0556 | loss_rpn_cls: 0.0029 | loss_rpn_loc: 0.0072 | Total Loss: 0.4181\n",
      "Epoch 2237 | loss_cls: 0.0305 | loss_box_reg: 0.1021 | loss_mask: 0.1636 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.2365 | Total Loss: 0.5353\n",
      "Epoch 2238 | loss_cls: 0.0673 | loss_box_reg: 0.1262 | loss_mask: 0.0661 | loss_rpn_cls: 0.0173 | loss_rpn_loc: 0.0453 | Total Loss: 0.3222\n",
      "Epoch 2239 | loss_cls: 0.0699 | loss_box_reg: 0.1120 | loss_mask: 0.0415 | loss_rpn_cls: 0.0003 | loss_rpn_loc: 0.0075 | Total Loss: 0.2312\n",
      "\u001b[32m[07/29 18:33:44 d2.utils.events]: \u001b[0m eta: 0:04:58  iter: 2239      time: 0.3352  last_time: 0.4051   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2240 | loss_cls: 0.0788 | loss_box_reg: 0.1539 | loss_mask: 0.0518 | loss_rpn_cls: 0.0045 | loss_rpn_loc: 0.1347 | Total Loss: 0.4238\n",
      "Epoch 2241 | loss_cls: 0.0600 | loss_box_reg: 0.0817 | loss_mask: 0.0471 | loss_rpn_cls: 0.0112 | loss_rpn_loc: 0.0521 | Total Loss: 0.2520\n",
      "Epoch 2242 | loss_cls: 0.0915 | loss_box_reg: 0.1495 | loss_mask: 0.0606 | loss_rpn_cls: 0.0060 | loss_rpn_loc: 0.0066 | Total Loss: 0.3142\n",
      "Epoch 2243 | loss_cls: 0.0338 | loss_box_reg: 0.0408 | loss_mask: 0.0984 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.0864 | Total Loss: 0.2607\n",
      "Epoch 2244 | loss_cls: 0.0431 | loss_box_reg: 0.0681 | loss_mask: 0.0686 | loss_rpn_cls: 0.0045 | loss_rpn_loc: 0.0261 | Total Loss: 0.2104\n",
      "Epoch 2245 | loss_cls: 0.0816 | loss_box_reg: 0.1917 | loss_mask: 0.1164 | loss_rpn_cls: 0.0061 | loss_rpn_loc: 0.0497 | Total Loss: 0.4455\n",
      "Epoch 2246 | loss_cls: 0.0287 | loss_box_reg: 0.1113 | loss_mask: 0.0326 | loss_rpn_cls: 0.0009 | loss_rpn_loc: 0.0141 | Total Loss: 0.1876\n",
      "Epoch 2247 | loss_cls: 0.0800 | loss_box_reg: 0.2564 | loss_mask: 0.0663 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0197 | Total Loss: 0.4228\n",
      "Epoch 2248 | loss_cls: 0.0642 | loss_box_reg: 0.2973 | loss_mask: 0.0414 | loss_rpn_cls: 0.0060 | loss_rpn_loc: 0.0980 | Total Loss: 0.5069\n",
      "Epoch 2249 | loss_cls: 0.1168 | loss_box_reg: 0.2440 | loss_mask: 0.0845 | loss_rpn_cls: 0.0081 | loss_rpn_loc: 0.0679 | Total Loss: 0.5212\n",
      "Epoch 2250 | loss_cls: 0.0276 | loss_box_reg: 0.0474 | loss_mask: 0.0833 | loss_rpn_cls: 0.0090 | loss_rpn_loc: 0.0736 | Total Loss: 0.2410\n",
      "Epoch 2251 | loss_cls: 0.0418 | loss_box_reg: 0.2041 | loss_mask: 0.0704 | loss_rpn_cls: 0.0053 | loss_rpn_loc: 0.0089 | Total Loss: 0.3305\n",
      "Epoch 2252 | loss_cls: 0.0432 | loss_box_reg: 0.1040 | loss_mask: 0.1308 | loss_rpn_cls: 0.0001 | loss_rpn_loc: 0.0209 | Total Loss: 0.2990\n",
      "Epoch 2253 | loss_cls: 0.0507 | loss_box_reg: 0.1423 | loss_mask: 0.0739 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.0055 | Total Loss: 0.2737\n",
      "Epoch 2254 | loss_cls: 0.0504 | loss_box_reg: 0.1426 | loss_mask: 0.0388 | loss_rpn_cls: 0.0003 | loss_rpn_loc: 0.0098 | Total Loss: 0.2419\n",
      "Epoch 2255 | loss_cls: 0.0503 | loss_box_reg: 0.0592 | loss_mask: 0.0578 | loss_rpn_cls: 0.0143 | loss_rpn_loc: 0.1033 | Total Loss: 0.2849\n",
      "Epoch 2256 | loss_cls: 0.0674 | loss_box_reg: 0.2850 | loss_mask: 0.1253 | loss_rpn_cls: 0.0093 | loss_rpn_loc: 0.0190 | Total Loss: 0.5060\n",
      "Epoch 2257 | loss_cls: 0.0433 | loss_box_reg: 0.2116 | loss_mask: 0.0550 | loss_rpn_cls: 0.0195 | loss_rpn_loc: 0.0717 | Total Loss: 0.4011\n",
      "Epoch 2258 | loss_cls: 0.0233 | loss_box_reg: 0.0751 | loss_mask: 0.0918 | loss_rpn_cls: 0.0104 | loss_rpn_loc: 0.0962 | Total Loss: 0.2968\n",
      "Epoch 2259 | loss_cls: 0.1895 | loss_box_reg: 0.1857 | loss_mask: 0.0852 | loss_rpn_cls: 0.0089 | loss_rpn_loc: 0.0609 | Total Loss: 0.5302\n",
      "\u001b[32m[07/29 18:33:52 d2.utils.events]: \u001b[0m eta: 0:04:51  iter: 2259      time: 0.3356  last_time: 0.4105   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2260 | loss_cls: 0.0283 | loss_box_reg: 0.2147 | loss_mask: 0.1227 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.0038 | Total Loss: 0.3722\n",
      "Epoch 2261 | loss_cls: 0.1179 | loss_box_reg: 0.4053 | loss_mask: 0.2939 | loss_rpn_cls: 0.0021 | loss_rpn_loc: 0.0303 | Total Loss: 0.8495\n",
      "Epoch 2262 | loss_cls: 0.0817 | loss_box_reg: 0.1735 | loss_mask: 0.0850 | loss_rpn_cls: 0.0049 | loss_rpn_loc: 0.0630 | Total Loss: 0.4080\n",
      "Epoch 2263 | loss_cls: 0.0667 | loss_box_reg: 0.0975 | loss_mask: 0.0434 | loss_rpn_cls: 0.0168 | loss_rpn_loc: 0.0053 | Total Loss: 0.2297\n",
      "Epoch 2264 | loss_cls: 0.0752 | loss_box_reg: 0.1821 | loss_mask: 0.0702 | loss_rpn_cls: 0.0008 | loss_rpn_loc: 0.0041 | Total Loss: 0.3325\n",
      "Epoch 2265 | loss_cls: 0.0595 | loss_box_reg: 0.1167 | loss_mask: 0.0861 | loss_rpn_cls: 0.0036 | loss_rpn_loc: 0.0030 | Total Loss: 0.2688\n",
      "Epoch 2266 | loss_cls: 0.0725 | loss_box_reg: 0.0735 | loss_mask: 0.0523 | loss_rpn_cls: 0.0020 | loss_rpn_loc: 0.1028 | Total Loss: 0.3032\n",
      "Epoch 2267 | loss_cls: 0.0531 | loss_box_reg: 0.1299 | loss_mask: 0.1381 | loss_rpn_cls: 0.0054 | loss_rpn_loc: 0.0934 | Total Loss: 0.4200\n",
      "Epoch 2268 | loss_cls: 0.0568 | loss_box_reg: 0.2312 | loss_mask: 0.0825 | loss_rpn_cls: 0.0031 | loss_rpn_loc: 0.0361 | Total Loss: 0.4097\n",
      "Epoch 2269 | loss_cls: 0.0474 | loss_box_reg: 0.0550 | loss_mask: 0.1972 | loss_rpn_cls: 0.0017 | loss_rpn_loc: 0.0341 | Total Loss: 0.3355\n",
      "Epoch 2270 | loss_cls: 0.0381 | loss_box_reg: 0.1582 | loss_mask: 0.3305 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.0880 | Total Loss: 0.6163\n",
      "Epoch 2271 | loss_cls: 0.0727 | loss_box_reg: 0.1261 | loss_mask: 0.0966 | loss_rpn_cls: 0.0071 | loss_rpn_loc: 0.1176 | Total Loss: 0.4201\n",
      "Epoch 2272 | loss_cls: 0.0494 | loss_box_reg: 0.1156 | loss_mask: 0.1930 | loss_rpn_cls: 0.0008 | loss_rpn_loc: 0.0997 | Total Loss: 0.4585\n",
      "Epoch 2273 | loss_cls: 0.0511 | loss_box_reg: 0.0976 | loss_mask: 0.0561 | loss_rpn_cls: 0.0018 | loss_rpn_loc: 0.1255 | Total Loss: 0.3321\n",
      "Epoch 2274 | loss_cls: 0.0551 | loss_box_reg: 0.1493 | loss_mask: 0.2815 | loss_rpn_cls: 0.0125 | loss_rpn_loc: 0.0869 | Total Loss: 0.5853\n",
      "Epoch 2275 | loss_cls: 0.1365 | loss_box_reg: 0.2415 | loss_mask: 0.0576 | loss_rpn_cls: 0.0068 | loss_rpn_loc: 0.1632 | Total Loss: 0.6056\n",
      "Epoch 2276 | loss_cls: 0.0621 | loss_box_reg: 0.3152 | loss_mask: 0.1219 | loss_rpn_cls: 0.0043 | loss_rpn_loc: 0.0248 | Total Loss: 0.5283\n",
      "Epoch 2277 | loss_cls: 0.0900 | loss_box_reg: 0.1968 | loss_mask: 0.0566 | loss_rpn_cls: 0.0151 | loss_rpn_loc: 0.0605 | Total Loss: 0.4191\n",
      "Epoch 2278 | loss_cls: 0.1105 | loss_box_reg: 0.2062 | loss_mask: 0.1023 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.0111 | Total Loss: 0.4327\n",
      "Epoch 2279 | loss_cls: 0.0290 | loss_box_reg: 0.0888 | loss_mask: 0.0542 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.1180 | Total Loss: 0.2907\n",
      "\u001b[32m[07/29 18:33:58 d2.utils.events]: \u001b[0m eta: 0:04:43  iter: 2279      time: 0.3356  last_time: 0.3986   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2280 | loss_cls: 0.0606 | loss_box_reg: 0.1208 | loss_mask: 0.0564 | loss_rpn_cls: 0.0054 | loss_rpn_loc: 0.0265 | Total Loss: 0.2696\n",
      "Epoch 2281 | loss_cls: 0.0487 | loss_box_reg: 0.1405 | loss_mask: 0.1530 | loss_rpn_cls: 0.0114 | loss_rpn_loc: 0.1211 | Total Loss: 0.4747\n",
      "Epoch 2282 | loss_cls: 0.0539 | loss_box_reg: 0.1031 | loss_mask: 0.1116 | loss_rpn_cls: 0.0046 | loss_rpn_loc: 0.0068 | Total Loss: 0.2801\n",
      "Epoch 2283 | loss_cls: 0.0269 | loss_box_reg: 0.1009 | loss_mask: 0.1700 | loss_rpn_cls: 0.0017 | loss_rpn_loc: 0.0023 | Total Loss: 0.3018\n",
      "Epoch 2284 | loss_cls: 0.0433 | loss_box_reg: 0.1730 | loss_mask: 0.1153 | loss_rpn_cls: 0.0017 | loss_rpn_loc: 0.1226 | Total Loss: 0.4558\n",
      "Epoch 2285 | loss_cls: 0.0667 | loss_box_reg: 0.1041 | loss_mask: 0.0638 | loss_rpn_cls: 0.0053 | loss_rpn_loc: 0.1985 | Total Loss: 0.4385\n",
      "Epoch 2286 | loss_cls: 0.0318 | loss_box_reg: 0.0614 | loss_mask: 0.1586 | loss_rpn_cls: 0.0042 | loss_rpn_loc: 0.1980 | Total Loss: 0.4540\n",
      "Epoch 2287 | loss_cls: 0.0548 | loss_box_reg: 0.2170 | loss_mask: 0.0423 | loss_rpn_cls: 0.0207 | loss_rpn_loc: 0.1962 | Total Loss: 0.5310\n",
      "Epoch 2288 | loss_cls: 0.0598 | loss_box_reg: 0.2486 | loss_mask: 0.0544 | loss_rpn_cls: 0.0003 | loss_rpn_loc: 0.0215 | Total Loss: 0.3846\n",
      "Epoch 2289 | loss_cls: 0.0578 | loss_box_reg: 0.0883 | loss_mask: 0.0692 | loss_rpn_cls: 0.0047 | loss_rpn_loc: 0.1151 | Total Loss: 0.3351\n",
      "Epoch 2290 | loss_cls: 0.0777 | loss_box_reg: 0.1453 | loss_mask: 0.1225 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.1982 | Total Loss: 0.5462\n",
      "Epoch 2291 | loss_cls: 0.0360 | loss_box_reg: 0.1340 | loss_mask: 0.0510 | loss_rpn_cls: 0.0008 | loss_rpn_loc: 0.0045 | Total Loss: 0.2263\n",
      "Epoch 2292 | loss_cls: 0.0747 | loss_box_reg: 0.2429 | loss_mask: 0.0669 | loss_rpn_cls: 0.0597 | loss_rpn_loc: 0.1403 | Total Loss: 0.5845\n",
      "Epoch 2293 | loss_cls: 0.0756 | loss_box_reg: 0.1441 | loss_mask: 0.0640 | loss_rpn_cls: 0.0078 | loss_rpn_loc: 0.0975 | Total Loss: 0.3891\n",
      "Epoch 2294 | loss_cls: 0.0378 | loss_box_reg: 0.2379 | loss_mask: 0.4919 | loss_rpn_cls: 0.0124 | loss_rpn_loc: 0.1069 | Total Loss: 0.8869\n",
      "Epoch 2295 | loss_cls: 0.0998 | loss_box_reg: 0.1464 | loss_mask: 0.1501 | loss_rpn_cls: 0.0083 | loss_rpn_loc: 0.1607 | Total Loss: 0.5653\n",
      "Epoch 2296 | loss_cls: 0.0759 | loss_box_reg: 0.3040 | loss_mask: 0.2027 | loss_rpn_cls: 0.0048 | loss_rpn_loc: 0.0053 | Total Loss: 0.5928\n",
      "Epoch 2297 | loss_cls: 0.0364 | loss_box_reg: 0.0918 | loss_mask: 0.1540 | loss_rpn_cls: 0.0146 | loss_rpn_loc: 0.0326 | Total Loss: 0.3294\n",
      "Epoch 2298 | loss_cls: 0.0643 | loss_box_reg: 0.1307 | loss_mask: 0.1261 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.0156 | Total Loss: 0.3378\n",
      "Epoch 2299 | loss_cls: 0.0227 | loss_box_reg: 0.1452 | loss_mask: 0.1500 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.1758 | Total Loss: 0.4948\n",
      "\u001b[32m[07/29 18:34:06 d2.utils.events]: \u001b[0m eta: 0:04:35  iter: 2299      time: 0.3358  last_time: 0.4209   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2300 | loss_cls: 0.0458 | loss_box_reg: 0.0333 | loss_mask: 0.0751 | loss_rpn_cls: 0.0032 | loss_rpn_loc: 0.1105 | Total Loss: 0.2680\n",
      "Epoch 2301 | loss_cls: 0.0690 | loss_box_reg: 0.1472 | loss_mask: 0.0576 | loss_rpn_cls: 0.0008 | loss_rpn_loc: 0.0106 | Total Loss: 0.2852\n",
      "Epoch 2302 | loss_cls: 0.0428 | loss_box_reg: 0.1592 | loss_mask: 0.0748 | loss_rpn_cls: 0.0157 | loss_rpn_loc: 0.0071 | Total Loss: 0.2996\n",
      "Epoch 2303 | loss_cls: 0.0196 | loss_box_reg: 0.0861 | loss_mask: 0.0639 | loss_rpn_cls: 0.0057 | loss_rpn_loc: 0.0974 | Total Loss: 0.2727\n",
      "Epoch 2304 | loss_cls: 0.0491 | loss_box_reg: 0.1271 | loss_mask: 0.0458 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.0266 | Total Loss: 0.2509\n",
      "Epoch 2305 | loss_cls: 0.0430 | loss_box_reg: 0.0786 | loss_mask: 0.0441 | loss_rpn_cls: 0.0030 | loss_rpn_loc: 0.0979 | Total Loss: 0.2666\n",
      "Epoch 2306 | loss_cls: 0.0543 | loss_box_reg: 0.1116 | loss_mask: 0.1021 | loss_rpn_cls: 0.0042 | loss_rpn_loc: 0.0202 | Total Loss: 0.2923\n",
      "Epoch 2307 | loss_cls: 0.0747 | loss_box_reg: 0.1508 | loss_mask: 0.0506 | loss_rpn_cls: 0.0052 | loss_rpn_loc: 0.0649 | Total Loss: 0.3461\n",
      "Epoch 2308 | loss_cls: 0.0630 | loss_box_reg: 0.2355 | loss_mask: 0.1200 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.0047 | Total Loss: 0.4251\n",
      "Epoch 2309 | loss_cls: 0.0576 | loss_box_reg: 0.1361 | loss_mask: 0.0596 | loss_rpn_cls: 0.0129 | loss_rpn_loc: 0.2440 | Total Loss: 0.5102\n",
      "Epoch 2310 | loss_cls: 0.0785 | loss_box_reg: 0.1559 | loss_mask: 0.0524 | loss_rpn_cls: 0.0136 | loss_rpn_loc: 0.0531 | Total Loss: 0.3534\n",
      "Epoch 2311 | loss_cls: 0.0670 | loss_box_reg: 0.0658 | loss_mask: 0.0744 | loss_rpn_cls: 0.0032 | loss_rpn_loc: 0.0984 | Total Loss: 0.3088\n",
      "Epoch 2312 | loss_cls: 0.0650 | loss_box_reg: 0.2061 | loss_mask: 0.0890 | loss_rpn_cls: 0.0026 | loss_rpn_loc: 0.0045 | Total Loss: 0.3673\n",
      "Epoch 2313 | loss_cls: 0.0290 | loss_box_reg: 0.0483 | loss_mask: 0.1123 | loss_rpn_cls: 0.0024 | loss_rpn_loc: 0.0894 | Total Loss: 0.2814\n",
      "Epoch 2314 | loss_cls: 0.1324 | loss_box_reg: 0.2157 | loss_mask: 0.0750 | loss_rpn_cls: 0.0056 | loss_rpn_loc: 0.0603 | Total Loss: 0.4890\n",
      "Epoch 2315 | loss_cls: 0.0764 | loss_box_reg: 0.1654 | loss_mask: 0.1660 | loss_rpn_cls: 0.0037 | loss_rpn_loc: 0.0405 | Total Loss: 0.4520\n",
      "Epoch 2316 | loss_cls: 0.0855 | loss_box_reg: 0.1342 | loss_mask: 0.0910 | loss_rpn_cls: 0.0068 | loss_rpn_loc: 0.0085 | Total Loss: 0.3260\n",
      "Epoch 2317 | loss_cls: 0.0323 | loss_box_reg: 0.0856 | loss_mask: 0.0590 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0109 | Total Loss: 0.1885\n",
      "Epoch 2318 | loss_cls: 0.0854 | loss_box_reg: 0.1176 | loss_mask: 0.0582 | loss_rpn_cls: 0.0087 | loss_rpn_loc: 0.0063 | Total Loss: 0.2762\n",
      "Epoch 2319 | loss_cls: 0.0302 | loss_box_reg: 0.0744 | loss_mask: 0.1162 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.0882 | Total Loss: 0.3100\n",
      "\u001b[32m[07/29 18:34:13 d2.utils.events]: \u001b[0m eta: 0:04:27  iter: 2319      time: 0.3359  last_time: 0.4059   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2320 | loss_cls: 0.0760 | loss_box_reg: 0.1429 | loss_mask: 0.0662 | loss_rpn_cls: 0.0075 | loss_rpn_loc: 0.0805 | Total Loss: 0.3731\n",
      "Epoch 2321 | loss_cls: 0.0642 | loss_box_reg: 0.1742 | loss_mask: 0.0961 | loss_rpn_cls: 0.0024 | loss_rpn_loc: 0.0055 | Total Loss: 0.3424\n",
      "Epoch 2322 | loss_cls: 0.0485 | loss_box_reg: 0.1013 | loss_mask: 0.0900 | loss_rpn_cls: 0.0246 | loss_rpn_loc: 0.0071 | Total Loss: 0.2715\n",
      "Epoch 2323 | loss_cls: 0.0564 | loss_box_reg: 0.1816 | loss_mask: 0.0916 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.0417 | Total Loss: 0.3723\n",
      "Epoch 2324 | loss_cls: 0.0737 | loss_box_reg: 0.1952 | loss_mask: 0.1571 | loss_rpn_cls: 0.0096 | loss_rpn_loc: 0.0088 | Total Loss: 0.4442\n",
      "Epoch 2325 | loss_cls: 0.0306 | loss_box_reg: 0.0631 | loss_mask: 0.0384 | loss_rpn_cls: 0.0085 | loss_rpn_loc: 0.0172 | Total Loss: 0.1578\n",
      "Epoch 2326 | loss_cls: 0.0312 | loss_box_reg: 0.0978 | loss_mask: 0.1459 | loss_rpn_cls: 0.0122 | loss_rpn_loc: 0.1262 | Total Loss: 0.4133\n",
      "Epoch 2327 | loss_cls: 0.0671 | loss_box_reg: 0.1544 | loss_mask: 0.0579 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.0423 | Total Loss: 0.3226\n",
      "Epoch 2328 | loss_cls: 0.0452 | loss_box_reg: 0.1875 | loss_mask: 0.0828 | loss_rpn_cls: 0.0121 | loss_rpn_loc: 0.0549 | Total Loss: 0.3826\n",
      "Epoch 2329 | loss_cls: 0.0750 | loss_box_reg: 0.1654 | loss_mask: 0.1021 | loss_rpn_cls: 0.0043 | loss_rpn_loc: 0.1468 | Total Loss: 0.4936\n",
      "Epoch 2330 | loss_cls: 0.0446 | loss_box_reg: 0.1680 | loss_mask: 0.0457 | loss_rpn_cls: 0.0088 | loss_rpn_loc: 0.1223 | Total Loss: 0.3894\n",
      "Epoch 2331 | loss_cls: 0.0286 | loss_box_reg: 0.0580 | loss_mask: 0.1511 | loss_rpn_cls: 0.0031 | loss_rpn_loc: 0.0923 | Total Loss: 0.3331\n",
      "Epoch 2332 | loss_cls: 0.0574 | loss_box_reg: 0.2023 | loss_mask: 0.1399 | loss_rpn_cls: 0.0038 | loss_rpn_loc: 0.1396 | Total Loss: 0.5429\n",
      "Epoch 2333 | loss_cls: 0.0158 | loss_box_reg: 0.0435 | loss_mask: 0.0929 | loss_rpn_cls: 0.0139 | loss_rpn_loc: 0.0949 | Total Loss: 0.2610\n",
      "Epoch 2334 | loss_cls: 0.0316 | loss_box_reg: 0.0627 | loss_mask: 0.1060 | loss_rpn_cls: 0.0031 | loss_rpn_loc: 0.0944 | Total Loss: 0.2978\n",
      "Epoch 2335 | loss_cls: 0.0634 | loss_box_reg: 0.1722 | loss_mask: 0.0559 | loss_rpn_cls: 0.0026 | loss_rpn_loc: 0.0065 | Total Loss: 0.3007\n",
      "Epoch 2336 | loss_cls: 0.0366 | loss_box_reg: 0.1498 | loss_mask: 0.0884 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.0033 | Total Loss: 0.2813\n",
      "Epoch 2337 | loss_cls: 0.0617 | loss_box_reg: 0.1778 | loss_mask: 0.0354 | loss_rpn_cls: 0.0061 | loss_rpn_loc: 0.1438 | Total Loss: 0.4247\n",
      "Epoch 2338 | loss_cls: 0.0317 | loss_box_reg: 0.1687 | loss_mask: 0.1201 | loss_rpn_cls: 0.0057 | loss_rpn_loc: 0.0401 | Total Loss: 0.3662\n",
      "Epoch 2339 | loss_cls: 0.0599 | loss_box_reg: 0.1193 | loss_mask: 0.0362 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.0522 | Total Loss: 0.2685\n",
      "\u001b[32m[07/29 18:34:20 d2.utils.events]: \u001b[0m eta: 0:04:20  iter: 2339      time: 0.3363  last_time: 0.2711   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2340 | loss_cls: 0.0161 | loss_box_reg: 0.0732 | loss_mask: 0.0936 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0165 | Total Loss: 0.1997\n",
      "Epoch 2341 | loss_cls: 0.1177 | loss_box_reg: 0.2040 | loss_mask: 0.1460 | loss_rpn_cls: 0.0113 | loss_rpn_loc: 0.0675 | Total Loss: 0.5466\n",
      "Epoch 2342 | loss_cls: 0.0936 | loss_box_reg: 0.2343 | loss_mask: 0.0476 | loss_rpn_cls: 0.0103 | loss_rpn_loc: 0.1307 | Total Loss: 0.5166\n",
      "Epoch 2343 | loss_cls: 0.0438 | loss_box_reg: 0.0541 | loss_mask: 0.1168 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.1948 | Total Loss: 0.4129\n",
      "Epoch 2344 | loss_cls: 0.0501 | loss_box_reg: 0.1848 | loss_mask: 0.1621 | loss_rpn_cls: 0.0002 | loss_rpn_loc: 0.0312 | Total Loss: 0.4283\n",
      "Epoch 2345 | loss_cls: 0.0227 | loss_box_reg: 0.0760 | loss_mask: 0.0638 | loss_rpn_cls: 0.0177 | loss_rpn_loc: 0.0109 | Total Loss: 0.1912\n",
      "Epoch 2346 | loss_cls: 0.0607 | loss_box_reg: 0.1780 | loss_mask: 0.0515 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0047 | Total Loss: 0.2956\n",
      "Epoch 2347 | loss_cls: 0.0468 | loss_box_reg: 0.1621 | loss_mask: 0.0861 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0072 | Total Loss: 0.3028\n",
      "Epoch 2348 | loss_cls: 0.0448 | loss_box_reg: 0.1835 | loss_mask: 0.1765 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0525 | Total Loss: 0.4578\n",
      "Epoch 2349 | loss_cls: 0.0978 | loss_box_reg: 0.1969 | loss_mask: 0.1926 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.0841 | Total Loss: 0.5737\n",
      "Epoch 2350 | loss_cls: 0.0323 | loss_box_reg: 0.0738 | loss_mask: 0.0671 | loss_rpn_cls: 0.0038 | loss_rpn_loc: 0.0193 | Total Loss: 0.1962\n",
      "Epoch 2351 | loss_cls: 0.0504 | loss_box_reg: 0.1119 | loss_mask: 0.1097 | loss_rpn_cls: 0.0016 | loss_rpn_loc: 0.0057 | Total Loss: 0.2794\n",
      "Epoch 2352 | loss_cls: 0.0528 | loss_box_reg: 0.1005 | loss_mask: 0.0530 | loss_rpn_cls: 0.0026 | loss_rpn_loc: 0.0053 | Total Loss: 0.2142\n",
      "Epoch 2353 | loss_cls: 0.0320 | loss_box_reg: 0.0993 | loss_mask: 0.0509 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.0632 | Total Loss: 0.2474\n",
      "Epoch 2354 | loss_cls: 0.0484 | loss_box_reg: 0.0949 | loss_mask: 0.0493 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.1438 | Total Loss: 0.3377\n",
      "Epoch 2355 | loss_cls: 0.0624 | loss_box_reg: 0.1805 | loss_mask: 0.0561 | loss_rpn_cls: 0.0089 | loss_rpn_loc: 0.0349 | Total Loss: 0.3428\n",
      "Epoch 2356 | loss_cls: 0.0273 | loss_box_reg: 0.1157 | loss_mask: 0.1099 | loss_rpn_cls: 0.0049 | loss_rpn_loc: 0.0973 | Total Loss: 0.3551\n",
      "Epoch 2357 | loss_cls: 0.0308 | loss_box_reg: 0.1872 | loss_mask: 0.0454 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.0702 | Total Loss: 0.3363\n",
      "Epoch 2358 | loss_cls: 0.0784 | loss_box_reg: 0.1700 | loss_mask: 0.0883 | loss_rpn_cls: 0.0031 | loss_rpn_loc: 0.0043 | Total Loss: 0.3441\n",
      "Epoch 2359 | loss_cls: 0.0991 | loss_box_reg: 0.2821 | loss_mask: 0.1227 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0147 | Total Loss: 0.5193\n",
      "\u001b[32m[07/29 18:34:27 d2.utils.events]: \u001b[0m eta: 0:04:12  iter: 2359      time: 0.3362  last_time: 0.2826   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2360 | loss_cls: 0.0525 | loss_box_reg: 0.1459 | loss_mask: 0.1106 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0309 | Total Loss: 0.3404\n",
      "Epoch 2361 | loss_cls: 0.0806 | loss_box_reg: 0.1755 | loss_mask: 0.1182 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.0116 | Total Loss: 0.3885\n",
      "Epoch 2362 | loss_cls: 0.0368 | loss_box_reg: 0.1239 | loss_mask: 0.0359 | loss_rpn_cls: 0.0069 | loss_rpn_loc: 0.0703 | Total Loss: 0.2738\n",
      "Epoch 2363 | loss_cls: 0.0464 | loss_box_reg: 0.0763 | loss_mask: 0.0540 | loss_rpn_cls: 0.0059 | loss_rpn_loc: 0.0137 | Total Loss: 0.1962\n",
      "Epoch 2364 | loss_cls: 0.1132 | loss_box_reg: 0.2135 | loss_mask: 0.0447 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.0080 | Total Loss: 0.3814\n",
      "Epoch 2365 | loss_cls: 0.0567 | loss_box_reg: 0.1828 | loss_mask: 0.0884 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.0044 | Total Loss: 0.3337\n",
      "Epoch 2366 | loss_cls: 0.1724 | loss_box_reg: 0.2491 | loss_mask: 0.0717 | loss_rpn_cls: 0.0146 | loss_rpn_loc: 0.2861 | Total Loss: 0.7939\n",
      "Epoch 2367 | loss_cls: 0.0258 | loss_box_reg: 0.1559 | loss_mask: 0.0777 | loss_rpn_cls: 0.0087 | loss_rpn_loc: 0.0591 | Total Loss: 0.3273\n",
      "Epoch 2368 | loss_cls: 0.0627 | loss_box_reg: 0.1372 | loss_mask: 0.0904 | loss_rpn_cls: 0.0082 | loss_rpn_loc: 0.0795 | Total Loss: 0.3780\n",
      "Epoch 2369 | loss_cls: 0.0955 | loss_box_reg: 0.2061 | loss_mask: 0.0554 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.0257 | Total Loss: 0.3833\n",
      "Epoch 2370 | loss_cls: 0.0300 | loss_box_reg: 0.0395 | loss_mask: 0.0607 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.1080 | Total Loss: 0.2394\n",
      "Epoch 2371 | loss_cls: 0.0806 | loss_box_reg: 0.1818 | loss_mask: 0.0792 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.0159 | Total Loss: 0.3625\n",
      "Epoch 2372 | loss_cls: 0.0507 | loss_box_reg: 0.2050 | loss_mask: 0.0443 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0396 | Total Loss: 0.3403\n",
      "Epoch 2373 | loss_cls: 0.1478 | loss_box_reg: 0.3641 | loss_mask: 0.0604 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.1579 | Total Loss: 0.7335\n",
      "Epoch 2374 | loss_cls: 0.0501 | loss_box_reg: 0.1140 | loss_mask: 0.0492 | loss_rpn_cls: 0.0197 | loss_rpn_loc: 0.1432 | Total Loss: 0.3761\n",
      "Epoch 2375 | loss_cls: 0.0639 | loss_box_reg: 0.1549 | loss_mask: 0.0572 | loss_rpn_cls: 0.0168 | loss_rpn_loc: 0.0813 | Total Loss: 0.3740\n",
      "Epoch 2376 | loss_cls: 0.0416 | loss_box_reg: 0.1093 | loss_mask: 0.0780 | loss_rpn_cls: 0.0127 | loss_rpn_loc: 0.0066 | Total Loss: 0.2483\n",
      "Epoch 2377 | loss_cls: 0.0148 | loss_box_reg: 0.0572 | loss_mask: 0.0586 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.0176 | Total Loss: 0.1517\n",
      "Epoch 2378 | loss_cls: 0.0681 | loss_box_reg: 0.1355 | loss_mask: 0.1663 | loss_rpn_cls: 0.0017 | loss_rpn_loc: 0.0811 | Total Loss: 0.4527\n",
      "Epoch 2379 | loss_cls: 0.0379 | loss_box_reg: 0.1374 | loss_mask: 0.0708 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.0711 | Total Loss: 0.3181\n",
      "\u001b[32m[07/29 18:34:33 d2.utils.events]: \u001b[0m eta: 0:04:04  iter: 2379      time: 0.3362  last_time: 0.4050   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2380 | loss_cls: 0.0609 | loss_box_reg: 0.1129 | loss_mask: 0.0524 | loss_rpn_cls: 0.0067 | loss_rpn_loc: 0.0320 | Total Loss: 0.2650\n",
      "Epoch 2381 | loss_cls: 0.0880 | loss_box_reg: 0.1769 | loss_mask: 0.0406 | loss_rpn_cls: 0.0036 | loss_rpn_loc: 0.0056 | Total Loss: 0.3148\n",
      "Epoch 2382 | loss_cls: 0.0874 | loss_box_reg: 0.3373 | loss_mask: 0.2138 | loss_rpn_cls: 0.0064 | loss_rpn_loc: 0.0649 | Total Loss: 0.7098\n",
      "Epoch 2383 | loss_cls: 0.0575 | loss_box_reg: 0.0798 | loss_mask: 0.0714 | loss_rpn_cls: 0.0159 | loss_rpn_loc: 0.1117 | Total Loss: 0.3363\n",
      "Epoch 2384 | loss_cls: 0.0242 | loss_box_reg: 0.0905 | loss_mask: 0.0419 | loss_rpn_cls: 0.0001 | loss_rpn_loc: 0.0062 | Total Loss: 0.1630\n",
      "Epoch 2385 | loss_cls: 0.0722 | loss_box_reg: 0.1997 | loss_mask: 0.0619 | loss_rpn_cls: 0.0104 | loss_rpn_loc: 0.0026 | Total Loss: 0.3469\n",
      "Epoch 2386 | loss_cls: 0.0286 | loss_box_reg: 0.0579 | loss_mask: 0.0721 | loss_rpn_cls: 0.0009 | loss_rpn_loc: 0.0030 | Total Loss: 0.1625\n",
      "Epoch 2387 | loss_cls: 0.1807 | loss_box_reg: 0.2003 | loss_mask: 0.0434 | loss_rpn_cls: 0.0056 | loss_rpn_loc: 0.1290 | Total Loss: 0.5589\n",
      "Epoch 2388 | loss_cls: 0.0464 | loss_box_reg: 0.1469 | loss_mask: 0.0399 | loss_rpn_cls: 0.0086 | loss_rpn_loc: 0.0139 | Total Loss: 0.2557\n",
      "Epoch 2389 | loss_cls: 0.0429 | loss_box_reg: 0.1453 | loss_mask: 0.0870 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.0308 | Total Loss: 0.3074\n",
      "Epoch 2390 | loss_cls: 0.0233 | loss_box_reg: 0.0480 | loss_mask: 0.0325 | loss_rpn_cls: 0.0065 | loss_rpn_loc: 0.0163 | Total Loss: 0.1266\n",
      " Best model saved at Epoch 2390 | Total Loss: 0.1266\n",
      "Epoch 2391 | loss_cls: 0.0716 | loss_box_reg: 0.2367 | loss_mask: 0.0448 | loss_rpn_cls: 0.0120 | loss_rpn_loc: 0.1006 | Total Loss: 0.4657\n",
      "Epoch 2392 | loss_cls: 0.0651 | loss_box_reg: 0.2047 | loss_mask: 0.0633 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.0470 | Total Loss: 0.3815\n",
      "Epoch 2393 | loss_cls: 0.0328 | loss_box_reg: 0.1347 | loss_mask: 0.0597 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.0124 | Total Loss: 0.2411\n",
      "Epoch 2394 | loss_cls: 0.0487 | loss_box_reg: 0.1391 | loss_mask: 0.1070 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0313 | Total Loss: 0.3272\n",
      "Epoch 2395 | loss_cls: 0.0399 | loss_box_reg: 0.2304 | loss_mask: 0.1148 | loss_rpn_cls: 0.0046 | loss_rpn_loc: 0.0041 | Total Loss: 0.3938\n",
      "Epoch 2396 | loss_cls: 0.1194 | loss_box_reg: 0.1670 | loss_mask: 0.0486 | loss_rpn_cls: 0.0072 | loss_rpn_loc: 0.1398 | Total Loss: 0.4819\n",
      "Epoch 2397 | loss_cls: 0.0871 | loss_box_reg: 0.1465 | loss_mask: 0.0931 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.0665 | Total Loss: 0.3945\n",
      "Epoch 2398 | loss_cls: 0.1235 | loss_box_reg: 0.2712 | loss_mask: 0.0772 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.0093 | Total Loss: 0.4831\n",
      "Epoch 2399 | loss_cls: 0.0405 | loss_box_reg: 0.0464 | loss_mask: 0.0547 | loss_rpn_cls: 0.0141 | loss_rpn_loc: 0.0140 | Total Loss: 0.1698\n",
      "\u001b[32m[07/29 18:34:40 d2.utils.events]: \u001b[0m eta: 0:03:56  iter: 2399      time: 0.3361  last_time: 0.2716   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2400 | loss_cls: 0.0302 | loss_box_reg: 0.0631 | loss_mask: 0.0529 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0492 | Total Loss: 0.1965\n",
      "Epoch 2401 | loss_cls: 0.1155 | loss_box_reg: 0.1461 | loss_mask: 0.0581 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0208 | Total Loss: 0.3412\n",
      "Epoch 2402 | loss_cls: 0.0484 | loss_box_reg: 0.1127 | loss_mask: 0.1124 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0068 | Total Loss: 0.2809\n",
      "Epoch 2403 | loss_cls: 0.0480 | loss_box_reg: 0.1171 | loss_mask: 0.0547 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0109 | Total Loss: 0.2311\n",
      "Epoch 2404 | loss_cls: 0.0610 | loss_box_reg: 0.2184 | loss_mask: 0.0590 | loss_rpn_cls: 0.0424 | loss_rpn_loc: 0.0096 | Total Loss: 0.3904\n",
      "Epoch 2405 | loss_cls: 0.0792 | loss_box_reg: 0.2073 | loss_mask: 0.1021 | loss_rpn_cls: 0.0225 | loss_rpn_loc: 0.0455 | Total Loss: 0.4566\n",
      "Epoch 2406 | loss_cls: 0.0496 | loss_box_reg: 0.1039 | loss_mask: 0.1640 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.1192 | Total Loss: 0.4386\n",
      "Epoch 2407 | loss_cls: 0.0345 | loss_box_reg: 0.1575 | loss_mask: 0.1128 | loss_rpn_cls: 0.0003 | loss_rpn_loc: 0.0368 | Total Loss: 0.3419\n",
      "Epoch 2408 | loss_cls: 0.0445 | loss_box_reg: 0.1996 | loss_mask: 0.1232 | loss_rpn_cls: 0.0036 | loss_rpn_loc: 0.0306 | Total Loss: 0.4014\n",
      "Epoch 2409 | loss_cls: 0.0458 | loss_box_reg: 0.1248 | loss_mask: 0.0593 | loss_rpn_cls: 0.0031 | loss_rpn_loc: 0.2042 | Total Loss: 0.4372\n",
      "Epoch 2410 | loss_cls: 0.0177 | loss_box_reg: 0.1463 | loss_mask: 0.0630 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.0174 | Total Loss: 0.2456\n",
      "Epoch 2411 | loss_cls: 0.0574 | loss_box_reg: 0.1166 | loss_mask: 0.0636 | loss_rpn_cls: 0.0170 | loss_rpn_loc: 0.0303 | Total Loss: 0.2849\n",
      "Epoch 2412 | loss_cls: 0.0557 | loss_box_reg: 0.2041 | loss_mask: 0.0483 | loss_rpn_cls: 0.0052 | loss_rpn_loc: 0.0371 | Total Loss: 0.3505\n",
      "Epoch 2413 | loss_cls: 0.0578 | loss_box_reg: 0.1535 | loss_mask: 0.0953 | loss_rpn_cls: 0.0070 | loss_rpn_loc: 0.0076 | Total Loss: 0.3212\n",
      "Epoch 2414 | loss_cls: 0.0122 | loss_box_reg: 0.0451 | loss_mask: 0.2040 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.1024 | Total Loss: 0.3662\n",
      "Epoch 2415 | loss_cls: 0.0784 | loss_box_reg: 0.1076 | loss_mask: 0.0369 | loss_rpn_cls: 0.0097 | loss_rpn_loc: 0.0093 | Total Loss: 0.2417\n",
      "Epoch 2416 | loss_cls: 0.0487 | loss_box_reg: 0.1088 | loss_mask: 0.0711 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.0171 | Total Loss: 0.2461\n",
      "Epoch 2417 | loss_cls: 0.0535 | loss_box_reg: 0.1657 | loss_mask: 0.0758 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0172 | Total Loss: 0.3133\n",
      "Epoch 2418 | loss_cls: 0.0569 | loss_box_reg: 0.1689 | loss_mask: 0.1030 | loss_rpn_cls: 0.0049 | loss_rpn_loc: 0.0746 | Total Loss: 0.4083\n",
      "Epoch 2419 | loss_cls: 0.0310 | loss_box_reg: 0.0540 | loss_mask: 0.0950 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0163 | Total Loss: 0.1969\n",
      "\u001b[32m[07/29 18:34:46 d2.utils.events]: \u001b[0m eta: 0:03:48  iter: 2419      time: 0.3360  last_time: 0.2667   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2420 | loss_cls: 0.0787 | loss_box_reg: 0.1997 | loss_mask: 0.0536 | loss_rpn_cls: 0.0119 | loss_rpn_loc: 0.2696 | Total Loss: 0.6135\n",
      "Epoch 2421 | loss_cls: 0.0229 | loss_box_reg: 0.0561 | loss_mask: 0.0411 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.0196 | Total Loss: 0.1410\n",
      "Epoch 2422 | loss_cls: 0.0281 | loss_box_reg: 0.0687 | loss_mask: 0.2962 | loss_rpn_cls: 0.0050 | loss_rpn_loc: 0.2098 | Total Loss: 0.6077\n",
      "Epoch 2423 | loss_cls: 0.0559 | loss_box_reg: 0.1258 | loss_mask: 0.0762 | loss_rpn_cls: 0.0900 | loss_rpn_loc: 0.2169 | Total Loss: 0.5648\n",
      "Epoch 2424 | loss_cls: 0.0754 | loss_box_reg: 0.1219 | loss_mask: 0.0770 | loss_rpn_cls: 0.0040 | loss_rpn_loc: 0.0153 | Total Loss: 0.2935\n",
      "Epoch 2425 | loss_cls: 0.0512 | loss_box_reg: 0.1361 | loss_mask: 0.0931 | loss_rpn_cls: 0.0036 | loss_rpn_loc: 0.0929 | Total Loss: 0.3768\n",
      "Epoch 2426 | loss_cls: 0.0598 | loss_box_reg: 0.1746 | loss_mask: 0.0575 | loss_rpn_cls: 0.0028 | loss_rpn_loc: 0.0336 | Total Loss: 0.3284\n",
      "Epoch 2427 | loss_cls: 0.0269 | loss_box_reg: 0.0689 | loss_mask: 0.0413 | loss_rpn_cls: 0.0065 | loss_rpn_loc: 0.0561 | Total Loss: 0.1997\n",
      "Epoch 2428 | loss_cls: 0.0366 | loss_box_reg: 0.1387 | loss_mask: 0.1930 | loss_rpn_cls: 0.0067 | loss_rpn_loc: 0.0835 | Total Loss: 0.4583\n",
      "Epoch 2429 | loss_cls: 0.1110 | loss_box_reg: 0.2912 | loss_mask: 0.1220 | loss_rpn_cls: 0.0008 | loss_rpn_loc: 0.0562 | Total Loss: 0.5812\n",
      "Epoch 2430 | loss_cls: 0.0325 | loss_box_reg: 0.1279 | loss_mask: 0.1262 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.1310 | Total Loss: 0.4195\n",
      "Epoch 2431 | loss_cls: 0.0191 | loss_box_reg: 0.0630 | loss_mask: 0.0301 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.0031 | Total Loss: 0.1203\n",
      " Best model saved at Epoch 2431 | Total Loss: 0.1203\n",
      "Epoch 2432 | loss_cls: 0.0320 | loss_box_reg: 0.1116 | loss_mask: 0.0369 | loss_rpn_cls: 0.0021 | loss_rpn_loc: 0.0039 | Total Loss: 0.1865\n",
      "Epoch 2433 | loss_cls: 0.0181 | loss_box_reg: 0.0721 | loss_mask: 0.1602 | loss_rpn_cls: 0.0078 | loss_rpn_loc: 0.1138 | Total Loss: 0.3720\n",
      "Epoch 2434 | loss_cls: 0.0740 | loss_box_reg: 0.1891 | loss_mask: 0.0484 | loss_rpn_cls: 0.0018 | loss_rpn_loc: 0.0078 | Total Loss: 0.3211\n",
      "Epoch 2435 | loss_cls: 0.0510 | loss_box_reg: 0.0810 | loss_mask: 0.1052 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.2822 | Total Loss: 0.5227\n",
      "Epoch 2436 | loss_cls: 0.0406 | loss_box_reg: 0.0950 | loss_mask: 0.0639 | loss_rpn_cls: 0.0083 | loss_rpn_loc: 0.0739 | Total Loss: 0.2817\n",
      "Epoch 2437 | loss_cls: 0.0401 | loss_box_reg: 0.1878 | loss_mask: 0.2314 | loss_rpn_cls: 0.0046 | loss_rpn_loc: 0.2094 | Total Loss: 0.6732\n",
      "Epoch 2438 | loss_cls: 0.0302 | loss_box_reg: 0.1238 | loss_mask: 0.1917 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.0775 | Total Loss: 0.4256\n",
      "Epoch 2439 | loss_cls: 0.0445 | loss_box_reg: 0.1467 | loss_mask: 0.0725 | loss_rpn_cls: 0.0255 | loss_rpn_loc: 0.0042 | Total Loss: 0.2934\n",
      "\u001b[32m[07/29 18:34:53 d2.utils.events]: \u001b[0m eta: 0:03:40  iter: 2439      time: 0.3361  last_time: 0.1903   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2440 | loss_cls: 0.0479 | loss_box_reg: 0.1426 | loss_mask: 0.1050 | loss_rpn_cls: 0.0017 | loss_rpn_loc: 0.0233 | Total Loss: 0.3204\n",
      "Epoch 2441 | loss_cls: 0.0751 | loss_box_reg: 0.1526 | loss_mask: 0.2124 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.0514 | Total Loss: 0.4929\n",
      "Epoch 2442 | loss_cls: 0.0754 | loss_box_reg: 0.1510 | loss_mask: 0.0734 | loss_rpn_cls: 0.0094 | loss_rpn_loc: 0.1108 | Total Loss: 0.4200\n",
      "Epoch 2443 | loss_cls: 0.0850 | loss_box_reg: 0.1250 | loss_mask: 0.0715 | loss_rpn_cls: 0.0002 | loss_rpn_loc: 0.0128 | Total Loss: 0.2945\n",
      "Epoch 2444 | loss_cls: 0.0348 | loss_box_reg: 0.1578 | loss_mask: 0.1179 | loss_rpn_cls: 0.0020 | loss_rpn_loc: 0.1488 | Total Loss: 0.4613\n",
      "Epoch 2445 | loss_cls: 0.0490 | loss_box_reg: 0.1252 | loss_mask: 0.0522 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.0263 | Total Loss: 0.2532\n",
      "Epoch 2446 | loss_cls: 0.0319 | loss_box_reg: 0.0582 | loss_mask: 0.0968 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.0853 | Total Loss: 0.2736\n",
      "Epoch 2447 | loss_cls: 0.0545 | loss_box_reg: 0.2349 | loss_mask: 0.0462 | loss_rpn_cls: 0.0107 | loss_rpn_loc: 0.0153 | Total Loss: 0.3616\n",
      "Epoch 2448 | loss_cls: 0.0632 | loss_box_reg: 0.1266 | loss_mask: 0.0709 | loss_rpn_cls: 0.0199 | loss_rpn_loc: 0.1226 | Total Loss: 0.4032\n",
      "Epoch 2449 | loss_cls: 0.0565 | loss_box_reg: 0.1491 | loss_mask: 0.0616 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.0362 | Total Loss: 0.3039\n",
      "Epoch 2450 | loss_cls: 0.0551 | loss_box_reg: 0.1045 | loss_mask: 0.0739 | loss_rpn_cls: 0.0028 | loss_rpn_loc: 0.0366 | Total Loss: 0.2729\n",
      "Epoch 2451 | loss_cls: 0.0883 | loss_box_reg: 0.1186 | loss_mask: 0.1195 | loss_rpn_cls: 0.0026 | loss_rpn_loc: 0.0058 | Total Loss: 0.3348\n",
      "Epoch 2452 | loss_cls: 0.0157 | loss_box_reg: 0.0396 | loss_mask: 0.0782 | loss_rpn_cls: 0.0046 | loss_rpn_loc: 0.1775 | Total Loss: 0.3156\n",
      "Epoch 2453 | loss_cls: 0.0521 | loss_box_reg: 0.1790 | loss_mask: 0.1055 | loss_rpn_cls: 0.0042 | loss_rpn_loc: 0.0279 | Total Loss: 0.3687\n",
      "Epoch 2454 | loss_cls: 0.0209 | loss_box_reg: 0.1897 | loss_mask: 0.0743 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.0557 | Total Loss: 0.3415\n",
      "Epoch 2455 | loss_cls: 0.0493 | loss_box_reg: 0.0867 | loss_mask: 0.0881 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.1260 | Total Loss: 0.3511\n",
      "Epoch 2456 | loss_cls: 0.1483 | loss_box_reg: 0.2215 | loss_mask: 0.0864 | loss_rpn_cls: 0.0059 | loss_rpn_loc: 0.1304 | Total Loss: 0.5925\n",
      "Epoch 2457 | loss_cls: 0.0358 | loss_box_reg: 0.0722 | loss_mask: 0.0370 | loss_rpn_cls: 0.0101 | loss_rpn_loc: 0.0080 | Total Loss: 0.1631\n",
      "Epoch 2458 | loss_cls: 0.0939 | loss_box_reg: 0.1614 | loss_mask: 0.0476 | loss_rpn_cls: 0.0141 | loss_rpn_loc: 0.1920 | Total Loss: 0.5089\n",
      "Epoch 2459 | loss_cls: 0.0271 | loss_box_reg: 0.0669 | loss_mask: 0.0675 | loss_rpn_cls: 0.0063 | loss_rpn_loc: 0.1040 | Total Loss: 0.2718\n",
      "\u001b[32m[07/29 18:35:01 d2.utils.events]: \u001b[0m eta: 0:03:32  iter: 2459      time: 0.3363  last_time: 0.3923   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2460 | loss_cls: 0.0280 | loss_box_reg: 0.0349 | loss_mask: 0.0920 | loss_rpn_cls: 0.0030 | loss_rpn_loc: 0.1156 | Total Loss: 0.2734\n",
      "Epoch 2461 | loss_cls: 0.0516 | loss_box_reg: 0.1743 | loss_mask: 0.0452 | loss_rpn_cls: 0.0096 | loss_rpn_loc: 0.1012 | Total Loss: 0.3820\n",
      "Epoch 2462 | loss_cls: 0.0732 | loss_box_reg: 0.0638 | loss_mask: 0.0649 | loss_rpn_cls: 0.0018 | loss_rpn_loc: 0.0102 | Total Loss: 0.2139\n",
      "Epoch 2463 | loss_cls: 0.0470 | loss_box_reg: 0.0652 | loss_mask: 0.0824 | loss_rpn_cls: 0.0067 | loss_rpn_loc: 0.1082 | Total Loss: 0.3095\n",
      "Epoch 2464 | loss_cls: 0.0210 | loss_box_reg: 0.0572 | loss_mask: 0.0455 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.0174 | Total Loss: 0.1423\n",
      "Epoch 2465 | loss_cls: 0.0811 | loss_box_reg: 0.2252 | loss_mask: 0.0405 | loss_rpn_cls: 0.0032 | loss_rpn_loc: 0.1496 | Total Loss: 0.4996\n",
      "Epoch 2466 | loss_cls: 0.0324 | loss_box_reg: 0.1630 | loss_mask: 0.1516 | loss_rpn_cls: 0.0102 | loss_rpn_loc: 0.0944 | Total Loss: 0.4516\n",
      "Epoch 2467 | loss_cls: 0.0406 | loss_box_reg: 0.1340 | loss_mask: 0.0659 | loss_rpn_cls: 0.0098 | loss_rpn_loc: 0.0771 | Total Loss: 0.3274\n",
      "Epoch 2468 | loss_cls: 0.0873 | loss_box_reg: 0.1302 | loss_mask: 0.0471 | loss_rpn_cls: 0.0236 | loss_rpn_loc: 0.1870 | Total Loss: 0.4753\n",
      "Epoch 2469 | loss_cls: 0.0542 | loss_box_reg: 0.1526 | loss_mask: 0.0573 | loss_rpn_cls: 0.0083 | loss_rpn_loc: 0.0316 | Total Loss: 0.3039\n",
      "Epoch 2470 | loss_cls: 0.0229 | loss_box_reg: 0.0773 | loss_mask: 0.2323 | loss_rpn_cls: 0.0016 | loss_rpn_loc: 0.1216 | Total Loss: 0.4556\n",
      "Epoch 2471 | loss_cls: 0.0700 | loss_box_reg: 0.1707 | loss_mask: 0.0534 | loss_rpn_cls: 0.0096 | loss_rpn_loc: 0.0068 | Total Loss: 0.3105\n",
      "Epoch 2472 | loss_cls: 0.0702 | loss_box_reg: 0.1153 | loss_mask: 0.0524 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.1046 | Total Loss: 0.3449\n",
      "Epoch 2473 | loss_cls: 0.0479 | loss_box_reg: 0.0999 | loss_mask: 0.0424 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.0338 | Total Loss: 0.2255\n",
      "Epoch 2474 | loss_cls: 0.0718 | loss_box_reg: 0.2298 | loss_mask: 0.0903 | loss_rpn_cls: 0.0053 | loss_rpn_loc: 0.0041 | Total Loss: 0.4013\n",
      "Epoch 2475 | loss_cls: 0.0872 | loss_box_reg: 0.3060 | loss_mask: 0.1299 | loss_rpn_cls: 0.0031 | loss_rpn_loc: 0.0399 | Total Loss: 0.5661\n",
      "Epoch 2476 | loss_cls: 0.0292 | loss_box_reg: 0.0842 | loss_mask: 0.1037 | loss_rpn_cls: 0.0064 | loss_rpn_loc: 0.1077 | Total Loss: 0.3313\n",
      "Epoch 2477 | loss_cls: 0.0453 | loss_box_reg: 0.1023 | loss_mask: 0.0321 | loss_rpn_cls: 0.0039 | loss_rpn_loc: 0.0179 | Total Loss: 0.2014\n",
      "Epoch 2478 | loss_cls: 0.0500 | loss_box_reg: 0.1513 | loss_mask: 0.0971 | loss_rpn_cls: 0.0018 | loss_rpn_loc: 0.0834 | Total Loss: 0.3837\n",
      "Epoch 2479 | loss_cls: 0.0783 | loss_box_reg: 0.1755 | loss_mask: 0.0776 | loss_rpn_cls: 0.0031 | loss_rpn_loc: 0.0103 | Total Loss: 0.3448\n",
      "\u001b[32m[07/29 18:35:08 d2.utils.events]: \u001b[0m eta: 0:03:24  iter: 2479      time: 0.3365  last_time: 0.1845   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2480 | loss_cls: 0.0360 | loss_box_reg: 0.1543 | loss_mask: 0.1563 | loss_rpn_cls: 0.0107 | loss_rpn_loc: 0.0118 | Total Loss: 0.3691\n",
      "Epoch 2481 | loss_cls: 0.0456 | loss_box_reg: 0.1872 | loss_mask: 0.0567 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0891 | Total Loss: 0.3796\n",
      "Epoch 2482 | loss_cls: 0.0456 | loss_box_reg: 0.0869 | loss_mask: 0.0419 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.0644 | Total Loss: 0.2401\n",
      "Epoch 2483 | loss_cls: 0.0322 | loss_box_reg: 0.1011 | loss_mask: 0.1270 | loss_rpn_cls: 0.0115 | loss_rpn_loc: 0.0784 | Total Loss: 0.3502\n",
      "Epoch 2484 | loss_cls: 0.0351 | loss_box_reg: 0.0792 | loss_mask: 0.0684 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.0193 | Total Loss: 0.2024\n",
      "Epoch 2485 | loss_cls: 0.0572 | loss_box_reg: 0.1440 | loss_mask: 0.0581 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0272 | Total Loss: 0.2875\n",
      "Epoch 2486 | loss_cls: 0.1376 | loss_box_reg: 0.2332 | loss_mask: 0.0758 | loss_rpn_cls: 0.0139 | loss_rpn_loc: 0.0629 | Total Loss: 0.5235\n",
      "Epoch 2487 | loss_cls: 0.0398 | loss_box_reg: 0.0578 | loss_mask: 0.0682 | loss_rpn_cls: 0.0055 | loss_rpn_loc: 0.1495 | Total Loss: 0.3209\n",
      "Epoch 2488 | loss_cls: 0.0745 | loss_box_reg: 0.0982 | loss_mask: 0.1232 | loss_rpn_cls: 0.0056 | loss_rpn_loc: 0.1003 | Total Loss: 0.4018\n",
      "Epoch 2489 | loss_cls: 0.0644 | loss_box_reg: 0.0592 | loss_mask: 0.0891 | loss_rpn_cls: 0.0063 | loss_rpn_loc: 0.0202 | Total Loss: 0.2392\n",
      "Epoch 2490 | loss_cls: 0.1220 | loss_box_reg: 0.2166 | loss_mask: 0.0809 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0221 | Total Loss: 0.4423\n",
      "Epoch 2491 | loss_cls: 0.0485 | loss_box_reg: 0.1958 | loss_mask: 0.0396 | loss_rpn_cls: 0.0207 | loss_rpn_loc: 0.1487 | Total Loss: 0.4532\n",
      "Epoch 2492 | loss_cls: 0.0575 | loss_box_reg: 0.1795 | loss_mask: 0.0539 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0416 | Total Loss: 0.3332\n",
      "Epoch 2493 | loss_cls: 0.0260 | loss_box_reg: 0.0902 | loss_mask: 0.1012 | loss_rpn_cls: 0.0059 | loss_rpn_loc: 0.0207 | Total Loss: 0.2441\n",
      "Epoch 2494 | loss_cls: 0.0464 | loss_box_reg: 0.1606 | loss_mask: 0.0540 | loss_rpn_cls: 0.0095 | loss_rpn_loc: 0.0541 | Total Loss: 0.3246\n",
      "Epoch 2495 | loss_cls: 0.0500 | loss_box_reg: 0.1508 | loss_mask: 0.2190 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.1691 | Total Loss: 0.5904\n",
      "Epoch 2496 | loss_cls: 0.0353 | loss_box_reg: 0.1141 | loss_mask: 0.1000 | loss_rpn_cls: 0.0095 | loss_rpn_loc: 0.0928 | Total Loss: 0.3517\n",
      "Epoch 2497 | loss_cls: 0.0779 | loss_box_reg: 0.1921 | loss_mask: 0.0439 | loss_rpn_cls: 0.0052 | loss_rpn_loc: 0.1992 | Total Loss: 0.5183\n",
      "Epoch 2498 | loss_cls: 0.0461 | loss_box_reg: 0.2767 | loss_mask: 0.1947 | loss_rpn_cls: 0.0021 | loss_rpn_loc: 0.0829 | Total Loss: 0.6024\n",
      "Epoch 2499 | loss_cls: 0.0600 | loss_box_reg: 0.1466 | loss_mask: 0.1657 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.0075 | Total Loss: 0.3831\n",
      "\u001b[32m[07/29 18:35:15 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 2499      time: 0.3365  last_time: 0.2873   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2500 | loss_cls: 0.0288 | loss_box_reg: 0.0956 | loss_mask: 0.0511 | loss_rpn_cls: 0.0074 | loss_rpn_loc: 0.1207 | Total Loss: 0.3036\n",
      "Epoch 2501 | loss_cls: 0.0741 | loss_box_reg: 0.2257 | loss_mask: 0.0673 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.0089 | Total Loss: 0.3795\n",
      "Epoch 2502 | loss_cls: 0.0498 | loss_box_reg: 0.1404 | loss_mask: 0.1110 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.0132 | Total Loss: 0.3160\n",
      "Epoch 2503 | loss_cls: 0.0333 | loss_box_reg: 0.1418 | loss_mask: 0.0647 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0256 | Total Loss: 0.2658\n",
      "Epoch 2504 | loss_cls: 0.0101 | loss_box_reg: 0.0791 | loss_mask: 0.0672 | loss_rpn_cls: 0.0115 | loss_rpn_loc: 0.0956 | Total Loss: 0.2635\n",
      "Epoch 2505 | loss_cls: 0.0254 | loss_box_reg: 0.0584 | loss_mask: 0.0430 | loss_rpn_cls: 0.0016 | loss_rpn_loc: 0.1335 | Total Loss: 0.2620\n",
      "Epoch 2506 | loss_cls: 0.0820 | loss_box_reg: 0.2529 | loss_mask: 0.0900 | loss_rpn_cls: 0.0030 | loss_rpn_loc: 0.0738 | Total Loss: 0.5018\n",
      "Epoch 2507 | loss_cls: 0.0359 | loss_box_reg: 0.1009 | loss_mask: 0.0309 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.0051 | Total Loss: 0.1779\n",
      "Epoch 2508 | loss_cls: 0.0266 | loss_box_reg: 0.0865 | loss_mask: 0.0653 | loss_rpn_cls: 0.0022 | loss_rpn_loc: 0.0171 | Total Loss: 0.1977\n",
      "Epoch 2509 | loss_cls: 0.0795 | loss_box_reg: 0.1170 | loss_mask: 0.0775 | loss_rpn_cls: 0.0112 | loss_rpn_loc: 0.0931 | Total Loss: 0.3782\n",
      "Epoch 2510 | loss_cls: 0.0498 | loss_box_reg: 0.1050 | loss_mask: 0.1012 | loss_rpn_cls: 0.0060 | loss_rpn_loc: 0.1194 | Total Loss: 0.3814\n",
      "Epoch 2511 | loss_cls: 0.0735 | loss_box_reg: 0.1475 | loss_mask: 0.1367 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.0383 | Total Loss: 0.3986\n",
      "Epoch 2512 | loss_cls: 0.0470 | loss_box_reg: 0.1447 | loss_mask: 0.0784 | loss_rpn_cls: 0.0149 | loss_rpn_loc: 0.0284 | Total Loss: 0.3133\n",
      "Epoch 2513 | loss_cls: 0.0425 | loss_box_reg: 0.1282 | loss_mask: 0.0608 | loss_rpn_cls: 0.0238 | loss_rpn_loc: 0.0744 | Total Loss: 0.3297\n",
      "Epoch 2514 | loss_cls: 0.0115 | loss_box_reg: 0.0759 | loss_mask: 0.0372 | loss_rpn_cls: 0.0041 | loss_rpn_loc: 0.1060 | Total Loss: 0.2348\n",
      "Epoch 2515 | loss_cls: 0.0408 | loss_box_reg: 0.0745 | loss_mask: 0.1060 | loss_rpn_cls: 0.0002 | loss_rpn_loc: 0.0020 | Total Loss: 0.2234\n",
      "Epoch 2516 | loss_cls: 0.0260 | loss_box_reg: 0.0927 | loss_mask: 0.0398 | loss_rpn_cls: 0.0036 | loss_rpn_loc: 0.0374 | Total Loss: 0.1994\n",
      "Epoch 2517 | loss_cls: 0.0578 | loss_box_reg: 0.0993 | loss_mask: 0.0631 | loss_rpn_cls: 0.0016 | loss_rpn_loc: 0.0192 | Total Loss: 0.2409\n",
      "Epoch 2518 | loss_cls: 0.0420 | loss_box_reg: 0.1372 | loss_mask: 0.0404 | loss_rpn_cls: 0.0294 | loss_rpn_loc: 0.0668 | Total Loss: 0.3159\n",
      "Epoch 2519 | loss_cls: 0.0184 | loss_box_reg: 0.0812 | loss_mask: 0.3519 | loss_rpn_cls: 0.0002 | loss_rpn_loc: 0.0207 | Total Loss: 0.4724\n",
      "\u001b[32m[07/29 18:35:21 d2.utils.events]: \u001b[0m eta: 0:03:09  iter: 2519      time: 0.3364  last_time: 0.2652   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2520 | loss_cls: 0.0639 | loss_box_reg: 0.1191 | loss_mask: 0.1067 | loss_rpn_cls: 0.0200 | loss_rpn_loc: 0.1140 | Total Loss: 0.4237\n",
      "Epoch 2521 | loss_cls: 0.0662 | loss_box_reg: 0.1009 | loss_mask: 0.0407 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.0384 | Total Loss: 0.2485\n",
      "Epoch 2522 | loss_cls: 0.0315 | loss_box_reg: 0.0740 | loss_mask: 0.0602 | loss_rpn_cls: 0.0008 | loss_rpn_loc: 0.0050 | Total Loss: 0.1715\n",
      "Epoch 2523 | loss_cls: 0.1730 | loss_box_reg: 0.3803 | loss_mask: 0.1630 | loss_rpn_cls: 0.0021 | loss_rpn_loc: 0.0793 | Total Loss: 0.7977\n",
      "Epoch 2524 | loss_cls: 0.0333 | loss_box_reg: 0.1132 | loss_mask: 0.0617 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.1072 | Total Loss: 0.3188\n",
      "Epoch 2525 | loss_cls: 0.0593 | loss_box_reg: 0.1219 | loss_mask: 0.0386 | loss_rpn_cls: 0.0145 | loss_rpn_loc: 0.2007 | Total Loss: 0.4350\n",
      "Epoch 2526 | loss_cls: 0.0357 | loss_box_reg: 0.0979 | loss_mask: 0.0687 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0395 | Total Loss: 0.2423\n",
      "Epoch 2527 | loss_cls: 0.0532 | loss_box_reg: 0.3187 | loss_mask: 0.0785 | loss_rpn_cls: 0.0039 | loss_rpn_loc: 0.0243 | Total Loss: 0.4785\n",
      "Epoch 2528 | loss_cls: 0.0418 | loss_box_reg: 0.1194 | loss_mask: 0.2113 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0028 | Total Loss: 0.3758\n",
      "Epoch 2529 | loss_cls: 0.0554 | loss_box_reg: 0.1083 | loss_mask: 0.1027 | loss_rpn_cls: 0.0077 | loss_rpn_loc: 0.0134 | Total Loss: 0.2875\n",
      "Epoch 2530 | loss_cls: 0.0494 | loss_box_reg: 0.1368 | loss_mask: 0.1315 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0100 | Total Loss: 0.3287\n",
      "Epoch 2531 | loss_cls: 0.1587 | loss_box_reg: 0.1653 | loss_mask: 0.0445 | loss_rpn_cls: 0.0028 | loss_rpn_loc: 0.0171 | Total Loss: 0.3884\n",
      "Epoch 2532 | loss_cls: 0.0134 | loss_box_reg: 0.0704 | loss_mask: 0.0986 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.0136 | Total Loss: 0.1969\n",
      "Epoch 2533 | loss_cls: 0.0231 | loss_box_reg: 0.0610 | loss_mask: 0.0264 | loss_rpn_cls: 0.0055 | loss_rpn_loc: 0.0020 | Total Loss: 0.1181\n",
      " Best model saved at Epoch 2533 | Total Loss: 0.1181\n",
      "Epoch 2534 | loss_cls: 0.0451 | loss_box_reg: 0.1235 | loss_mask: 0.0486 | loss_rpn_cls: 0.0390 | loss_rpn_loc: 0.1794 | Total Loss: 0.4357\n",
      "Epoch 2535 | loss_cls: 0.0611 | loss_box_reg: 0.2394 | loss_mask: 0.0884 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.1442 | Total Loss: 0.5346\n",
      "Epoch 2536 | loss_cls: 0.0478 | loss_box_reg: 0.1684 | loss_mask: 0.0679 | loss_rpn_cls: 0.0113 | loss_rpn_loc: 0.0079 | Total Loss: 0.3034\n",
      "Epoch 2537 | loss_cls: 0.0595 | loss_box_reg: 0.1333 | loss_mask: 0.0508 | loss_rpn_cls: 0.0063 | loss_rpn_loc: 0.0044 | Total Loss: 0.2543\n",
      "Epoch 2538 | loss_cls: 0.0440 | loss_box_reg: 0.1039 | loss_mask: 0.3227 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.1236 | Total Loss: 0.5947\n",
      "Epoch 2539 | loss_cls: 0.0653 | loss_box_reg: 0.1500 | loss_mask: 0.0881 | loss_rpn_cls: 0.0203 | loss_rpn_loc: 0.0042 | Total Loss: 0.3280\n",
      "\u001b[32m[07/29 18:35:28 d2.utils.events]: \u001b[0m eta: 0:03:01  iter: 2539      time: 0.3364  last_time: 0.2758   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2540 | loss_cls: 0.0758 | loss_box_reg: 0.1897 | loss_mask: 0.0944 | loss_rpn_cls: 0.0096 | loss_rpn_loc: 0.0045 | Total Loss: 0.3741\n",
      "Epoch 2541 | loss_cls: 0.0421 | loss_box_reg: 0.0382 | loss_mask: 0.0984 | loss_rpn_cls: 0.0052 | loss_rpn_loc: 0.2306 | Total Loss: 0.4145\n",
      "Epoch 2542 | loss_cls: 0.1136 | loss_box_reg: 0.1601 | loss_mask: 0.0610 | loss_rpn_cls: 0.0062 | loss_rpn_loc: 0.0517 | Total Loss: 0.3926\n",
      "Epoch 2543 | loss_cls: 0.1137 | loss_box_reg: 0.3588 | loss_mask: 0.2377 | loss_rpn_cls: 0.0038 | loss_rpn_loc: 0.0080 | Total Loss: 0.7220\n",
      "Epoch 2544 | loss_cls: 0.0541 | loss_box_reg: 0.1766 | loss_mask: 0.0666 | loss_rpn_cls: 0.0052 | loss_rpn_loc: 0.1700 | Total Loss: 0.4724\n",
      "Epoch 2545 | loss_cls: 0.0321 | loss_box_reg: 0.1015 | loss_mask: 0.0353 | loss_rpn_cls: 0.0219 | loss_rpn_loc: 0.1055 | Total Loss: 0.2963\n",
      "Epoch 2546 | loss_cls: 0.0268 | loss_box_reg: 0.1549 | loss_mask: 0.0560 | loss_rpn_cls: 0.0065 | loss_rpn_loc: 0.0308 | Total Loss: 0.2750\n",
      "Epoch 2547 | loss_cls: 0.0796 | loss_box_reg: 0.2496 | loss_mask: 0.1615 | loss_rpn_cls: 0.0072 | loss_rpn_loc: 0.0085 | Total Loss: 0.5063\n",
      "Epoch 2548 | loss_cls: 0.0617 | loss_box_reg: 0.1006 | loss_mask: 0.0555 | loss_rpn_cls: 0.0129 | loss_rpn_loc: 0.0131 | Total Loss: 0.2437\n",
      "Epoch 2549 | loss_cls: 0.0598 | loss_box_reg: 0.1190 | loss_mask: 0.1724 | loss_rpn_cls: 0.0147 | loss_rpn_loc: 0.2063 | Total Loss: 0.5722\n",
      "Epoch 2550 | loss_cls: 0.0704 | loss_box_reg: 0.1015 | loss_mask: 0.0575 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.1005 | Total Loss: 0.3350\n",
      "Epoch 2551 | loss_cls: 0.0833 | loss_box_reg: 0.2078 | loss_mask: 0.0660 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.0063 | Total Loss: 0.3654\n",
      "Epoch 2552 | loss_cls: 0.0458 | loss_box_reg: 0.2104 | loss_mask: 0.0905 | loss_rpn_cls: 0.0054 | loss_rpn_loc: 0.1605 | Total Loss: 0.5125\n",
      "Epoch 2553 | loss_cls: 0.0886 | loss_box_reg: 0.1872 | loss_mask: 0.0907 | loss_rpn_cls: 0.0062 | loss_rpn_loc: 0.0470 | Total Loss: 0.4197\n",
      "Epoch 2554 | loss_cls: 0.0613 | loss_box_reg: 0.1291 | loss_mask: 0.0877 | loss_rpn_cls: 0.0213 | loss_rpn_loc: 0.0067 | Total Loss: 0.3061\n",
      "Epoch 2555 | loss_cls: 0.0532 | loss_box_reg: 0.0960 | loss_mask: 0.0509 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.0115 | Total Loss: 0.2149\n",
      "Epoch 2556 | loss_cls: 0.0191 | loss_box_reg: 0.0897 | loss_mask: 0.0422 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.0836 | Total Loss: 0.2360\n",
      "Epoch 2557 | loss_cls: 0.1017 | loss_box_reg: 0.2186 | loss_mask: 0.0365 | loss_rpn_cls: 0.0644 | loss_rpn_loc: 0.2041 | Total Loss: 0.6254\n",
      "Epoch 2558 | loss_cls: 0.0452 | loss_box_reg: 0.1655 | loss_mask: 0.1471 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0186 | Total Loss: 0.3775\n",
      "Epoch 2559 | loss_cls: 0.0454 | loss_box_reg: 0.1342 | loss_mask: 0.0580 | loss_rpn_cls: 0.0089 | loss_rpn_loc: 0.0074 | Total Loss: 0.2538\n",
      "\u001b[32m[07/29 18:35:34 d2.utils.events]: \u001b[0m eta: 0:02:53  iter: 2559      time: 0.3364  last_time: 0.2624   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2560 | loss_cls: 0.0383 | loss_box_reg: 0.1223 | loss_mask: 0.1731 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.1260 | Total Loss: 0.4609\n",
      "Epoch 2561 | loss_cls: 0.0254 | loss_box_reg: 0.0613 | loss_mask: 0.0750 | loss_rpn_cls: 0.0151 | loss_rpn_loc: 0.0218 | Total Loss: 0.1986\n",
      "Epoch 2562 | loss_cls: 0.1275 | loss_box_reg: 0.2322 | loss_mask: 0.0780 | loss_rpn_cls: 0.0152 | loss_rpn_loc: 0.0597 | Total Loss: 0.5126\n",
      "Epoch 2563 | loss_cls: 0.0458 | loss_box_reg: 0.1791 | loss_mask: 0.0594 | loss_rpn_cls: 0.0003 | loss_rpn_loc: 0.0310 | Total Loss: 0.3157\n",
      "Epoch 2564 | loss_cls: 0.0362 | loss_box_reg: 0.0745 | loss_mask: 0.0980 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.0996 | Total Loss: 0.3097\n",
      "Epoch 2565 | loss_cls: 0.0399 | loss_box_reg: 0.1599 | loss_mask: 0.0388 | loss_rpn_cls: 0.0092 | loss_rpn_loc: 0.0745 | Total Loss: 0.3222\n",
      "Epoch 2566 | loss_cls: 0.0351 | loss_box_reg: 0.1108 | loss_mask: 0.0652 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.0016 | Total Loss: 0.2160\n",
      "Epoch 2567 | loss_cls: 0.1103 | loss_box_reg: 0.1651 | loss_mask: 0.0653 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.0149 | Total Loss: 0.3567\n",
      "Epoch 2568 | loss_cls: 0.0442 | loss_box_reg: 0.2090 | loss_mask: 0.1270 | loss_rpn_cls: 0.0037 | loss_rpn_loc: 0.0148 | Total Loss: 0.3987\n",
      "Epoch 2569 | loss_cls: 0.0612 | loss_box_reg: 0.1698 | loss_mask: 0.1054 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0975 | Total Loss: 0.4350\n",
      "Epoch 2570 | loss_cls: 0.0579 | loss_box_reg: 0.1099 | loss_mask: 0.0669 | loss_rpn_cls: 0.0078 | loss_rpn_loc: 0.1585 | Total Loss: 0.4009\n",
      "Epoch 2571 | loss_cls: 0.0339 | loss_box_reg: 0.0704 | loss_mask: 0.1087 | loss_rpn_cls: 0.0066 | loss_rpn_loc: 0.0923 | Total Loss: 0.3119\n",
      "Epoch 2572 | loss_cls: 0.1012 | loss_box_reg: 0.2486 | loss_mask: 0.0792 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.0892 | Total Loss: 0.5200\n",
      "Epoch 2573 | loss_cls: 0.0205 | loss_box_reg: 0.1080 | loss_mask: 0.0365 | loss_rpn_cls: 0.0121 | loss_rpn_loc: 0.1076 | Total Loss: 0.2848\n",
      "Epoch 2574 | loss_cls: 0.0268 | loss_box_reg: 0.1189 | loss_mask: 0.0506 | loss_rpn_cls: 0.0147 | loss_rpn_loc: 0.0302 | Total Loss: 0.2412\n",
      "Epoch 2575 | loss_cls: 0.0836 | loss_box_reg: 0.1328 | loss_mask: 0.0485 | loss_rpn_cls: 0.0277 | loss_rpn_loc: 0.0107 | Total Loss: 0.3033\n",
      "Epoch 2576 | loss_cls: 0.0435 | loss_box_reg: 0.0902 | loss_mask: 0.0426 | loss_rpn_cls: 0.0093 | loss_rpn_loc: 0.0161 | Total Loss: 0.2017\n",
      "Epoch 2577 | loss_cls: 0.0499 | loss_box_reg: 0.2341 | loss_mask: 0.0663 | loss_rpn_cls: 0.0133 | loss_rpn_loc: 0.0626 | Total Loss: 0.4262\n",
      "Epoch 2578 | loss_cls: 0.0296 | loss_box_reg: 0.0637 | loss_mask: 0.1087 | loss_rpn_cls: 0.0065 | loss_rpn_loc: 0.0336 | Total Loss: 0.2421\n",
      "Epoch 2579 | loss_cls: 0.0762 | loss_box_reg: 0.1604 | loss_mask: 0.1045 | loss_rpn_cls: 0.0029 | loss_rpn_loc: 0.0450 | Total Loss: 0.3890\n",
      "\u001b[32m[07/29 18:35:41 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 2579      time: 0.3362  last_time: 0.1885   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2580 | loss_cls: 0.0661 | loss_box_reg: 0.0846 | loss_mask: 0.0501 | loss_rpn_cls: 0.0160 | loss_rpn_loc: 0.1149 | Total Loss: 0.3317\n",
      "Epoch 2581 | loss_cls: 0.1200 | loss_box_reg: 0.1625 | loss_mask: 0.0613 | loss_rpn_cls: 0.0054 | loss_rpn_loc: 0.1380 | Total Loss: 0.4872\n",
      "Epoch 2582 | loss_cls: 0.0381 | loss_box_reg: 0.0932 | loss_mask: 0.0712 | loss_rpn_cls: 0.0156 | loss_rpn_loc: 0.0396 | Total Loss: 0.2578\n",
      "Epoch 2583 | loss_cls: 0.0249 | loss_box_reg: 0.0884 | loss_mask: 0.0757 | loss_rpn_cls: 0.0200 | loss_rpn_loc: 0.1210 | Total Loss: 0.3301\n",
      "Epoch 2584 | loss_cls: 0.0567 | loss_box_reg: 0.1169 | loss_mask: 0.0783 | loss_rpn_cls: 0.0085 | loss_rpn_loc: 0.0561 | Total Loss: 0.3165\n",
      "Epoch 2585 | loss_cls: 0.0438 | loss_box_reg: 0.0986 | loss_mask: 0.0672 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.0091 | Total Loss: 0.2192\n",
      "Epoch 2586 | loss_cls: 0.0441 | loss_box_reg: 0.0855 | loss_mask: 0.0576 | loss_rpn_cls: 0.0047 | loss_rpn_loc: 0.1186 | Total Loss: 0.3105\n",
      "Epoch 2587 | loss_cls: 0.1094 | loss_box_reg: 0.1617 | loss_mask: 0.0451 | loss_rpn_cls: 0.0030 | loss_rpn_loc: 0.0597 | Total Loss: 0.3789\n",
      "Epoch 2588 | loss_cls: 0.0454 | loss_box_reg: 0.0442 | loss_mask: 0.0319 | loss_rpn_cls: 0.0139 | loss_rpn_loc: 0.0113 | Total Loss: 0.1467\n",
      "Epoch 2589 | loss_cls: 0.0500 | loss_box_reg: 0.0958 | loss_mask: 0.0709 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.0500 | Total Loss: 0.2693\n",
      "Epoch 2590 | loss_cls: 0.0388 | loss_box_reg: 0.1265 | loss_mask: 0.0857 | loss_rpn_cls: 0.0041 | loss_rpn_loc: 0.1866 | Total Loss: 0.4417\n",
      "Epoch 2591 | loss_cls: 0.0172 | loss_box_reg: 0.0533 | loss_mask: 0.0304 | loss_rpn_cls: 0.0002 | loss_rpn_loc: 0.0035 | Total Loss: 0.1046\n",
      " Best model saved at Epoch 2591 | Total Loss: 0.1046\n",
      "Epoch 2592 | loss_cls: 0.0482 | loss_box_reg: 0.1907 | loss_mask: 0.0470 | loss_rpn_cls: 0.0059 | loss_rpn_loc: 0.0071 | Total Loss: 0.2990\n",
      "Epoch 2593 | loss_cls: 0.0612 | loss_box_reg: 0.1869 | loss_mask: 0.1838 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0054 | Total Loss: 0.4380\n",
      "Epoch 2594 | loss_cls: 0.0283 | loss_box_reg: 0.1731 | loss_mask: 0.1287 | loss_rpn_cls: 0.0096 | loss_rpn_loc: 0.0227 | Total Loss: 0.3623\n",
      "Epoch 2595 | loss_cls: 0.1022 | loss_box_reg: 0.2267 | loss_mask: 0.1110 | loss_rpn_cls: 0.0125 | loss_rpn_loc: 0.0618 | Total Loss: 0.5141\n",
      "Epoch 2596 | loss_cls: 0.0308 | loss_box_reg: 0.0394 | loss_mask: 0.1366 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.1186 | Total Loss: 0.3269\n",
      "Epoch 2597 | loss_cls: 0.0469 | loss_box_reg: 0.1001 | loss_mask: 0.1556 | loss_rpn_cls: 0.0117 | loss_rpn_loc: 0.1287 | Total Loss: 0.4429\n",
      "Epoch 2598 | loss_cls: 0.0498 | loss_box_reg: 0.2195 | loss_mask: 0.1645 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.1712 | Total Loss: 0.6063\n",
      "Epoch 2599 | loss_cls: 0.0660 | loss_box_reg: 0.1824 | loss_mask: 0.2117 | loss_rpn_cls: 0.0022 | loss_rpn_loc: 0.0860 | Total Loss: 0.5483\n",
      "\u001b[32m[07/29 18:35:48 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 2599      time: 0.3365  last_time: 0.4029   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2600 | loss_cls: 0.0165 | loss_box_reg: 0.0415 | loss_mask: 0.1983 | loss_rpn_cls: 0.0107 | loss_rpn_loc: 0.0767 | Total Loss: 0.3439\n",
      "Epoch 2601 | loss_cls: 0.1031 | loss_box_reg: 0.1671 | loss_mask: 0.0495 | loss_rpn_cls: 0.0079 | loss_rpn_loc: 0.1669 | Total Loss: 0.4945\n",
      "Epoch 2602 | loss_cls: 0.0841 | loss_box_reg: 0.1318 | loss_mask: 0.0417 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.0435 | Total Loss: 0.3026\n",
      "Epoch 2603 | loss_cls: 0.1003 | loss_box_reg: 0.2376 | loss_mask: 0.5234 | loss_rpn_cls: 0.0079 | loss_rpn_loc: 0.0367 | Total Loss: 0.9060\n",
      "Epoch 2604 | loss_cls: 0.0181 | loss_box_reg: 0.0655 | loss_mask: 0.2754 | loss_rpn_cls: 0.0117 | loss_rpn_loc: 0.1935 | Total Loss: 0.5640\n",
      "Epoch 2605 | loss_cls: 0.0226 | loss_box_reg: 0.0971 | loss_mask: 0.0577 | loss_rpn_cls: 0.0001 | loss_rpn_loc: 0.0232 | Total Loss: 0.2007\n",
      "Epoch 2606 | loss_cls: 0.0891 | loss_box_reg: 0.1825 | loss_mask: 0.0865 | loss_rpn_cls: 0.0054 | loss_rpn_loc: 0.0247 | Total Loss: 0.3881\n",
      "Epoch 2607 | loss_cls: 0.0270 | loss_box_reg: 0.0422 | loss_mask: 0.0559 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.1080 | Total Loss: 0.2357\n",
      "Epoch 2608 | loss_cls: 0.0448 | loss_box_reg: 0.0657 | loss_mask: 0.1097 | loss_rpn_cls: 0.0030 | loss_rpn_loc: 0.0133 | Total Loss: 0.2364\n",
      "Epoch 2609 | loss_cls: 0.0371 | loss_box_reg: 0.0839 | loss_mask: 0.0676 | loss_rpn_cls: 0.0022 | loss_rpn_loc: 0.0197 | Total Loss: 0.2105\n",
      "Epoch 2610 | loss_cls: 0.0476 | loss_box_reg: 0.1001 | loss_mask: 0.0552 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.0093 | Total Loss: 0.2128\n",
      "Epoch 2611 | loss_cls: 0.0754 | loss_box_reg: 0.1399 | loss_mask: 0.0771 | loss_rpn_cls: 0.0021 | loss_rpn_loc: 0.1523 | Total Loss: 0.4469\n",
      "Epoch 2612 | loss_cls: 0.0358 | loss_box_reg: 0.0568 | loss_mask: 0.0720 | loss_rpn_cls: 0.0009 | loss_rpn_loc: 0.0086 | Total Loss: 0.1741\n",
      "Epoch 2613 | loss_cls: 0.0458 | loss_box_reg: 0.1848 | loss_mask: 0.0372 | loss_rpn_cls: 0.0079 | loss_rpn_loc: 0.0707 | Total Loss: 0.3464\n",
      "Epoch 2614 | loss_cls: 0.0752 | loss_box_reg: 0.1342 | loss_mask: 0.0902 | loss_rpn_cls: 0.0002 | loss_rpn_loc: 0.0080 | Total Loss: 0.3077\n",
      "Epoch 2615 | loss_cls: 0.1157 | loss_box_reg: 0.2470 | loss_mask: 0.1380 | loss_rpn_cls: 0.0029 | loss_rpn_loc: 0.0976 | Total Loss: 0.6012\n",
      "Epoch 2616 | loss_cls: 0.0498 | loss_box_reg: 0.1718 | loss_mask: 0.0453 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.2556 | Total Loss: 0.5276\n",
      "Epoch 2617 | loss_cls: 0.0648 | loss_box_reg: 0.1773 | loss_mask: 0.0667 | loss_rpn_cls: 0.0127 | loss_rpn_loc: 0.0053 | Total Loss: 0.3268\n",
      "Epoch 2618 | loss_cls: 0.0887 | loss_box_reg: 0.0627 | loss_mask: 0.0402 | loss_rpn_cls: 0.0040 | loss_rpn_loc: 0.0120 | Total Loss: 0.2076\n",
      "Epoch 2619 | loss_cls: 0.0575 | loss_box_reg: 0.1254 | loss_mask: 0.1054 | loss_rpn_cls: 0.0133 | loss_rpn_loc: 0.1222 | Total Loss: 0.4239\n",
      "\u001b[32m[07/29 18:35:55 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 2619      time: 0.3366  last_time: 0.4194   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2620 | loss_cls: 0.0415 | loss_box_reg: 0.1935 | loss_mask: 0.0565 | loss_rpn_cls: 0.0008 | loss_rpn_loc: 0.0407 | Total Loss: 0.3329\n",
      "Epoch 2621 | loss_cls: 0.0220 | loss_box_reg: 0.0288 | loss_mask: 0.0878 | loss_rpn_cls: 0.0037 | loss_rpn_loc: 0.0275 | Total Loss: 0.1698\n",
      "Epoch 2622 | loss_cls: 0.0604 | loss_box_reg: 0.1741 | loss_mask: 0.0594 | loss_rpn_cls: 0.0106 | loss_rpn_loc: 0.1748 | Total Loss: 0.4794\n",
      "Epoch 2623 | loss_cls: 0.0858 | loss_box_reg: 0.1510 | loss_mask: 0.0355 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.0400 | Total Loss: 0.3150\n",
      "Epoch 2624 | loss_cls: 0.0238 | loss_box_reg: 0.1102 | loss_mask: 0.0545 | loss_rpn_cls: 0.0139 | loss_rpn_loc: 0.0342 | Total Loss: 0.2365\n",
      "Epoch 2625 | loss_cls: 0.0193 | loss_box_reg: 0.0747 | loss_mask: 0.0661 | loss_rpn_cls: 0.0028 | loss_rpn_loc: 0.1099 | Total Loss: 0.2727\n",
      "Epoch 2626 | loss_cls: 0.0505 | loss_box_reg: 0.0937 | loss_mask: 0.0520 | loss_rpn_cls: 0.0042 | loss_rpn_loc: 0.1241 | Total Loss: 0.3245\n",
      "Epoch 2627 | loss_cls: 0.0386 | loss_box_reg: 0.1370 | loss_mask: 0.0731 | loss_rpn_cls: 0.0003 | loss_rpn_loc: 0.0046 | Total Loss: 0.2536\n",
      "Epoch 2628 | loss_cls: 0.0431 | loss_box_reg: 0.1022 | loss_mask: 0.1098 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.0998 | Total Loss: 0.3581\n",
      "Epoch 2629 | loss_cls: 0.0277 | loss_box_reg: 0.1436 | loss_mask: 0.2006 | loss_rpn_cls: 0.0016 | loss_rpn_loc: 0.0346 | Total Loss: 0.4082\n",
      "Epoch 2630 | loss_cls: 0.0594 | loss_box_reg: 0.2195 | loss_mask: 0.0866 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.0241 | Total Loss: 0.3928\n",
      "Epoch 2631 | loss_cls: 0.0402 | loss_box_reg: 0.0998 | loss_mask: 0.0793 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0199 | Total Loss: 0.2397\n",
      "Epoch 2632 | loss_cls: 0.0212 | loss_box_reg: 0.0563 | loss_mask: 0.1003 | loss_rpn_cls: 0.0042 | loss_rpn_loc: 0.1059 | Total Loss: 0.2879\n",
      "Epoch 2633 | loss_cls: 0.0408 | loss_box_reg: 0.2254 | loss_mask: 0.1851 | loss_rpn_cls: 0.0003 | loss_rpn_loc: 0.0485 | Total Loss: 0.5002\n",
      "Epoch 2634 | loss_cls: 0.0470 | loss_box_reg: 0.1844 | loss_mask: 0.0423 | loss_rpn_cls: 0.0167 | loss_rpn_loc: 0.1485 | Total Loss: 0.4390\n",
      "Epoch 2635 | loss_cls: 0.0956 | loss_box_reg: 0.1426 | loss_mask: 0.0727 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.0194 | Total Loss: 0.3317\n",
      "Epoch 2636 | loss_cls: 0.0161 | loss_box_reg: 0.0348 | loss_mask: 0.0357 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.0225 | Total Loss: 0.1096\n",
      "Epoch 2637 | loss_cls: 0.0972 | loss_box_reg: 0.1295 | loss_mask: 0.0778 | loss_rpn_cls: 0.0776 | loss_rpn_loc: 0.3742 | Total Loss: 0.7562\n",
      "Epoch 2638 | loss_cls: 0.0286 | loss_box_reg: 0.0750 | loss_mask: 0.1279 | loss_rpn_cls: 0.0008 | loss_rpn_loc: 0.1259 | Total Loss: 0.3581\n",
      "Epoch 2639 | loss_cls: 0.0715 | loss_box_reg: 0.3546 | loss_mask: 0.1671 | loss_rpn_cls: 0.0035 | loss_rpn_loc: 0.0094 | Total Loss: 0.6062\n",
      "\u001b[32m[07/29 18:36:02 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 2639      time: 0.3367  last_time: 0.2901   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2640 | loss_cls: 0.0803 | loss_box_reg: 0.0965 | loss_mask: 0.0552 | loss_rpn_cls: 0.0040 | loss_rpn_loc: 0.1422 | Total Loss: 0.3782\n",
      "Epoch 2641 | loss_cls: 0.0346 | loss_box_reg: 0.0596 | loss_mask: 0.1482 | loss_rpn_cls: 0.0100 | loss_rpn_loc: 0.0959 | Total Loss: 0.3483\n",
      "Epoch 2642 | loss_cls: 0.0932 | loss_box_reg: 0.2076 | loss_mask: 0.0633 | loss_rpn_cls: 0.0024 | loss_rpn_loc: 0.1911 | Total Loss: 0.5577\n",
      "Epoch 2643 | loss_cls: 0.0296 | loss_box_reg: 0.1550 | loss_mask: 0.0695 | loss_rpn_cls: 0.0038 | loss_rpn_loc: 0.0048 | Total Loss: 0.2627\n",
      "Epoch 2644 | loss_cls: 0.0465 | loss_box_reg: 0.1301 | loss_mask: 0.0788 | loss_rpn_cls: 0.0029 | loss_rpn_loc: 0.0054 | Total Loss: 0.2638\n",
      "Epoch 2645 | loss_cls: 0.0452 | loss_box_reg: 0.1031 | loss_mask: 0.1060 | loss_rpn_cls: 0.0056 | loss_rpn_loc: 0.0797 | Total Loss: 0.3397\n",
      "Epoch 2646 | loss_cls: 0.0583 | loss_box_reg: 0.2068 | loss_mask: 0.0586 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.0840 | Total Loss: 0.4091\n",
      "Epoch 2647 | loss_cls: 0.0279 | loss_box_reg: 0.0569 | loss_mask: 0.1132 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.0911 | Total Loss: 0.2917\n",
      "Epoch 2648 | loss_cls: 0.0418 | loss_box_reg: 0.1394 | loss_mask: 0.0692 | loss_rpn_cls: 0.0017 | loss_rpn_loc: 0.0581 | Total Loss: 0.3102\n",
      "Epoch 2649 | loss_cls: 0.0374 | loss_box_reg: 0.0297 | loss_mask: 0.2142 | loss_rpn_cls: 0.0002 | loss_rpn_loc: 0.0313 | Total Loss: 0.3128\n",
      "Epoch 2650 | loss_cls: 0.0787 | loss_box_reg: 0.1682 | loss_mask: 0.1300 | loss_rpn_cls: 0.0049 | loss_rpn_loc: 0.0050 | Total Loss: 0.3869\n",
      "Epoch 2651 | loss_cls: 0.1001 | loss_box_reg: 0.1564 | loss_mask: 0.0467 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.0427 | Total Loss: 0.3484\n",
      "Epoch 2652 | loss_cls: 0.0496 | loss_box_reg: 0.1152 | loss_mask: 0.0538 | loss_rpn_cls: 0.0002 | loss_rpn_loc: 0.0135 | Total Loss: 0.2323\n",
      "Epoch 2653 | loss_cls: 0.0224 | loss_box_reg: 0.0711 | loss_mask: 0.0276 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0093 | Total Loss: 0.1310\n",
      "Epoch 2654 | loss_cls: 0.0161 | loss_box_reg: 0.0711 | loss_mask: 0.2040 | loss_rpn_cls: 0.0026 | loss_rpn_loc: 0.2023 | Total Loss: 0.4962\n",
      "Epoch 2655 | loss_cls: 0.1055 | loss_box_reg: 0.3596 | loss_mask: 0.1270 | loss_rpn_cls: 0.0020 | loss_rpn_loc: 0.0823 | Total Loss: 0.6764\n",
      "Epoch 2656 | loss_cls: 0.0414 | loss_box_reg: 0.0818 | loss_mask: 0.0533 | loss_rpn_cls: 0.0073 | loss_rpn_loc: 0.0088 | Total Loss: 0.1926\n",
      "Epoch 2657 | loss_cls: 0.0414 | loss_box_reg: 0.0801 | loss_mask: 0.0466 | loss_rpn_cls: 0.0003 | loss_rpn_loc: 0.0048 | Total Loss: 0.1731\n",
      "Epoch 2658 | loss_cls: 0.0420 | loss_box_reg: 0.1062 | loss_mask: 0.0407 | loss_rpn_cls: 0.0059 | loss_rpn_loc: 0.0224 | Total Loss: 0.2172\n",
      "Epoch 2659 | loss_cls: 0.0919 | loss_box_reg: 0.1176 | loss_mask: 0.0771 | loss_rpn_cls: 0.0048 | loss_rpn_loc: 0.0612 | Total Loss: 0.3526\n",
      "\u001b[32m[07/29 18:36:09 d2.utils.events]: \u001b[0m eta: 0:02:13  iter: 2659      time: 0.3368  last_time: 0.4189   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2660 | loss_cls: 0.1139 | loss_box_reg: 0.2078 | loss_mask: 0.1030 | loss_rpn_cls: 0.0048 | loss_rpn_loc: 0.0709 | Total Loss: 0.5003\n",
      "Epoch 2661 | loss_cls: 0.0227 | loss_box_reg: 0.0605 | loss_mask: 0.0759 | loss_rpn_cls: 0.0137 | loss_rpn_loc: 0.1206 | Total Loss: 0.2934\n",
      "Epoch 2662 | loss_cls: 0.0603 | loss_box_reg: 0.1586 | loss_mask: 0.1237 | loss_rpn_cls: 0.0003 | loss_rpn_loc: 0.0169 | Total Loss: 0.3598\n",
      "Epoch 2663 | loss_cls: 0.0488 | loss_box_reg: 0.2547 | loss_mask: 0.1028 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.0738 | Total Loss: 0.4807\n",
      "Epoch 2664 | loss_cls: 0.1027 | loss_box_reg: 0.1894 | loss_mask: 0.0732 | loss_rpn_cls: 0.0029 | loss_rpn_loc: 0.0313 | Total Loss: 0.3996\n",
      "Epoch 2665 | loss_cls: 0.0295 | loss_box_reg: 0.1264 | loss_mask: 0.0507 | loss_rpn_cls: 0.0117 | loss_rpn_loc: 0.0334 | Total Loss: 0.2518\n",
      "Epoch 2666 | loss_cls: 0.0214 | loss_box_reg: 0.0794 | loss_mask: 0.0598 | loss_rpn_cls: 0.0087 | loss_rpn_loc: 0.0529 | Total Loss: 0.2222\n",
      "Epoch 2667 | loss_cls: 0.0312 | loss_box_reg: 0.1321 | loss_mask: 0.1453 | loss_rpn_cls: 0.0094 | loss_rpn_loc: 0.0239 | Total Loss: 0.3420\n",
      "Epoch 2668 | loss_cls: 0.0178 | loss_box_reg: 0.0510 | loss_mask: 0.0297 | loss_rpn_cls: 0.0044 | loss_rpn_loc: 0.1042 | Total Loss: 0.2072\n",
      "Epoch 2669 | loss_cls: 0.0591 | loss_box_reg: 0.1457 | loss_mask: 0.0664 | loss_rpn_cls: 0.0254 | loss_rpn_loc: 0.1577 | Total Loss: 0.4544\n",
      "Epoch 2670 | loss_cls: 0.0283 | loss_box_reg: 0.0898 | loss_mask: 0.0302 | loss_rpn_cls: 0.0080 | loss_rpn_loc: 0.0061 | Total Loss: 0.1624\n",
      "Epoch 2671 | loss_cls: 0.1156 | loss_box_reg: 0.2450 | loss_mask: 0.0614 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.0466 | Total Loss: 0.4708\n",
      "Epoch 2672 | loss_cls: 0.0433 | loss_box_reg: 0.1506 | loss_mask: 0.0830 | loss_rpn_cls: 0.0036 | loss_rpn_loc: 0.1594 | Total Loss: 0.4399\n",
      "Epoch 2673 | loss_cls: 0.0485 | loss_box_reg: 0.0855 | loss_mask: 0.1091 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.1202 | Total Loss: 0.3657\n",
      "Epoch 2674 | loss_cls: 0.0669 | loss_box_reg: 0.1008 | loss_mask: 0.0450 | loss_rpn_cls: 0.0042 | loss_rpn_loc: 0.0158 | Total Loss: 0.2327\n",
      "Epoch 2675 | loss_cls: 0.0554 | loss_box_reg: 0.1572 | loss_mask: 0.1013 | loss_rpn_cls: 0.0110 | loss_rpn_loc: 0.0926 | Total Loss: 0.4175\n",
      "Epoch 2676 | loss_cls: 0.0250 | loss_box_reg: 0.0439 | loss_mask: 0.0532 | loss_rpn_cls: 0.0009 | loss_rpn_loc: 0.0877 | Total Loss: 0.2108\n",
      "Epoch 2677 | loss_cls: 0.1013 | loss_box_reg: 0.2165 | loss_mask: 0.0321 | loss_rpn_cls: 0.1185 | loss_rpn_loc: 0.3737 | Total Loss: 0.8421\n",
      "Epoch 2678 | loss_cls: 0.1197 | loss_box_reg: 0.1442 | loss_mask: 0.0456 | loss_rpn_cls: 0.0021 | loss_rpn_loc: 0.1073 | Total Loss: 0.4190\n",
      "Epoch 2679 | loss_cls: 0.0287 | loss_box_reg: 0.0456 | loss_mask: 0.0632 | loss_rpn_cls: 0.0024 | loss_rpn_loc: 0.0192 | Total Loss: 0.1591\n",
      "\u001b[32m[07/29 18:36:16 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 2679      time: 0.3368  last_time: 0.2566   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2680 | loss_cls: 0.0278 | loss_box_reg: 0.1670 | loss_mask: 0.0949 | loss_rpn_cls: 0.0092 | loss_rpn_loc: 0.0393 | Total Loss: 0.3382\n",
      "Epoch 2681 | loss_cls: 0.1114 | loss_box_reg: 0.2114 | loss_mask: 0.1598 | loss_rpn_cls: 0.0164 | loss_rpn_loc: 0.0378 | Total Loss: 0.5368\n",
      "Epoch 2682 | loss_cls: 0.0197 | loss_box_reg: 0.0843 | loss_mask: 0.0925 | loss_rpn_cls: 0.0051 | loss_rpn_loc: 0.0989 | Total Loss: 0.3004\n",
      "Epoch 2683 | loss_cls: 0.0760 | loss_box_reg: 0.2251 | loss_mask: 0.2253 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.0151 | Total Loss: 0.5425\n",
      "Epoch 2684 | loss_cls: 0.0439 | loss_box_reg: 0.0833 | loss_mask: 0.0466 | loss_rpn_cls: 0.0038 | loss_rpn_loc: 0.0599 | Total Loss: 0.2376\n",
      "Epoch 2685 | loss_cls: 0.0333 | loss_box_reg: 0.1268 | loss_mask: 0.1859 | loss_rpn_cls: 0.0115 | loss_rpn_loc: 0.1732 | Total Loss: 0.5307\n",
      "Epoch 2686 | loss_cls: 0.0379 | loss_box_reg: 0.0947 | loss_mask: 0.0765 | loss_rpn_cls: 0.0206 | loss_rpn_loc: 0.1298 | Total Loss: 0.3595\n",
      "Epoch 2687 | loss_cls: 0.0563 | loss_box_reg: 0.1485 | loss_mask: 0.0930 | loss_rpn_cls: 0.0236 | loss_rpn_loc: 0.0576 | Total Loss: 0.3789\n",
      "Epoch 2688 | loss_cls: 0.0892 | loss_box_reg: 0.0937 | loss_mask: 0.0498 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.0082 | Total Loss: 0.2424\n",
      "Epoch 2689 | loss_cls: 0.0439 | loss_box_reg: 0.1152 | loss_mask: 0.0359 | loss_rpn_cls: 0.0054 | loss_rpn_loc: 0.0114 | Total Loss: 0.2118\n",
      "Epoch 2690 | loss_cls: 0.0303 | loss_box_reg: 0.0662 | loss_mask: 0.1019 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.1113 | Total Loss: 0.3112\n",
      "Epoch 2691 | loss_cls: 0.0424 | loss_box_reg: 0.1102 | loss_mask: 0.0550 | loss_rpn_cls: 0.0134 | loss_rpn_loc: 0.0888 | Total Loss: 0.3098\n",
      "Epoch 2692 | loss_cls: 0.0589 | loss_box_reg: 0.2358 | loss_mask: 0.0912 | loss_rpn_cls: 0.0020 | loss_rpn_loc: 0.0098 | Total Loss: 0.3978\n",
      "Epoch 2693 | loss_cls: 0.0433 | loss_box_reg: 0.0681 | loss_mask: 0.0931 | loss_rpn_cls: 0.0219 | loss_rpn_loc: 0.0107 | Total Loss: 0.2371\n",
      "Epoch 2694 | loss_cls: 0.0337 | loss_box_reg: 0.0698 | loss_mask: 0.0436 | loss_rpn_cls: 0.0031 | loss_rpn_loc: 0.0118 | Total Loss: 0.1620\n",
      "Epoch 2695 | loss_cls: 0.0763 | loss_box_reg: 0.1639 | loss_mask: 0.1373 | loss_rpn_cls: 0.0094 | loss_rpn_loc: 0.0184 | Total Loss: 0.4054\n",
      "Epoch 2696 | loss_cls: 0.0657 | loss_box_reg: 0.2240 | loss_mask: 0.0789 | loss_rpn_cls: 0.0048 | loss_rpn_loc: 0.0108 | Total Loss: 0.3843\n",
      "Epoch 2697 | loss_cls: 0.0659 | loss_box_reg: 0.1815 | loss_mask: 0.0412 | loss_rpn_cls: 0.0088 | loss_rpn_loc: 0.1640 | Total Loss: 0.4613\n",
      "Epoch 2698 | loss_cls: 0.1335 | loss_box_reg: 0.3871 | loss_mask: 0.0528 | loss_rpn_cls: 0.0048 | loss_rpn_loc: 0.0371 | Total Loss: 0.6153\n",
      "Epoch 2699 | loss_cls: 0.0330 | loss_box_reg: 0.0680 | loss_mask: 0.0394 | loss_rpn_cls: 0.0160 | loss_rpn_loc: 0.0169 | Total Loss: 0.1733\n",
      "\u001b[32m[07/29 18:36:23 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 2699      time: 0.3369  last_time: 0.4154   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2700 | loss_cls: 0.0526 | loss_box_reg: 0.1877 | loss_mask: 0.3546 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0843 | Total Loss: 0.6800\n",
      "Epoch 2701 | loss_cls: 0.0176 | loss_box_reg: 0.0630 | loss_mask: 0.0550 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.0797 | Total Loss: 0.2187\n",
      "Epoch 2702 | loss_cls: 0.0238 | loss_box_reg: 0.0482 | loss_mask: 0.1295 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0239 | Total Loss: 0.2258\n",
      "Epoch 2703 | loss_cls: 0.0403 | loss_box_reg: 0.1675 | loss_mask: 0.1148 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.0569 | Total Loss: 0.3829\n",
      "Epoch 2704 | loss_cls: 0.0609 | loss_box_reg: 0.1564 | loss_mask: 0.0936 | loss_rpn_cls: 0.0326 | loss_rpn_loc: 0.1230 | Total Loss: 0.4665\n",
      "Epoch 2705 | loss_cls: 0.0271 | loss_box_reg: 0.0599 | loss_mask: 0.0686 | loss_rpn_cls: 0.0072 | loss_rpn_loc: 0.0590 | Total Loss: 0.2218\n",
      "Epoch 2706 | loss_cls: 0.0408 | loss_box_reg: 0.1201 | loss_mask: 0.1079 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.0779 | Total Loss: 0.3494\n",
      "Epoch 2707 | loss_cls: 0.0194 | loss_box_reg: 0.0618 | loss_mask: 0.0533 | loss_rpn_cls: 0.0133 | loss_rpn_loc: 0.1355 | Total Loss: 0.2834\n",
      "Epoch 2708 | loss_cls: 0.0367 | loss_box_reg: 0.1905 | loss_mask: 0.0778 | loss_rpn_cls: 0.0104 | loss_rpn_loc: 0.0670 | Total Loss: 0.3823\n",
      "Epoch 2709 | loss_cls: 0.0498 | loss_box_reg: 0.0813 | loss_mask: 0.1113 | loss_rpn_cls: 0.0084 | loss_rpn_loc: 0.0207 | Total Loss: 0.2716\n",
      "Epoch 2710 | loss_cls: 0.0271 | loss_box_reg: 0.1235 | loss_mask: 0.0598 | loss_rpn_cls: 0.0021 | loss_rpn_loc: 0.0924 | Total Loss: 0.3049\n",
      "Epoch 2711 | loss_cls: 0.1302 | loss_box_reg: 0.2830 | loss_mask: 0.0483 | loss_rpn_cls: 0.0008 | loss_rpn_loc: 0.0130 | Total Loss: 0.4754\n",
      "Epoch 2712 | loss_cls: 0.0329 | loss_box_reg: 0.1058 | loss_mask: 0.0897 | loss_rpn_cls: 0.0047 | loss_rpn_loc: 0.1189 | Total Loss: 0.3519\n",
      "Epoch 2713 | loss_cls: 0.0396 | loss_box_reg: 0.0677 | loss_mask: 0.0484 | loss_rpn_cls: 0.0063 | loss_rpn_loc: 0.0088 | Total Loss: 0.1707\n",
      "Epoch 2714 | loss_cls: 0.1259 | loss_box_reg: 0.0996 | loss_mask: 0.0407 | loss_rpn_cls: 0.0128 | loss_rpn_loc: 0.1299 | Total Loss: 0.4089\n",
      "Epoch 2715 | loss_cls: 0.0733 | loss_box_reg: 0.1484 | loss_mask: 0.0921 | loss_rpn_cls: 0.0063 | loss_rpn_loc: 0.0159 | Total Loss: 0.3360\n",
      "Epoch 2716 | loss_cls: 0.0379 | loss_box_reg: 0.1149 | loss_mask: 0.0857 | loss_rpn_cls: 0.0171 | loss_rpn_loc: 0.0746 | Total Loss: 0.3302\n",
      "Epoch 2717 | loss_cls: 0.0341 | loss_box_reg: 0.1200 | loss_mask: 0.0488 | loss_rpn_cls: 0.0115 | loss_rpn_loc: 0.0359 | Total Loss: 0.2503\n",
      "Epoch 2718 | loss_cls: 0.0480 | loss_box_reg: 0.2123 | loss_mask: 0.1364 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0049 | Total Loss: 0.4020\n",
      "Epoch 2719 | loss_cls: 0.0527 | loss_box_reg: 0.0987 | loss_mask: 0.0684 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.0020 | Total Loss: 0.2237\n",
      "\u001b[32m[07/29 18:36:30 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 2719      time: 0.3370  last_time: 0.1864   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2720 | loss_cls: 0.0548 | loss_box_reg: 0.1349 | loss_mask: 0.0963 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0785 | Total Loss: 0.3652\n",
      "Epoch 2721 | loss_cls: 0.0373 | loss_box_reg: 0.1049 | loss_mask: 0.0462 | loss_rpn_cls: 0.0082 | loss_rpn_loc: 0.0177 | Total Loss: 0.2143\n",
      "Epoch 2722 | loss_cls: 0.0566 | loss_box_reg: 0.1164 | loss_mask: 0.0443 | loss_rpn_cls: 0.0048 | loss_rpn_loc: 0.0401 | Total Loss: 0.2623\n",
      "Epoch 2723 | loss_cls: 0.0723 | loss_box_reg: 0.1724 | loss_mask: 0.0471 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.0674 | Total Loss: 0.3619\n",
      "Epoch 2724 | loss_cls: 0.0281 | loss_box_reg: 0.0898 | loss_mask: 0.0572 | loss_rpn_cls: 0.0069 | loss_rpn_loc: 0.0109 | Total Loss: 0.1929\n",
      "Epoch 2725 | loss_cls: 0.0337 | loss_box_reg: 0.1014 | loss_mask: 0.1039 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0321 | Total Loss: 0.2717\n",
      "Epoch 2726 | loss_cls: 0.0354 | loss_box_reg: 0.0830 | loss_mask: 0.0558 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.0211 | Total Loss: 0.1964\n",
      "Epoch 2727 | loss_cls: 0.0479 | loss_box_reg: 0.0926 | loss_mask: 0.0832 | loss_rpn_cls: 0.0061 | loss_rpn_loc: 0.0201 | Total Loss: 0.2498\n",
      "Epoch 2728 | loss_cls: 0.0526 | loss_box_reg: 0.1146 | loss_mask: 0.0708 | loss_rpn_cls: 0.0029 | loss_rpn_loc: 0.0038 | Total Loss: 0.2447\n",
      "Epoch 2729 | loss_cls: 0.0354 | loss_box_reg: 0.1312 | loss_mask: 0.0671 | loss_rpn_cls: 0.0060 | loss_rpn_loc: 0.0034 | Total Loss: 0.2431\n",
      "Epoch 2730 | loss_cls: 0.0199 | loss_box_reg: 0.0877 | loss_mask: 0.1819 | loss_rpn_cls: 0.0008 | loss_rpn_loc: 0.0823 | Total Loss: 0.3726\n",
      "Epoch 2731 | loss_cls: 0.0541 | loss_box_reg: 0.0980 | loss_mask: 0.0732 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.1035 | Total Loss: 0.3315\n",
      "Epoch 2732 | loss_cls: 0.0554 | loss_box_reg: 0.2261 | loss_mask: 0.1242 | loss_rpn_cls: 0.0120 | loss_rpn_loc: 0.1128 | Total Loss: 0.5306\n",
      "Epoch 2733 | loss_cls: 0.0412 | loss_box_reg: 0.0655 | loss_mask: 0.1145 | loss_rpn_cls: 0.0018 | loss_rpn_loc: 0.0173 | Total Loss: 0.2403\n",
      "Epoch 2734 | loss_cls: 0.0804 | loss_box_reg: 0.1742 | loss_mask: 0.1038 | loss_rpn_cls: 0.0022 | loss_rpn_loc: 0.0695 | Total Loss: 0.4303\n",
      "Epoch 2735 | loss_cls: 0.1745 | loss_box_reg: 0.1757 | loss_mask: 0.0361 | loss_rpn_cls: 0.0170 | loss_rpn_loc: 0.2038 | Total Loss: 0.6071\n",
      "Epoch 2736 | loss_cls: 0.0294 | loss_box_reg: 0.0972 | loss_mask: 0.1097 | loss_rpn_cls: 0.0091 | loss_rpn_loc: 0.0955 | Total Loss: 0.3409\n",
      "Epoch 2737 | loss_cls: 0.0153 | loss_box_reg: 0.0717 | loss_mask: 0.0676 | loss_rpn_cls: 0.0274 | loss_rpn_loc: 0.1535 | Total Loss: 0.3355\n",
      "Epoch 2738 | loss_cls: 0.0176 | loss_box_reg: 0.1246 | loss_mask: 0.1052 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.0495 | Total Loss: 0.2988\n",
      "Epoch 2739 | loss_cls: 0.0534 | loss_box_reg: 0.1747 | loss_mask: 0.0707 | loss_rpn_cls: 0.0001 | loss_rpn_loc: 0.0265 | Total Loss: 0.3255\n",
      "\u001b[32m[07/29 18:36:37 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 2739      time: 0.3371  last_time: 0.3978   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2740 | loss_cls: 0.0162 | loss_box_reg: 0.0700 | loss_mask: 0.1486 | loss_rpn_cls: 0.0187 | loss_rpn_loc: 0.2090 | Total Loss: 0.4626\n",
      "Epoch 2741 | loss_cls: 0.0956 | loss_box_reg: 0.1703 | loss_mask: 0.0364 | loss_rpn_cls: 0.0264 | loss_rpn_loc: 0.2650 | Total Loss: 0.5937\n",
      "Epoch 2742 | loss_cls: 0.0377 | loss_box_reg: 0.1486 | loss_mask: 0.0578 | loss_rpn_cls: 0.0031 | loss_rpn_loc: 0.0870 | Total Loss: 0.3342\n",
      "Epoch 2743 | loss_cls: 0.0187 | loss_box_reg: 0.0835 | loss_mask: 0.0295 | loss_rpn_cls: 0.0003 | loss_rpn_loc: 0.0026 | Total Loss: 0.1346\n",
      "Epoch 2744 | loss_cls: 0.0929 | loss_box_reg: 0.1281 | loss_mask: 0.0751 | loss_rpn_cls: 0.0147 | loss_rpn_loc: 0.0866 | Total Loss: 0.3975\n",
      "Epoch 2745 | loss_cls: 0.0627 | loss_box_reg: 0.1240 | loss_mask: 0.0591 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.0090 | Total Loss: 0.2559\n",
      "Epoch 2746 | loss_cls: 0.0473 | loss_box_reg: 0.1243 | loss_mask: 0.0471 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0364 | Total Loss: 0.2554\n",
      "Epoch 2747 | loss_cls: 0.0799 | loss_box_reg: 0.1923 | loss_mask: 0.0842 | loss_rpn_cls: 0.0052 | loss_rpn_loc: 0.0264 | Total Loss: 0.3880\n",
      "Epoch 2748 | loss_cls: 0.0170 | loss_box_reg: 0.0867 | loss_mask: 0.0325 | loss_rpn_cls: 0.0122 | loss_rpn_loc: 0.0348 | Total Loss: 0.1832\n",
      "Epoch 2749 | loss_cls: 0.0452 | loss_box_reg: 0.1138 | loss_mask: 0.0465 | loss_rpn_cls: 0.0108 | loss_rpn_loc: 0.0732 | Total Loss: 0.2895\n",
      "Epoch 2750 | loss_cls: 0.1057 | loss_box_reg: 0.1915 | loss_mask: 0.1976 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.0299 | Total Loss: 0.5261\n",
      "Epoch 2751 | loss_cls: 0.0958 | loss_box_reg: 0.1664 | loss_mask: 0.0856 | loss_rpn_cls: 0.0053 | loss_rpn_loc: 0.0354 | Total Loss: 0.3885\n",
      "Epoch 2752 | loss_cls: 0.0441 | loss_box_reg: 0.2538 | loss_mask: 0.0452 | loss_rpn_cls: 0.0060 | loss_rpn_loc: 0.0023 | Total Loss: 0.3514\n",
      "Epoch 2753 | loss_cls: 0.0160 | loss_box_reg: 0.0939 | loss_mask: 0.0558 | loss_rpn_cls: 0.0146 | loss_rpn_loc: 0.0261 | Total Loss: 0.2064\n",
      "Epoch 2754 | loss_cls: 0.0662 | loss_box_reg: 0.1645 | loss_mask: 0.0354 | loss_rpn_cls: 0.0022 | loss_rpn_loc: 0.0323 | Total Loss: 0.3007\n",
      "Epoch 2755 | loss_cls: 0.1023 | loss_box_reg: 0.1779 | loss_mask: 0.1025 | loss_rpn_cls: 0.0104 | loss_rpn_loc: 0.0044 | Total Loss: 0.3975\n",
      "Epoch 2756 | loss_cls: 0.1391 | loss_box_reg: 0.1631 | loss_mask: 0.0502 | loss_rpn_cls: 0.0238 | loss_rpn_loc: 0.0917 | Total Loss: 0.4679\n",
      "Epoch 2757 | loss_cls: 0.0358 | loss_box_reg: 0.0854 | loss_mask: 0.0395 | loss_rpn_cls: 0.0001 | loss_rpn_loc: 0.0055 | Total Loss: 0.1664\n",
      "Epoch 2758 | loss_cls: 0.0940 | loss_box_reg: 0.1023 | loss_mask: 0.1800 | loss_rpn_cls: 0.0022 | loss_rpn_loc: 0.0386 | Total Loss: 0.4171\n",
      "Epoch 2759 | loss_cls: 0.0670 | loss_box_reg: 0.1855 | loss_mask: 0.1429 | loss_rpn_cls: 0.0079 | loss_rpn_loc: 0.0107 | Total Loss: 0.4141\n",
      "\u001b[32m[07/29 18:36:44 d2.utils.events]: \u001b[0m eta: 0:01:34  iter: 2759      time: 0.3371  last_time: 0.4174   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2760 | loss_cls: 0.0353 | loss_box_reg: 0.0388 | loss_mask: 0.0861 | loss_rpn_cls: 0.0158 | loss_rpn_loc: 0.1402 | Total Loss: 0.3161\n",
      "Epoch 2761 | loss_cls: 0.0232 | loss_box_reg: 0.0902 | loss_mask: 0.0522 | loss_rpn_cls: 0.0026 | loss_rpn_loc: 0.1474 | Total Loss: 0.3156\n",
      "Epoch 2762 | loss_cls: 0.1233 | loss_box_reg: 0.1412 | loss_mask: 0.0688 | loss_rpn_cls: 0.0054 | loss_rpn_loc: 0.0863 | Total Loss: 0.4252\n",
      "Epoch 2763 | loss_cls: 0.1211 | loss_box_reg: 0.2617 | loss_mask: 0.1615 | loss_rpn_cls: 0.0203 | loss_rpn_loc: 0.0605 | Total Loss: 0.6251\n",
      "Epoch 2764 | loss_cls: 0.0386 | loss_box_reg: 0.1008 | loss_mask: 0.0474 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.1253 | Total Loss: 0.3154\n",
      "Epoch 2765 | loss_cls: 0.0224 | loss_box_reg: 0.0912 | loss_mask: 0.0603 | loss_rpn_cls: 0.0044 | loss_rpn_loc: 0.0159 | Total Loss: 0.1943\n",
      "Epoch 2766 | loss_cls: 0.0655 | loss_box_reg: 0.0985 | loss_mask: 0.0670 | loss_rpn_cls: 0.0085 | loss_rpn_loc: 0.0036 | Total Loss: 0.2431\n",
      "Epoch 2767 | loss_cls: 0.0700 | loss_box_reg: 0.1040 | loss_mask: 0.0480 | loss_rpn_cls: 0.0009 | loss_rpn_loc: 0.0124 | Total Loss: 0.2353\n",
      "Epoch 2768 | loss_cls: 0.0637 | loss_box_reg: 0.1321 | loss_mask: 0.1206 | loss_rpn_cls: 0.0057 | loss_rpn_loc: 0.0379 | Total Loss: 0.3601\n",
      "Epoch 2769 | loss_cls: 0.0675 | loss_box_reg: 0.2196 | loss_mask: 0.0930 | loss_rpn_cls: 0.0119 | loss_rpn_loc: 0.1428 | Total Loss: 0.5349\n",
      "Epoch 2770 | loss_cls: 0.0300 | loss_box_reg: 0.0654 | loss_mask: 0.0689 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.0199 | Total Loss: 0.1869\n",
      "Epoch 2771 | loss_cls: 0.0413 | loss_box_reg: 0.0743 | loss_mask: 0.0955 | loss_rpn_cls: 0.0085 | loss_rpn_loc: 0.0057 | Total Loss: 0.2253\n",
      "Epoch 2772 | loss_cls: 0.0160 | loss_box_reg: 0.0325 | loss_mask: 0.0459 | loss_rpn_cls: 0.0132 | loss_rpn_loc: 0.1100 | Total Loss: 0.2177\n",
      "Epoch 2773 | loss_cls: 0.0577 | loss_box_reg: 0.1911 | loss_mask: 0.1307 | loss_rpn_cls: 0.0010 | loss_rpn_loc: 0.0082 | Total Loss: 0.3887\n",
      "Epoch 2774 | loss_cls: 0.0202 | loss_box_reg: 0.1081 | loss_mask: 0.1852 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0360 | Total Loss: 0.3506\n",
      "Epoch 2775 | loss_cls: 0.0252 | loss_box_reg: 0.0588 | loss_mask: 0.0828 | loss_rpn_cls: 0.0066 | loss_rpn_loc: 0.1581 | Total Loss: 0.3315\n",
      "Epoch 2776 | loss_cls: 0.0621 | loss_box_reg: 0.0903 | loss_mask: 0.0850 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.0087 | Total Loss: 0.2465\n",
      "Epoch 2777 | loss_cls: 0.0466 | loss_box_reg: 0.0956 | loss_mask: 0.0813 | loss_rpn_cls: 0.0038 | loss_rpn_loc: 0.0899 | Total Loss: 0.3172\n",
      "Epoch 2778 | loss_cls: 0.0343 | loss_box_reg: 0.0875 | loss_mask: 0.0977 | loss_rpn_cls: 0.0009 | loss_rpn_loc: 0.0196 | Total Loss: 0.2400\n",
      "Epoch 2779 | loss_cls: 0.0836 | loss_box_reg: 0.1102 | loss_mask: 0.0663 | loss_rpn_cls: 0.0056 | loss_rpn_loc: 0.0244 | Total Loss: 0.2900\n",
      "\u001b[32m[07/29 18:36:51 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 2779      time: 0.3372  last_time: 0.4114   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2780 | loss_cls: 0.0519 | loss_box_reg: 0.1120 | loss_mask: 0.0540 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.0075 | Total Loss: 0.2266\n",
      "Epoch 2781 | loss_cls: 0.0686 | loss_box_reg: 0.1893 | loss_mask: 0.0750 | loss_rpn_cls: 0.0002 | loss_rpn_loc: 0.0402 | Total Loss: 0.3734\n",
      "Epoch 2782 | loss_cls: 0.0363 | loss_box_reg: 0.0521 | loss_mask: 0.0247 | loss_rpn_cls: 0.0052 | loss_rpn_loc: 0.0043 | Total Loss: 0.1225\n",
      "Epoch 2783 | loss_cls: 0.0353 | loss_box_reg: 0.1326 | loss_mask: 0.0580 | loss_rpn_cls: 0.0173 | loss_rpn_loc: 0.0619 | Total Loss: 0.3051\n",
      "Epoch 2784 | loss_cls: 0.0489 | loss_box_reg: 0.2385 | loss_mask: 0.2204 | loss_rpn_cls: 0.0052 | loss_rpn_loc: 0.1240 | Total Loss: 0.6370\n",
      "Epoch 2785 | loss_cls: 0.0259 | loss_box_reg: 0.1142 | loss_mask: 0.0505 | loss_rpn_cls: 0.0086 | loss_rpn_loc: 0.1293 | Total Loss: 0.3286\n",
      "Epoch 2786 | loss_cls: 0.0611 | loss_box_reg: 0.1585 | loss_mask: 0.0433 | loss_rpn_cls: 0.0018 | loss_rpn_loc: 0.0773 | Total Loss: 0.3421\n",
      "Epoch 2787 | loss_cls: 0.0458 | loss_box_reg: 0.0941 | loss_mask: 0.1092 | loss_rpn_cls: 0.0099 | loss_rpn_loc: 0.0721 | Total Loss: 0.3310\n",
      "Epoch 2788 | loss_cls: 0.0249 | loss_box_reg: 0.0930 | loss_mask: 0.0406 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.0021 | Total Loss: 0.1625\n",
      "Epoch 2789 | loss_cls: 0.0261 | loss_box_reg: 0.0609 | loss_mask: 0.0454 | loss_rpn_cls: 0.0042 | loss_rpn_loc: 0.0141 | Total Loss: 0.1507\n",
      "Epoch 2790 | loss_cls: 0.0624 | loss_box_reg: 0.1667 | loss_mask: 0.0705 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.1212 | Total Loss: 0.4222\n",
      "Epoch 2791 | loss_cls: 0.0529 | loss_box_reg: 0.1103 | loss_mask: 0.0725 | loss_rpn_cls: 0.0017 | loss_rpn_loc: 0.0059 | Total Loss: 0.2434\n",
      "Epoch 2792 | loss_cls: 0.0492 | loss_box_reg: 0.1369 | loss_mask: 0.1664 | loss_rpn_cls: 0.0017 | loss_rpn_loc: 0.1782 | Total Loss: 0.5325\n",
      "Epoch 2793 | loss_cls: 0.0336 | loss_box_reg: 0.0377 | loss_mask: 0.0416 | loss_rpn_cls: 0.0037 | loss_rpn_loc: 0.1178 | Total Loss: 0.2344\n",
      "Epoch 2794 | loss_cls: 0.0350 | loss_box_reg: 0.0737 | loss_mask: 0.0851 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.1034 | Total Loss: 0.2985\n",
      "Epoch 2795 | loss_cls: 0.0380 | loss_box_reg: 0.0959 | loss_mask: 0.1417 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0026 | Total Loss: 0.2787\n",
      "Epoch 2796 | loss_cls: 0.1125 | loss_box_reg: 0.2862 | loss_mask: 0.0592 | loss_rpn_cls: 0.0080 | loss_rpn_loc: 0.0850 | Total Loss: 0.5509\n",
      "Epoch 2797 | loss_cls: 0.0303 | loss_box_reg: 0.1388 | loss_mask: 0.0427 | loss_rpn_cls: 0.0149 | loss_rpn_loc: 0.0391 | Total Loss: 0.2659\n",
      "Epoch 2798 | loss_cls: 0.1261 | loss_box_reg: 0.2918 | loss_mask: 0.0639 | loss_rpn_cls: 0.0208 | loss_rpn_loc: 0.0872 | Total Loss: 0.5899\n",
      "Epoch 2799 | loss_cls: 0.0220 | loss_box_reg: 0.1835 | loss_mask: 0.0820 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0104 | Total Loss: 0.2983\n",
      "\u001b[32m[07/29 18:36:58 d2.utils.events]: \u001b[0m eta: 0:01:19  iter: 2799      time: 0.3374  last_time: 0.2672   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2800 | loss_cls: 0.0677 | loss_box_reg: 0.2287 | loss_mask: 0.0381 | loss_rpn_cls: 0.0213 | loss_rpn_loc: 0.1552 | Total Loss: 0.5110\n",
      "Epoch 2801 | loss_cls: 0.0477 | loss_box_reg: 0.1140 | loss_mask: 0.1223 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.0265 | Total Loss: 0.3141\n",
      "Epoch 2802 | loss_cls: 0.0140 | loss_box_reg: 0.0398 | loss_mask: 0.0543 | loss_rpn_cls: 0.0046 | loss_rpn_loc: 0.1059 | Total Loss: 0.2187\n",
      "Epoch 2803 | loss_cls: 0.0278 | loss_box_reg: 0.1470 | loss_mask: 0.1634 | loss_rpn_cls: 0.0074 | loss_rpn_loc: 0.1328 | Total Loss: 0.4785\n",
      "Epoch 2804 | loss_cls: 0.0448 | loss_box_reg: 0.1699 | loss_mask: 0.0624 | loss_rpn_cls: 0.0029 | loss_rpn_loc: 0.0292 | Total Loss: 0.3092\n",
      "Epoch 2805 | loss_cls: 0.0388 | loss_box_reg: 0.1080 | loss_mask: 0.0464 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0308 | Total Loss: 0.2251\n",
      "Epoch 2806 | loss_cls: 0.0208 | loss_box_reg: 0.0564 | loss_mask: 0.2610 | loss_rpn_cls: 0.0054 | loss_rpn_loc: 0.0285 | Total Loss: 0.3722\n",
      "Epoch 2807 | loss_cls: 0.0406 | loss_box_reg: 0.1288 | loss_mask: 0.0443 | loss_rpn_cls: 0.0074 | loss_rpn_loc: 0.1201 | Total Loss: 0.3412\n",
      "Epoch 2808 | loss_cls: 0.0554 | loss_box_reg: 0.1145 | loss_mask: 0.0868 | loss_rpn_cls: 0.0031 | loss_rpn_loc: 0.0259 | Total Loss: 0.2856\n",
      "Epoch 2809 | loss_cls: 0.0296 | loss_box_reg: 0.0774 | loss_mask: 0.0482 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0202 | Total Loss: 0.1760\n",
      "Epoch 2810 | loss_cls: 0.0817 | loss_box_reg: 0.1639 | loss_mask: 0.0666 | loss_rpn_cls: 0.0110 | loss_rpn_loc: 0.0061 | Total Loss: 0.3293\n",
      "Epoch 2811 | loss_cls: 0.0791 | loss_box_reg: 0.0856 | loss_mask: 0.0436 | loss_rpn_cls: 0.0069 | loss_rpn_loc: 0.0127 | Total Loss: 0.2279\n",
      "Epoch 2812 | loss_cls: 0.0594 | loss_box_reg: 0.1895 | loss_mask: 0.1373 | loss_rpn_cls: 0.0037 | loss_rpn_loc: 0.0479 | Total Loss: 0.4379\n",
      "Epoch 2813 | loss_cls: 0.0351 | loss_box_reg: 0.0966 | loss_mask: 0.1047 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0122 | Total Loss: 0.2498\n",
      "Epoch 2814 | loss_cls: 0.0187 | loss_box_reg: 0.0545 | loss_mask: 0.0405 | loss_rpn_cls: 0.0075 | loss_rpn_loc: 0.0205 | Total Loss: 0.1417\n",
      "Epoch 2815 | loss_cls: 0.0356 | loss_box_reg: 0.1371 | loss_mask: 0.2307 | loss_rpn_cls: 0.0016 | loss_rpn_loc: 0.1076 | Total Loss: 0.5126\n",
      "Epoch 2816 | loss_cls: 0.0502 | loss_box_reg: 0.1133 | loss_mask: 0.1299 | loss_rpn_cls: 0.0032 | loss_rpn_loc: 0.0348 | Total Loss: 0.3314\n",
      "Epoch 2817 | loss_cls: 0.0430 | loss_box_reg: 0.0891 | loss_mask: 0.0921 | loss_rpn_cls: 0.0041 | loss_rpn_loc: 0.0034 | Total Loss: 0.2317\n",
      "Epoch 2818 | loss_cls: 0.0781 | loss_box_reg: 0.1535 | loss_mask: 0.0666 | loss_rpn_cls: 0.0017 | loss_rpn_loc: 0.0262 | Total Loss: 0.3261\n",
      "Epoch 2819 | loss_cls: 0.0400 | loss_box_reg: 0.1487 | loss_mask: 0.0981 | loss_rpn_cls: 0.0002 | loss_rpn_loc: 0.0099 | Total Loss: 0.2970\n",
      "\u001b[32m[07/29 18:37:04 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 2819      time: 0.3372  last_time: 0.2761   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2820 | loss_cls: 0.0361 | loss_box_reg: 0.1050 | loss_mask: 0.0471 | loss_rpn_cls: 0.0008 | loss_rpn_loc: 0.0073 | Total Loss: 0.1964\n",
      "Epoch 2821 | loss_cls: 0.0673 | loss_box_reg: 0.1997 | loss_mask: 0.0719 | loss_rpn_cls: 0.0031 | loss_rpn_loc: 0.0208 | Total Loss: 0.3629\n",
      "Epoch 2822 | loss_cls: 0.0430 | loss_box_reg: 0.2007 | loss_mask: 0.0431 | loss_rpn_cls: 0.0002 | loss_rpn_loc: 0.0030 | Total Loss: 0.2899\n",
      "Epoch 2823 | loss_cls: 0.0925 | loss_box_reg: 0.1004 | loss_mask: 0.0513 | loss_rpn_cls: 0.0152 | loss_rpn_loc: 0.1005 | Total Loss: 0.3599\n",
      "Epoch 2824 | loss_cls: 0.0461 | loss_box_reg: 0.1104 | loss_mask: 0.0589 | loss_rpn_cls: 0.0069 | loss_rpn_loc: 0.0769 | Total Loss: 0.2992\n",
      "Epoch 2825 | loss_cls: 0.1184 | loss_box_reg: 0.1894 | loss_mask: 0.0640 | loss_rpn_cls: 0.0028 | loss_rpn_loc: 0.0072 | Total Loss: 0.3817\n",
      "Epoch 2826 | loss_cls: 0.0631 | loss_box_reg: 0.1900 | loss_mask: 0.0897 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.0256 | Total Loss: 0.3711\n",
      "Epoch 2827 | loss_cls: 0.1152 | loss_box_reg: 0.2139 | loss_mask: 0.0758 | loss_rpn_cls: 0.0183 | loss_rpn_loc: 0.2688 | Total Loss: 0.6919\n",
      "Epoch 2828 | loss_cls: 0.0082 | loss_box_reg: 0.0547 | loss_mask: 0.2220 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.1229 | Total Loss: 0.4082\n",
      "Epoch 2829 | loss_cls: 0.0640 | loss_box_reg: 0.1167 | loss_mask: 0.0519 | loss_rpn_cls: 0.0249 | loss_rpn_loc: 0.0315 | Total Loss: 0.2889\n",
      "Epoch 2830 | loss_cls: 0.0226 | loss_box_reg: 0.1203 | loss_mask: 0.0529 | loss_rpn_cls: 0.0055 | loss_rpn_loc: 0.0122 | Total Loss: 0.2135\n",
      "Epoch 2831 | loss_cls: 0.0440 | loss_box_reg: 0.2295 | loss_mask: 0.1609 | loss_rpn_cls: 0.0428 | loss_rpn_loc: 0.1823 | Total Loss: 0.6596\n",
      "Epoch 2832 | loss_cls: 0.0554 | loss_box_reg: 0.0887 | loss_mask: 0.0626 | loss_rpn_cls: 0.0009 | loss_rpn_loc: 0.0080 | Total Loss: 0.2156\n",
      "Epoch 2833 | loss_cls: 0.0472 | loss_box_reg: 0.1113 | loss_mask: 0.2089 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.0777 | Total Loss: 0.4463\n",
      "Epoch 2834 | loss_cls: 0.0482 | loss_box_reg: 0.0852 | loss_mask: 0.0757 | loss_rpn_cls: 0.0036 | loss_rpn_loc: 0.1245 | Total Loss: 0.3373\n",
      "Epoch 2835 | loss_cls: 0.0716 | loss_box_reg: 0.2192 | loss_mask: 0.2756 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0163 | Total Loss: 0.5833\n",
      "Epoch 2836 | loss_cls: 0.0448 | loss_box_reg: 0.0544 | loss_mask: 0.1420 | loss_rpn_cls: 0.0001 | loss_rpn_loc: 0.0099 | Total Loss: 0.2511\n",
      "Epoch 2837 | loss_cls: 0.0503 | loss_box_reg: 0.1238 | loss_mask: 0.0374 | loss_rpn_cls: 0.0008 | loss_rpn_loc: 0.0069 | Total Loss: 0.2191\n",
      "Epoch 2838 | loss_cls: 0.0639 | loss_box_reg: 0.0722 | loss_mask: 0.0719 | loss_rpn_cls: 0.0011 | loss_rpn_loc: 0.0016 | Total Loss: 0.2108\n",
      "Epoch 2839 | loss_cls: 0.0388 | loss_box_reg: 0.0683 | loss_mask: 0.0888 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.0065 | Total Loss: 0.2058\n",
      "\u001b[32m[07/29 18:37:11 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 2839      time: 0.3372  last_time: 0.2807   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2840 | loss_cls: 0.0953 | loss_box_reg: 0.1785 | loss_mask: 0.0418 | loss_rpn_cls: 0.0183 | loss_rpn_loc: 0.0721 | Total Loss: 0.4060\n",
      "Epoch 2841 | loss_cls: 0.0740 | loss_box_reg: 0.1337 | loss_mask: 0.1533 | loss_rpn_cls: 0.0085 | loss_rpn_loc: 0.0373 | Total Loss: 0.4067\n",
      "Epoch 2842 | loss_cls: 0.1008 | loss_box_reg: 0.1933 | loss_mask: 0.0675 | loss_rpn_cls: 0.0073 | loss_rpn_loc: 0.0456 | Total Loss: 0.4145\n",
      "Epoch 2843 | loss_cls: 0.0275 | loss_box_reg: 0.1100 | loss_mask: 0.0884 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.1180 | Total Loss: 0.3445\n",
      "Epoch 2844 | loss_cls: 0.0201 | loss_box_reg: 0.0368 | loss_mask: 0.0709 | loss_rpn_cls: 0.0085 | loss_rpn_loc: 0.0244 | Total Loss: 0.1608\n",
      "Epoch 2845 | loss_cls: 0.0583 | loss_box_reg: 0.1423 | loss_mask: 0.0571 | loss_rpn_cls: 0.0069 | loss_rpn_loc: 0.0448 | Total Loss: 0.3093\n",
      "Epoch 2846 | loss_cls: 0.0268 | loss_box_reg: 0.0638 | loss_mask: 0.0481 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.0472 | Total Loss: 0.1882\n",
      "Epoch 2847 | loss_cls: 0.0486 | loss_box_reg: 0.1013 | loss_mask: 0.0722 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.0302 | Total Loss: 0.2537\n",
      "Epoch 2848 | loss_cls: 0.0342 | loss_box_reg: 0.0455 | loss_mask: 0.0336 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.0067 | Total Loss: 0.1204\n",
      "Epoch 2849 | loss_cls: 0.0239 | loss_box_reg: 0.0698 | loss_mask: 0.1041 | loss_rpn_cls: 0.0081 | loss_rpn_loc: 0.0691 | Total Loss: 0.2751\n",
      "Epoch 2850 | loss_cls: 0.0255 | loss_box_reg: 0.0700 | loss_mask: 0.2771 | loss_rpn_cls: 0.0076 | loss_rpn_loc: 0.2247 | Total Loss: 0.6048\n",
      "Epoch 2851 | loss_cls: 0.0232 | loss_box_reg: 0.0384 | loss_mask: 0.0904 | loss_rpn_cls: 0.0018 | loss_rpn_loc: 0.1107 | Total Loss: 0.2645\n",
      "Epoch 2852 | loss_cls: 0.0342 | loss_box_reg: 0.0774 | loss_mask: 0.0483 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.0040 | Total Loss: 0.1659\n",
      "Epoch 2853 | loss_cls: 0.0472 | loss_box_reg: 0.0709 | loss_mask: 0.1085 | loss_rpn_cls: 0.0139 | loss_rpn_loc: 0.1096 | Total Loss: 0.3501\n",
      "Epoch 2854 | loss_cls: 0.0940 | loss_box_reg: 0.1094 | loss_mask: 0.0600 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.0181 | Total Loss: 0.2820\n",
      "Epoch 2855 | loss_cls: 0.0614 | loss_box_reg: 0.1875 | loss_mask: 0.0735 | loss_rpn_cls: 0.0021 | loss_rpn_loc: 0.0746 | Total Loss: 0.3992\n",
      "Epoch 2856 | loss_cls: 0.0687 | loss_box_reg: 0.1479 | loss_mask: 0.1364 | loss_rpn_cls: 0.0062 | loss_rpn_loc: 0.0747 | Total Loss: 0.4340\n",
      "Epoch 2857 | loss_cls: 0.0213 | loss_box_reg: 0.0477 | loss_mask: 0.0638 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.1734 | Total Loss: 0.3088\n",
      "Epoch 2858 | loss_cls: 0.0571 | loss_box_reg: 0.0944 | loss_mask: 0.0542 | loss_rpn_cls: 0.0202 | loss_rpn_loc: 0.0970 | Total Loss: 0.3230\n",
      "Epoch 2859 | loss_cls: 0.0724 | loss_box_reg: 0.1530 | loss_mask: 0.0646 | loss_rpn_cls: 0.0124 | loss_rpn_loc: 0.0302 | Total Loss: 0.3325\n",
      "\u001b[32m[07/29 18:37:18 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 2859      time: 0.3373  last_time: 0.2846   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2860 | loss_cls: 0.0304 | loss_box_reg: 0.0984 | loss_mask: 0.1110 | loss_rpn_cls: 0.0002 | loss_rpn_loc: 0.0211 | Total Loss: 0.2611\n",
      "Epoch 2861 | loss_cls: 0.0542 | loss_box_reg: 0.1087 | loss_mask: 0.0876 | loss_rpn_cls: 0.0032 | loss_rpn_loc: 0.0041 | Total Loss: 0.2578\n",
      "Epoch 2862 | loss_cls: 0.0394 | loss_box_reg: 0.1997 | loss_mask: 0.0575 | loss_rpn_cls: 0.0085 | loss_rpn_loc: 0.0016 | Total Loss: 0.3068\n",
      "Epoch 2863 | loss_cls: 0.1507 | loss_box_reg: 0.3397 | loss_mask: 0.0616 | loss_rpn_cls: 0.0078 | loss_rpn_loc: 0.1501 | Total Loss: 0.7099\n",
      "Epoch 2864 | loss_cls: 0.0387 | loss_box_reg: 0.0886 | loss_mask: 0.0652 | loss_rpn_cls: 0.0160 | loss_rpn_loc: 0.0963 | Total Loss: 0.3047\n",
      "Epoch 2865 | loss_cls: 0.0749 | loss_box_reg: 0.1253 | loss_mask: 0.0499 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0117 | Total Loss: 0.2624\n",
      "Epoch 2866 | loss_cls: 0.1082 | loss_box_reg: 0.2232 | loss_mask: 0.0446 | loss_rpn_cls: 0.1188 | loss_rpn_loc: 0.3101 | Total Loss: 0.8049\n",
      "Epoch 2867 | loss_cls: 0.0498 | loss_box_reg: 0.2151 | loss_mask: 0.0700 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.0512 | Total Loss: 0.3874\n",
      "Epoch 2868 | loss_cls: 0.0383 | loss_box_reg: 0.1672 | loss_mask: 0.0386 | loss_rpn_cls: 0.0121 | loss_rpn_loc: 0.1096 | Total Loss: 0.3659\n",
      "Epoch 2869 | loss_cls: 0.0465 | loss_box_reg: 0.1748 | loss_mask: 0.0638 | loss_rpn_cls: 0.0338 | loss_rpn_loc: 0.1620 | Total Loss: 0.4808\n",
      "Epoch 2870 | loss_cls: 0.0676 | loss_box_reg: 0.1796 | loss_mask: 0.1813 | loss_rpn_cls: 0.0139 | loss_rpn_loc: 0.0029 | Total Loss: 0.4452\n",
      "Epoch 2871 | loss_cls: 0.0416 | loss_box_reg: 0.1472 | loss_mask: 0.0741 | loss_rpn_cls: 0.0031 | loss_rpn_loc: 0.0098 | Total Loss: 0.2758\n",
      "Epoch 2872 | loss_cls: 0.0633 | loss_box_reg: 0.2051 | loss_mask: 0.0782 | loss_rpn_cls: 0.0007 | loss_rpn_loc: 0.0397 | Total Loss: 0.3869\n",
      "Epoch 2873 | loss_cls: 0.1026 | loss_box_reg: 0.1386 | loss_mask: 0.0347 | loss_rpn_cls: 0.0090 | loss_rpn_loc: 0.1384 | Total Loss: 0.4233\n",
      "Epoch 2874 | loss_cls: 0.0635 | loss_box_reg: 0.1095 | loss_mask: 0.0538 | loss_rpn_cls: 0.0144 | loss_rpn_loc: 0.0661 | Total Loss: 0.3073\n",
      "Epoch 2875 | loss_cls: 0.0888 | loss_box_reg: 0.1293 | loss_mask: 0.0570 | loss_rpn_cls: 0.0158 | loss_rpn_loc: 0.0184 | Total Loss: 0.3092\n",
      "Epoch 2876 | loss_cls: 0.0492 | loss_box_reg: 0.2203 | loss_mask: 0.2942 | loss_rpn_cls: 0.0029 | loss_rpn_loc: 0.0107 | Total Loss: 0.5773\n",
      "Epoch 2877 | loss_cls: 0.0672 | loss_box_reg: 0.0759 | loss_mask: 0.0436 | loss_rpn_cls: 0.0093 | loss_rpn_loc: 0.0198 | Total Loss: 0.2158\n",
      "Epoch 2878 | loss_cls: 0.0385 | loss_box_reg: 0.1725 | loss_mask: 0.1012 | loss_rpn_cls: 0.0038 | loss_rpn_loc: 0.0495 | Total Loss: 0.3655\n",
      "Epoch 2879 | loss_cls: 0.0499 | loss_box_reg: 0.1304 | loss_mask: 0.0400 | loss_rpn_cls: 0.0094 | loss_rpn_loc: 0.0760 | Total Loss: 0.3057\n",
      "\u001b[32m[07/29 18:37:25 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 2879      time: 0.3373  last_time: 0.4278   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2880 | loss_cls: 0.0652 | loss_box_reg: 0.2425 | loss_mask: 0.1545 | loss_rpn_cls: 0.0082 | loss_rpn_loc: 0.0324 | Total Loss: 0.5027\n",
      "Epoch 2881 | loss_cls: 0.0288 | loss_box_reg: 0.0510 | loss_mask: 0.0460 | loss_rpn_cls: 0.0109 | loss_rpn_loc: 0.0146 | Total Loss: 0.1513\n",
      "Epoch 2882 | loss_cls: 0.0446 | loss_box_reg: 0.1077 | loss_mask: 0.1388 | loss_rpn_cls: 0.0065 | loss_rpn_loc: 0.0058 | Total Loss: 0.3034\n",
      "Epoch 2883 | loss_cls: 0.0548 | loss_box_reg: 0.1197 | loss_mask: 0.0605 | loss_rpn_cls: 0.0021 | loss_rpn_loc: 0.0229 | Total Loss: 0.2598\n",
      "Epoch 2884 | loss_cls: 0.0288 | loss_box_reg: 0.0818 | loss_mask: 0.0558 | loss_rpn_cls: 0.0055 | loss_rpn_loc: 0.0144 | Total Loss: 0.1862\n",
      "Epoch 2885 | loss_cls: 0.0345 | loss_box_reg: 0.1587 | loss_mask: 0.0541 | loss_rpn_cls: 0.0142 | loss_rpn_loc: 0.0795 | Total Loss: 0.3410\n",
      "Epoch 2886 | loss_cls: 0.0491 | loss_box_reg: 0.0803 | loss_mask: 0.0344 | loss_rpn_cls: 0.0115 | loss_rpn_loc: 0.0015 | Total Loss: 0.1768\n",
      "Epoch 2887 | loss_cls: 0.0300 | loss_box_reg: 0.0317 | loss_mask: 0.0621 | loss_rpn_cls: 0.0033 | loss_rpn_loc: 0.0162 | Total Loss: 0.1433\n",
      "Epoch 2888 | loss_cls: 0.0203 | loss_box_reg: 0.0551 | loss_mask: 0.0540 | loss_rpn_cls: 0.0162 | loss_rpn_loc: 0.1378 | Total Loss: 0.2835\n",
      "Epoch 2889 | loss_cls: 0.0309 | loss_box_reg: 0.0807 | loss_mask: 0.1241 | loss_rpn_cls: 0.0018 | loss_rpn_loc: 0.0129 | Total Loss: 0.2505\n",
      "Epoch 2890 | loss_cls: 0.0553 | loss_box_reg: 0.1133 | loss_mask: 0.0564 | loss_rpn_cls: 0.0085 | loss_rpn_loc: 0.0071 | Total Loss: 0.2406\n",
      "Epoch 2891 | loss_cls: 0.0423 | loss_box_reg: 0.0509 | loss_mask: 0.0505 | loss_rpn_cls: 0.0052 | loss_rpn_loc: 0.0692 | Total Loss: 0.2181\n",
      "Epoch 2892 | loss_cls: 0.0375 | loss_box_reg: 0.1495 | loss_mask: 0.0740 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.0898 | Total Loss: 0.3523\n",
      "Epoch 2893 | loss_cls: 0.0378 | loss_box_reg: 0.0974 | loss_mask: 0.0877 | loss_rpn_cls: 0.0005 | loss_rpn_loc: 0.0998 | Total Loss: 0.3233\n",
      "Epoch 2894 | loss_cls: 0.0444 | loss_box_reg: 0.1004 | loss_mask: 0.0260 | loss_rpn_cls: 0.0196 | loss_rpn_loc: 0.3765 | Total Loss: 0.5670\n",
      "Epoch 2895 | loss_cls: 0.0396 | loss_box_reg: 0.0775 | loss_mask: 0.0471 | loss_rpn_cls: 0.0009 | loss_rpn_loc: 0.1040 | Total Loss: 0.2691\n",
      "Epoch 2896 | loss_cls: 0.0200 | loss_box_reg: 0.0413 | loss_mask: 0.1909 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.0955 | Total Loss: 0.3491\n",
      "Epoch 2897 | loss_cls: 0.0387 | loss_box_reg: 0.0806 | loss_mask: 0.0694 | loss_rpn_cls: 0.0032 | loss_rpn_loc: 0.1565 | Total Loss: 0.3484\n",
      "Epoch 2898 | loss_cls: 0.0356 | loss_box_reg: 0.1049 | loss_mask: 0.0695 | loss_rpn_cls: 0.0036 | loss_rpn_loc: 0.0517 | Total Loss: 0.2653\n",
      "Epoch 2899 | loss_cls: 0.0332 | loss_box_reg: 0.0627 | loss_mask: 0.0320 | loss_rpn_cls: 0.0006 | loss_rpn_loc: 0.0020 | Total Loss: 0.1306\n",
      "\u001b[32m[07/29 18:37:32 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 2899      time: 0.3374  last_time: 0.2841   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2900 | loss_cls: 0.1041 | loss_box_reg: 0.1119 | loss_mask: 0.0496 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.0448 | Total Loss: 0.3116\n",
      "Epoch 2901 | loss_cls: 0.0336 | loss_box_reg: 0.0899 | loss_mask: 0.1642 | loss_rpn_cls: 0.0133 | loss_rpn_loc: 0.1579 | Total Loss: 0.4588\n",
      "Epoch 2902 | loss_cls: 0.0388 | loss_box_reg: 0.1342 | loss_mask: 0.1174 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.0823 | Total Loss: 0.3743\n",
      "Epoch 2903 | loss_cls: 0.0825 | loss_box_reg: 0.1979 | loss_mask: 0.0605 | loss_rpn_cls: 0.0100 | loss_rpn_loc: 0.0597 | Total Loss: 0.4106\n",
      "Epoch 2904 | loss_cls: 0.0461 | loss_box_reg: 0.0660 | loss_mask: 0.1225 | loss_rpn_cls: 0.0062 | loss_rpn_loc: 0.1046 | Total Loss: 0.3455\n",
      "Epoch 2905 | loss_cls: 0.0375 | loss_box_reg: 0.1069 | loss_mask: 0.0277 | loss_rpn_cls: 0.0126 | loss_rpn_loc: 0.0574 | Total Loss: 0.2422\n",
      "Epoch 2906 | loss_cls: 0.0695 | loss_box_reg: 0.0914 | loss_mask: 0.0381 | loss_rpn_cls: 0.0160 | loss_rpn_loc: 0.0251 | Total Loss: 0.2401\n",
      "Epoch 2907 | loss_cls: 0.0279 | loss_box_reg: 0.0741 | loss_mask: 0.0566 | loss_rpn_cls: 0.0003 | loss_rpn_loc: 0.0196 | Total Loss: 0.1785\n",
      "Epoch 2908 | loss_cls: 0.0279 | loss_box_reg: 0.0660 | loss_mask: 0.0745 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.1048 | Total Loss: 0.2756\n",
      "Epoch 2909 | loss_cls: 0.0348 | loss_box_reg: 0.0883 | loss_mask: 0.0827 | loss_rpn_cls: 0.0063 | loss_rpn_loc: 0.1123 | Total Loss: 0.3244\n",
      "Epoch 2910 | loss_cls: 0.0347 | loss_box_reg: 0.0834 | loss_mask: 0.0437 | loss_rpn_cls: 0.0075 | loss_rpn_loc: 0.0069 | Total Loss: 0.1762\n",
      "Epoch 2911 | loss_cls: 0.1009 | loss_box_reg: 0.1453 | loss_mask: 0.0610 | loss_rpn_cls: 0.0037 | loss_rpn_loc: 0.1115 | Total Loss: 0.4224\n",
      "Epoch 2912 | loss_cls: 0.0745 | loss_box_reg: 0.1288 | loss_mask: 0.0440 | loss_rpn_cls: 0.0030 | loss_rpn_loc: 0.0314 | Total Loss: 0.2817\n",
      "Epoch 2913 | loss_cls: 0.0603 | loss_box_reg: 0.1998 | loss_mask: 0.0790 | loss_rpn_cls: 0.0055 | loss_rpn_loc: 0.0039 | Total Loss: 0.3485\n",
      "Epoch 2914 | loss_cls: 0.0341 | loss_box_reg: 0.1550 | loss_mask: 0.0994 | loss_rpn_cls: 0.0090 | loss_rpn_loc: 0.0202 | Total Loss: 0.3177\n",
      "Epoch 2915 | loss_cls: 0.0518 | loss_box_reg: 0.0802 | loss_mask: 0.0380 | loss_rpn_cls: 0.0297 | loss_rpn_loc: 0.0233 | Total Loss: 0.2230\n",
      "Epoch 2916 | loss_cls: 0.0218 | loss_box_reg: 0.0227 | loss_mask: 0.1117 | loss_rpn_cls: 0.0053 | loss_rpn_loc: 0.1673 | Total Loss: 0.3288\n",
      "Epoch 2917 | loss_cls: 0.0724 | loss_box_reg: 0.2081 | loss_mask: 0.0719 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.0094 | Total Loss: 0.3641\n",
      "Epoch 2918 | loss_cls: 0.1056 | loss_box_reg: 0.2109 | loss_mask: 0.0507 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.1488 | Total Loss: 0.5179\n",
      "Epoch 2919 | loss_cls: 0.0496 | loss_box_reg: 0.1017 | loss_mask: 0.0967 | loss_rpn_cls: 0.0096 | loss_rpn_loc: 0.0837 | Total Loss: 0.3413\n",
      "\u001b[32m[07/29 18:37:39 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 2919      time: 0.3375  last_time: 0.4149   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2920 | loss_cls: 0.0490 | loss_box_reg: 0.0717 | loss_mask: 0.0608 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.0066 | Total Loss: 0.1900\n",
      "Epoch 2921 | loss_cls: 0.0157 | loss_box_reg: 0.0810 | loss_mask: 0.1370 | loss_rpn_cls: 0.0055 | loss_rpn_loc: 0.1033 | Total Loss: 0.3425\n",
      "Epoch 2922 | loss_cls: 0.0459 | loss_box_reg: 0.1817 | loss_mask: 0.1029 | loss_rpn_cls: 0.0079 | loss_rpn_loc: 0.0359 | Total Loss: 0.3742\n",
      "Epoch 2923 | loss_cls: 0.0355 | loss_box_reg: 0.0719 | loss_mask: 0.0656 | loss_rpn_cls: 0.0017 | loss_rpn_loc: 0.0504 | Total Loss: 0.2252\n",
      "Epoch 2924 | loss_cls: 0.0520 | loss_box_reg: 0.2234 | loss_mask: 0.1563 | loss_rpn_cls: 0.0165 | loss_rpn_loc: 0.0235 | Total Loss: 0.4717\n",
      "Epoch 2925 | loss_cls: 0.0519 | loss_box_reg: 0.0652 | loss_mask: 0.0891 | loss_rpn_cls: 0.0097 | loss_rpn_loc: 0.0032 | Total Loss: 0.2191\n",
      "Epoch 2926 | loss_cls: 0.0559 | loss_box_reg: 0.1479 | loss_mask: 0.0471 | loss_rpn_cls: 0.0110 | loss_rpn_loc: 0.0498 | Total Loss: 0.3118\n",
      "Epoch 2927 | loss_cls: 0.0594 | loss_box_reg: 0.1627 | loss_mask: 0.1130 | loss_rpn_cls: 0.0337 | loss_rpn_loc: 0.0509 | Total Loss: 0.4198\n",
      "Epoch 2928 | loss_cls: 0.0566 | loss_box_reg: 0.1378 | loss_mask: 0.0952 | loss_rpn_cls: 0.0207 | loss_rpn_loc: 0.0847 | Total Loss: 0.3951\n",
      "Epoch 2929 | loss_cls: 0.0464 | loss_box_reg: 0.1565 | loss_mask: 0.0575 | loss_rpn_cls: 0.0058 | loss_rpn_loc: 0.1204 | Total Loss: 0.3866\n",
      "Epoch 2930 | loss_cls: 0.0376 | loss_box_reg: 0.0847 | loss_mask: 0.0861 | loss_rpn_cls: 0.0021 | loss_rpn_loc: 0.0123 | Total Loss: 0.2229\n",
      "Epoch 2931 | loss_cls: 0.0197 | loss_box_reg: 0.1172 | loss_mask: 0.0437 | loss_rpn_cls: 0.0004 | loss_rpn_loc: 0.0044 | Total Loss: 0.1854\n",
      "Epoch 2932 | loss_cls: 0.0295 | loss_box_reg: 0.1487 | loss_mask: 0.0947 | loss_rpn_cls: 0.0066 | loss_rpn_loc: 0.0241 | Total Loss: 0.3037\n",
      "Epoch 2933 | loss_cls: 0.0362 | loss_box_reg: 0.1038 | loss_mask: 0.0400 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.0261 | Total Loss: 0.2074\n",
      "Epoch 2934 | loss_cls: 0.0493 | loss_box_reg: 0.0855 | loss_mask: 0.0593 | loss_rpn_cls: 0.0060 | loss_rpn_loc: 0.0215 | Total Loss: 0.2216\n",
      "Epoch 2935 | loss_cls: 0.0473 | loss_box_reg: 0.1084 | loss_mask: 0.0418 | loss_rpn_cls: 0.0085 | loss_rpn_loc: 0.1509 | Total Loss: 0.3569\n",
      "Epoch 2936 | loss_cls: 0.0432 | loss_box_reg: 0.0982 | loss_mask: 0.1491 | loss_rpn_cls: 0.0097 | loss_rpn_loc: 0.1203 | Total Loss: 0.4204\n",
      "Epoch 2937 | loss_cls: 0.0986 | loss_box_reg: 0.1925 | loss_mask: 0.0408 | loss_rpn_cls: 0.0013 | loss_rpn_loc: 0.0256 | Total Loss: 0.3588\n",
      "Epoch 2938 | loss_cls: 0.0622 | loss_box_reg: 0.1557 | loss_mask: 0.0481 | loss_rpn_cls: 0.0372 | loss_rpn_loc: 0.0693 | Total Loss: 0.3726\n",
      "Epoch 2939 | loss_cls: 0.0495 | loss_box_reg: 0.2460 | loss_mask: 0.1217 | loss_rpn_cls: 0.0104 | loss_rpn_loc: 0.1242 | Total Loss: 0.5518\n",
      "\u001b[32m[07/29 18:37:46 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 2939      time: 0.3375  last_time: 0.2871   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2940 | loss_cls: 0.0463 | loss_box_reg: 0.1493 | loss_mask: 0.0750 | loss_rpn_cls: 0.0308 | loss_rpn_loc: 0.0496 | Total Loss: 0.3509\n",
      "Epoch 2941 | loss_cls: 0.1198 | loss_box_reg: 0.1011 | loss_mask: 0.0364 | loss_rpn_cls: 0.0034 | loss_rpn_loc: 0.0093 | Total Loss: 0.2701\n",
      "Epoch 2942 | loss_cls: 0.0310 | loss_box_reg: 0.0768 | loss_mask: 0.0558 | loss_rpn_cls: 0.0090 | loss_rpn_loc: 0.1693 | Total Loss: 0.3420\n",
      "Epoch 2943 | loss_cls: 0.0750 | loss_box_reg: 0.2602 | loss_mask: 0.0414 | loss_rpn_cls: 0.0088 | loss_rpn_loc: 0.1432 | Total Loss: 0.5286\n",
      "Epoch 2944 | loss_cls: 0.0873 | loss_box_reg: 0.1524 | loss_mask: 0.0960 | loss_rpn_cls: 0.0002 | loss_rpn_loc: 0.0081 | Total Loss: 0.3440\n",
      "Epoch 2945 | loss_cls: 0.0826 | loss_box_reg: 0.2330 | loss_mask: 0.0403 | loss_rpn_cls: 0.0097 | loss_rpn_loc: 0.0868 | Total Loss: 0.4524\n",
      "Epoch 2946 | loss_cls: 0.0191 | loss_box_reg: 0.0652 | loss_mask: 0.0472 | loss_rpn_cls: 0.0018 | loss_rpn_loc: 0.0177 | Total Loss: 0.1510\n",
      "Epoch 2947 | loss_cls: 0.0466 | loss_box_reg: 0.2498 | loss_mask: 0.1532 | loss_rpn_cls: 0.0043 | loss_rpn_loc: 0.0140 | Total Loss: 0.4678\n",
      "Epoch 2948 | loss_cls: 0.0774 | loss_box_reg: 0.1553 | loss_mask: 0.0337 | loss_rpn_cls: 0.0021 | loss_rpn_loc: 0.0289 | Total Loss: 0.2974\n",
      "Epoch 2949 | loss_cls: 0.0422 | loss_box_reg: 0.1216 | loss_mask: 0.0708 | loss_rpn_cls: 0.0037 | loss_rpn_loc: 0.0081 | Total Loss: 0.2464\n",
      "Epoch 2950 | loss_cls: 0.0428 | loss_box_reg: 0.1625 | loss_mask: 0.0712 | loss_rpn_cls: 0.0029 | loss_rpn_loc: 0.1168 | Total Loss: 0.3962\n",
      "Epoch 2951 | loss_cls: 0.0271 | loss_box_reg: 0.1784 | loss_mask: 0.1361 | loss_rpn_cls: 0.0022 | loss_rpn_loc: 0.0351 | Total Loss: 0.3790\n",
      "Epoch 2952 | loss_cls: 0.0284 | loss_box_reg: 0.0565 | loss_mask: 0.0473 | loss_rpn_cls: 0.0057 | loss_rpn_loc: 0.0071 | Total Loss: 0.1449\n",
      "Epoch 2953 | loss_cls: 0.0521 | loss_box_reg: 0.1743 | loss_mask: 0.0661 | loss_rpn_cls: 0.0085 | loss_rpn_loc: 0.0107 | Total Loss: 0.3118\n",
      "Epoch 2954 | loss_cls: 0.0562 | loss_box_reg: 0.2619 | loss_mask: 0.1494 | loss_rpn_cls: 0.0037 | loss_rpn_loc: 0.0095 | Total Loss: 0.4808\n",
      "Epoch 2955 | loss_cls: 0.0468 | loss_box_reg: 0.1333 | loss_mask: 0.0759 | loss_rpn_cls: 0.0060 | loss_rpn_loc: 0.0249 | Total Loss: 0.2868\n",
      "Epoch 2956 | loss_cls: 0.0332 | loss_box_reg: 0.2200 | loss_mask: 0.0384 | loss_rpn_cls: 0.0018 | loss_rpn_loc: 0.1493 | Total Loss: 0.4428\n",
      "Epoch 2957 | loss_cls: 0.0746 | loss_box_reg: 0.1426 | loss_mask: 0.0502 | loss_rpn_cls: 0.0064 | loss_rpn_loc: 0.0091 | Total Loss: 0.2829\n",
      "Epoch 2958 | loss_cls: 0.0765 | loss_box_reg: 0.1310 | loss_mask: 0.0879 | loss_rpn_cls: 0.0195 | loss_rpn_loc: 0.0311 | Total Loss: 0.3459\n",
      "Epoch 2959 | loss_cls: 0.0558 | loss_box_reg: 0.1813 | loss_mask: 0.0585 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.0102 | Total Loss: 0.3072\n",
      "\u001b[32m[07/29 18:37:53 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 2959      time: 0.3376  last_time: 0.4155   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2960 | loss_cls: 0.0613 | loss_box_reg: 0.1794 | loss_mask: 0.0431 | loss_rpn_cls: 0.0037 | loss_rpn_loc: 0.2488 | Total Loss: 0.5363\n",
      "Epoch 2961 | loss_cls: 0.0345 | loss_box_reg: 0.1025 | loss_mask: 0.0774 | loss_rpn_cls: 0.0039 | loss_rpn_loc: 0.0461 | Total Loss: 0.2645\n",
      "Epoch 2962 | loss_cls: 0.0233 | loss_box_reg: 0.0967 | loss_mask: 0.0480 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.0334 | Total Loss: 0.2028\n",
      "Epoch 2963 | loss_cls: 0.0548 | loss_box_reg: 0.1483 | loss_mask: 0.0531 | loss_rpn_cls: 0.0113 | loss_rpn_loc: 0.0457 | Total Loss: 0.3132\n",
      "Epoch 2964 | loss_cls: 0.0860 | loss_box_reg: 0.1203 | loss_mask: 0.0941 | loss_rpn_cls: 0.0040 | loss_rpn_loc: 0.1356 | Total Loss: 0.4401\n",
      "Epoch 2965 | loss_cls: 0.0280 | loss_box_reg: 0.0448 | loss_mask: 0.1944 | loss_rpn_cls: 0.0015 | loss_rpn_loc: 0.0027 | Total Loss: 0.2713\n",
      "Epoch 2966 | loss_cls: 0.1029 | loss_box_reg: 0.1909 | loss_mask: 0.0614 | loss_rpn_cls: 0.0207 | loss_rpn_loc: 0.0603 | Total Loss: 0.4363\n",
      "Epoch 2967 | loss_cls: 0.0522 | loss_box_reg: 0.1926 | loss_mask: 0.0421 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.0361 | Total Loss: 0.3254\n",
      "Epoch 2968 | loss_cls: 0.0230 | loss_box_reg: 0.0385 | loss_mask: 0.0511 | loss_rpn_cls: 0.0129 | loss_rpn_loc: 0.0065 | Total Loss: 0.1320\n",
      "Epoch 2969 | loss_cls: 0.0169 | loss_box_reg: 0.0457 | loss_mask: 0.0660 | loss_rpn_cls: 0.0016 | loss_rpn_loc: 0.0022 | Total Loss: 0.1324\n",
      "Epoch 2970 | loss_cls: 0.0613 | loss_box_reg: 0.3355 | loss_mask: 0.1029 | loss_rpn_cls: 0.0012 | loss_rpn_loc: 0.0183 | Total Loss: 0.5192\n",
      "Epoch 2971 | loss_cls: 0.0227 | loss_box_reg: 0.0584 | loss_mask: 0.0762 | loss_rpn_cls: 0.0043 | loss_rpn_loc: 0.0141 | Total Loss: 0.1757\n",
      "Epoch 2972 | loss_cls: 0.0899 | loss_box_reg: 0.1004 | loss_mask: 0.0461 | loss_rpn_cls: 0.0081 | loss_rpn_loc: 0.0235 | Total Loss: 0.2679\n",
      "Epoch 2973 | loss_cls: 0.0450 | loss_box_reg: 0.1172 | loss_mask: 0.0459 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.0812 | Total Loss: 0.2908\n",
      "Epoch 2974 | loss_cls: 0.0396 | loss_box_reg: 0.1223 | loss_mask: 0.0722 | loss_rpn_cls: 0.0067 | loss_rpn_loc: 0.0306 | Total Loss: 0.2714\n",
      "Epoch 2975 | loss_cls: 0.0714 | loss_box_reg: 0.1224 | loss_mask: 0.0818 | loss_rpn_cls: 0.0019 | loss_rpn_loc: 0.1119 | Total Loss: 0.3892\n",
      "Epoch 2976 | loss_cls: 0.0242 | loss_box_reg: 0.0700 | loss_mask: 0.0343 | loss_rpn_cls: 0.0014 | loss_rpn_loc: 0.0126 | Total Loss: 0.1425\n",
      "Epoch 2977 | loss_cls: 0.0187 | loss_box_reg: 0.0645 | loss_mask: 0.0603 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.1105 | Total Loss: 0.2566\n",
      "Epoch 2978 | loss_cls: 0.0328 | loss_box_reg: 0.1080 | loss_mask: 0.1174 | loss_rpn_cls: 0.0122 | loss_rpn_loc: 0.0175 | Total Loss: 0.2879\n",
      "Epoch 2979 | loss_cls: 0.0182 | loss_box_reg: 0.0982 | loss_mask: 0.0503 | loss_rpn_cls: 0.0009 | loss_rpn_loc: 0.0375 | Total Loss: 0.2051\n",
      "\u001b[32m[07/29 18:37:59 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 2979      time: 0.3374  last_time: 0.2896   lr: 0.00025  max_mem: 2292M\n",
      "Epoch 2980 | loss_cls: 0.0312 | loss_box_reg: 0.0781 | loss_mask: 0.0753 | loss_rpn_cls: 0.0017 | loss_rpn_loc: 0.0097 | Total Loss: 0.1960\n",
      "Epoch 2981 | loss_cls: 0.0332 | loss_box_reg: 0.0545 | loss_mask: 0.0587 | loss_rpn_cls: 0.0057 | loss_rpn_loc: 0.1063 | Total Loss: 0.2585\n",
      "Epoch 2982 | loss_cls: 0.0449 | loss_box_reg: 0.1342 | loss_mask: 0.0921 | loss_rpn_cls: 0.0017 | loss_rpn_loc: 0.0040 | Total Loss: 0.2768\n",
      "Epoch 2983 | loss_cls: 0.0280 | loss_box_reg: 0.1099 | loss_mask: 0.0405 | loss_rpn_cls: 0.0023 | loss_rpn_loc: 0.0219 | Total Loss: 0.2026\n",
      "Epoch 2984 | loss_cls: 0.0428 | loss_box_reg: 0.0593 | loss_mask: 0.0448 | loss_rpn_cls: 0.0042 | loss_rpn_loc: 0.0316 | Total Loss: 0.1827\n",
      "Epoch 2985 | loss_cls: 0.0520 | loss_box_reg: 0.0875 | loss_mask: 0.0557 | loss_rpn_cls: 0.0002 | loss_rpn_loc: 0.0144 | Total Loss: 0.2098\n",
      "Epoch 2986 | loss_cls: 0.1030 | loss_box_reg: 0.1116 | loss_mask: 0.0779 | loss_rpn_cls: 0.0003 | loss_rpn_loc: 0.0228 | Total Loss: 0.3156\n",
      "Epoch 2987 | loss_cls: 0.0243 | loss_box_reg: 0.0813 | loss_mask: 0.1641 | loss_rpn_cls: 0.0053 | loss_rpn_loc: 0.1301 | Total Loss: 0.4051\n",
      "Epoch 2988 | loss_cls: 0.0645 | loss_box_reg: 0.0622 | loss_mask: 0.0499 | loss_rpn_cls: 0.0025 | loss_rpn_loc: 0.1028 | Total Loss: 0.2818\n",
      "Epoch 2989 | loss_cls: 0.1407 | loss_box_reg: 0.2269 | loss_mask: 0.0643 | loss_rpn_cls: 0.0065 | loss_rpn_loc: 0.0355 | Total Loss: 0.4739\n",
      "Epoch 2990 | loss_cls: 0.0654 | loss_box_reg: 0.1291 | loss_mask: 0.0847 | loss_rpn_cls: 0.0001 | loss_rpn_loc: 0.0055 | Total Loss: 0.2849\n",
      "Epoch 2991 | loss_cls: 0.0263 | loss_box_reg: 0.0435 | loss_mask: 0.0892 | loss_rpn_cls: 0.0030 | loss_rpn_loc: 0.1040 | Total Loss: 0.2660\n",
      "Epoch 2992 | loss_cls: 0.0798 | loss_box_reg: 0.1292 | loss_mask: 0.0502 | loss_rpn_cls: 0.0022 | loss_rpn_loc: 0.1230 | Total Loss: 0.3845\n",
      "Epoch 2993 | loss_cls: 0.0566 | loss_box_reg: 0.1022 | loss_mask: 0.0325 | loss_rpn_cls: 0.0182 | loss_rpn_loc: 0.0284 | Total Loss: 0.2380\n",
      "Epoch 2994 | loss_cls: 0.0275 | loss_box_reg: 0.0995 | loss_mask: 0.0564 | loss_rpn_cls: 0.0048 | loss_rpn_loc: 0.0111 | Total Loss: 0.1993\n",
      "Epoch 2995 | loss_cls: 0.0859 | loss_box_reg: 0.1323 | loss_mask: 0.0856 | loss_rpn_cls: 0.0027 | loss_rpn_loc: 0.0711 | Total Loss: 0.3776\n",
      "Epoch 2996 | loss_cls: 0.0624 | loss_box_reg: 0.1208 | loss_mask: 0.0714 | loss_rpn_cls: 0.0093 | loss_rpn_loc: 0.0160 | Total Loss: 0.2799\n",
      "Epoch 2997 | loss_cls: 0.0488 | loss_box_reg: 0.1097 | loss_mask: 0.0366 | loss_rpn_cls: 0.0184 | loss_rpn_loc: 0.0601 | Total Loss: 0.2736\n",
      "Epoch 2998 | loss_cls: 0.0484 | loss_box_reg: 0.0795 | loss_mask: 0.0364 | loss_rpn_cls: 0.0142 | loss_rpn_loc: 0.0225 | Total Loss: 0.2012\n",
      "Epoch 2999 | loss_cls: 0.0337 | loss_box_reg: 0.1684 | loss_mask: 0.0666 | loss_rpn_cls: 0.0032 | loss_rpn_loc: 0.0417 | Total Loss: 0.3135\n",
      "\u001b[32m[07/29 18:38:06 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 2999      time: 0.3373  last_time: 0.4010   lr: 0.00025  max_mem: 2292M\n",
      "\u001b[32m[07/29 18:38:06 d2.engine.hooks]: \u001b[0mOverall training speed: 2998 iterations in 0:16:51 (0.3373 s / it)\n",
      "\u001b[32m[07/29 18:38:06 d2.engine.hooks]: \u001b[0mTotal training time: 0:16:52 (0:00:01 on hooks)\n",
      "\n",
      " Training completed!\n",
      " Best Model => Epoch: 2591, Total Loss: 0.1046\n",
      " Model saved at: C:\\Users\\ROG\\Documents\\Termatics\\segmentation\\detectron_maskrcnn\\training_dataset_generated\\training_sets\\model\\best_model.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.data import build_detection_train_loader\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.data import transforms as T\n",
    "from detectron2.data import DatasetMapper\n",
    "\n",
    "#mlflow tracking\n",
    "# import mlflow\n",
    "# mlflow.pytorch.autolog(log_models=True)\n",
    "# mlflow.set_tracking_uri('https://mlflow.krschap.tech')\n",
    "\n",
    "\n",
    "# Define working directory\n",
    "WORK_DIR = r\"C:\\Users\\ROG\\Documents\\Termatics\\segmentation\\detectron_maskrcnn\\training_dataset_generated\\training_sets\"\n",
    "OUTPUT_DIR = os.path.join(WORK_DIR, \"model\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Custom mapper with augmentation\n",
    "def custom_mapper(dataset_dict):\n",
    "    dataset_dict = dataset_dict.copy()\n",
    "    image = utils.read_image(dataset_dict[\"file_name\"], format=\"BGR\")\n",
    "    aug_input = T.AugInput(image)\n",
    "\n",
    "    augmentation_list = [\n",
    "        T.ResizeShortestEdge(short_edge_length=(512, 768, 1024), max_size=1333, sample_style='choice'),\n",
    "        T.RandomFlip(horizontal=True),\n",
    "        T.RandomBrightness(0.9, 1.1),\n",
    "        T.RandomContrast(0.9, 1.1)\n",
    "    ]\n",
    "    transforms = T.AugmentationList(augmentation_list)(aug_input)\n",
    "\n",
    "    image = aug_input.image\n",
    "    annos = [\n",
    "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
    "        for obj in dataset_dict.get(\"annotations\", []) if obj.get(\"iscrowd\", 0) == 0\n",
    "    ]\n",
    "    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n",
    "    dataset_dict[\"instances\"] = utils.annotations_to_instances(annos, image.shape[:2])\n",
    "    return dataset_dict\n",
    "\n",
    "# Custom trainer that logs and saves best model\n",
    "class TrainerWithBest(DefaultTrainer):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__(cfg)\n",
    "        self.best_total_loss = float(\"inf\")\n",
    "        self.best_epoch = -1\n",
    "        self.epoch_counter = 0\n",
    "        self.best_model_path = os.path.join(cfg.OUTPUT_DIR, \"best_model.pth\")\n",
    "\n",
    "    def run_step(self):\n",
    "        self.model.train()\n",
    "        data = next(self._trainer._data_loader_iter)\n",
    "        loss_dict = self.model(data)\n",
    "        total_loss = sum(loss_dict.values())\n",
    "    \n",
    "        self.optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        self.optimizer.step()\n",
    "    \n",
    "        loss_items = {k: v.item() for k, v in loss_dict.items()}\n",
    "        total_loss_val = total_loss.item()\n",
    "    \n",
    "        print(f\"Epoch {self.epoch_counter:04d} | \" +\n",
    "              \" | \".join([f\"{k}: {v:.4f}\" for k, v in loss_items.items()]) +\n",
    "              f\" | Total Loss: {total_loss_val:.4f}\")\n",
    "    \n",
    "        if total_loss_val < self.best_total_loss:\n",
    "            self.best_total_loss = total_loss_val\n",
    "            self.best_epoch = self.epoch_counter\n",
    "            torch.save(self.model.state_dict(), self.best_model_path)\n",
    "            print(f\" Best model saved at Epoch {self.epoch_counter} | Total Loss: {total_loss_val:.4f}\")\n",
    "    \n",
    "        self.epoch_counter += 1\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        print(\" Augmentations applied: ResizeShortestEdge(512,768,1024), RandomFlip, RandomBrightness(0.91.1), RandomContrast(0.91.1)\")\n",
    "        return build_detection_train_loader(cfg, mapper=custom_mapper)\n",
    "\n",
    "# Config setup\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"solar_train\",)\n",
    "cfg.DATASETS.TEST = ()  # Skip validation\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.MAX_ITER = 3000\n",
    "cfg.SOLVER.STEPS = []\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "cfg.INPUT.MIN_SIZE_TRAIN = (512, 768, 1024)\n",
    "cfg.INPUT.MAX_SIZE_TRAIN = 1333\n",
    "cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "cfg.OUTPUT_DIR = OUTPUT_DIR\n",
    "\n",
    "# Start training\n",
    "trainer = TrainerWithBest(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\n Training completed!\")\n",
    "print(f\" Best Model => Epoch: {trainer.best_epoch}, Total Loss: {trainer.best_total_loss:.4f}\")\n",
    "print(f\" Model saved at: {trainer.best_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ce005d-42cb-4b39-87d9-353fd667ad41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Detectron2)",
   "language": "python",
   "name": "detectron_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
